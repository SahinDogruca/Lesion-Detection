{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13746508,"sourceType":"datasetVersion","datasetId":8747102,"isSourceIdPinned":false},{"sourceId":686039,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":520365,"modelId":534659}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\ndataset = kagglehub.dataset_download(\"ahindoruca/data-v2-aug\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T09:39:50.260719Z","iopub.execute_input":"2025-12-15T09:39:50.260973Z","iopub.status.idle":"2025-12-15T09:39:52.798559Z","shell.execute_reply.started":"2025-12-15T09:39:50.260949Z","shell.execute_reply":"2025-12-15T09:39:52.797954Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!mkdir /kaggle/working/data\n!cp -r /kaggle/input/data-v2-aug/data_v2_aug/* /kaggle/working/data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T11:47:51.723555Z","iopub.execute_input":"2025-12-15T11:47:51.723852Z","iopub.status.idle":"2025-12-15T11:48:35.058254Z","shell.execute_reply.started":"2025-12-15T11:47:51.723831Z","shell.execute_reply":"2025-12-15T11:48:35.057267Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!cat /kaggle/working/data/data.yaml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T11:50:28.447869Z","iopub.execute_input":"2025-12-15T11:50:28.448441Z","iopub.status.idle":"2025-12-15T11:50:28.566002Z","shell.execute_reply.started":"2025-12-15T11:50:28.448406Z","shell.execute_reply":"2025-12-15T11:50:28.565262Z"}},"outputs":[{"name":"stdout","text":"names:\n- dentigeroz kist\n- keratokist\n- radikuler kist\n- ameloblastoma\n- odontoma\nnc: 5\npath: /Users/sahindogruca/Desktop/code/ytü/semester-7/computerProject2/data/data_v2_aug\ntest: test/images\ntrain: train/images\nval: valid/images\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"%%writefile /kaggle/working/data.yaml\npath: /kaggle/working/data\ntrain: train/images\nval: valid/images\ntest: test/images\n\nnames:\n- dentigeroz kist\n- keratokist\n- radikuler kist\n- ameloblastoma\n- odontoma\nnc: 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T11:50:34.457057Z","iopub.execute_input":"2025-12-15T11:50:34.457384Z","iopub.status.idle":"2025-12-15T11:50:34.463411Z","shell.execute_reply.started":"2025-12-15T11:50:34.457353Z","shell.execute_reply":"2025-12-15T11:50:34.462762Z"}},"outputs":[{"name":"stdout","text":"Writing /kaggle/working/data.yaml\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import json\nimport os\nimport yaml\nfrom pathlib import Path\nfrom PIL import Image\nfrom tqdm import tqdm\nimport cv2\nimport numpy as np\nimport shutil\n\n\ndef load_yaml(yaml_path):\n    \"\"\"Load YAML configuration file\"\"\"\n    with open(yaml_path, 'r') as f:\n        data = yaml.safe_load(f)\n    return data\n\n\ndef polygon_to_bbox(polygon):\n    \"\"\"\n    Convert polygon coordinates to bounding box [x, y, width, height]\n    polygon: list of [x1, y1, x2, y2, ..., xn, yn] (normalized 0-1)\n    \"\"\"\n    x_coords = polygon[0::2]\n    y_coords = polygon[1::2]\n    \n    x_min = min(x_coords)\n    y_min = min(y_coords)\n    x_max = max(x_coords)\n    y_max = max(y_coords)\n    \n    width = x_max - x_min\n    height = y_max - y_min\n    \n    return [x_min, y_min, width, height]\n\n\ndef calculate_area(polygon, img_width, img_height):\n    \"\"\"Calculate polygon area in pixel coordinates\"\"\"\n    # Convert normalized coordinates to pixel coordinates\n    points = []\n    for i in range(0, len(polygon), 2):\n        x = polygon[i] * img_width\n        y = polygon[i + 1] * img_height\n        points.append([x, y])\n    \n    points = np.array(points, dtype=np.int32)\n    area = cv2.contourArea(points)\n    return float(area)\n\n\ndef convert_yolo_to_coco(data_yaml_path, output_root):\n    \"\"\"\n    Convert YOLO polygon dataset to COCO format with standard directory structure\n    \n    Args:\n        data_yaml_path: Path to data.yaml file\n        output_root: Root directory for output (will create dataset/ structure)\n    \"\"\"\n    # Load configuration\n    config = load_yaml(data_yaml_path)\n    dataset_path = Path(config['path'])\n    class_names = config['names']\n    num_classes = config['nc']\n    \n    print(f\"Dataset path: {dataset_path}\")\n    print(f\"Number of classes: {num_classes}\")\n    print(f\"Classes: {class_names}\")\n    \n    # Create standard COCO directory structure\n    output_root = Path(output_root)\n    images_dir = output_root / \"images\"\n    annotations_dir = output_root / \"annotations\"\n    \n    os.makedirs(images_dir, exist_ok=True)\n    os.makedirs(annotations_dir, exist_ok=True)\n    \n    print(f\"\\nCreating COCO dataset at: {output_root}\")\n    print(f\"  images/\")\n    print(f\"  annotations/\")\n    \n    # Process each split (train, val, test)\n    splits = []\n    if 'train' in config:\n        splits.append(('train', config['train']))\n    if 'val' in config:\n        splits.append(('val', config['val']))\n    if 'test' in config:\n        splits.append(('test', config['test']))\n    \n    for split_name, split_path in splits:\n        print(f\"\\n{'='*60}\")\n        print(f\"Processing {split_name} split...\")\n        print('='*60)\n        \n        # Create split-specific image directory\n        split_images_dir = images_dir / split_name\n        os.makedirs(split_images_dir, exist_ok=True)\n        \n        # Initialize COCO format structure\n        coco_data = {\n            \"images\": [],\n            \"annotations\": [],\n            \"categories\": []\n        }\n        \n        # Add categories\n        for i, class_name in enumerate(class_names):\n            coco_data[\"categories\"].append({\n                \"id\": i,\n                \"name\": class_name,\n                \"supercategory\": \"object\"\n            })\n        \n        # Get image directory from original dataset\n        images_src = dataset_path / split_path\n        \n        # Determine labels directory\n        if 'train' in split_path:\n            labels_dir = dataset_path / 'train' / 'labels'\n        elif 'valid' in split_path or 'val' in split_path:\n            labels_dir = dataset_path / 'valid' / 'labels'\n        elif 'test' in split_path:\n            labels_dir = dataset_path / 'test' / 'labels'\n        else:\n            labels_dir = images_src.parent / 'labels'\n        \n        print(f\"Source images: {images_src}\")\n        print(f\"Source labels: {labels_dir}\")\n        print(f\"Destination images: {split_images_dir}\")\n        \n        if not images_src.exists():\n            print(f\"Warning: {images_src} does not exist, skipping...\")\n            continue\n        \n        # Get all image files\n        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n        image_files = []\n        for ext in image_extensions:\n            image_files.extend(list(images_src.glob(f'*{ext}')))\n            image_files.extend(list(images_src.glob(f'*{ext.upper()}')))\n        \n        print(f\"Found {len(image_files)} images\")\n        \n        annotation_id = 1\n        \n        # Process each image\n        for image_id, image_path in enumerate(tqdm(image_files, desc=f\"Converting {split_name}\")):\n            # Copy image to new location\n            dest_image_path = split_images_dir / image_path.name\n            if not dest_image_path.exists():\n                shutil.copy2(image_path, dest_image_path)\n            \n            # Load image to get dimensions\n            try:\n                img = Image.open(image_path)\n                img_width, img_height = img.size\n            except Exception as e:\n                print(f\"Error loading image {image_path}: {e}\")\n                continue\n            \n            # Add image info (use just filename, path will be images/split/)\n            coco_data[\"images\"].append({\n                \"id\": image_id,\n                \"file_name\": image_path.name,\n                \"width\": img_width,\n                \"height\": img_height\n            })\n            \n            # Get corresponding label file\n            label_path = labels_dir / f\"{image_path.stem}.txt\"\n            \n            if not label_path.exists():\n                # No annotations for this image\n                continue\n            \n            # Read label file\n            try:\n                with open(label_path, 'r') as f:\n                    lines = f.readlines()\n            except Exception as e:\n                print(f\"Error reading label {label_path}: {e}\")\n                continue\n            \n            # Process each annotation\n            for line in lines:\n                parts = line.strip().split()\n                if len(parts) < 7:  # At least class_id + 3 points (6 coordinates)\n                    continue\n                \n                class_id = int(parts[0])\n                \n                # Extract polygon coordinates (normalized)\n                polygon = [float(x) for x in parts[1:]]\n                \n                # Convert normalized coordinates to pixel coordinates for COCO\n                segmentation = []\n                for i in range(0, len(polygon), 2):\n                    x = polygon[i] * img_width\n                    y = polygon[i + 1] * img_height\n                    segmentation.append(x)\n                    segmentation.append(y)\n                \n                # Calculate bounding box from polygon (normalized)\n                bbox_norm = polygon_to_bbox(polygon)\n                \n                # Convert bbox to pixel coordinates [x, y, width, height]\n                bbox = [\n                    bbox_norm[0] * img_width,\n                    bbox_norm[1] * img_height,\n                    bbox_norm[2] * img_width,\n                    bbox_norm[3] * img_height\n                ]\n                \n                # Calculate area\n                area = calculate_area(polygon, img_width, img_height)\n                \n                # Add annotation\n                coco_data[\"annotations\"].append({\n                    \"id\": annotation_id,\n                    \"image_id\": image_id,\n                    \"category_id\": class_id,\n                    \"bbox\": bbox,\n                    \"area\": area,\n                    \"segmentation\": [segmentation],\n                    \"iscrowd\": 0\n                })\n                \n                annotation_id += 1\n        \n        # Save COCO JSON file with standard naming\n        output_file = annotations_dir / f\"instances_{split_name}.json\"\n        with open(output_file, 'w') as f:\n            json.dump(coco_data, f, indent=2)\n        \n        print(f\"\\nSaved annotations to {output_file}\")\n        print(f\"  Images: {len(coco_data['images'])}\")\n        print(f\"  Annotations: {len(coco_data['annotations'])}\")\n        print(f\"  Categories: {len(coco_data['categories'])}\")\n        print(f\"Copied images to {split_images_dir}\")\n  \n    return output_root\n\n\nif __name__ == \"__main__\":\n    # Paths\n    data_yaml_path = \"/kaggle/working/data.yaml\"\n    output_root = \"/kaggle/working/coco_dataset\" \n    \n\n    dataset_root = convert_yolo_to_coco(data_yaml_path, output_root)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T11:50:38.251759Z","iopub.execute_input":"2025-12-15T11:50:38.252456Z","iopub.status.idle":"2025-12-15T11:50:45.893612Z","shell.execute_reply.started":"2025-12-15T11:50:38.252431Z","shell.execute_reply":"2025-12-15T11:50:45.892902Z"}},"outputs":[{"name":"stdout","text":"Dataset path: /kaggle/working/data\nNumber of classes: 5\nClasses: ['dentigeroz kist', 'keratokist', 'radikuler kist', 'ameloblastoma', 'odontoma']\n\nCreating COCO dataset at: /kaggle/working/coco_dataset\n  images/\n  annotations/\n\n============================================================\nProcessing train split...\n============================================================\nSource images: /kaggle/working/data/train/images\nSource labels: /kaggle/working/data/train/labels\nDestination images: /kaggle/working/coco_dataset/images/train\nFound 1005 images\n","output_type":"stream"},{"name":"stderr","text":"Converting train: 100%|██████████| 1005/1005 [00:03<00:00, 257.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nSaved annotations to /kaggle/working/coco_dataset/annotations/instances_train.json\n  Images: 1005\n  Annotations: 1036\n  Categories: 5\nCopied images to /kaggle/working/coco_dataset/images/train\n\n============================================================\nProcessing val split...\n============================================================\nSource images: /kaggle/working/data/valid/images\nSource labels: /kaggle/working/data/valid/labels\nDestination images: /kaggle/working/coco_dataset/images/val\nFound 97 images\n","output_type":"stream"},{"name":"stderr","text":"Converting val: 100%|██████████| 97/97 [00:00<00:00, 103.35it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nSaved annotations to /kaggle/working/coco_dataset/annotations/instances_val.json\n  Images: 97\n  Annotations: 104\n  Categories: 5\nCopied images to /kaggle/working/coco_dataset/images/val\n\n============================================================\nProcessing test split...\n============================================================\nSource images: /kaggle/working/data/test/images\nSource labels: /kaggle/working/data/test/labels\nDestination images: /kaggle/working/coco_dataset/images/test\nFound 98 images\n","output_type":"stream"},{"name":"stderr","text":"Converting test: 100%|██████████| 98/98 [00:02<00:00, 45.25it/s] ","output_type":"stream"},{"name":"stdout","text":"\nSaved annotations to /kaggle/working/coco_dataset/annotations/instances_test.json\n  Images: 98\n  Annotations: 103\n  Categories: 5\nCopied images to /kaggle/working/coco_dataset/images/test\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\n!git clone https://github.com/RT-DETRs/RT-DETRv4.git\n%cd RT-DETRv4\n\n!pip install -q -r requirements.txt\n\n!pip install -q pyyaml opencv-python pillow tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T11:50:49.088263Z","iopub.execute_input":"2025-12-15T11:50:49.089056Z","iopub.status.idle":"2025-12-15T11:52:39.338046Z","shell.execute_reply.started":"2025-12-15T11:50:49.089030Z","shell.execute_reply":"2025-12-15T11:52:39.337271Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'RT-DETRv4'...\nremote: Enumerating objects: 178, done.\u001b[K\nremote: Counting objects: 100% (45/45), done.\u001b[K\nremote: Compressing objects: 100% (22/22), done.\u001b[K\nremote: Total 178 (delta 27), reused 23 (delta 23), pack-reused 133 (from 1)\u001b[K\nReceiving objects: 100% (178/178), 5.72 MiB | 28.71 MiB/s, done.\nResolving deltas: 100% (48/48), done.\n/kaggle/working/RT-DETRv4\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m579.2/579.2 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\n# Clone DINOv3\n!git clone https://github.com/facebookresearch/dinov3.git\n\n# Download DINOv3 weights\nimport os\nos.makedirs('pretrain', exist_ok=True)\n\n# Download ViT-B/16-LVD-1689M checkpoint\n!wget -P pretrain/ https://dl.fbaipublicfiles.com/dinov3/dinov3_vitb16_pretrain_lvd1689m.pth\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T09:45:34.338982Z","iopub.execute_input":"2025-12-15T09:45:34.339738Z","iopub.status.idle":"2025-12-15T09:45:35.751183Z","shell.execute_reply.started":"2025-12-15T09:45:34.339704Z","shell.execute_reply":"2025-12-15T09:45:35.750247Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'dinov3'...\nremote: Enumerating objects: 538, done.\u001b[K\nremote: Counting objects: 100% (363/363), done.\u001b[K\nremote: Compressing objects: 100% (264/264), done.\u001b[K\nremote: Total 538 (delta 201), reused 99 (delta 99), pack-reused 175 (from 1)\u001b[K\nReceiving objects: 100% (538/538), 9.88 MiB | 26.63 MiB/s, done.\nResolving deltas: 100% (223/223), done.\n--2025-12-15 09:45:35--  https://dl.fbaipublicfiles.com/dinov3/dinov3_vitb16_pretrain_lvd1689m.pth\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.51, 3.163.189.96, 3.163.189.14, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.51|:443... connected.\nHTTP request sent, awaiting response... 403 Forbidden\n2025-12-15 09:45:35 ERROR 403: Forbidden.\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# DINOv3 weights'i Hugging Face'den indir\n!pip install -q huggingface_hub\n\nfrom huggingface_hub import hf_hub_download\n\nos.makedirs('pretrain', exist_ok=True)\n\n# DINOv3 ViT-B/16 model\nhf_hub_download(\n    repo_id=\"facebook/dinov2-base\", \n    filename=\"pytorch_model.bin\",\n    local_dir=\"pretrain/\",\n    local_dir_use_symlinks=False\n)\n\n# Dosyayı yeniden adlandır\n!mv pretrain/pytorch_model.bin pretrain/dinov3_vitb16_pretrain_lvd1689m.pth\n\nprint(\"✓ DINOv3 weights downloaded from Hugging Face!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T09:45:38.745760Z","iopub.execute_input":"2025-12-15T09:45:38.746456Z","iopub.status.idle":"2025-12-15T09:45:44.353854Z","shell.execute_reply.started":"2025-12-15T09:45:38.746423Z","shell.execute_reply":"2025-12-15T09:45:44.353089Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\nFor more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02726fb701f740c2ac8c11dd815e0fff"}},"metadata":{}},{"name":"stdout","text":"✓ DINOv3 weights downloaded from Hugging Face!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"\nimport json\n\ncoco_dataset_path = '/kaggle/working/coco_dataset'\nassert os.path.exists(coco_dataset_path), \"Please run yolo_polygon_to_coco.py first!\"\n\n\ntrain_ann = f'{coco_dataset_path}/annotations/instances_train.json'\nval_ann = f'{coco_dataset_path}/annotations/instances_val.json'\n\nwith open(train_ann, 'r') as f:\n    train_data = json.load(f)\n\nwith open(val_ann, 'r') as f:\n    val_data = json.load(f)\n\nnum_classes = len(train_data['categories'])\nclass_names = [cat['name'] for cat in train_data['categories']]\n\nprint(f\"✓ Dataset found at: {coco_dataset_path}\")\nprint(f\"  Train images: {len(train_data['images'])}\")\nprint(f\"  Train annotations: {len(train_data['annotations'])}\")\nprint(f\"  Val images: {len(val_data['images'])}\")\nprint(f\"  Val annotations: {len(val_data['annotations'])}\")\nprint(f\"  Number of classes: {num_classes}\")\nprint(f\"  Classes: {class_names}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T11:52:48.599656Z","iopub.execute_input":"2025-12-15T11:52:48.599966Z","iopub.status.idle":"2025-12-15T11:52:48.629712Z","shell.execute_reply.started":"2025-12-15T11:52:48.599936Z","shell.execute_reply":"2025-12-15T11:52:48.628920Z"}},"outputs":[{"name":"stdout","text":"✓ Dataset found at: /kaggle/working/coco_dataset\n  Train images: 1005\n  Train annotations: 1036\n  Val images: 97\n  Val annotations: 104\n  Number of classes: 5\n  Classes: ['dentigeroz kist', 'keratokist', 'radikuler kist', 'ameloblastoma', 'odontoma']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\nimport yaml\n\n# Create custom dataset config\ncustom_dataset_config = {\n    'task': 'detection',\n    'evaluator': {\n        'type': 'CocoEvaluator',\n        'iou_types': ['bbox']\n    },\n    'num_classes': 5,\n    'remap_mscoco_category': False,  # IMPORTANT: For custom dataset\n    \n    'train_dataloader': {\n        'type': 'DataLoader',\n        'dataset': {\n            'type': 'CocoDetection',\n            'img_folder': f'{coco_dataset_path}/images/train',\n            'ann_file': f'{coco_dataset_path}/annotations/instances_train.json',\n            'return_masks': False,\n            'transforms': {\n                'type': 'Compose',\n                'ops': None\n            }\n        },\n        'shuffle': True,\n        'num_workers': 4,\n        'drop_last': True,\n        'collate_fn': {\n            'type': 'BatchImageCollateFunction'\n        }\n    },\n    \n    'val_dataloader': {\n        'type': 'DataLoader',\n        'dataset': {\n            'type': 'CocoDetection',\n            'img_folder': f'{coco_dataset_path}/images/val',\n            'ann_file': f'{coco_dataset_path}/annotations/instances_val.json',\n            'return_masks': False,\n            'transforms': {\n                'type': 'Compose',\n                'ops': None\n            }\n        },\n        'shuffle': False,\n        'num_workers': 4,\n        'drop_last': False,\n        'collate_fn': {\n            'type': 'BatchImageCollateFunction'\n        }\n    }\n}\n\n# Save config\nos.makedirs('configs/dataset', exist_ok=True)\nconfig_path = 'configs/dataset/dental_detection.yml'\nwith open(config_path, 'w') as f:\n    yaml.dump(custom_dataset_config, f, default_flow_style=False)\n\nprint(f\"✓ Custom dataset config saved: {config_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T11:52:54.694843Z","iopub.execute_input":"2025-12-15T11:52:54.695405Z","iopub.status.idle":"2025-12-15T11:52:54.704176Z","shell.execute_reply.started":"2025-12-15T11:52:54.695380Z","shell.execute_reply":"2025-12-15T11:52:54.703603Z"}},"outputs":[{"name":"stdout","text":"✓ Custom dataset config saved: configs/dataset/dental_detection.yml\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"%cd RT-DETRv4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T09:50:20.171591Z","iopub.execute_input":"2025-12-14T09:50:20.172504Z","iopub.status.idle":"2025-12-14T09:50:20.178255Z","shell.execute_reply.started":"2025-12-14T09:50:20.172468Z","shell.execute_reply":"2025-12-14T09:50:20.177630Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/RT-DETRv4\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"\nimport yaml\n\n# X model için config\nbase_config = 'configs/rtv4/rtv4_hgnetv2_x_coco.yml'  # s → x\ncustom_config = 'configs/rtv4/rtv4_hgnetv2_x_dental.yml'  # s → x\n\n# Read base config\nwith open(base_config, 'r') as f:\n    config = yaml.safe_load(f)\n\n# Modify for custom dataset\nconfig['includes'] = [\n    'configs/base/dataloader.yml',\n    'configs/base/optimizer.yml',\n    'configs/base/rtv4_base.yml',\n    'configs/dataset/dental_detection.yml',\n]\n\n# Teacher model yok ise kaldır (403 hatası varsa)\nif 'teacher_model' in config:\n    config['teacher_model'] = None  # veya teacher olmadan eğit\n\n# Epochs\nif 'epochs' in config:\n    config['epochs'] = 100\n\n# Save\nwith open(custom_config, 'w') as f:\n    yaml.dump(config, f, default_flow_style=False)\n\nprint(f\"✓ Config saved: {custom_config}\")\nprint(f\"  Model: RT-DETRv4-X\")\nprint(f\"  Epochs: {config.get('epochs', 'default')}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T11:53:00.478953Z","iopub.execute_input":"2025-12-15T11:53:00.479674Z","iopub.status.idle":"2025-12-15T11:53:00.491714Z","shell.execute_reply.started":"2025-12-15T11:53:00.479648Z","shell.execute_reply":"2025-12-15T11:53:00.490939Z"}},"outputs":[{"name":"stdout","text":"✓ Config saved: configs/rtv4/rtv4_hgnetv2_x_dental.yml\n  Model: RT-DETRv4-X\n  Epochs: default\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"pip install tensorboard==2.15.2\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip uninstall -y numpy\n!pip install numpy==1.26.4\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T11:53:04.560790Z","iopub.execute_input":"2025-12-15T11:53:04.561564Z","iopub.status.idle":"2025-12-15T11:53:11.727743Z","shell.execute_reply.started":"2025-12-15T11:53:04.561541Z","shell.execute_reply":"2025-12-15T11:53:11.726960Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: numpy 2.2.6\nUninstalling numpy-2.2.6:\n  Successfully uninstalled numpy-2.2.6\nCollecting numpy==1.26.4\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.4\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!ls /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:12:34.782016Z","iopub.execute_input":"2025-12-15T12:12:34.782607Z","iopub.status.idle":"2025-12-15T12:12:34.913945Z","shell.execute_reply.started":"2025-12-15T12:12:34.782575Z","shell.execute_reply":"2025-12-15T12:12:34.913190Z"}},"outputs":[{"name":"stdout","text":"best.pt  coco_dataset  data  data.yaml\tRT-DETRv4\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!rm -rf /kaggle/working/data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T12:13:03.358251Z","iopub.execute_input":"2025-12-15T12:13:03.358921Z","iopub.status.idle":"2025-12-15T12:13:03.682365Z","shell.execute_reply.started":"2025-12-15T12:13:03.358889Z","shell.execute_reply":"2025-12-15T12:13:03.681561Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import yaml\n\n# RT-DETRv4-X - batch=4, imgsz=896, diğer her şey orijinal\ncustom_config = {\n    '__include__': [\n        \n        '../dfine/dfine_hgnetv2_x_coco.yml',  # X model\n        '../base/rtv4.yml'\n    ],\n\n    'output_dir': './outputs/rtv4_datav2_pretrain',\n\n    # -------------------------------------------------\n    # Dataset\n    # -------------------------------------------------\n    'num_classes': 5,\n    'remap_mscoco_category': False,\n\n    # -------------------------------------------------\n    # Train dataloader\n    # -------------------------------------------------\n    'train_dataloader': {\n        'total_batch_size': 4,\n        'num_workers': 2,\n        'dataset': {\n            'img_folder': '/kaggle/working/coco_dataset/images/train',\n            'ann_file': '/kaggle/working/coco_dataset/annotations/instances_train.json',\n            'transforms': {\n                'ops': [\n                    {'type': 'RandomPhotometricDistort', 'p': 0.3},  # Hafif\n                    {'type': 'Resize', 'size': [896, 896]}, \n                    {'type': 'SanitizeBoundingBoxes', 'min_size': 1},\n                    {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True},\n                    {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}\n                ],\n                'policy': {\n                    'name': 'stop_epoch',\n                    'epoch': [4, 25, 38],  # Kısa mosaic schedule\n                    'ops': ['Mosaic']\n                },\n                'mosaic_prob': 0.0  # Hafif mosaic\n            },\n        },\n        'collate_fn': {\n            'base_size': 896,\n            'base_size_repeat': 0,\n            'stop_epoch': 38,\n            'mixup_prob': 0.0,  # Hafif mixup\n            'mixup_epochs': [4, 25]\n        }\n    },\n\n    # -------------------------------------------------\n    # Validation dataloader\n    # -------------------------------------------------\n    'val_dataloader': {\n        'total_batch_size': 4,\n        'num_workers': 2,\n        'dataset': {\n            'img_folder': '/kaggle/working/coco_dataset/images/val',\n            'ann_file': '/kaggle/working/coco_dataset/annotations/instances_val.json',\n            'transforms': {\n                'ops': [\n                    {'type': 'Resize', 'size': [896, 896]},\n                    {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}\n                ]\n            }\n        }\n    },\n\n    # -------------------------------------------------\n    # Teacher distillation kapalı (memory + stabilite)\n    # -------------------------------------------------\n    'HybridEncoder': {\n        'distill_teacher_dim': 0\n    },\n\n    'RTv4Criterion': {\n        'weight_dict': {\n            'loss_distill': 0\n        },\n        'losses': ['mal', 'boxes', 'local']\n    },\n\n    # -------------------------------------------------\n    # Optimizer (batch=4 için uygun)\n    # -------------------------------------------------\n    'optimizer': {\n        'lr': 3e-5,\n        'weight_decay': 0.0001,\n    },\n\n\n    # -------------------------------------------------\n    # Training\n    # -------------------------------------------------\n    'epoches': 60,\n    'eval_spatial_size': [896, 896],\n    'save_checkpoint_interval': 20,\n\n    'pretrained': 'outputs/rtv4_datav2_pretrain/best_stg1.pth',\n    'resume': False,\n}\n\n# -------------------------------------------------\n# Config dosyasını yaz\n# -------------------------------------------------\nconfig_path = 'configs/rtv4/rtv4_hgnetv2_x_dental_896.yml'\nwith open(config_path, 'w') as f:\n    yaml.dump(custom_config, f, default_flow_style=False, sort_keys=False)\n\nprint(\"✓ RT-DETRv4-X Config hazır\")\nprint(\"  Model: X (largest)\")\nprint(\"  Batch: 4\")\nprint(\"  Image: 896x896\")\nprint(\"  Augmentation: Orijinal\")\nprint(\"  Epochs: 100\")\n\n# -------------------------------------------------\n# GPU temizle\n# -------------------------------------------------\nimport gc, torch\ngc.collect()\ntorch.cuda.empty_cache()\n\n# -------------------------------------------------\n# Eğit\n# -------------------------------------------------\n!torchrun --nproc_per_node=1 train.py \\\n    -c configs/rtv4/rtv4_hgnetv2_x_dental_896.yml \\\n    --use-amp \\\n    --seed=0 \\\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T13:54:08.851909Z","iopub.execute_input":"2025-12-15T13:54:08.852385Z","execution_failed":"2025-12-15T18:26:36.110Z"}},"outputs":[{"name":"stdout","text":"✓ RT-DETRv4-X Config hazır\n  Model: X (largest)\n  Batch: 4\n  Image: 896x896\n  Augmentation: Orijinal\n  Epochs: 100\n2025-12-15 13:54:13.395582: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765806853.416740     702 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765806853.423629     702 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n    from tensorboard.compat import notf  # noqa: F401\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n\nDuring handling of the above exception, another exception occurred:\n\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n    from tensorboard.compat import notf  # noqa: F401\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n\nDuring handling of the above exception, another exception occurred:\n\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n    from tensorboard.compat import notf  # noqa: F401\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n\nDuring handling of the above exception, another exception occurred:\n\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n    from tensorboard.compat import notf  # noqa: F401\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n\nDuring handling of the above exception, another exception occurred:\n\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n    from tensorboard.compat import notf  # noqa: F401\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n\nDuring handling of the above exception, another exception occurred:\n\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n[rank0]:[W1215 13:54:23.654248334 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\nInitialized distributed mode...\ncfg:  {'task': 'detection', '_model': None, '_postprocessor': None, '_criterion': None, '_optimizer': None, '_lr_scheduler': None, '_lr_warmup_scheduler': None, '_train_dataloader': None, '_val_dataloader': None, '_ema': None, '_scaler': None, '_train_dataset': None, '_val_dataset': None, '_collate_fn': None, '_evaluator': None, '_writer': None, 'num_workers': 0, 'batch_size': None, '_train_batch_size': None, '_val_batch_size': None, '_train_shuffle': None, '_val_shuffle': None, 'resume': False, 'tuning': None, 'epoches': 60, 'last_epoch': -1, 'lrsheduler': 'flatcosine', 'lr_gamma': 0.5, 'no_aug_epoch': 8, 'warmup_iter': 2000, 'flat_epoch': 29, 'use_amp': True, 'use_ema': True, 'ema_decay': 0.9999, 'ema_warmups': 2000, 'sync_bn': True, 'clip_max_norm': 0.1, 'find_unused_parameters': False, 'seed': 0, 'print_freq': 100, 'checkpoint_freq': 4, 'output_dir': './outputs/rtv4_datav2_pretrain', 'summary_dir': None, 'device': '', '_teacher_model': None, 'yaml_cfg': {'task': 'detection', 'evaluator': {'type': 'CocoEvaluator', 'iou_types': ['bbox']}, 'num_classes': 5, 'remap_mscoco_category': False, 'train_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/kaggle/working/coco_dataset/images/train', 'ann_file': '/kaggle/working/coco_dataset/annotations/instances_train.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'RandomPhotometricDistort', 'p': 0.3}, {'type': 'Resize', 'size': [896, 896]}, {'type': 'SanitizeBoundingBoxes', 'min_size': 1}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}, {'type': 'ConvertBoxes', 'fmt': 'cxcywh', 'normalize': True}], 'policy': {'name': 'stop_epoch', 'epoch': [4, 25, 38], 'ops': ['Mosaic']}, 'mosaic_prob': 0.0}}, 'shuffle': True, 'num_workers': 2, 'drop_last': True, 'collate_fn': {'type': 'BatchImageCollateFunction', 'base_size': 896, 'base_size_repeat': 0, 'stop_epoch': 38, 'ema_restart_decay': 0.9998, 'mixup_prob': 0.0, 'mixup_epochs': [4, 25]}, 'total_batch_size': 4}, 'val_dataloader': {'type': 'DataLoader', 'dataset': {'type': 'CocoDetection', 'img_folder': '/kaggle/working/coco_dataset/images/val', 'ann_file': '/kaggle/working/coco_dataset/annotations/instances_val.json', 'return_masks': False, 'transforms': {'type': 'Compose', 'ops': [{'type': 'Resize', 'size': [896, 896]}, {'type': 'ConvertPILImage', 'dtype': 'float32', 'scale': True}]}}, 'shuffle': False, 'num_workers': 2, 'drop_last': False, 'collate_fn': {'type': 'BatchImageCollateFunction'}, 'total_batch_size': 4}, 'print_freq': 100, 'output_dir': './outputs/rtv4_datav2_pretrain', 'checkpoint_freq': 4, 'sync_bn': True, 'find_unused_parameters': False, 'use_amp': True, 'scaler': {'type': 'GradScaler', 'enabled': True}, 'use_ema': True, 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 1000, 'start': 0}, 'epoches': 60, 'clip_max_norm': 0.1, 'optimizer': {'type': 'AdamW', 'params': [{'params': '^(?=.*backbone)(?!.*norm|bn).*$', 'lr': 2.5e-06}, {'params': '^(?=.*(?:encoder|decoder))(?=.*(?:norm|bn)).*$', 'weight_decay': 0.0}], 'lr': 3e-05, 'betas': [0.9, 0.999], 'weight_decay': 0.0001}, 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [500], 'gamma': 0.1}, 'lr_warmup_scheduler': {'type': 'LinearWarmup', 'warmup_duration': 500}, 'model': 'RTv4', 'criterion': 'RTv4Criterion', 'postprocessor': 'PostProcessor', 'use_focal_loss': True, 'eval_spatial_size': [896, 896], 'RTv4': {'backbone': 'HGNetv2', 'encoder': 'HybridEncoder', 'decoder': 'DFINETransformer'}, 'lrsheduler': 'flatcosine', 'lr_gamma': 0.5, 'warmup_iter': 2000, 'flat_epoch': 29, 'no_aug_epoch': 8, 'HGNetv2': {'pretrained': True, 'local_model_dir': './pretrain/hgnetv2/', 'name': 'B5', 'return_idx': [1, 2, 3], 'freeze_stem_only': True, 'freeze_at': -1, 'freeze_norm': False}, 'HybridEncoder': {'in_channels': [512, 1024, 2048], 'feat_strides': [8, 16, 32], 'hidden_dim': 384, 'use_encoder_idx': [2], 'num_encoder_layers': 1, 'nhead': 8, 'dim_feedforward': 2048, 'dropout': 0.0, 'enc_act': 'gelu', 'expansion': 1.0, 'depth_mult': 1, 'act': 'silu', 'distill_teacher_dim': 0}, 'DFINETransformer': {'feat_channels': [384, 384, 384], 'feat_strides': [8, 16, 32], 'hidden_dim': 256, 'num_levels': 3, 'num_layers': 6, 'eval_idx': -1, 'num_queries': 300, 'num_denoising': 100, 'label_noise_ratio': 0.5, 'box_noise_scale': 1.0, 'reg_max': 32, 'reg_scale': 8, 'layer_scale': 1, 'num_points': [3, 6, 3], 'cross_attn_method': 'default', 'query_select_method': 'default', 'activation': 'silu', 'mlp_act': 'silu'}, 'PostProcessor': {'num_top_queries': 300}, 'RTv4Criterion': {'weight_dict': {'loss_vfl': 1, 'loss_bbox': 5, 'loss_giou': 2, 'loss_fgl': 0.15, 'loss_ddf': 1.5, 'loss_mal': 1, 'loss_distill': 0}, 'losses': ['mal', 'boxes', 'local'], 'alpha': 0.75, 'gamma': 1.5, 'reg_max': 32, 'matcher': {'type': 'HungarianMatcher', 'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2}, 'alpha': 0.25, 'gamma': 2.0}}, '__include__': ['../dfine/dfine_hgnetv2_x_coco.yml', '../base/rtv4.yml'], 'save_checkpoint_interval': 20, 'pretrained': 'outputs/rtv4_datav2_pretrain/best_stg1.pth', 'resume': False, 'config': 'configs/rtv4/rtv4_hgnetv2_x_dental_896.yml', 'seed': 0, 'test_only': False, 'print_method': 'builtin', 'print_rank': 0}}\nLoaded stage1 B5 HGNetV2 from local file.\n/kaggle/working/RT-DETRv4/engine/core/workspace.py:180: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  return module(**module_kwargs)\nInitial lr: [2.5e-06, 3e-05, 3e-05]\nbuilding train_dataloader with batch_size=4...\n     ### Transform @RandomPhotometricDistort ###    \n     ### Transform @Resize ###    \n     ### Transform @SanitizeBoundingBoxes ###    \n     ### Transform @ConvertPILImage ###    \n     ### Transform @ConvertBoxes ###    \n     ### ImgTransforms Epochs: [4, 25, 38] ### \n     ### Policy_ops@['Mosaic'] ###\n     ### Multi-scale Training until 38 epochs ### \n     ### Multi-scales@ [672, 704, 736, 768, 800, 832, 864, 1120, 1088, 1056, 1024, 992, 960, 928] ###        \nbuilding val_dataloader with batch_size=4...\n     ### Transform @Resize ###    \n     ### Transform @ConvertPILImage ###    \n\n------------------------------------- Calculate Flops Results -------------------------------------\nNotations:\nnumber of parameters (Params), number of multiply-accumulate operations(MACs),\nnumber of floating-point operations (FLOPs), floating-point operations per second (FLOPS),\nfwd FLOPs (model forward propagation FLOPs), bwd FLOPs (model backward propagation FLOPs),\ndefault model backpropagation takes 2.00 times as much computation as forward propagation.\n\nTotal Training Params:                                                  61.64 M \nfwd MACs:                                                               195.381 GMACs\nfwd FLOPs:                                                              391.487 GFLOPS\nfwd+bwd MACs:                                                           586.144 GMACs\nfwd+bwd FLOPs:                                                          1.1745 TFLOPS\n---------------------------------------------------------------------------------------------------\n{'Model FLOPs:391.487 GFLOPS   MACs:195.381 GMACs   Params:61637805'}\n------------------------------------------Start training-------------------------------------------\n     ## Using Self-defined Scheduler-flatcosine ## \n[2.5e-06, 3e-05, 3e-05] [1.25e-06, 1.5e-05, 1.5e-05] 15060 2000 7279 2008\nnumber of trainable parameters: 62561353\nEpoch: [0]  [  0/251]  eta: 0:12:00  lr: 0.000000  loss: 61.8836 (61.8836)  loss_mal: 0.5786 (0.5786)  loss_bbox: 1.3200 (1.3200)  loss_giou: 1.7066 (1.7066)  loss_fgl: 0.4014 (0.4014)  loss_mal_aux_0: 0.5068 (0.5068)  loss_bbox_aux_0: 1.3200 (1.3200)  loss_giou_aux_0: 1.7066 (1.7066)  loss_fgl_aux_0: 0.4014 (0.4014)  loss_mal_aux_1: 0.4258 (0.4258)  loss_bbox_aux_1: 1.3200 (1.3200)  loss_giou_aux_1: 1.7066 (1.7066)  loss_fgl_aux_1: 0.4014 (0.4014)  loss_mal_aux_2: 0.5513 (0.5513)  loss_bbox_aux_2: 1.3200 (1.3200)  loss_giou_aux_2: 1.7066 (1.7066)  loss_fgl_aux_2: 0.4014 (0.4014)  loss_mal_aux_3: 0.6978 (0.6978)  loss_bbox_aux_3: 1.3200 (1.3200)  loss_giou_aux_3: 1.7066 (1.7066)  loss_fgl_aux_3: 0.4014 (0.4014)  loss_mal_aux_4: 0.6523 (0.6523)  loss_bbox_aux_4: 1.3200 (1.3200)  loss_giou_aux_4: 1.7066 (1.7066)  loss_fgl_aux_4: 0.4014 (0.4014)  loss_mal_pre: 0.5068 (0.5068)  loss_bbox_pre: 1.3200 (1.3200)  loss_giou_pre: 1.7066 (1.7066)  loss_mal_enc_0: 0.6802 (0.6802)  loss_bbox_enc_0: 1.3200 (1.3200)  loss_giou_enc_0: 1.7066 (1.7066)  loss_mal_dn_0: 1.1934 (1.1934)  loss_bbox_dn_0: 1.1310 (1.1310)  loss_giou_dn_0: 1.3847 (1.3847)  loss_fgl_dn_0: 0.8151 (0.8151)  loss_mal_dn_1: 1.1992 (1.1992)  loss_bbox_dn_1: 1.1310 (1.1310)  loss_giou_dn_1: 1.3847 (1.3847)  loss_fgl_dn_1: 0.8151 (0.8151)  loss_mal_dn_2: 1.1494 (1.1494)  loss_bbox_dn_2: 1.1310 (1.1310)  loss_giou_dn_2: 1.3847 (1.3847)  loss_fgl_dn_2: 0.8151 (0.8151)  loss_mal_dn_3: 1.0928 (1.0928)  loss_bbox_dn_3: 1.1310 (1.1310)  loss_giou_dn_3: 1.3847 (1.3847)  loss_fgl_dn_3: 0.8151 (0.8151)  loss_mal_dn_4: 1.1846 (1.1846)  loss_bbox_dn_4: 1.1310 (1.1310)  loss_giou_dn_4: 1.3847 (1.3847)  loss_fgl_dn_4: 0.8151 (0.8151)  loss_mal_dn_5: 1.1504 (1.1504)  loss_bbox_dn_5: 1.1310 (1.1310)  loss_giou_dn_5: 1.3847 (1.3847)  loss_fgl_dn_5: 0.8151 (0.8151)  loss_mal_dn_pre: 1.1934 (1.1934)  loss_bbox_dn_pre: 1.1310 (1.1310)  loss_giou_dn_pre: 1.3847 (1.3847)  time: 2.8720  data: 0.9795  max mem: 10492\nEpoch: [0]  [100/251]  eta: 0:03:09  lr: 0.000000  loss: 59.5299 (60.2297)  loss_mal: 0.7324 (0.7686)  loss_bbox: 0.9892 (1.1667)  loss_giou: 1.7152 (1.7163)  loss_fgl: 0.4651 (0.4858)  loss_mal_aux_0: 0.6924 (0.7636)  loss_bbox_aux_0: 0.9892 (1.1667)  loss_giou_aux_0: 1.7152 (1.7163)  loss_fgl_aux_0: 0.4651 (0.4858)  loss_mal_aux_1: 0.7085 (0.7562)  loss_bbox_aux_1: 0.9892 (1.1667)  loss_giou_aux_1: 1.7152 (1.7163)  loss_fgl_aux_1: 0.4651 (0.4858)  loss_mal_aux_2: 0.7236 (0.7854)  loss_bbox_aux_2: 0.9892 (1.1667)  loss_giou_aux_2: 1.7152 (1.7163)  loss_fgl_aux_2: 0.4651 (0.4858)  loss_mal_aux_3: 0.6680 (0.7822)  loss_bbox_aux_3: 0.9892 (1.1667)  loss_giou_aux_3: 1.7152 (1.7163)  loss_fgl_aux_3: 0.4651 (0.4858)  loss_mal_aux_4: 0.7261 (0.8024)  loss_bbox_aux_4: 0.9892 (1.1667)  loss_giou_aux_4: 1.7152 (1.7163)  loss_fgl_aux_4: 0.4651 (0.4858)  loss_mal_pre: 0.6924 (0.7636)  loss_bbox_pre: 0.9892 (1.1667)  loss_giou_pre: 1.7152 (1.7163)  loss_mal_enc_0: 0.7612 (0.7807)  loss_bbox_enc_0: 0.9892 (1.1667)  loss_giou_enc_0: 1.7152 (1.7163)  loss_mal_dn_0: 1.0918 (1.1033)  loss_bbox_dn_0: 0.7533 (0.7869)  loss_giou_dn_0: 1.3730 (1.3800)  loss_fgl_dn_0: 0.8163 (0.8133)  loss_mal_dn_1: 1.1396 (1.1490)  loss_bbox_dn_1: 0.7533 (0.7869)  loss_giou_dn_1: 1.3730 (1.3800)  loss_fgl_dn_1: 0.8163 (0.8133)  loss_mal_dn_2: 1.1426 (1.1400)  loss_bbox_dn_2: 0.7533 (0.7869)  loss_giou_dn_2: 1.3730 (1.3800)  loss_fgl_dn_2: 0.8163 (0.8133)  loss_mal_dn_3: 1.1875 (1.1728)  loss_bbox_dn_3: 0.7533 (0.7869)  loss_giou_dn_3: 1.3730 (1.3800)  loss_fgl_dn_3: 0.8163 (0.8133)  loss_mal_dn_4: 1.1709 (1.1681)  loss_bbox_dn_4: 0.7533 (0.7869)  loss_giou_dn_4: 1.3730 (1.3800)  loss_fgl_dn_4: 0.8163 (0.8133)  loss_mal_dn_5: 1.1611 (1.1636)  loss_bbox_dn_5: 0.7533 (0.7869)  loss_giou_dn_5: 1.3730 (1.3800)  loss_fgl_dn_5: 0.8163 (0.8133)  loss_mal_dn_pre: 1.0918 (1.1033)  loss_bbox_dn_pre: 0.7533 (0.7869)  loss_giou_dn_pre: 1.3730 (1.3800)  loss_ddf_aux_0: 0.0000 (0.0000)  loss_ddf_aux_1: 0.0000 (0.0000)  loss_ddf_aux_2: 0.0000 (0.0000)  loss_ddf_aux_3: 0.0000 (0.0000)  loss_ddf_aux_4: 0.0000 (0.0000)  loss_ddf_dn_0: 0.0000 (0.0000)  loss_ddf_dn_1: 0.0000 (0.0000)  loss_ddf_dn_2: 0.0000 (0.0000)  loss_ddf_dn_3: 0.0000 (0.0000)  loss_ddf_dn_4: 0.0000 (0.0000)  time: 1.2574  data: 0.0113  max mem: 13413\nEpoch: [0]  [200/251]  eta: 0:01:02  lr: 0.000000  loss: 58.7884 (60.3562)  loss_mal: 0.7402 (0.7745)  loss_bbox: 0.9750 (1.1729)  loss_giou: 1.6688 (1.7088)  loss_fgl: 0.4708 (0.4855)  loss_mal_aux_0: 0.7192 (0.7739)  loss_bbox_aux_0: 0.9751 (1.1730)  loss_giou_aux_0: 1.6689 (1.7088)  loss_fgl_aux_0: 0.4707 (0.4855)  loss_mal_aux_1: 0.7759 (0.7698)  loss_bbox_aux_1: 0.9751 (1.1730)  loss_giou_aux_1: 1.6689 (1.7088)  loss_fgl_aux_1: 0.4707 (0.4855)  loss_mal_aux_2: 0.7510 (0.7940)  loss_bbox_aux_2: 0.9750 (1.1730)  loss_giou_aux_2: 1.6688 (1.7088)  loss_fgl_aux_2: 0.4707 (0.4855)  loss_mal_aux_3: 0.7363 (0.7948)  loss_bbox_aux_3: 0.9750 (1.1730)  loss_giou_aux_3: 1.6688 (1.7088)  loss_fgl_aux_3: 0.4708 (0.4855)  loss_mal_aux_4: 0.8296 (0.8057)  loss_bbox_aux_4: 0.9750 (1.1730)  loss_giou_aux_4: 1.6688 (1.7088)  loss_fgl_aux_4: 0.4708 (0.4855)  loss_mal_pre: 0.7192 (0.7739)  loss_bbox_pre: 0.9751 (1.1730)  loss_giou_pre: 1.6689 (1.7088)  loss_mal_enc_0: 0.7427 (0.8031)  loss_bbox_enc_0: 0.9752 (1.1730)  loss_giou_enc_0: 1.6689 (1.7088)  loss_mal_dn_0: 1.0830 (1.1022)  loss_bbox_dn_0: 0.6949 (0.7949)  loss_giou_dn_0: 1.3807 (1.3815)  loss_fgl_dn_0: 0.8111 (0.8117)  loss_mal_dn_1: 1.1133 (1.1510)  loss_bbox_dn_1: 0.6949 (0.7949)  loss_giou_dn_1: 1.3807 (1.3815)  loss_fgl_dn_1: 0.8111 (0.8117)  loss_mal_dn_2: 1.1279 (1.1383)  loss_bbox_dn_2: 0.6949 (0.7949)  loss_giou_dn_2: 1.3807 (1.3815)  loss_fgl_dn_2: 0.8111 (0.8117)  loss_mal_dn_3: 1.1387 (1.1715)  loss_bbox_dn_3: 0.6949 (0.7949)  loss_giou_dn_3: 1.3807 (1.3815)  loss_fgl_dn_3: 0.8111 (0.8117)  loss_mal_dn_4: 1.1729 (1.1673)  loss_bbox_dn_4: 0.6949 (0.7949)  loss_giou_dn_4: 1.3807 (1.3815)  loss_fgl_dn_4: 0.8111 (0.8117)  loss_mal_dn_5: 1.1357 (1.1617)  loss_bbox_dn_5: 0.6949 (0.7949)  loss_giou_dn_5: 1.3807 (1.3815)  loss_fgl_dn_5: 0.8112 (0.8117)  loss_mal_dn_pre: 1.0830 (1.1022)  loss_bbox_dn_pre: 0.6949 (0.7949)  loss_giou_dn_pre: 1.3807 (1.3815)  loss_ddf_aux_0: 0.0000 (0.0000)  loss_ddf_aux_1: 0.0000 (0.0000)  loss_ddf_aux_2: 0.0000 (0.0000)  loss_ddf_aux_3: 0.0000 (0.0000)  loss_ddf_aux_4: 0.0000 (0.0000)  loss_ddf_dn_0: 0.0000 (0.0000)  loss_ddf_dn_1: 0.0000 (0.0000)  loss_ddf_dn_2: 0.0000 (0.0000)  loss_ddf_dn_3: 0.0000 (0.0000)  loss_ddf_dn_4: 0.0000 (0.0000)  time: 1.1516  data: 0.0105  max mem: 13413\nEpoch: [0]  [250/251]  eta: 0:00:01  lr: 0.000000  loss: 62.5815 (60.6416)  loss_mal: 0.7012 (0.7703)  loss_bbox: 1.3188 (1.1972)  loss_giou: 1.7657 (1.7107)  loss_fgl: 0.4121 (0.4841)  loss_mal_aux_0: 0.6069 (0.7655)  loss_bbox_aux_0: 1.3193 (1.1973)  loss_giou_aux_0: 1.7661 (1.7108)  loss_fgl_aux_0: 0.4119 (0.4841)  loss_mal_aux_1: 0.6929 (0.7695)  loss_bbox_aux_1: 1.3192 (1.1973)  loss_giou_aux_1: 1.7661 (1.7108)  loss_fgl_aux_1: 0.4119 (0.4841)  loss_mal_aux_2: 0.6699 (0.7903)  loss_bbox_aux_2: 1.3191 (1.1973)  loss_giou_aux_2: 1.7660 (1.7108)  loss_fgl_aux_2: 0.4120 (0.4841)  loss_mal_aux_3: 0.6670 (0.7875)  loss_bbox_aux_3: 1.3190 (1.1973)  loss_giou_aux_3: 1.7659 (1.7108)  loss_fgl_aux_3: 0.4119 (0.4841)  loss_mal_aux_4: 0.7100 (0.8018)  loss_bbox_aux_4: 1.3189 (1.1972)  loss_giou_aux_4: 1.7658 (1.7107)  loss_fgl_aux_4: 0.4120 (0.4841)  loss_mal_pre: 0.6069 (0.7655)  loss_bbox_pre: 1.3193 (1.1973)  loss_giou_pre: 1.7661 (1.7108)  loss_mal_enc_0: 0.7246 (0.7963)  loss_bbox_enc_0: 1.3194 (1.1973)  loss_giou_enc_0: 1.7662 (1.7109)  loss_mal_dn_0: 1.1270 (1.1055)  loss_bbox_dn_0: 0.8891 (0.8122)  loss_giou_dn_0: 1.3698 (1.3806)  loss_fgl_dn_0: 0.8168 (0.8124)  loss_mal_dn_1: 1.1631 (1.1532)  loss_bbox_dn_1: 0.8891 (0.8122)  loss_giou_dn_1: 1.3698 (1.3806)  loss_fgl_dn_1: 0.8168 (0.8124)  loss_mal_dn_2: 1.1289 (1.1387)  loss_bbox_dn_2: 0.8891 (0.8122)  loss_giou_dn_2: 1.3698 (1.3806)  loss_fgl_dn_2: 0.8168 (0.8124)  loss_mal_dn_3: 1.1562 (1.1691)  loss_bbox_dn_3: 0.8891 (0.8123)  loss_giou_dn_3: 1.3698 (1.3806)  loss_fgl_dn_3: 0.8168 (0.8124)  loss_mal_dn_4: 1.1729 (1.1682)  loss_bbox_dn_4: 0.8891 (0.8123)  loss_giou_dn_4: 1.3697 (1.3806)  loss_fgl_dn_4: 0.8168 (0.8124)  loss_mal_dn_5: 1.1641 (1.1607)  loss_bbox_dn_5: 0.8891 (0.8123)  loss_giou_dn_5: 1.3697 (1.3806)  loss_fgl_dn_5: 0.8168 (0.8124)  loss_mal_dn_pre: 1.1270 (1.1055)  loss_bbox_dn_pre: 0.8891 (0.8122)  loss_giou_dn_pre: 1.3698 (1.3806)  loss_ddf_aux_0: 0.0000 (0.0000)  loss_ddf_aux_1: 0.0000 (0.0000)  loss_ddf_aux_2: 0.0000 (0.0000)  loss_ddf_aux_3: 0.0000 (0.0000)  loss_ddf_aux_4: 0.0000 (0.0000)  loss_ddf_dn_0: 0.0000 (0.0000)  loss_ddf_dn_1: 0.0000 (0.0000)  loss_ddf_dn_2: 0.0000 (0.0000)  loss_ddf_dn_3: 0.0000 (0.0000)  loss_ddf_dn_4: 0.0000 (0.0000)  time: 1.1146  data: 0.0116  max mem: 13413\nEpoch: [0] Total time: 0:05:06 (1.2224 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7963  data: 0.4543  max mem: 13413\nTest:  [10/25]  eta: 0:00:06    time: 0.4122  data: 0.0649  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3398  data: 0.0236  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.3271  data: 0.0225  max mem: 13413\nTest: Total time: 0:00:08 (0.3464 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.05s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.008\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\nbest_stat: {'epoch': 0, 'coco_eval_bbox': 8.148636728393359e-07}\nEpoch: [1]  [  0/251]  eta: 0:10:43  lr: 0.000000  loss: 59.3018 (59.3018)  loss_mal: 0.6196 (0.6196)  loss_bbox: 1.1474 (1.1474)  loss_giou: 1.9034 (1.9034)  loss_fgl: 0.3645 (0.3645)  loss_mal_aux_0: 0.5693 (0.5693)  loss_bbox_aux_0: 1.1479 (1.1479)  loss_giou_aux_0: 1.9037 (1.9037)  loss_fgl_aux_0: 0.3644 (0.3644)  loss_ddf_aux_0: 0.0000 (0.0000)  loss_mal_aux_1: 0.4116 (0.4116)  loss_bbox_aux_1: 1.1478 (1.1478)  loss_giou_aux_1: 1.9036 (1.9036)  loss_fgl_aux_1: 0.3645 (0.3645)  loss_ddf_aux_1: 0.0000 (0.0000)  loss_mal_aux_2: 0.5264 (0.5264)  loss_bbox_aux_2: 1.1477 (1.1477)  loss_giou_aux_2: 1.9036 (1.9036)  loss_fgl_aux_2: 0.3645 (0.3645)  loss_ddf_aux_2: 0.0000 (0.0000)  loss_mal_aux_3: 0.5474 (0.5474)  loss_bbox_aux_3: 1.1476 (1.1476)  loss_giou_aux_3: 1.9035 (1.9035)  loss_fgl_aux_3: 0.3645 (0.3645)  loss_ddf_aux_3: 0.0000 (0.0000)  loss_mal_aux_4: 0.6157 (0.6157)  loss_bbox_aux_4: 1.1475 (1.1475)  loss_giou_aux_4: 1.9035 (1.9035)  loss_fgl_aux_4: 0.3645 (0.3645)  loss_ddf_aux_4: 0.0000 (0.0000)  loss_mal_pre: 0.5693 (0.5693)  loss_bbox_pre: 1.1479 (1.1479)  loss_giou_pre: 1.9037 (1.9037)  loss_mal_enc_0: 0.4756 (0.4756)  loss_bbox_enc_0: 1.1480 (1.1480)  loss_giou_enc_0: 1.9038 (1.9038)  loss_mal_dn_0: 1.1436 (1.1436)  loss_bbox_dn_0: 0.8278 (0.8278)  loss_giou_dn_0: 1.3626 (1.3626)  loss_fgl_dn_0: 0.8231 (0.8231)  loss_ddf_dn_0: 0.0000 (0.0000)  loss_mal_dn_1: 1.1475 (1.1475)  loss_bbox_dn_1: 0.8278 (0.8278)  loss_giou_dn_1: 1.3626 (1.3626)  loss_fgl_dn_1: 0.8231 (0.8231)  loss_ddf_dn_1: 0.0000 (0.0000)  loss_mal_dn_2: 1.1699 (1.1699)  loss_bbox_dn_2: 0.8278 (0.8278)  loss_giou_dn_2: 1.3626 (1.3626)  loss_fgl_dn_2: 0.8232 (0.8232)  loss_ddf_dn_2: 0.0000 (0.0000)  loss_mal_dn_3: 1.1182 (1.1182)  loss_bbox_dn_3: 0.8278 (0.8278)  loss_giou_dn_3: 1.3626 (1.3626)  loss_fgl_dn_3: 0.8232 (0.8232)  loss_ddf_dn_3: 0.0000 (0.0000)  loss_mal_dn_4: 1.1230 (1.1230)  loss_bbox_dn_4: 0.8278 (0.8278)  loss_giou_dn_4: 1.3626 (1.3626)  loss_fgl_dn_4: 0.8232 (0.8232)  loss_ddf_dn_4: 0.0000 (0.0000)  loss_mal_dn_5: 1.2520 (1.2520)  loss_bbox_dn_5: 0.8279 (0.8279)  loss_giou_dn_5: 1.3626 (1.3626)  loss_fgl_dn_5: 0.8232 (0.8232)  loss_mal_dn_pre: 1.1436 (1.1436)  loss_bbox_dn_pre: 0.8278 (0.8278)  loss_giou_dn_pre: 1.3626 (1.3626)  time: 2.5623  data: 1.2076  max mem: 13413\nEpoch: [1]  [100/251]  eta: 0:03:08  lr: 0.000000  loss: 58.5010 (59.7386)  loss_mal: 0.7964 (0.7782)  loss_bbox: 1.0671 (1.1237)  loss_giou: 1.6814 (1.7057)  loss_fgl: 0.4899 (0.4922)  loss_mal_aux_0: 0.7217 (0.7516)  loss_bbox_aux_0: 1.0691 (1.1245)  loss_giou_aux_0: 1.6821 (1.7064)  loss_fgl_aux_0: 0.4895 (0.4920)  loss_ddf_aux_0: -0.0001 (0.0001)  loss_mal_aux_1: 0.7803 (0.7678)  loss_bbox_aux_1: 1.0686 (1.1243)  loss_giou_aux_1: 1.6820 (1.7063)  loss_fgl_aux_1: 0.4896 (0.4921)  loss_ddf_aux_1: -0.0001 (0.0001)  loss_mal_aux_2: 0.7021 (0.7409)  loss_bbox_aux_2: 1.0683 (1.1242)  loss_giou_aux_2: 1.6819 (1.7061)  loss_fgl_aux_2: 0.4897 (0.4921)  loss_ddf_aux_2: -0.0001 (0.0001)  loss_mal_aux_3: 0.7847 (0.7657)  loss_bbox_aux_3: 1.0678 (1.1240)  loss_giou_aux_3: 1.6817 (1.7060)  loss_fgl_aux_3: 0.4897 (0.4922)  loss_ddf_aux_3: 0.0001 (0.0001)  loss_mal_aux_4: 0.7695 (0.7821)  loss_bbox_aux_4: 1.0675 (1.1238)  loss_giou_aux_4: 1.6816 (1.7058)  loss_fgl_aux_4: 0.4899 (0.4922)  loss_ddf_aux_4: 0.0004 (0.0003)  loss_mal_pre: 0.7217 (0.7515)  loss_bbox_pre: 1.0693 (1.1245)  loss_giou_pre: 1.6821 (1.7065)  loss_mal_enc_0: 0.7910 (0.7780)  loss_bbox_enc_0: 1.0697 (1.1247)  loss_giou_enc_0: 1.6823 (1.7066)  loss_mal_dn_0: 1.0732 (1.0973)  loss_bbox_dn_0: 0.7613 (0.7981)  loss_giou_dn_0: 1.3778 (1.3769)  loss_fgl_dn_0: 0.8166 (0.8156)  loss_ddf_dn_0: -0.0001 (0.0001)  loss_mal_dn_1: 1.1260 (1.1398)  loss_bbox_dn_1: 0.7613 (0.7981)  loss_giou_dn_1: 1.3778 (1.3769)  loss_fgl_dn_1: 0.8167 (0.8156)  loss_ddf_dn_1: -0.0001 (0.0001)  loss_mal_dn_2: 1.1055 (1.1218)  loss_bbox_dn_2: 0.7614 (0.7981)  loss_giou_dn_2: 1.3778 (1.3769)  loss_fgl_dn_2: 0.8166 (0.8156)  loss_ddf_dn_2: -0.0001 (0.0001)  loss_mal_dn_3: 1.1328 (1.1570)  loss_bbox_dn_3: 0.7615 (0.7982)  loss_giou_dn_3: 1.3777 (1.3769)  loss_fgl_dn_3: 0.8166 (0.8156)  loss_ddf_dn_3: 0.0001 (0.0001)  loss_mal_dn_4: 1.1504 (1.1463)  loss_bbox_dn_4: 0.7616 (0.7982)  loss_giou_dn_4: 1.3777 (1.3769)  loss_fgl_dn_4: 0.8165 (0.8156)  loss_ddf_dn_4: 0.0005 (0.0003)  loss_mal_dn_5: 1.1299 (1.1468)  loss_bbox_dn_5: 0.7617 (0.7983)  loss_giou_dn_5: 1.3776 (1.3769)  loss_fgl_dn_5: 0.8165 (0.8156)  loss_mal_dn_pre: 1.0732 (1.0973)  loss_bbox_dn_pre: 0.7613 (0.7981)  loss_giou_dn_pre: 1.3778 (1.3769)  time: 1.2695  data: 0.0129  max mem: 13413\nEpoch: [1]  [200/251]  eta: 0:01:02  lr: 0.000000  loss: 59.9815 (59.9958)  loss_mal: 0.8276 (0.7739)  loss_bbox: 1.0200 (1.1464)  loss_giou: 1.6250 (1.6973)  loss_fgl: 0.5361 (0.4998)  loss_mal_aux_0: 0.7524 (0.7656)  loss_bbox_aux_0: 1.0227 (1.1478)  loss_giou_aux_0: 1.6278 (1.6987)  loss_fgl_aux_0: 0.5357 (0.4994)  loss_ddf_aux_0: -0.0008 (-0.0003)  loss_mal_aux_1: 0.7524 (0.7802)  loss_bbox_aux_1: 1.0222 (1.1475)  loss_giou_aux_1: 1.6273 (1.6984)  loss_fgl_aux_1: 0.5358 (0.4995)  loss_ddf_aux_1: -0.0007 (-0.0002)  loss_mal_aux_2: 0.7397 (0.7520)  loss_bbox_aux_2: 1.0215 (1.1473)  loss_giou_aux_2: 1.6268 (1.6982)  loss_fgl_aux_2: 0.5359 (0.4996)  loss_ddf_aux_2: -0.0002 (-0.0001)  loss_mal_aux_3: 0.6978 (0.7750)  loss_bbox_aux_3: 1.0209 (1.1470)  loss_giou_aux_3: 1.6262 (1.6979)  loss_fgl_aux_3: 0.5360 (0.4997)  loss_ddf_aux_3: -0.0001 (0.0001)  loss_mal_aux_4: 0.7949 (0.7830)  loss_bbox_aux_4: 1.0205 (1.1467)  loss_giou_aux_4: 1.6257 (1.6976)  loss_fgl_aux_4: 0.5361 (0.4998)  loss_ddf_aux_4: -0.0001 (0.0002)  loss_mal_pre: 0.7524 (0.7655)  loss_bbox_pre: 1.0229 (1.1478)  loss_giou_pre: 1.6280 (1.6988)  loss_mal_enc_0: 0.7930 (0.8016)  loss_bbox_enc_0: 1.0234 (1.1481)  loss_giou_enc_0: 1.6287 (1.6990)  loss_mal_dn_0: 1.0742 (1.0873)  loss_bbox_dn_0: 0.7901 (0.8133)  loss_giou_dn_0: 1.3833 (1.3781)  loss_fgl_dn_0: 0.8141 (0.8148)  loss_ddf_dn_0: -0.0012 (-0.0004)  loss_mal_dn_1: 1.1074 (1.1304)  loss_bbox_dn_1: 0.7902 (0.8134)  loss_giou_dn_1: 1.3833 (1.3781)  loss_fgl_dn_1: 0.8140 (0.8148)  loss_ddf_dn_1: -0.0012 (-0.0003)  loss_mal_dn_2: 1.0430 (1.1033)  loss_bbox_dn_2: 0.7902 (0.8134)  loss_giou_dn_2: 1.3834 (1.3781)  loss_fgl_dn_2: 0.8139 (0.8148)  loss_ddf_dn_2: -0.0004 (-0.0002)  loss_mal_dn_3: 1.1338 (1.1451)  loss_bbox_dn_3: 0.7903 (0.8135)  loss_giou_dn_3: 1.3834 (1.3781)  loss_fgl_dn_3: 0.8139 (0.8147)  loss_ddf_dn_3: -0.0001 (0.0001)  loss_mal_dn_4: 1.0938 (1.1312)  loss_bbox_dn_4: 0.7905 (0.8136)  loss_giou_dn_4: 1.3835 (1.3781)  loss_fgl_dn_4: 0.8138 (0.8147)  loss_ddf_dn_4: -0.0001 (0.0003)  loss_mal_dn_5: 1.0674 (1.1235)  loss_bbox_dn_5: 0.7908 (0.8137)  loss_giou_dn_5: 1.3835 (1.3781)  loss_fgl_dn_5: 0.8138 (0.8147)  loss_mal_dn_pre: 1.0742 (1.0873)  loss_bbox_dn_pre: 0.7902 (0.8134)  loss_giou_dn_pre: 1.3833 (1.3781)  time: 1.0515  data: 0.0119  max mem: 13413\nEpoch: [1]  [250/251]  eta: 0:00:01  lr: 0.000000  loss: 61.0471 (59.9809)  loss_mal: 0.7588 (0.7811)  loss_bbox: 1.1515 (1.1480)  loss_giou: 1.6592 (1.6992)  loss_fgl: 0.4965 (0.4983)  loss_mal_aux_0: 0.7471 (0.7686)  loss_bbox_aux_0: 1.1541 (1.1497)  loss_giou_aux_0: 1.6639 (1.7010)  loss_fgl_aux_0: 0.4951 (0.4978)  loss_ddf_aux_0: -0.0010 (-0.0004)  loss_mal_aux_1: 0.7593 (0.7853)  loss_bbox_aux_1: 1.1536 (1.1494)  loss_giou_aux_1: 1.6631 (1.7006)  loss_fgl_aux_1: 0.4955 (0.4980)  loss_ddf_aux_1: -0.0006 (-0.0003)  loss_mal_aux_2: 0.7866 (0.7571)  loss_bbox_aux_2: 1.1530 (1.1491)  loss_giou_aux_2: 1.6623 (1.7003)  loss_fgl_aux_2: 0.4957 (0.4981)  loss_ddf_aux_2: -0.0003 (-0.0001)  loss_mal_aux_3: 0.7822 (0.7850)  loss_bbox_aux_3: 1.1526 (1.1487)  loss_giou_aux_3: 1.6612 (1.7000)  loss_fgl_aux_3: 0.4960 (0.4982)  loss_ddf_aux_3: -0.0002 (0.0000)  loss_mal_aux_4: 0.7446 (0.7874)  loss_bbox_aux_4: 1.1521 (1.1484)  loss_giou_aux_4: 1.6602 (1.6996)  loss_fgl_aux_4: 0.4963 (0.4983)  loss_ddf_aux_4: -0.0002 (0.0001)  loss_mal_pre: 0.7471 (0.7685)  loss_bbox_pre: 1.1543 (1.1498)  loss_giou_pre: 1.6642 (1.7011)  loss_mal_enc_0: 0.8130 (0.8069)  loss_bbox_enc_0: 1.1548 (1.1501)  loss_giou_enc_0: 1.6646 (1.7014)  loss_mal_dn_0: 1.0381 (1.0777)  loss_bbox_dn_0: 0.8969 (0.8129)  loss_giou_dn_0: 1.3767 (1.3790)  loss_fgl_dn_0: 0.8131 (0.8141)  loss_ddf_dn_0: -0.0014 (-0.0006)  loss_mal_dn_1: 1.0723 (1.1204)  loss_bbox_dn_1: 0.8969 (0.8129)  loss_giou_dn_1: 1.3767 (1.3790)  loss_fgl_dn_1: 0.8130 (0.8141)  loss_ddf_dn_1: -0.0010 (-0.0005)  loss_mal_dn_2: 1.0332 (1.0918)  loss_bbox_dn_2: 0.8968 (0.8129)  loss_giou_dn_2: 1.3768 (1.3790)  loss_fgl_dn_2: 0.8128 (0.8140)  loss_ddf_dn_2: -0.0001 (-0.0002)  loss_mal_dn_3: 1.0586 (1.1329)  loss_bbox_dn_3: 0.8970 (0.8130)  loss_giou_dn_3: 1.3768 (1.3790)  loss_fgl_dn_3: 0.8127 (0.8140)  loss_ddf_dn_3: -0.0001 (0.0001)  loss_mal_dn_4: 1.0615 (1.1202)  loss_bbox_dn_4: 0.8973 (0.8132)  loss_giou_dn_4: 1.3768 (1.3790)  loss_fgl_dn_4: 0.8125 (0.8139)  loss_ddf_dn_4: -0.0003 (0.0002)  loss_mal_dn_5: 1.0176 (1.1088)  loss_bbox_dn_5: 0.8976 (0.8133)  loss_giou_dn_5: 1.3768 (1.3790)  loss_fgl_dn_5: 0.8124 (0.8139)  loss_mal_dn_pre: 1.0381 (1.0778)  loss_bbox_dn_pre: 0.8969 (0.8129)  loss_giou_dn_pre: 1.3767 (1.3790)  time: 1.2325  data: 0.0111  max mem: 13413\nEpoch: [1] Total time: 0:05:09 (1.2334 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7920  data: 0.4683  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3552  data: 0.0660  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3378  data: 0.0232  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.3258  data: 0.0221  max mem: 13413\nTest: Total time: 0:00:08 (0.3446 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.006\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.048\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\nbest_stat: {'epoch': 1, 'coco_eval_bbox': 5.432059476859253e-06}\nEpoch: [2]  [  0/251]  eta: 0:12:04  lr: 0.000000  loss: 59.8155 (59.8155)  loss_mal: 0.8545 (0.8545)  loss_bbox: 0.9933 (0.9933)  loss_giou: 1.6329 (1.6329)  loss_fgl: 0.5502 (0.5502)  loss_mal_aux_0: 0.8081 (0.8081)  loss_bbox_aux_0: 0.9937 (0.9937)  loss_giou_aux_0: 1.6347 (1.6347)  loss_fgl_aux_0: 0.5498 (0.5498)  loss_ddf_aux_0: -0.0011 (-0.0011)  loss_mal_aux_1: 0.8228 (0.8228)  loss_bbox_aux_1: 0.9936 (0.9936)  loss_giou_aux_1: 1.6343 (1.6343)  loss_fgl_aux_1: 0.5499 (0.5499)  loss_ddf_aux_1: -0.0005 (-0.0005)  loss_mal_aux_2: 0.8149 (0.8149)  loss_bbox_aux_2: 0.9935 (0.9935)  loss_giou_aux_2: 1.6340 (1.6340)  loss_fgl_aux_2: 0.5500 (0.5500)  loss_ddf_aux_2: -0.0004 (-0.0004)  loss_mal_aux_3: 0.9126 (0.9126)  loss_bbox_aux_3: 0.9936 (0.9936)  loss_giou_aux_3: 1.6336 (1.6336)  loss_fgl_aux_3: 0.5501 (0.5501)  loss_ddf_aux_3: -0.0002 (-0.0002)  loss_mal_aux_4: 0.8647 (0.8647)  loss_bbox_aux_4: 0.9935 (0.9935)  loss_giou_aux_4: 1.6333 (1.6333)  loss_fgl_aux_4: 0.5501 (0.5501)  loss_ddf_aux_4: -0.0002 (-0.0002)  loss_mal_pre: 0.8081 (0.8081)  loss_bbox_pre: 0.9938 (0.9938)  loss_giou_pre: 1.6348 (1.6348)  loss_mal_enc_0: 0.7402 (0.7402)  loss_bbox_enc_0: 0.9943 (0.9943)  loss_giou_enc_0: 1.6358 (1.6358)  loss_mal_dn_0: 1.1045 (1.1045)  loss_bbox_dn_0: 0.9626 (0.9626)  loss_giou_dn_0: 1.3491 (1.3491)  loss_fgl_dn_0: 0.8423 (0.8423)  loss_ddf_dn_0: -0.0013 (-0.0013)  loss_mal_dn_1: 1.0938 (1.0938)  loss_bbox_dn_1: 0.9626 (0.9626)  loss_giou_dn_1: 1.3491 (1.3491)  loss_fgl_dn_1: 0.8422 (0.8422)  loss_ddf_dn_1: -0.0009 (-0.0009)  loss_mal_dn_2: 1.0400 (1.0400)  loss_bbox_dn_2: 0.9624 (0.9624)  loss_giou_dn_2: 1.3490 (1.3490)  loss_fgl_dn_2: 0.8421 (0.8421)  loss_ddf_dn_2: -0.0000 (-0.0000)  loss_mal_dn_3: 1.1670 (1.1670)  loss_bbox_dn_3: 0.9624 (0.9624)  loss_giou_dn_3: 1.3490 (1.3490)  loss_fgl_dn_3: 0.8420 (0.8420)  loss_ddf_dn_3: -0.0001 (-0.0001)  loss_mal_dn_4: 1.0371 (1.0371)  loss_bbox_dn_4: 0.9625 (0.9625)  loss_giou_dn_4: 1.3489 (1.3489)  loss_fgl_dn_4: 0.8420 (0.8420)  loss_ddf_dn_4: -0.0005 (-0.0005)  loss_mal_dn_5: 1.0918 (1.0918)  loss_bbox_dn_5: 0.9626 (0.9626)  loss_giou_dn_5: 1.3488 (1.3488)  loss_fgl_dn_5: 0.8419 (0.8419)  loss_mal_dn_pre: 1.1045 (1.1045)  loss_bbox_dn_pre: 0.9628 (0.9628)  loss_giou_dn_pre: 1.3492 (1.3492)  time: 2.8853  data: 1.2706  max mem: 13413\nEpoch: [2]  [100/251]  eta: 0:03:15  lr: 0.000000  loss: 57.3792 (59.2510)  loss_mal: 0.7954 (0.8270)  loss_bbox: 0.9687 (1.1230)  loss_giou: 1.6790 (1.6971)  loss_fgl: 0.4846 (0.5037)  loss_mal_aux_0: 0.8267 (0.8003)  loss_bbox_aux_0: 0.9697 (1.1280)  loss_giou_aux_0: 1.6882 (1.7025)  loss_fgl_aux_0: 0.4828 (0.5022)  loss_ddf_aux_0: -0.0009 (-0.0009)  loss_mal_aux_1: 0.8135 (0.8034)  loss_bbox_aux_1: 0.9697 (1.1271)  loss_giou_aux_1: 1.6868 (1.7014)  loss_fgl_aux_1: 0.4832 (0.5026)  loss_ddf_aux_1: -0.0002 (-0.0002)  loss_mal_aux_2: 0.8022 (0.8010)  loss_bbox_aux_2: 0.9697 (1.1261)  loss_giou_aux_2: 1.6850 (1.7004)  loss_fgl_aux_2: 0.4836 (0.5028)  loss_ddf_aux_2: -0.0001 (-0.0001)  loss_mal_aux_3: 0.7798 (0.8039)  loss_bbox_aux_3: 0.9695 (1.1251)  loss_giou_aux_3: 1.6831 (1.6993)  loss_fgl_aux_3: 0.4839 (0.5031)  loss_ddf_aux_3: -0.0000 (-0.0000)  loss_mal_aux_4: 0.7598 (0.8092)  loss_bbox_aux_4: 0.9692 (1.1241)  loss_giou_aux_4: 1.6811 (1.6983)  loss_fgl_aux_4: 0.4843 (0.5034)  loss_ddf_aux_4: -0.0001 (-0.0001)  loss_mal_pre: 0.8267 (0.8000)  loss_bbox_pre: 0.9698 (1.1283)  loss_giou_pre: 1.6885 (1.7028)  loss_mal_enc_0: 0.8135 (0.7881)  loss_bbox_enc_0: 0.9702 (1.1292)  loss_giou_enc_0: 1.6897 (1.7038)  loss_mal_dn_0: 1.0195 (1.0155)  loss_bbox_dn_0: 0.7169 (0.7851)  loss_giou_dn_0: 1.3710 (1.3834)  loss_fgl_dn_0: 0.8176 (0.8107)  loss_ddf_dn_0: -0.0010 (-0.0012)  loss_mal_dn_1: 1.0400 (1.0435)  loss_bbox_dn_1: 0.7170 (0.7851)  loss_giou_dn_1: 1.3710 (1.3834)  loss_fgl_dn_1: 0.8174 (0.8106)  loss_ddf_dn_1: 0.0003 (-0.0002)  loss_mal_dn_2: 0.9810 (0.9961)  loss_bbox_dn_2: 0.7171 (0.7852)  loss_giou_dn_2: 1.3709 (1.3834)  loss_fgl_dn_2: 0.8171 (0.8103)  loss_ddf_dn_2: 0.0001 (0.0001)  loss_mal_dn_3: 1.0312 (1.0464)  loss_bbox_dn_3: 0.7173 (0.7855)  loss_giou_dn_3: 1.3708 (1.3834)  loss_fgl_dn_3: 0.8169 (0.8102)  loss_ddf_dn_3: -0.0001 (-0.0001)  loss_mal_dn_4: 1.0010 (1.0214)  loss_bbox_dn_4: 0.7176 (0.7859)  loss_giou_dn_4: 1.3707 (1.3834)  loss_fgl_dn_4: 0.8168 (0.8101)  loss_ddf_dn_4: -0.0002 (-0.0003)  loss_mal_dn_5: 1.0029 (1.0038)  loss_bbox_dn_5: 0.7181 (0.7865)  loss_giou_dn_5: 1.3705 (1.3834)  loss_fgl_dn_5: 0.8166 (0.8099)  loss_mal_dn_pre: 1.0205 (1.0158)  loss_bbox_dn_pre: 0.7170 (0.7851)  loss_giou_dn_pre: 1.3710 (1.3834)  time: 1.2124  data: 0.0120  max mem: 13413\nEpoch: [2]  [200/251]  eta: 0:01:04  lr: 0.000000  loss: 58.9366 (59.2609)  loss_mal: 0.8447 (0.8431)  loss_bbox: 0.9848 (1.1313)  loss_giou: 1.5896 (1.6770)  loss_fgl: 0.5332 (0.5181)  loss_mal_aux_0: 0.8252 (0.8062)  loss_bbox_aux_0: 1.0047 (1.1388)  loss_giou_aux_0: 1.6038 (1.6850)  loss_fgl_aux_0: 0.5311 (0.5158)  loss_ddf_aux_0: -0.0004 (-0.0008)  loss_mal_aux_1: 0.8599 (0.8106)  loss_bbox_aux_1: 1.0008 (1.1374)  loss_giou_aux_1: 1.6008 (1.6835)  loss_fgl_aux_1: 0.5317 (0.5163)  loss_ddf_aux_1: 0.0002 (-0.0001)  loss_mal_aux_2: 0.8115 (0.8092)  loss_bbox_aux_2: 0.9969 (1.1360)  loss_giou_aux_2: 1.5980 (1.6819)  loss_fgl_aux_2: 0.5321 (0.5168)  loss_ddf_aux_2: 0.0003 (-0.0000)  loss_mal_aux_3: 0.7783 (0.8252)  loss_bbox_aux_3: 0.9932 (1.1345)  loss_giou_aux_3: 1.5951 (1.6803)  loss_fgl_aux_3: 0.5325 (0.5172)  loss_ddf_aux_3: 0.0001 (-0.0000)  loss_mal_aux_4: 0.8193 (0.8239)  loss_bbox_aux_4: 0.9890 (1.1329)  loss_giou_aux_4: 1.5922 (1.6786)  loss_fgl_aux_4: 0.5330 (0.5177)  loss_ddf_aux_4: 0.0001 (-0.0001)  loss_mal_pre: 0.8247 (0.8052)  loss_bbox_pre: 1.0059 (1.1393)  loss_giou_pre: 1.6047 (1.6855)  loss_mal_enc_0: 0.7764 (0.7998)  loss_bbox_enc_0: 1.0092 (1.1406)  loss_giou_enc_0: 1.6075 (1.6869)  loss_mal_dn_0: 0.9326 (0.9861)  loss_bbox_dn_0: 0.7834 (0.8069)  loss_giou_dn_0: 1.3666 (1.3799)  loss_fgl_dn_0: 0.8191 (0.8136)  loss_ddf_dn_0: -0.0006 (-0.0009)  loss_mal_dn_1: 0.9492 (1.0122)  loss_bbox_dn_1: 0.7834 (0.8070)  loss_giou_dn_1: 1.3668 (1.3799)  loss_fgl_dn_1: 0.8187 (0.8133)  loss_ddf_dn_1: 0.0003 (0.0001)  loss_mal_dn_2: 0.8667 (0.9577)  loss_bbox_dn_2: 0.7832 (0.8070)  loss_giou_dn_2: 1.3670 (1.3799)  loss_fgl_dn_2: 0.8182 (0.8131)  loss_ddf_dn_2: -0.0001 (0.0000)  loss_mal_dn_3: 0.9507 (1.0180)  loss_bbox_dn_3: 0.7836 (0.8076)  loss_giou_dn_3: 1.3672 (1.3799)  loss_fgl_dn_3: 0.8179 (0.8129)  loss_ddf_dn_3: 0.0001 (-0.0000)  loss_mal_dn_4: 0.9023 (0.9799)  loss_bbox_dn_4: 0.7840 (0.8082)  loss_giou_dn_4: 1.3675 (1.3799)  loss_fgl_dn_4: 0.8176 (0.8127)  loss_ddf_dn_4: -0.0001 (-0.0001)  loss_mal_dn_5: 0.8735 (0.9577)  loss_bbox_dn_5: 0.7847 (0.8092)  loss_giou_dn_5: 1.3681 (1.3799)  loss_fgl_dn_5: 0.8171 (0.8125)  loss_mal_dn_pre: 0.9336 (0.9867)  loss_bbox_dn_pre: 0.7837 (0.8070)  loss_giou_dn_pre: 1.3666 (1.3799)  time: 1.3641  data: 0.0114  max mem: 13413\nEpoch: [2]  [250/251]  eta: 0:00:01  lr: 0.000000  loss: 57.2001 (59.1183)  loss_mal: 0.9956 (0.8625)  loss_bbox: 0.9331 (1.1169)  loss_giou: 1.5715 (1.6671)  loss_fgl: 0.5497 (0.5267)  loss_mal_aux_0: 0.8564 (0.8166)  loss_bbox_aux_0: 0.9537 (1.1269)  loss_giou_aux_0: 1.5957 (1.6775)  loss_fgl_aux_0: 0.5439 (0.5238)  loss_ddf_aux_0: -0.0001 (-0.0007)  loss_mal_aux_1: 0.8687 (0.8220)  loss_bbox_aux_1: 0.9506 (1.1250)  loss_giou_aux_1: 1.5915 (1.6755)  loss_fgl_aux_1: 0.5452 (0.5244)  loss_ddf_aux_1: 0.0003 (-0.0000)  loss_mal_aux_2: 0.8403 (0.8161)  loss_bbox_aux_2: 0.9467 (1.1232)  loss_giou_aux_2: 1.5868 (1.6736)  loss_fgl_aux_2: 0.5453 (0.5250)  loss_ddf_aux_2: 0.0000 (0.0000)  loss_mal_aux_3: 0.9131 (0.8358)  loss_bbox_aux_3: 0.9431 (1.1212)  loss_giou_aux_3: 1.5817 (1.6714)  loss_fgl_aux_3: 0.5463 (0.5256)  loss_ddf_aux_3: 0.0000 (-0.0000)  loss_mal_aux_4: 0.8911 (0.8368)  loss_bbox_aux_4: 0.9376 (1.1191)  loss_giou_aux_4: 1.5758 (1.6692)  loss_fgl_aux_4: 0.5483 (0.5262)  loss_ddf_aux_4: 0.0000 (-0.0001)  loss_mal_pre: 0.8564 (0.8158)  loss_bbox_pre: 0.9547 (1.1274)  loss_giou_pre: 1.5968 (1.6781)  loss_mal_enc_0: 0.7778 (0.8062)  loss_bbox_enc_0: 0.9571 (1.1290)  loss_giou_enc_0: 1.5991 (1.6798)  loss_mal_dn_0: 0.9014 (0.9712)  loss_bbox_dn_0: 0.7771 (0.8115)  loss_giou_dn_0: 1.3864 (1.3797)  loss_fgl_dn_0: 0.8068 (0.8137)  loss_ddf_dn_0: 0.0006 (-0.0007)  loss_mal_dn_1: 0.9233 (0.9931)  loss_bbox_dn_1: 0.7774 (0.8116)  loss_giou_dn_1: 1.3863 (1.3797)  loss_fgl_dn_1: 0.8062 (0.8134)  loss_ddf_dn_1: 0.0002 (0.0001)  loss_mal_dn_2: 0.8154 (0.9341)  loss_bbox_dn_2: 0.7779 (0.8117)  loss_giou_dn_2: 1.3862 (1.3797)  loss_fgl_dn_2: 0.8054 (0.8131)  loss_ddf_dn_2: 0.0002 (0.0001)  loss_mal_dn_3: 0.8599 (0.9951)  loss_bbox_dn_3: 0.7797 (0.8124)  loss_giou_dn_3: 1.3860 (1.3797)  loss_fgl_dn_3: 0.8050 (0.8128)  loss_ddf_dn_3: 0.0001 (-0.0000)  loss_mal_dn_4: 0.8223 (0.9541)  loss_bbox_dn_4: 0.7823 (0.8133)  loss_giou_dn_4: 1.3858 (1.3797)  loss_fgl_dn_4: 0.8046 (0.8126)  loss_ddf_dn_4: 0.0000 (-0.0001)  loss_mal_dn_5: 0.7988 (0.9333)  loss_bbox_dn_5: 0.7855 (0.8145)  loss_giou_dn_5: 1.3859 (1.3798)  loss_fgl_dn_5: 0.8042 (0.8124)  loss_mal_dn_pre: 0.9019 (0.9718)  loss_bbox_dn_pre: 0.7776 (0.8117)  loss_giou_dn_pre: 1.3864 (1.3797)  time: 1.2068  data: 0.0112  max mem: 13413\nEpoch: [2] Total time: 0:05:14 (1.2543 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8292  data: 0.5071  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3609  data: 0.0704  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3109  data: 0.0245  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2966  data: 0.0216  max mem: 13413\nTest: Total time: 0:00:08 (0.3246 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.05s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.003\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.004\nbest_stat: {'epoch': 1, 'coco_eval_bbox': 5.432059476859253e-06}\nEpoch: [3]  [  0/251]  eta: 0:09:38  lr: 0.000000  loss: 66.7973 (66.7973)  loss_mal: 0.9917 (0.9917)  loss_bbox: 1.7575 (1.7575)  loss_giou: 1.5765 (1.5765)  loss_fgl: 0.5925 (0.5925)  loss_mal_aux_0: 0.9653 (0.9653)  loss_bbox_aux_0: 1.7968 (1.7968)  loss_giou_aux_0: 1.6166 (1.6166)  loss_fgl_aux_0: 0.5808 (0.5808)  loss_ddf_aux_0: -0.0000 (-0.0000)  loss_mal_aux_1: 0.9312 (0.9312)  loss_bbox_aux_1: 1.7901 (1.7901)  loss_giou_aux_1: 1.6100 (1.6100)  loss_fgl_aux_1: 0.5827 (0.5827)  loss_ddf_aux_1: 0.0003 (0.0003)  loss_mal_aux_2: 1.0312 (1.0312)  loss_bbox_aux_2: 1.7825 (1.7825)  loss_giou_aux_2: 1.6026 (1.6026)  loss_fgl_aux_2: 0.5849 (0.5849)  loss_ddf_aux_2: 0.0000 (0.0000)  loss_mal_aux_3: 0.6982 (0.6982)  loss_bbox_aux_3: 1.7746 (1.7746)  loss_giou_aux_3: 1.5946 (1.5946)  loss_fgl_aux_3: 0.5872 (0.5872)  loss_ddf_aux_3: 0.0001 (0.0001)  loss_mal_aux_4: 0.9526 (0.9526)  loss_bbox_aux_4: 1.7657 (1.7657)  loss_giou_aux_4: 1.5854 (1.5854)  loss_fgl_aux_4: 0.5900 (0.5900)  loss_ddf_aux_4: -0.0000 (-0.0000)  loss_mal_pre: 0.9644 (0.9644)  loss_bbox_pre: 1.7987 (1.7987)  loss_giou_pre: 1.6184 (1.6184)  loss_mal_enc_0: 1.0576 (1.0576)  loss_bbox_enc_0: 1.8030 (1.8030)  loss_giou_enc_0: 1.6225 (1.6225)  loss_mal_dn_0: 0.9189 (0.9189)  loss_bbox_dn_0: 1.1813 (1.1813)  loss_giou_dn_0: 1.3698 (1.3698)  loss_fgl_dn_0: 0.8156 (0.8156)  loss_ddf_dn_0: 0.0008 (0.0008)  loss_mal_dn_1: 0.8364 (0.8364)  loss_bbox_dn_1: 1.1812 (1.1812)  loss_giou_dn_1: 1.3695 (1.3695)  loss_fgl_dn_1: 0.8151 (0.8151)  loss_ddf_dn_1: 0.0002 (0.0002)  loss_mal_dn_2: 0.7700 (0.7700)  loss_bbox_dn_2: 1.1810 (1.1810)  loss_giou_dn_2: 1.3690 (1.3690)  loss_fgl_dn_2: 0.8146 (0.8146)  loss_ddf_dn_2: 0.0002 (0.0002)  loss_mal_dn_3: 0.8237 (0.8237)  loss_bbox_dn_3: 1.1823 (1.1823)  loss_giou_dn_3: 1.3685 (1.3685)  loss_fgl_dn_3: 0.8142 (0.8142)  loss_ddf_dn_3: 0.0002 (0.0002)  loss_mal_dn_4: 0.7939 (0.7939)  loss_bbox_dn_4: 1.1845 (1.1845)  loss_giou_dn_4: 1.3679 (1.3679)  loss_fgl_dn_4: 0.8139 (0.8139)  loss_ddf_dn_4: 0.0002 (0.0002)  loss_mal_dn_5: 0.7783 (0.7783)  loss_bbox_dn_5: 1.1874 (1.1874)  loss_giou_dn_5: 1.3675 (1.3675)  loss_fgl_dn_5: 0.8134 (0.8134)  loss_mal_dn_pre: 0.9194 (0.9194)  loss_bbox_dn_pre: 1.1819 (1.1819)  loss_giou_dn_pre: 1.3699 (1.3699)  time: 2.3032  data: 0.6842  max mem: 13413\nEpoch: [3]  [100/251]  eta: 0:03:06  lr: 0.000000  loss: 55.8604 (58.1152)  loss_mal: 1.0977 (1.0096)  loss_bbox: 0.8957 (1.0628)  loss_giou: 1.5465 (1.5991)  loss_fgl: 0.5601 (0.5730)  loss_mal_aux_0: 0.9546 (0.8466)  loss_bbox_aux_0: 0.9104 (1.0981)  loss_giou_aux_0: 1.5990 (1.6340)  loss_fgl_aux_0: 0.5525 (0.5634)  loss_ddf_aux_0: 0.0008 (0.0004)  loss_mal_aux_1: 0.8843 (0.8481)  loss_bbox_aux_1: 0.8973 (1.0916)  loss_giou_aux_1: 1.5920 (1.6276)  loss_fgl_aux_1: 0.5531 (0.5656)  loss_ddf_aux_1: 0.0007 (0.0005)  loss_mal_aux_2: 0.9302 (0.8579)  loss_bbox_aux_2: 0.8933 (1.0850)  loss_giou_aux_2: 1.5830 (1.6210)  loss_fgl_aux_2: 0.5533 (0.5674)  loss_ddf_aux_2: 0.0005 (0.0003)  loss_mal_aux_3: 0.9424 (0.8668)  loss_bbox_aux_3: 0.8923 (1.0777)  loss_giou_aux_3: 1.5710 (1.6136)  loss_fgl_aux_3: 0.5540 (0.5694)  loss_ddf_aux_3: 0.0002 (0.0002)  loss_mal_aux_4: 1.0498 (0.9563)  loss_bbox_aux_4: 0.8923 (1.0696)  loss_giou_aux_4: 1.5582 (1.6057)  loss_fgl_aux_4: 0.5575 (0.5715)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 0.9541 (0.8413)  loss_bbox_pre: 0.9135 (1.0997)  loss_giou_pre: 1.6010 (1.6357)  loss_mal_enc_0: 0.8413 (0.8381)  loss_bbox_enc_0: 0.9214 (1.1041)  loss_giou_enc_0: 1.6072 (1.6405)  loss_mal_dn_0: 0.7798 (0.8316)  loss_bbox_dn_0: 0.7516 (0.8275)  loss_giou_dn_0: 1.3879 (1.3780)  loss_fgl_dn_0: 0.8095 (0.8145)  loss_ddf_dn_0: 0.0015 (0.0011)  loss_mal_dn_1: 0.7798 (0.8324)  loss_bbox_dn_1: 0.7520 (0.8276)  loss_giou_dn_1: 1.3881 (1.3780)  loss_fgl_dn_1: 0.8085 (0.8138)  loss_ddf_dn_1: 0.0010 (0.0006)  loss_mal_dn_2: 0.7114 (0.7631)  loss_bbox_dn_2: 0.7530 (0.8282)  loss_giou_dn_2: 1.3887 (1.3781)  loss_fgl_dn_2: 0.8070 (0.8128)  loss_ddf_dn_2: 0.0006 (0.0004)  loss_mal_dn_3: 0.7749 (0.8222)  loss_bbox_dn_3: 0.7574 (0.8312)  loss_giou_dn_3: 1.3883 (1.3782)  loss_fgl_dn_3: 0.8061 (0.8120)  loss_ddf_dn_3: 0.0002 (0.0002)  loss_mal_dn_4: 0.7246 (0.7712)  loss_bbox_dn_4: 0.7633 (0.8355)  loss_giou_dn_4: 1.3882 (1.3786)  loss_fgl_dn_4: 0.8048 (0.8112)  loss_ddf_dn_4: 0.0001 (0.0001)  loss_mal_dn_5: 0.7515 (0.7752)  loss_bbox_dn_5: 0.7693 (0.8406)  loss_giou_dn_5: 1.3887 (1.3794)  loss_fgl_dn_5: 0.8032 (0.8101)  loss_mal_dn_pre: 0.7812 (0.8328)  loss_bbox_dn_pre: 0.7528 (0.8284)  loss_giou_dn_pre: 1.3877 (1.3780)  time: 1.2388  data: 0.0120  max mem: 13413\nEpoch: [3]  [200/251]  eta: 0:01:02  lr: 0.000001  loss: 56.1380 (57.6870)  loss_mal: 1.0625 (1.0611)  loss_bbox: 0.8179 (0.9966)  loss_giou: 1.5132 (1.5536)  loss_fgl: 0.6351 (0.6088)  loss_mal_aux_0: 0.8701 (0.8853)  loss_bbox_aux_0: 0.8869 (1.0477)  loss_giou_aux_0: 1.5931 (1.6048)  loss_fgl_aux_0: 0.6382 (0.5965)  loss_ddf_aux_0: 0.0038 (0.0014)  loss_mal_aux_1: 0.9316 (0.8998)  loss_bbox_aux_1: 0.8693 (1.0372)  loss_giou_aux_1: 1.5775 (1.5945)  loss_fgl_aux_1: 0.6408 (0.5995)  loss_ddf_aux_1: 0.0025 (0.0011)  loss_mal_aux_2: 0.9385 (0.9189)  loss_bbox_aux_2: 0.8513 (1.0268)  loss_giou_aux_2: 1.5555 (1.5841)  loss_fgl_aux_2: 0.6399 (0.6021)  loss_ddf_aux_2: 0.0015 (0.0007)  loss_mal_aux_3: 1.0137 (0.9496)  loss_bbox_aux_3: 0.8353 (1.0161)  loss_giou_aux_3: 1.5441 (1.5733)  loss_fgl_aux_3: 0.6396 (0.6045)  loss_ddf_aux_3: 0.0006 (0.0003)  loss_mal_aux_4: 1.0723 (1.0214)  loss_bbox_aux_4: 0.8245 (1.0048)  loss_giou_aux_4: 1.5290 (1.5618)  loss_fgl_aux_4: 0.6377 (0.6072)  loss_ddf_aux_4: 0.0002 (0.0001)  loss_mal_pre: 0.8628 (0.8809)  loss_bbox_pre: 0.8919 (1.0503)  loss_giou_pre: 1.5960 (1.6074)  loss_mal_enc_0: 0.8242 (0.8648)  loss_bbox_enc_0: 0.9050 (1.0576)  loss_giou_enc_0: 1.6032 (1.6147)  loss_mal_dn_0: 0.7383 (0.7947)  loss_bbox_dn_0: 0.7617 (0.8170)  loss_giou_dn_0: 1.3754 (1.3769)  loss_fgl_dn_0: 0.8184 (0.8153)  loss_ddf_dn_0: 0.0030 (0.0017)  loss_mal_dn_1: 0.7173 (0.7868)  loss_bbox_dn_1: 0.7613 (0.8168)  loss_giou_dn_1: 1.3756 (1.3770)  loss_fgl_dn_1: 0.8163 (0.8142)  loss_ddf_dn_1: 0.0025 (0.0012)  loss_mal_dn_2: 0.6641 (0.7274)  loss_bbox_dn_2: 0.7617 (0.8173)  loss_giou_dn_2: 1.3767 (1.3772)  loss_fgl_dn_2: 0.8131 (0.8125)  loss_ddf_dn_2: 0.0016 (0.0008)  loss_mal_dn_3: 0.6943 (0.7748)  loss_bbox_dn_3: 0.7681 (0.8219)  loss_giou_dn_3: 1.3777 (1.3779)  loss_fgl_dn_3: 0.8114 (0.8113)  loss_ddf_dn_3: 0.0008 (0.0004)  loss_mal_dn_4: 0.7026 (0.7419)  loss_bbox_dn_4: 0.7782 (0.8288)  loss_giou_dn_4: 1.3791 (1.3792)  loss_fgl_dn_4: 0.8096 (0.8098)  loss_ddf_dn_4: 0.0002 (0.0001)  loss_mal_dn_5: 0.7100 (0.7511)  loss_bbox_dn_5: 0.7874 (0.8366)  loss_giou_dn_5: 1.3808 (1.3811)  loss_fgl_dn_5: 0.8075 (0.8081)  loss_mal_dn_pre: 0.7402 (0.7960)  loss_bbox_dn_pre: 0.7644 (0.8187)  loss_giou_dn_pre: 1.3757 (1.3768)  time: 1.2005  data: 0.0118  max mem: 13413\nEpoch: [3]  [250/251]  eta: 0:00:01  lr: 0.000001  loss: 55.0354 (57.3775)  loss_mal: 1.0830 (1.0788)  loss_bbox: 0.7623 (0.9623)  loss_giou: 1.4475 (1.5257)  loss_fgl: 0.6261 (0.6282)  loss_mal_aux_0: 0.8271 (0.9019)  loss_bbox_aux_0: 0.7855 (1.0191)  loss_giou_aux_0: 1.5489 (1.5835)  loss_fgl_aux_0: 0.6205 (0.6141)  loss_ddf_aux_0: 0.0061 (0.0023)  loss_mal_aux_1: 0.9990 (0.9242)  loss_bbox_aux_1: 0.7611 (1.0066)  loss_giou_aux_1: 1.5212 (1.5702)  loss_fgl_aux_1: 0.6216 (0.6183)  loss_ddf_aux_1: 0.0040 (0.0016)  loss_mal_aux_2: 1.0557 (0.9475)  loss_bbox_aux_2: 0.7652 (0.9941)  loss_giou_aux_2: 1.4887 (1.5574)  loss_fgl_aux_2: 0.6270 (0.6217)  loss_ddf_aux_2: 0.0021 (0.0009)  loss_mal_aux_3: 0.9824 (0.9824)  loss_bbox_aux_3: 0.7719 (0.9822)  loss_giou_aux_3: 1.4660 (1.5453)  loss_fgl_aux_3: 0.6288 (0.6243)  loss_ddf_aux_3: 0.0009 (0.0004)  loss_mal_aux_4: 0.9990 (1.0472)  loss_bbox_aux_4: 0.7655 (0.9702)  loss_giou_aux_4: 1.4505 (1.5334)  loss_fgl_aux_4: 0.6278 (0.6269)  loss_ddf_aux_4: 0.0002 (0.0001)  loss_mal_pre: 0.8218 (0.8967)  loss_bbox_pre: 0.7916 (1.0223)  loss_giou_pre: 1.5520 (1.5869)  loss_mal_enc_0: 0.8584 (0.8821)  loss_bbox_enc_0: 0.7999 (1.0315)  loss_giou_enc_0: 1.5655 (1.5967)  loss_mal_dn_0: 0.6938 (0.7760)  loss_bbox_dn_0: 0.6596 (0.8112)  loss_giou_dn_0: 1.3820 (1.3777)  loss_fgl_dn_0: 0.8071 (0.8144)  loss_ddf_dn_0: 0.0051 (0.0023)  loss_mal_dn_1: 0.6689 (0.7655)  loss_bbox_dn_1: 0.6578 (0.8106)  loss_giou_dn_1: 1.3834 (1.3778)  loss_fgl_dn_1: 0.8043 (0.8131)  loss_ddf_dn_1: 0.0039 (0.0017)  loss_mal_dn_2: 0.6504 (0.7133)  loss_bbox_dn_2: 0.6573 (0.8108)  loss_giou_dn_2: 1.3851 (1.3782)  loss_fgl_dn_2: 0.7999 (0.8109)  loss_ddf_dn_2: 0.0023 (0.0011)  loss_mal_dn_3: 0.6714 (0.7555)  loss_bbox_dn_3: 0.6641 (0.8160)  loss_giou_dn_3: 1.3883 (1.3791)  loss_fgl_dn_3: 0.7965 (0.8094)  loss_ddf_dn_3: 0.0010 (0.0005)  loss_mal_dn_4: 0.6660 (0.7286)  loss_bbox_dn_4: 0.6722 (0.8237)  loss_giou_dn_4: 1.3910 (1.3807)  loss_fgl_dn_4: 0.7931 (0.8075)  loss_ddf_dn_4: 0.0003 (0.0002)  loss_mal_dn_5: 0.6694 (0.7358)  loss_bbox_dn_5: 0.6794 (0.8321)  loss_giou_dn_5: 1.3936 (1.3830)  loss_fgl_dn_5: 0.7898 (0.8056)  loss_mal_dn_pre: 0.6943 (0.7773)  loss_bbox_dn_pre: 0.6641 (0.8135)  loss_giou_dn_pre: 1.3828 (1.3775)  time: 1.2385  data: 0.0117  max mem: 13413\nEpoch: [3] Total time: 0:05:05 (1.2163 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8033  data: 0.4881  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3574  data: 0.0648  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3087  data: 0.0214  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2944  data: 0.0197  max mem: 13413\nTest: Total time: 0:00:08 (0.3210 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.013\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.018\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.060\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.042\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.053\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.205\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.011\nbest_stat: {'epoch': 3, 'coco_eval_bbox': 0.0012446933046997074}\nEpoch: [4]  [  0/251]  eta: 0:09:10  lr: 0.000001  loss: 60.9867 (60.9867)  loss_mal: 1.5205 (1.5205)  loss_bbox: 0.8686 (0.8686)  loss_giou: 1.1378 (1.1378)  loss_fgl: 0.9804 (0.9804)  loss_mal_aux_0: 1.2520 (1.2520)  loss_bbox_aux_0: 1.0230 (1.0230)  loss_giou_aux_0: 1.1699 (1.1699)  loss_fgl_aux_0: 0.9590 (0.9590)  loss_ddf_aux_0: 0.0073 (0.0073)  loss_mal_aux_1: 1.4121 (1.4121)  loss_bbox_aux_1: 0.9712 (0.9712)  loss_giou_aux_1: 1.1517 (1.1517)  loss_fgl_aux_1: 0.9693 (0.9693)  loss_ddf_aux_1: 0.0046 (0.0046)  loss_mal_aux_2: 1.3799 (1.3799)  loss_bbox_aux_2: 0.9190 (0.9190)  loss_giou_aux_2: 1.1408 (1.1408)  loss_fgl_aux_2: 0.9745 (0.9745)  loss_ddf_aux_2: 0.0025 (0.0025)  loss_mal_aux_3: 1.5996 (1.5996)  loss_bbox_aux_3: 0.8751 (0.8751)  loss_giou_aux_3: 1.1392 (1.1392)  loss_fgl_aux_3: 0.9755 (0.9755)  loss_ddf_aux_3: 0.0010 (0.0010)  loss_mal_aux_4: 1.4443 (1.4443)  loss_bbox_aux_4: 0.8656 (0.8656)  loss_giou_aux_4: 1.1385 (1.1385)  loss_fgl_aux_4: 0.9786 (0.9786)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 1.2451 (1.2451)  loss_bbox_pre: 1.0365 (1.0365)  loss_giou_pre: 1.1749 (1.1749)  loss_mal_enc_0: 1.3242 (1.3242)  loss_bbox_enc_0: 1.0702 (1.0702)  loss_giou_enc_0: 1.1918 (1.1918)  loss_mal_dn_0: 0.6924 (0.6924)  loss_bbox_dn_0: 1.1309 (1.1309)  loss_giou_dn_0: 1.3911 (1.3911)  loss_fgl_dn_0: 0.8029 (0.8029)  loss_ddf_dn_0: 0.0042 (0.0042)  loss_mal_dn_1: 0.6582 (0.6582)  loss_bbox_dn_1: 1.1256 (1.1256)  loss_giou_dn_1: 1.3904 (1.3904)  loss_fgl_dn_1: 0.8003 (0.8003)  loss_ddf_dn_1: 0.0035 (0.0035)  loss_mal_dn_2: 0.6514 (0.6514)  loss_bbox_dn_2: 1.1185 (1.1185)  loss_giou_dn_2: 1.3899 (1.3899)  loss_fgl_dn_2: 0.7956 (0.7956)  loss_ddf_dn_2: 0.0019 (0.0019)  loss_mal_dn_3: 0.6621 (0.6621)  loss_bbox_dn_3: 1.1207 (1.1207)  loss_giou_dn_3: 1.3891 (1.3891)  loss_fgl_dn_3: 0.7936 (0.7936)  loss_ddf_dn_3: 0.0009 (0.0009)  loss_mal_dn_4: 0.6323 (0.6323)  loss_bbox_dn_4: 1.1255 (1.1255)  loss_giou_dn_4: 1.3897 (1.3897)  loss_fgl_dn_4: 0.7906 (0.7906)  loss_ddf_dn_4: 0.0003 (0.0003)  loss_mal_dn_5: 0.6875 (0.6875)  loss_bbox_dn_5: 1.1316 (1.1316)  loss_giou_dn_5: 1.3909 (1.3909)  loss_fgl_dn_5: 0.7883 (0.7883)  loss_mal_dn_pre: 0.6934 (0.6934)  loss_bbox_dn_pre: 1.1383 (1.1383)  loss_giou_dn_pre: 1.3911 (1.3911)  time: 2.1938  data: 0.8621  max mem: 13413\nEpoch: [4]  [100/251]  eta: 0:03:07  lr: 0.000001  loss: 54.1845 (56.6432)  loss_mal: 1.1377 (1.1929)  loss_bbox: 0.7523 (0.8650)  loss_giou: 1.2435 (1.3500)  loss_fgl: 0.8227 (0.7683)  loss_mal_aux_0: 1.0674 (1.0823)  loss_bbox_aux_0: 0.7662 (0.9042)  loss_giou_aux_0: 1.3460 (1.4130)  loss_fgl_aux_0: 0.7950 (0.7570)  loss_ddf_aux_0: 0.0074 (0.0077)  loss_mal_aux_1: 1.2344 (1.1445)  loss_bbox_aux_1: 0.7310 (0.8808)  loss_giou_aux_1: 1.2979 (1.3841)  loss_fgl_aux_1: 0.8131 (0.7651)  loss_ddf_aux_1: 0.0043 (0.0046)  loss_mal_aux_2: 1.1719 (1.1698)  loss_bbox_aux_2: 0.7473 (0.8675)  loss_giou_aux_2: 1.2735 (1.3659)  loss_fgl_aux_2: 0.8173 (0.7681)  loss_ddf_aux_2: 0.0019 (0.0022)  loss_mal_aux_3: 1.1738 (1.2004)  loss_bbox_aux_3: 0.7452 (0.8631)  loss_giou_aux_3: 1.2568 (1.3561)  loss_fgl_aux_3: 0.8208 (0.7688)  loss_ddf_aux_3: 0.0007 (0.0008)  loss_mal_aux_4: 1.1562 (1.1991)  loss_bbox_aux_4: 0.7535 (0.8637)  loss_giou_aux_4: 1.2477 (1.3511)  loss_fgl_aux_4: 0.8220 (0.7688)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 1.0576 (1.0727)  loss_bbox_pre: 0.7630 (0.9118)  loss_giou_pre: 1.3630 (1.4218)  loss_mal_enc_0: 1.0537 (1.0389)  loss_bbox_enc_0: 0.7693 (0.9463)  loss_giou_enc_0: 1.4303 (1.4606)  loss_mal_dn_0: 0.6802 (0.6842)  loss_bbox_dn_0: 0.6793 (0.8071)  loss_giou_dn_0: 1.3791 (1.3798)  loss_fgl_dn_0: 0.8123 (0.8113)  loss_ddf_dn_0: 0.0091 (0.0067)  loss_mal_dn_1: 0.6494 (0.6576)  loss_bbox_dn_1: 0.6721 (0.8007)  loss_giou_dn_1: 1.3810 (1.3805)  loss_fgl_dn_1: 0.8062 (0.8069)  loss_ddf_dn_1: 0.0063 (0.0048)  loss_mal_dn_2: 0.6372 (0.6449)  loss_bbox_dn_2: 0.6664 (0.7934)  loss_giou_dn_2: 1.3843 (1.3824)  loss_fgl_dn_2: 0.7960 (0.7993)  loss_ddf_dn_2: 0.0025 (0.0022)  loss_mal_dn_3: 0.6533 (0.6573)  loss_bbox_dn_3: 0.6642 (0.7944)  loss_giou_dn_3: 1.3856 (1.3834)  loss_fgl_dn_3: 0.7916 (0.7957)  loss_ddf_dn_3: 0.0011 (0.0009)  loss_mal_dn_4: 0.6328 (0.6513)  loss_bbox_dn_4: 0.6621 (0.7946)  loss_giou_dn_4: 1.3867 (1.3848)  loss_fgl_dn_4: 0.7869 (0.7919)  loss_ddf_dn_4: 0.0002 (0.0003)  loss_mal_dn_5: 0.6401 (0.6558)  loss_bbox_dn_5: 0.6613 (0.7966)  loss_giou_dn_5: 1.3871 (1.3859)  loss_fgl_dn_5: 0.7841 (0.7896)  loss_mal_dn_pre: 0.6812 (0.6855)  loss_bbox_dn_pre: 0.6901 (0.8169)  loss_giou_dn_pre: 1.3776 (1.3794)  time: 1.1505  data: 0.0121  max mem: 13413\nEpoch: [4]  [200/251]  eta: 0:01:03  lr: 0.000001  loss: 55.5128 (56.4369)  loss_mal: 1.2656 (1.2292)  loss_bbox: 0.7077 (0.8207)  loss_giou: 1.1865 (1.3068)  loss_fgl: 0.8706 (0.8168)  loss_mal_aux_0: 1.4756 (1.2040)  loss_bbox_aux_0: 0.7217 (0.8334)  loss_giou_aux_0: 1.1982 (1.3378)  loss_fgl_aux_0: 0.8851 (0.8131)  loss_ddf_aux_0: 0.0039 (0.0066)  loss_mal_aux_1: 1.3604 (1.2411)  loss_bbox_aux_1: 0.7517 (0.8226)  loss_giou_aux_1: 1.1909 (1.3194)  loss_fgl_aux_1: 0.8750 (0.8180)  loss_ddf_aux_1: 0.0024 (0.0039)  loss_mal_aux_2: 1.2910 (1.2363)  loss_bbox_aux_2: 0.7434 (0.8175)  loss_giou_aux_2: 1.1983 (1.3107)  loss_fgl_aux_2: 0.8694 (0.8184)  loss_ddf_aux_2: 0.0011 (0.0018)  loss_mal_aux_3: 1.2451 (1.2454)  loss_bbox_aux_3: 0.7410 (0.8176)  loss_giou_aux_3: 1.1961 (1.3074)  loss_fgl_aux_3: 0.8723 (0.8178)  loss_ddf_aux_3: 0.0004 (0.0006)  loss_mal_aux_4: 1.2334 (1.2366)  loss_bbox_aux_4: 0.7173 (0.8194)  loss_giou_aux_4: 1.1876 (1.3066)  loss_fgl_aux_4: 0.8725 (0.8171)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.4297 (1.1932)  loss_bbox_pre: 0.7151 (0.8382)  loss_giou_pre: 1.2020 (1.3443)  loss_mal_enc_0: 1.2754 (1.1419)  loss_bbox_enc_0: 0.6893 (0.8719)  loss_giou_enc_0: 1.2307 (1.3868)  loss_mal_dn_0: 0.6621 (0.6763)  loss_bbox_dn_0: 0.7743 (0.7949)  loss_giou_dn_0: 1.3799 (1.3830)  loss_fgl_dn_0: 0.8032 (0.8071)  loss_ddf_dn_0: 0.0128 (0.0091)  loss_mal_dn_1: 0.6357 (0.6493)  loss_bbox_dn_1: 0.7620 (0.7865)  loss_giou_dn_1: 1.3838 (1.3839)  loss_fgl_dn_1: 0.7936 (0.8014)  loss_ddf_dn_1: 0.0075 (0.0061)  loss_mal_dn_2: 0.6240 (0.6377)  loss_bbox_dn_2: 0.7512 (0.7777)  loss_giou_dn_2: 1.3925 (1.3868)  loss_fgl_dn_2: 0.7767 (0.7911)  loss_ddf_dn_2: 0.0024 (0.0023)  loss_mal_dn_3: 0.6274 (0.6456)  loss_bbox_dn_3: 0.7494 (0.7770)  loss_giou_dn_3: 1.3958 (1.3881)  loss_fgl_dn_3: 0.7700 (0.7866)  loss_ddf_dn_3: 0.0010 (0.0010)  loss_mal_dn_4: 0.6167 (0.6390)  loss_bbox_dn_4: 0.7491 (0.7764)  loss_giou_dn_4: 1.4007 (1.3900)  loss_fgl_dn_4: 0.7629 (0.7816)  loss_ddf_dn_4: 0.0003 (0.0003)  loss_mal_dn_5: 0.6162 (0.6405)  loss_bbox_dn_5: 0.7493 (0.7772)  loss_giou_dn_5: 1.4023 (1.3910)  loss_fgl_dn_5: 0.7604 (0.7790)  loss_mal_dn_pre: 0.6631 (0.6773)  loss_bbox_dn_pre: 0.7915 (0.8073)  loss_giou_dn_pre: 1.3800 (1.3828)  time: 1.2947  data: 0.0115  max mem: 13413\nEpoch: [4]  [250/251]  eta: 0:00:01  lr: 0.000001  loss: 56.7303 (56.6698)  loss_mal: 1.4121 (1.2723)  loss_bbox: 0.6572 (0.8124)  loss_giou: 1.0411 (1.2706)  loss_fgl: 1.0532 (0.8519)  loss_mal_aux_0: 1.5391 (1.2703)  loss_bbox_aux_0: 0.6506 (0.8196)  loss_giou_aux_0: 1.0493 (1.2946)  loss_fgl_aux_0: 1.0255 (0.8486)  loss_ddf_aux_0: 0.0029 (0.0059)  loss_mal_aux_1: 1.5342 (1.2966)  loss_bbox_aux_1: 0.6585 (0.8127)  loss_giou_aux_1: 1.0400 (1.2805)  loss_fgl_aux_1: 1.0392 (0.8524)  loss_ddf_aux_1: 0.0019 (0.0035)  loss_mal_aux_2: 1.3926 (1.2765)  loss_bbox_aux_2: 0.6551 (0.8095)  loss_giou_aux_2: 1.0451 (1.2741)  loss_fgl_aux_2: 1.0471 (0.8526)  loss_ddf_aux_2: 0.0008 (0.0016)  loss_mal_aux_3: 1.3838 (1.2814)  loss_bbox_aux_3: 0.6603 (0.8103)  loss_giou_aux_3: 1.0499 (1.2717)  loss_fgl_aux_3: 1.0479 (0.8521)  loss_ddf_aux_3: 0.0003 (0.0006)  loss_mal_aux_4: 1.4365 (1.2717)  loss_bbox_aux_4: 0.6592 (0.8116)  loss_giou_aux_4: 1.0459 (1.2708)  loss_fgl_aux_4: 1.0517 (0.8518)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.5293 (1.2599)  loss_bbox_pre: 0.6449 (0.8232)  loss_giou_pre: 1.0598 (1.2999)  loss_mal_enc_0: 1.4717 (1.1953)  loss_bbox_enc_0: 0.6327 (0.8522)  loss_giou_enc_0: 1.0620 (1.3391)  loss_mal_dn_0: 0.6606 (0.6740)  loss_bbox_dn_0: 0.7826 (0.8044)  loss_giou_dn_0: 1.3845 (1.3820)  loss_fgl_dn_0: 0.8037 (0.8070)  loss_ddf_dn_0: 0.0103 (0.0095)  loss_mal_dn_1: 0.6382 (0.6470)  loss_bbox_dn_1: 0.7736 (0.7955)  loss_giou_dn_1: 1.3842 (1.3830)  loss_fgl_dn_1: 0.7969 (0.8007)  loss_ddf_dn_1: 0.0061 (0.0062)  loss_mal_dn_2: 0.6255 (0.6355)  loss_bbox_dn_2: 0.7685 (0.7868)  loss_giou_dn_2: 1.3837 (1.3862)  loss_fgl_dn_2: 0.7857 (0.7900)  loss_ddf_dn_2: 0.0019 (0.0023)  loss_mal_dn_3: 0.6323 (0.6425)  loss_bbox_dn_3: 0.7678 (0.7860)  loss_giou_dn_3: 1.3833 (1.3876)  loss_fgl_dn_3: 0.7813 (0.7853)  loss_ddf_dn_3: 0.0008 (0.0010)  loss_mal_dn_4: 0.6260 (0.6361)  loss_bbox_dn_4: 0.7686 (0.7857)  loss_giou_dn_4: 1.3831 (1.3897)  loss_fgl_dn_4: 0.7773 (0.7803)  loss_ddf_dn_4: 0.0002 (0.0003)  loss_mal_dn_5: 0.6333 (0.6378)  loss_bbox_dn_5: 0.7694 (0.7865)  loss_giou_dn_5: 1.3826 (1.3907)  loss_fgl_dn_5: 0.7759 (0.7778)  loss_mal_dn_pre: 0.6621 (0.6750)  loss_bbox_dn_pre: 0.8039 (0.8179)  loss_giou_dn_pre: 1.3798 (1.3818)  time: 1.2202  data: 0.0115  max mem: 13413\nEpoch: [4] Total time: 0:05:10 (1.2380 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8065  data: 0.4904  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3527  data: 0.0641  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3052  data: 0.0205  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2937  data: 0.0196  max mem: 13413\nTest: Total time: 0:00:07 (0.3188 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.016\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.005\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.014\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.078\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.147\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.100\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.138\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.463\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.044\nbest_stat: {'epoch': 4, 'coco_eval_bbox': 0.00412699240995582}\nEpoch: [5]  [  0/251]  eta: 0:09:17  lr: 0.000001  loss: 57.1576 (57.1576)  loss_mal: 1.1260 (1.1260)  loss_bbox: 1.0037 (1.0037)  loss_giou: 1.5223 (1.5223)  loss_fgl: 0.6496 (0.6496)  loss_mal_aux_0: 1.2871 (1.2871)  loss_bbox_aux_0: 1.0081 (1.0081)  loss_giou_aux_0: 1.5412 (1.5412)  loss_fgl_aux_0: 0.6612 (0.6612)  loss_ddf_aux_0: 0.0026 (0.0026)  loss_mal_aux_1: 1.1328 (1.1328)  loss_bbox_aux_1: 1.0214 (1.0214)  loss_giou_aux_1: 1.5437 (1.5437)  loss_fgl_aux_1: 0.6573 (0.6573)  loss_ddf_aux_1: 0.0018 (0.0018)  loss_mal_aux_2: 1.0625 (1.0625)  loss_bbox_aux_2: 1.0207 (1.0207)  loss_giou_aux_2: 1.5395 (1.5395)  loss_fgl_aux_2: 0.6518 (0.6518)  loss_ddf_aux_2: 0.0007 (0.0007)  loss_mal_aux_3: 1.0957 (1.0957)  loss_bbox_aux_3: 1.0179 (1.0179)  loss_giou_aux_3: 1.5358 (1.5358)  loss_fgl_aux_3: 0.6491 (0.6491)  loss_ddf_aux_3: 0.0004 (0.0004)  loss_mal_aux_4: 1.0762 (1.0762)  loss_bbox_aux_4: 1.0088 (1.0088)  loss_giou_aux_4: 1.5264 (1.5264)  loss_fgl_aux_4: 0.6498 (0.6498)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.2744 (1.2744)  loss_bbox_pre: 1.0030 (1.0030)  loss_giou_pre: 1.5393 (1.5393)  loss_mal_enc_0: 0.9790 (0.9790)  loss_bbox_enc_0: 0.9433 (0.9433)  loss_giou_enc_0: 1.5083 (1.5083)  loss_mal_dn_0: 0.6646 (0.6646)  loss_bbox_dn_0: 0.7213 (0.7213)  loss_giou_dn_0: 1.3697 (1.3697)  loss_fgl_dn_0: 0.8150 (0.8150)  loss_ddf_dn_0: 0.0097 (0.0097)  loss_mal_dn_1: 0.6494 (0.6494)  loss_bbox_dn_1: 0.7138 (0.7138)  loss_giou_dn_1: 1.3715 (1.3715)  loss_fgl_dn_1: 0.8068 (0.8068)  loss_ddf_dn_1: 0.0056 (0.0056)  loss_mal_dn_2: 0.6274 (0.6274)  loss_bbox_dn_2: 0.7097 (0.7097)  loss_giou_dn_2: 1.3753 (1.3753)  loss_fgl_dn_2: 0.7957 (0.7957)  loss_ddf_dn_2: 0.0018 (0.0018)  loss_mal_dn_3: 0.6357 (0.6357)  loss_bbox_dn_3: 0.7096 (0.7096)  loss_giou_dn_3: 1.3763 (1.3763)  loss_fgl_dn_3: 0.7913 (0.7913)  loss_ddf_dn_3: 0.0007 (0.0007)  loss_mal_dn_4: 0.6289 (0.6289)  loss_bbox_dn_4: 0.7117 (0.7117)  loss_giou_dn_4: 1.3785 (1.3785)  loss_fgl_dn_4: 0.7874 (0.7874)  loss_ddf_dn_4: 0.0002 (0.0002)  loss_mal_dn_5: 0.6138 (0.6138)  loss_bbox_dn_5: 0.7127 (0.7127)  loss_giou_dn_5: 1.3790 (1.3790)  loss_fgl_dn_5: 0.7860 (0.7860)  loss_mal_dn_pre: 0.6660 (0.6660)  loss_bbox_dn_pre: 0.7324 (0.7324)  loss_giou_dn_pre: 1.3686 (1.3686)  time: 2.2230  data: 0.8633  max mem: 13413\nEpoch: [5]  [100/251]  eta: 0:03:04  lr: 0.000001  loss: 56.3325 (57.1243)  loss_mal: 1.5498 (1.5070)  loss_bbox: 0.5703 (0.6795)  loss_giou: 0.9903 (1.0475)  loss_fgl: 1.1013 (1.0520)  loss_mal_aux_0: 1.5801 (1.6139)  loss_bbox_aux_0: 0.5799 (0.6846)  loss_giou_aux_0: 0.9908 (1.0559)  loss_fgl_aux_0: 1.1008 (1.0521)  loss_ddf_aux_0: 0.0027 (0.0027)  loss_mal_aux_1: 1.5469 (1.5434)  loss_bbox_aux_1: 0.5867 (0.6886)  loss_giou_aux_1: 0.9922 (1.0585)  loss_fgl_aux_1: 1.0992 (1.0505)  loss_ddf_aux_1: 0.0020 (0.0020)  loss_mal_aux_2: 1.5176 (1.4982)  loss_bbox_aux_2: 0.5840 (0.6863)  loss_giou_aux_2: 0.9898 (1.0560)  loss_fgl_aux_2: 1.0977 (1.0501)  loss_ddf_aux_2: 0.0008 (0.0008)  loss_mal_aux_3: 1.4932 (1.4912)  loss_bbox_aux_3: 0.5816 (0.6846)  loss_giou_aux_3: 0.9888 (1.0541)  loss_fgl_aux_3: 1.0978 (1.0502)  loss_ddf_aux_3: 0.0003 (0.0004)  loss_mal_aux_4: 1.5195 (1.5018)  loss_bbox_aux_4: 0.5769 (0.6815)  loss_giou_aux_4: 0.9903 (1.0503)  loss_fgl_aux_4: 1.0996 (1.0511)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.6230 (1.6049)  loss_bbox_pre: 0.5901 (0.6845)  loss_giou_pre: 0.9922 (1.0557)  loss_mal_enc_0: 1.6602 (1.6054)  loss_bbox_enc_0: 0.5823 (0.6765)  loss_giou_enc_0: 0.9863 (1.0530)  loss_mal_dn_0: 0.6519 (0.6587)  loss_bbox_dn_0: 0.7678 (0.8150)  loss_giou_dn_0: 1.3809 (1.3809)  loss_fgl_dn_0: 0.7970 (0.8037)  loss_ddf_dn_0: 0.0128 (0.0120)  loss_mal_dn_1: 0.6260 (0.6364)  loss_bbox_dn_1: 0.7583 (0.8056)  loss_giou_dn_1: 1.3872 (1.3834)  loss_fgl_dn_1: 0.7836 (0.7943)  loss_ddf_dn_1: 0.0075 (0.0070)  loss_mal_dn_2: 0.6133 (0.6235)  loss_bbox_dn_2: 0.7498 (0.8007)  loss_giou_dn_2: 1.3935 (1.3889)  loss_fgl_dn_2: 0.7710 (0.7820)  loss_ddf_dn_2: 0.0022 (0.0021)  loss_mal_dn_3: 0.6128 (0.6253)  loss_bbox_dn_3: 0.7483 (0.8009)  loss_giou_dn_3: 1.3944 (1.3911)  loss_fgl_dn_3: 0.7670 (0.7776)  loss_ddf_dn_3: 0.0009 (0.0009)  loss_mal_dn_4: 0.6128 (0.6223)  loss_bbox_dn_4: 0.7485 (0.8032)  loss_giou_dn_4: 1.3983 (1.3941)  loss_fgl_dn_4: 0.7648 (0.7742)  loss_ddf_dn_4: 0.0002 (0.0002)  loss_mal_dn_5: 0.6040 (0.6212)  loss_bbox_dn_5: 0.7490 (0.8046)  loss_giou_dn_5: 1.3990 (1.3949)  loss_fgl_dn_5: 0.7645 (0.7733)  loss_mal_dn_pre: 0.6548 (0.6604)  loss_bbox_dn_pre: 0.7832 (0.8317)  loss_giou_dn_pre: 1.3780 (1.3790)  time: 1.2091  data: 0.0117  max mem: 13413\nEpoch: [5]  [200/251]  eta: 0:01:02  lr: 0.000001  loss: 55.8223 (56.8959)  loss_mal: 1.4170 (1.5306)  loss_bbox: 0.5629 (0.6459)  loss_giou: 1.0315 (1.0134)  loss_fgl: 1.0566 (1.0809)  loss_mal_aux_0: 1.5469 (1.6347)  loss_bbox_aux_0: 0.6149 (0.6538)  loss_giou_aux_0: 1.0378 (1.0242)  loss_fgl_aux_0: 1.0734 (1.0806)  loss_ddf_aux_0: 0.0028 (0.0030)  loss_mal_aux_1: 1.4883 (1.5792)  loss_bbox_aux_1: 0.6089 (0.6553)  loss_giou_aux_1: 1.0333 (1.0248)  loss_fgl_aux_1: 1.0750 (1.0800)  loss_ddf_aux_1: 0.0020 (0.0021)  loss_mal_aux_2: 1.4961 (1.5280)  loss_bbox_aux_2: 0.5894 (0.6520)  loss_giou_aux_2: 1.0305 (1.0215)  loss_fgl_aux_2: 1.0677 (1.0795)  loss_ddf_aux_2: 0.0008 (0.0009)  loss_mal_aux_3: 1.5303 (1.5304)  loss_bbox_aux_3: 0.5791 (0.6502)  loss_giou_aux_3: 1.0276 (1.0195)  loss_fgl_aux_3: 1.0642 (1.0795)  loss_ddf_aux_3: 0.0004 (0.0004)  loss_mal_aux_4: 1.4395 (1.5284)  loss_bbox_aux_4: 0.5683 (0.6476)  loss_giou_aux_4: 1.0292 (1.0159)  loss_fgl_aux_4: 1.0600 (1.0802)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.5371 (1.6243)  loss_bbox_pre: 0.6250 (0.6548)  loss_giou_pre: 1.0360 (1.0249)  loss_mal_enc_0: 1.6094 (1.6245)  loss_bbox_enc_0: 0.5743 (0.6502)  loss_giou_enc_0: 1.0291 (1.0230)  loss_mal_dn_0: 0.6475 (0.6565)  loss_bbox_dn_0: 0.7770 (0.8043)  loss_giou_dn_0: 1.3852 (1.3812)  loss_fgl_dn_0: 0.7930 (0.8017)  loss_ddf_dn_0: 0.0133 (0.0129)  loss_mal_dn_1: 0.6294 (0.6341)  loss_bbox_dn_1: 0.7681 (0.7953)  loss_giou_dn_1: 1.3895 (1.3837)  loss_fgl_dn_1: 0.7826 (0.7918)  loss_ddf_dn_1: 0.0074 (0.0073)  loss_mal_dn_2: 0.6152 (0.6225)  loss_bbox_dn_2: 0.7639 (0.7906)  loss_giou_dn_2: 1.3909 (1.3883)  loss_fgl_dn_2: 0.7731 (0.7802)  loss_ddf_dn_2: 0.0022 (0.0021)  loss_mal_dn_3: 0.6182 (0.6245)  loss_bbox_dn_3: 0.7628 (0.7904)  loss_giou_dn_3: 1.3899 (1.3899)  loss_fgl_dn_3: 0.7712 (0.7764)  loss_ddf_dn_3: 0.0009 (0.0009)  loss_mal_dn_4: 0.6172 (0.6217)  loss_bbox_dn_4: 0.7620 (0.7917)  loss_giou_dn_4: 1.3890 (1.3916)  loss_fgl_dn_4: 0.7712 (0.7740)  loss_ddf_dn_4: 0.0002 (0.0002)  loss_mal_dn_5: 0.6177 (0.6209)  loss_bbox_dn_5: 0.7616 (0.7926)  loss_giou_dn_5: 1.3876 (1.3917)  loss_fgl_dn_5: 0.7722 (0.7737)  loss_mal_dn_pre: 0.6499 (0.6586)  loss_bbox_dn_pre: 0.7920 (0.8210)  loss_giou_dn_pre: 1.3823 (1.3790)  time: 1.2040  data: 0.0113  max mem: 13413\nEpoch: [5]  [250/251]  eta: 0:00:01  lr: 0.000001  loss: 54.3248 (56.5899)  loss_mal: 1.5430 (1.5361)  loss_bbox: 0.4580 (0.6215)  loss_giou: 0.8640 (0.9952)  loss_fgl: 1.1726 (1.0954)  loss_mal_aux_0: 1.6367 (1.6436)  loss_bbox_aux_0: 0.4652 (0.6279)  loss_giou_aux_0: 0.8632 (1.0047)  loss_fgl_aux_0: 1.1764 (1.0971)  loss_ddf_aux_0: 0.0030 (0.0030)  loss_mal_aux_1: 1.6533 (1.5844)  loss_bbox_aux_1: 0.4592 (0.6288)  loss_giou_aux_1: 0.8718 (1.0051)  loss_fgl_aux_1: 1.1813 (1.0963)  loss_ddf_aux_1: 0.0020 (0.0021)  loss_mal_aux_2: 1.5928 (1.5392)  loss_bbox_aux_2: 0.4513 (0.6258)  loss_giou_aux_2: 0.8789 (1.0022)  loss_fgl_aux_2: 1.1820 (1.0953)  loss_ddf_aux_2: 0.0008 (0.0009)  loss_mal_aux_3: 1.5781 (1.5368)  loss_bbox_aux_3: 0.4482 (0.6244)  loss_giou_aux_3: 0.8786 (1.0004)  loss_fgl_aux_3: 1.1805 (1.0950)  loss_ddf_aux_3: 0.0004 (0.0004)  loss_mal_aux_4: 1.5059 (1.5263)  loss_bbox_aux_4: 0.4520 (0.6225)  loss_giou_aux_4: 0.8706 (0.9974)  loss_fgl_aux_4: 1.1770 (1.0952)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.6172 (1.6321)  loss_bbox_pre: 0.4681 (0.6292)  loss_giou_pre: 0.8648 (1.0056)  loss_mal_enc_0: 1.5830 (1.6299)  loss_bbox_enc_0: 0.4883 (0.6259)  loss_giou_enc_0: 0.8808 (1.0044)  loss_mal_dn_0: 0.6387 (0.6540)  loss_bbox_dn_0: 0.6796 (0.7933)  loss_giou_dn_0: 1.3883 (1.3814)  loss_fgl_dn_0: 0.7902 (0.8008)  loss_ddf_dn_0: 0.0129 (0.0130)  loss_mal_dn_1: 0.6191 (0.6323)  loss_bbox_dn_1: 0.6710 (0.7847)  loss_giou_dn_1: 1.3895 (1.3839)  loss_fgl_dn_1: 0.7801 (0.7908)  loss_ddf_dn_1: 0.0068 (0.0073)  loss_mal_dn_2: 0.6108 (0.6215)  loss_bbox_dn_2: 0.6651 (0.7802)  loss_giou_dn_2: 1.3905 (1.3880)  loss_fgl_dn_2: 0.7722 (0.7799)  loss_ddf_dn_2: 0.0021 (0.0021)  loss_mal_dn_3: 0.6133 (0.6233)  loss_bbox_dn_3: 0.6632 (0.7799)  loss_giou_dn_3: 1.3900 (1.3892)  loss_fgl_dn_3: 0.7705 (0.7765)  loss_ddf_dn_3: 0.0008 (0.0009)  loss_mal_dn_4: 0.6138 (0.6200)  loss_bbox_dn_4: 0.6622 (0.7809)  loss_giou_dn_4: 1.3885 (1.3903)  loss_fgl_dn_4: 0.7707 (0.7747)  loss_ddf_dn_4: 0.0002 (0.0002)  loss_mal_dn_5: 0.6123 (0.6199)  loss_bbox_dn_5: 0.6616 (0.7815)  loss_giou_dn_5: 1.3864 (1.3900)  loss_fgl_dn_5: 0.7716 (0.7746)  loss_mal_dn_pre: 0.6421 (0.6562)  loss_bbox_dn_pre: 0.6994 (0.8098)  loss_giou_dn_pre: 1.3863 (1.3790)  time: 1.2549  data: 0.0116  max mem: 13413\nEpoch: [5] Total time: 0:05:08 (1.2309 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8131  data: 0.4878  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3544  data: 0.0652  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3052  data: 0.0202  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2936  data: 0.0195  max mem: 13413\nTest: Total time: 0:00:07 (0.3195 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.023\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.087\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.037\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.022\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.056\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.183\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.250\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.317\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.218\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.619\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.173\nbest_stat: {'epoch': 5, 'coco_eval_bbox': 0.022854988592235653}\nEpoch: [6]  [  0/251]  eta: 0:07:01  lr: 0.000001  loss: 57.0038 (57.0038)  loss_mal: 1.3164 (1.3164)  loss_bbox: 0.7161 (0.7161)  loss_giou: 1.1699 (1.1699)  loss_fgl: 0.9360 (0.9360)  loss_mal_aux_0: 1.4785 (1.4785)  loss_bbox_aux_0: 0.6937 (0.6937)  loss_giou_aux_0: 1.1646 (1.1646)  loss_fgl_aux_0: 0.9669 (0.9669)  loss_ddf_aux_0: 0.0025 (0.0025)  loss_mal_aux_1: 1.4023 (1.4023)  loss_bbox_aux_1: 0.6952 (0.6952)  loss_giou_aux_1: 1.1668 (1.1668)  loss_fgl_aux_1: 0.9596 (0.9596)  loss_ddf_aux_1: 0.0017 (0.0017)  loss_mal_aux_2: 1.2178 (1.2178)  loss_bbox_aux_2: 0.7020 (0.7020)  loss_giou_aux_2: 1.1679 (1.1679)  loss_fgl_aux_2: 0.9498 (0.9498)  loss_ddf_aux_2: 0.0007 (0.0007)  loss_mal_aux_3: 1.3135 (1.3135)  loss_bbox_aux_3: 0.7070 (0.7070)  loss_giou_aux_3: 1.1661 (1.1661)  loss_fgl_aux_3: 0.9461 (0.9461)  loss_ddf_aux_3: 0.0003 (0.0003)  loss_mal_aux_4: 1.3936 (1.3936)  loss_bbox_aux_4: 0.7132 (0.7132)  loss_giou_aux_4: 1.1687 (1.1687)  loss_fgl_aux_4: 0.9396 (0.9396)  loss_ddf_aux_4: 0.0000 (0.0000)  loss_mal_pre: 1.4766 (1.4766)  loss_bbox_pre: 0.6979 (0.6979)  loss_giou_pre: 1.1648 (1.1648)  loss_mal_enc_0: 1.3164 (1.3164)  loss_bbox_enc_0: 0.6957 (0.6957)  loss_giou_enc_0: 1.1838 (1.1838)  loss_mal_dn_0: 0.6235 (0.6235)  loss_bbox_dn_0: 0.9478 (0.9478)  loss_giou_dn_0: 1.4152 (1.4152)  loss_fgl_dn_0: 0.7708 (0.7708)  loss_ddf_dn_0: 0.0133 (0.0133)  loss_mal_dn_1: 0.6255 (0.6255)  loss_bbox_dn_1: 0.9361 (0.9361)  loss_giou_dn_1: 1.4157 (1.4157)  loss_fgl_dn_1: 0.7613 (0.7613)  loss_ddf_dn_1: 0.0071 (0.0071)  loss_mal_dn_2: 0.6182 (0.6182)  loss_bbox_dn_2: 0.9285 (0.9285)  loss_giou_dn_2: 1.4153 (1.4153)  loss_fgl_dn_2: 0.7534 (0.7534)  loss_ddf_dn_2: 0.0021 (0.0021)  loss_mal_dn_3: 0.6255 (0.6255)  loss_bbox_dn_3: 0.9260 (0.9260)  loss_giou_dn_3: 1.4142 (1.4142)  loss_fgl_dn_3: 0.7516 (0.7516)  loss_ddf_dn_3: 0.0008 (0.0008)  loss_mal_dn_4: 0.6294 (0.6294)  loss_bbox_dn_4: 0.9242 (0.9242)  loss_giou_dn_4: 1.4119 (1.4119)  loss_fgl_dn_4: 0.7518 (0.7518)  loss_ddf_dn_4: 0.0002 (0.0002)  loss_mal_dn_5: 0.6436 (0.6436)  loss_bbox_dn_5: 0.9234 (0.9234)  loss_giou_dn_5: 1.4104 (1.4104)  loss_fgl_dn_5: 0.7526 (0.7526)  loss_mal_dn_pre: 0.6235 (0.6235)  loss_bbox_dn_pre: 0.9746 (0.9746)  loss_giou_dn_pre: 1.4150 (1.4150)  time: 1.6804  data: 0.5506  max mem: 13413\nEpoch: [6]  [100/251]  eta: 0:03:09  lr: 0.000002  loss: 55.2437 (55.6834)  loss_mal: 1.5439 (1.5399)  loss_bbox: 0.4736 (0.5598)  loss_giou: 0.8414 (0.9203)  loss_fgl: 1.1721 (1.1469)  loss_mal_aux_0: 1.6113 (1.6100)  loss_bbox_aux_0: 0.4851 (0.5678)  loss_giou_aux_0: 0.8957 (0.9338)  loss_fgl_aux_0: 1.1658 (1.1557)  loss_ddf_aux_0: 0.0038 (0.0034)  loss_mal_aux_1: 1.6250 (1.5788)  loss_bbox_aux_1: 0.4779 (0.5653)  loss_giou_aux_1: 0.8853 (0.9312)  loss_fgl_aux_1: 1.1633 (1.1542)  loss_ddf_aux_1: 0.0024 (0.0023)  loss_mal_aux_2: 1.5645 (1.5355)  loss_bbox_aux_2: 0.4708 (0.5628)  loss_giou_aux_2: 0.8704 (0.9285)  loss_fgl_aux_2: 1.1618 (1.1502)  loss_ddf_aux_2: 0.0010 (0.0009)  loss_mal_aux_3: 1.5449 (1.5252)  loss_bbox_aux_3: 0.4679 (0.5616)  loss_giou_aux_3: 0.8624 (0.9262)  loss_fgl_aux_3: 1.1597 (1.1487)  loss_ddf_aux_3: 0.0004 (0.0004)  loss_mal_aux_4: 1.5508 (1.5369)  loss_bbox_aux_4: 0.4718 (0.5606)  loss_giou_aux_4: 0.8515 (0.9230)  loss_fgl_aux_4: 1.1674 (1.1477)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.6172 (1.5993)  loss_bbox_pre: 0.4887 (0.5713)  loss_giou_pre: 0.9059 (0.9364)  loss_mal_enc_0: 1.6592 (1.6556)  loss_bbox_enc_0: 0.5048 (0.5751)  loss_giou_enc_0: 0.9098 (0.9397)  loss_mal_dn_0: 0.6353 (0.6409)  loss_bbox_dn_0: 0.7487 (0.7860)  loss_giou_dn_0: 1.3929 (1.3844)  loss_fgl_dn_0: 0.7799 (0.7923)  loss_ddf_dn_0: 0.0160 (0.0151)  loss_mal_dn_1: 0.6167 (0.6224)  loss_bbox_dn_1: 0.7416 (0.7792)  loss_giou_dn_1: 1.3942 (1.3869)  loss_fgl_dn_1: 0.7687 (0.7813)  loss_ddf_dn_1: 0.0081 (0.0078)  loss_mal_dn_2: 0.6074 (0.6138)  loss_bbox_dn_2: 0.7368 (0.7758)  loss_giou_dn_2: 1.3951 (1.3884)  loss_fgl_dn_2: 0.7632 (0.7741)  loss_ddf_dn_2: 0.0023 (0.0023)  loss_mal_dn_3: 0.6138 (0.6167)  loss_bbox_dn_3: 0.7347 (0.7744)  loss_giou_dn_3: 1.3933 (1.3875)  loss_fgl_dn_3: 0.7618 (0.7730)  loss_ddf_dn_3: 0.0010 (0.0010)  loss_mal_dn_4: 0.6079 (0.6160)  loss_bbox_dn_4: 0.7338 (0.7734)  loss_giou_dn_4: 1.3907 (1.3853)  loss_fgl_dn_4: 0.7626 (0.7742)  loss_ddf_dn_4: 0.0003 (0.0003)  loss_mal_dn_5: 0.6113 (0.6174)  loss_bbox_dn_5: 0.7327 (0.7726)  loss_giou_dn_5: 1.3867 (1.3828)  loss_fgl_dn_5: 0.7650 (0.7759)  loss_mal_dn_pre: 0.6372 (0.6443)  loss_bbox_dn_pre: 0.7647 (0.8025)  loss_giou_dn_pre: 1.3876 (1.3805)  time: 1.2853  data: 0.0116  max mem: 13413\nEpoch: [6]  [200/251]  eta: 0:01:03  lr: 0.000002  loss: 55.3569 (55.5214)  loss_mal: 1.5020 (1.5466)  loss_bbox: 0.4470 (0.5407)  loss_giou: 0.8248 (0.9000)  loss_fgl: 1.2197 (1.1634)  loss_mal_aux_0: 1.6230 (1.6248)  loss_bbox_aux_0: 0.4516 (0.5508)  loss_giou_aux_0: 0.8242 (0.9165)  loss_fgl_aux_0: 1.2260 (1.1706)  loss_ddf_aux_0: 0.0045 (0.0038)  loss_mal_aux_1: 1.5928 (1.5722)  loss_bbox_aux_1: 0.4475 (0.5476)  loss_giou_aux_1: 0.8213 (0.9132)  loss_fgl_aux_1: 1.2252 (1.1697)  loss_ddf_aux_1: 0.0031 (0.0026)  loss_mal_aux_2: 1.5264 (1.5424)  loss_bbox_aux_2: 0.4441 (0.5447)  loss_giou_aux_2: 0.8244 (0.9101)  loss_fgl_aux_2: 1.2213 (1.1660)  loss_ddf_aux_2: 0.0014 (0.0010)  loss_mal_aux_3: 1.5137 (1.5337)  loss_bbox_aux_3: 0.4443 (0.5431)  loss_giou_aux_3: 0.8276 (0.9073)  loss_fgl_aux_3: 1.2203 (1.1650)  loss_ddf_aux_3: 0.0007 (0.0005)  loss_mal_aux_4: 1.5674 (1.5447)  loss_bbox_aux_4: 0.4421 (0.5416)  loss_giou_aux_4: 0.8262 (0.9033)  loss_fgl_aux_4: 1.2203 (1.1642)  loss_ddf_aux_4: 0.0002 (0.0001)  loss_mal_pre: 1.6162 (1.6151)  loss_bbox_pre: 0.4517 (0.5543)  loss_giou_pre: 0.8179 (0.9185)  loss_mal_enc_0: 1.7178 (1.6420)  loss_bbox_enc_0: 0.4554 (0.5599)  loss_giou_enc_0: 0.8306 (0.9241)  loss_mal_dn_0: 0.6289 (0.6368)  loss_bbox_dn_0: 0.7816 (0.7891)  loss_giou_dn_0: 1.3827 (1.3852)  loss_fgl_dn_0: 0.7876 (0.7897)  loss_ddf_dn_0: 0.0162 (0.0156)  loss_mal_dn_1: 0.6128 (0.6184)  loss_bbox_dn_1: 0.7773 (0.7828)  loss_giou_dn_1: 1.3828 (1.3875)  loss_fgl_dn_1: 0.7793 (0.7790)  loss_ddf_dn_1: 0.0088 (0.0081)  loss_mal_dn_2: 0.6055 (0.6103)  loss_bbox_dn_2: 0.7738 (0.7794)  loss_giou_dn_2: 1.3806 (1.3882)  loss_fgl_dn_2: 0.7759 (0.7730)  loss_ddf_dn_2: 0.0029 (0.0025)  loss_mal_dn_3: 0.6079 (0.6122)  loss_bbox_dn_3: 0.7714 (0.7777)  loss_giou_dn_3: 1.3772 (1.3867)  loss_fgl_dn_3: 0.7768 (0.7726)  loss_ddf_dn_3: 0.0013 (0.0010)  loss_mal_dn_4: 0.6104 (0.6129)  loss_bbox_dn_4: 0.7695 (0.7763)  loss_giou_dn_4: 1.3715 (1.3835)  loss_fgl_dn_4: 0.7809 (0.7747)  loss_ddf_dn_4: 0.0004 (0.0003)  loss_mal_dn_5: 0.6113 (0.6151)  loss_bbox_dn_5: 0.7682 (0.7752)  loss_giou_dn_5: 1.3647 (1.3802)  loss_fgl_dn_5: 0.7851 (0.7770)  loss_mal_dn_pre: 0.6333 (0.6408)  loss_bbox_dn_pre: 0.7956 (0.8050)  loss_giou_dn_pre: 1.3791 (1.3808)  time: 1.1378  data: 0.0116  max mem: 13413\nEpoch: [6]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 53.7817 (55.3393)  loss_mal: 1.5264 (1.5428)  loss_bbox: 0.4594 (0.5285)  loss_giou: 0.8097 (0.8929)  loss_fgl: 1.1967 (1.1651)  loss_mal_aux_0: 1.5713 (1.6201)  loss_bbox_aux_0: 0.4676 (0.5400)  loss_giou_aux_0: 0.8627 (0.9121)  loss_fgl_aux_0: 1.2247 (1.1739)  loss_ddf_aux_0: 0.0060 (0.0042)  loss_mal_aux_1: 1.5762 (1.5643)  loss_bbox_aux_1: 0.4651 (0.5367)  loss_giou_aux_1: 0.8530 (0.9082)  loss_fgl_aux_1: 1.2177 (1.1728)  loss_ddf_aux_1: 0.0045 (0.0028)  loss_mal_aux_2: 1.5234 (1.5359)  loss_bbox_aux_2: 0.4619 (0.5336)  loss_giou_aux_2: 0.8475 (0.9046)  loss_fgl_aux_2: 1.2028 (1.1686)  loss_ddf_aux_2: 0.0021 (0.0012)  loss_mal_aux_3: 1.5488 (1.5284)  loss_bbox_aux_3: 0.4486 (0.5315)  loss_giou_aux_3: 0.8274 (0.9011)  loss_fgl_aux_3: 1.2002 (1.1674)  loss_ddf_aux_3: 0.0011 (0.0006)  loss_mal_aux_4: 1.5400 (1.5361)  loss_bbox_aux_4: 0.4633 (0.5296)  loss_giou_aux_4: 0.8179 (0.8965)  loss_fgl_aux_4: 1.1979 (1.1662)  loss_ddf_aux_4: 0.0003 (0.0001)  loss_mal_pre: 1.5537 (1.6095)  loss_bbox_pre: 0.4768 (0.5438)  loss_giou_pre: 0.8611 (0.9148)  loss_mal_enc_0: 1.6826 (1.6408)  loss_bbox_enc_0: 0.4925 (0.5499)  loss_giou_enc_0: 0.8813 (0.9210)  loss_mal_dn_0: 0.6206 (0.6344)  loss_bbox_dn_0: 0.7317 (0.7872)  loss_giou_dn_0: 1.3856 (1.3858)  loss_fgl_dn_0: 0.7823 (0.7885)  loss_ddf_dn_0: 0.0175 (0.0157)  loss_mal_dn_1: 0.6069 (0.6167)  loss_bbox_dn_1: 0.7254 (0.7810)  loss_giou_dn_1: 1.3872 (1.3877)  loss_fgl_dn_1: 0.7754 (0.7783)  loss_ddf_dn_1: 0.0102 (0.0083)  loss_mal_dn_2: 0.6025 (0.6092)  loss_bbox_dn_2: 0.7202 (0.7775)  loss_giou_dn_2: 1.3854 (1.3876)  loss_fgl_dn_2: 0.7741 (0.7733)  loss_ddf_dn_2: 0.0035 (0.0026)  loss_mal_dn_3: 0.6089 (0.6113)  loss_bbox_dn_3: 0.7161 (0.7756)  loss_giou_dn_3: 1.3823 (1.3856)  loss_fgl_dn_3: 0.7762 (0.7733)  loss_ddf_dn_3: 0.0015 (0.0011)  loss_mal_dn_4: 0.6147 (0.6127)  loss_bbox_dn_4: 0.7119 (0.7741)  loss_giou_dn_4: 1.3751 (1.3818)  loss_fgl_dn_4: 0.7818 (0.7760)  loss_ddf_dn_4: 0.0004 (0.0003)  loss_mal_dn_5: 0.6211 (0.6154)  loss_bbox_dn_5: 0.7073 (0.7729)  loss_giou_dn_5: 1.3637 (1.3779)  loss_fgl_dn_5: 0.7860 (0.7788)  loss_mal_dn_pre: 0.6235 (0.6383)  loss_bbox_dn_pre: 0.7476 (0.8028)  loss_giou_dn_pre: 1.3812 (1.3815)  time: 1.1012  data: 0.0115  max mem: 13413\nEpoch: [6] Total time: 0:05:09 (1.2319 s / it)\nTest:  [ 0/25]  eta: 0:00:18    time: 0.7567  data: 0.4551  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3508  data: 0.0631  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3063  data: 0.0212  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2947  data: 0.0201  max mem: 13413\nTest: Total time: 0:00:07 (0.3185 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.035\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.130\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.057\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.037\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.236\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.292\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.309\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.772\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.179\nbest_stat: {'epoch': 6, 'coco_eval_bbox': 0.03539413346017755}\nEpoch: [7]  [  0/251]  eta: 0:06:13  lr: 0.000002  loss: 51.0266 (51.0266)  loss_mal: 1.5225 (1.5225)  loss_bbox: 0.3511 (0.3511)  loss_giou: 0.8710 (0.8710)  loss_fgl: 1.0864 (1.0864)  loss_mal_aux_0: 1.4570 (1.4570)  loss_bbox_aux_0: 0.3943 (0.3943)  loss_giou_aux_0: 0.9670 (0.9670)  loss_fgl_aux_0: 1.0719 (1.0719)  loss_ddf_aux_0: 0.0062 (0.0062)  loss_mal_aux_1: 1.5137 (1.5137)  loss_bbox_aux_1: 0.3805 (0.3805)  loss_giou_aux_1: 0.9482 (0.9482)  loss_fgl_aux_1: 1.0694 (1.0694)  loss_ddf_aux_1: 0.0043 (0.0043)  loss_mal_aux_2: 1.4121 (1.4121)  loss_bbox_aux_2: 0.3706 (0.3706)  loss_giou_aux_2: 0.9255 (0.9255)  loss_fgl_aux_2: 1.0689 (1.0689)  loss_ddf_aux_2: 0.0021 (0.0021)  loss_mal_aux_3: 1.6094 (1.6094)  loss_bbox_aux_3: 0.3686 (0.3686)  loss_giou_aux_3: 0.9093 (0.9093)  loss_fgl_aux_3: 1.0722 (1.0722)  loss_ddf_aux_3: 0.0010 (0.0010)  loss_mal_aux_4: 1.5117 (1.5117)  loss_bbox_aux_4: 0.3598 (0.3598)  loss_giou_aux_4: 0.8834 (0.8834)  loss_fgl_aux_4: 1.0840 (1.0840)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.4316 (1.4316)  loss_bbox_pre: 0.4063 (0.4063)  loss_giou_pre: 0.9858 (0.9858)  loss_mal_enc_0: 1.4189 (1.4189)  loss_bbox_enc_0: 0.4251 (0.4251)  loss_giou_enc_0: 1.0038 (1.0038)  loss_mal_dn_0: 0.6147 (0.6147)  loss_bbox_dn_0: 0.5131 (0.5131)  loss_giou_dn_0: 1.3675 (1.3675)  loss_fgl_dn_0: 0.7942 (0.7942)  loss_ddf_dn_0: 0.0239 (0.0239)  loss_mal_dn_1: 0.6089 (0.6089)  loss_bbox_dn_1: 0.5081 (0.5081)  loss_giou_dn_1: 1.3683 (1.3683)  loss_fgl_dn_1: 0.7844 (0.7844)  loss_ddf_dn_1: 0.0122 (0.0122)  loss_mal_dn_2: 0.6011 (0.6011)  loss_bbox_dn_2: 0.5061 (0.5061)  loss_giou_dn_2: 1.3685 (1.3685)  loss_fgl_dn_2: 0.7819 (0.7819)  loss_ddf_dn_2: 0.0042 (0.0042)  loss_mal_dn_3: 0.6035 (0.6035)  loss_bbox_dn_3: 0.5046 (0.5046)  loss_giou_dn_3: 1.3675 (1.3675)  loss_fgl_dn_3: 0.7824 (0.7824)  loss_ddf_dn_3: 0.0016 (0.0016)  loss_mal_dn_4: 0.5889 (0.5889)  loss_bbox_dn_4: 0.5042 (0.5042)  loss_giou_dn_4: 1.3659 (1.3659)  loss_fgl_dn_4: 0.7849 (0.7849)  loss_ddf_dn_4: 0.0004 (0.0004)  loss_mal_dn_5: 0.6094 (0.6094)  loss_bbox_dn_5: 0.5032 (0.5032)  loss_giou_dn_5: 1.3635 (1.3635)  loss_fgl_dn_5: 0.7868 (0.7868)  loss_mal_dn_pre: 0.6196 (0.6196)  loss_bbox_dn_pre: 0.5258 (0.5258)  loss_giou_dn_pre: 1.3633 (1.3633)  time: 1.4881  data: 0.4483  max mem: 13413\nEpoch: [7]  [100/251]  eta: 0:03:04  lr: 0.000002  loss: 54.3300 (54.6362)  loss_mal: 1.6270 (1.5454)  loss_bbox: 0.4418 (0.4947)  loss_giou: 0.8064 (0.8575)  loss_fgl: 1.1810 (1.1769)  loss_mal_aux_0: 1.5771 (1.5626)  loss_bbox_aux_0: 0.4344 (0.5092)  loss_giou_aux_0: 0.7996 (0.8939)  loss_fgl_aux_0: 1.2253 (1.1921)  loss_ddf_aux_0: 0.0097 (0.0079)  loss_mal_aux_1: 1.4971 (1.5098)  loss_bbox_aux_1: 0.4316 (0.5047)  loss_giou_aux_1: 0.7998 (0.8831)  loss_fgl_aux_1: 1.2260 (1.1919)  loss_ddf_aux_1: 0.0066 (0.0056)  loss_mal_aux_2: 1.5645 (1.4924)  loss_bbox_aux_2: 0.4235 (0.5009)  loss_giou_aux_2: 0.8027 (0.8750)  loss_fgl_aux_2: 1.2238 (1.1863)  loss_ddf_aux_2: 0.0032 (0.0027)  loss_mal_aux_3: 1.5723 (1.5169)  loss_bbox_aux_3: 0.4305 (0.4971)  loss_giou_aux_3: 0.7958 (0.8672)  loss_fgl_aux_3: 1.2155 (1.1849)  loss_ddf_aux_3: 0.0016 (0.0014)  loss_mal_aux_4: 1.5537 (1.5197)  loss_bbox_aux_4: 0.4448 (0.4951)  loss_giou_aux_4: 0.8120 (0.8611)  loss_fgl_aux_4: 1.1927 (1.1810)  loss_ddf_aux_4: 0.0004 (0.0003)  loss_mal_pre: 1.4971 (1.5423)  loss_bbox_pre: 0.4404 (0.5147)  loss_giou_pre: 0.8153 (0.9003)  loss_mal_enc_0: 1.6045 (1.6137)  loss_bbox_enc_0: 0.4495 (0.5251)  loss_giou_enc_0: 0.8842 (0.9164)  loss_mal_dn_0: 0.6226 (0.6233)  loss_bbox_dn_0: 0.7069 (0.7827)  loss_giou_dn_0: 1.3712 (1.3840)  loss_fgl_dn_0: 0.7883 (0.7829)  loss_ddf_dn_0: 0.0272 (0.0215)  loss_mal_dn_1: 0.6089 (0.6102)  loss_bbox_dn_1: 0.7031 (0.7775)  loss_giou_dn_1: 1.3707 (1.3831)  loss_fgl_dn_1: 0.7825 (0.7764)  loss_ddf_dn_1: 0.0159 (0.0126)  loss_mal_dn_2: 0.6123 (0.6101)  loss_bbox_dn_2: 0.6980 (0.7724)  loss_giou_dn_2: 1.3640 (1.3771)  loss_fgl_dn_2: 0.7859 (0.7783)  loss_ddf_dn_2: 0.0060 (0.0047)  loss_mal_dn_3: 0.6113 (0.6148)  loss_bbox_dn_3: 0.6935 (0.7677)  loss_giou_dn_3: 1.3569 (1.3698)  loss_fgl_dn_3: 0.7912 (0.7824)  loss_ddf_dn_3: 0.0025 (0.0020)  loss_mal_dn_4: 0.6235 (0.6227)  loss_bbox_dn_4: 0.6888 (0.7628)  loss_giou_dn_4: 1.3456 (1.3590)  loss_fgl_dn_4: 0.7970 (0.7898)  loss_ddf_dn_4: 0.0006 (0.0005)  loss_mal_dn_5: 0.6274 (0.6316)  loss_bbox_dn_5: 0.6848 (0.7587)  loss_giou_dn_5: 1.3376 (1.3487)  loss_fgl_dn_5: 0.8026 (0.7964)  loss_mal_dn_pre: 0.6274 (0.6283)  loss_bbox_dn_pre: 0.7147 (0.7956)  loss_giou_dn_pre: 1.3691 (1.3789)  time: 1.2658  data: 0.0114  max mem: 13413\nEpoch: [7]  [200/251]  eta: 0:01:02  lr: 0.000002  loss: 52.7133 (54.4453)  loss_mal: 1.4463 (1.5399)  loss_bbox: 0.4367 (0.4896)  loss_giou: 0.7948 (0.8513)  loss_fgl: 1.1914 (1.1833)  loss_mal_aux_0: 1.4932 (1.5655)  loss_bbox_aux_0: 0.3785 (0.5042)  loss_giou_aux_0: 0.8218 (0.8830)  loss_fgl_aux_0: 1.2450 (1.2038)  loss_ddf_aux_0: 0.0117 (0.0095)  loss_mal_aux_1: 1.4170 (1.5054)  loss_bbox_aux_1: 0.3998 (0.4996)  loss_giou_aux_1: 0.7946 (0.8717)  loss_fgl_aux_1: 1.2348 (1.2031)  loss_ddf_aux_1: 0.0081 (0.0066)  loss_mal_aux_2: 1.4131 (1.4816)  loss_bbox_aux_2: 0.4023 (0.4950)  loss_giou_aux_2: 0.8008 (0.8642)  loss_fgl_aux_2: 1.2150 (1.1961)  loss_ddf_aux_2: 0.0039 (0.0032)  loss_mal_aux_3: 1.4277 (1.5097)  loss_bbox_aux_3: 0.4116 (0.4910)  loss_giou_aux_3: 0.8005 (0.8574)  loss_fgl_aux_3: 1.2046 (1.1934)  loss_ddf_aux_3: 0.0018 (0.0016)  loss_mal_aux_4: 1.3906 (1.5113)  loss_bbox_aux_4: 0.4318 (0.4897)  loss_giou_aux_4: 0.8007 (0.8532)  loss_fgl_aux_4: 1.1945 (1.1881)  loss_ddf_aux_4: 0.0005 (0.0004)  loss_mal_pre: 1.4658 (1.5419)  loss_bbox_pre: 0.3789 (0.5094)  loss_giou_pre: 0.8150 (0.8887)  loss_mal_enc_0: 1.4941 (1.6044)  loss_bbox_enc_0: 0.4116 (0.5240)  loss_giou_enc_0: 0.8373 (0.9134)  loss_mal_dn_0: 0.6157 (0.6231)  loss_bbox_dn_0: 0.6316 (0.7719)  loss_giou_dn_0: 1.3753 (1.3794)  loss_fgl_dn_0: 0.7859 (0.7850)  loss_ddf_dn_0: 0.0365 (0.0257)  loss_mal_dn_1: 0.6118 (0.6130)  loss_bbox_dn_1: 0.6253 (0.7659)  loss_giou_dn_1: 1.3631 (1.3760)  loss_fgl_dn_1: 0.7874 (0.7809)  loss_ddf_dn_1: 0.0224 (0.0153)  loss_mal_dn_2: 0.6182 (0.6151)  loss_bbox_dn_2: 0.6144 (0.7587)  loss_giou_dn_2: 1.3493 (1.3663)  loss_fgl_dn_2: 0.7951 (0.7852)  loss_ddf_dn_2: 0.0094 (0.0061)  loss_mal_dn_3: 0.6294 (0.6227)  loss_bbox_dn_3: 0.6045 (0.7519)  loss_giou_dn_3: 1.3276 (1.3554)  loss_fgl_dn_3: 0.8001 (0.7910)  loss_ddf_dn_3: 0.0045 (0.0027)  loss_mal_dn_4: 0.6406 (0.6327)  loss_bbox_dn_4: 0.5914 (0.7440)  loss_giou_dn_4: 1.2992 (1.3396)  loss_fgl_dn_4: 0.8155 (0.8004)  loss_ddf_dn_4: 0.0012 (0.0007)  loss_mal_dn_5: 0.6592 (0.6444)  loss_bbox_dn_5: 0.5800 (0.7370)  loss_giou_dn_5: 1.2723 (1.3250)  loss_fgl_dn_5: 0.8293 (0.8087)  loss_mal_dn_pre: 0.6177 (0.6275)  loss_bbox_dn_pre: 0.6426 (0.7845)  loss_giou_dn_pre: 1.3754 (1.3753)  time: 1.2419  data: 0.0124  max mem: 13413\nEpoch: [7]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 54.0202 (54.4921)  loss_mal: 1.6553 (1.5652)  loss_bbox: 0.3753 (0.4788)  loss_giou: 0.7489 (0.8390)  loss_fgl: 1.2672 (1.1928)  loss_mal_aux_0: 1.6660 (1.5762)  loss_bbox_aux_0: 0.3805 (0.4953)  loss_giou_aux_0: 0.7326 (0.8711)  loss_fgl_aux_0: 1.3061 (1.2146)  loss_ddf_aux_0: 0.0151 (0.0105)  loss_mal_aux_1: 1.6221 (1.5256)  loss_bbox_aux_1: 0.3764 (0.4895)  loss_giou_aux_1: 0.7369 (0.8592)  loss_fgl_aux_1: 1.3068 (1.2137)  loss_ddf_aux_1: 0.0105 (0.0073)  loss_mal_aux_2: 1.6016 (1.5021)  loss_bbox_aux_2: 0.3751 (0.4842)  loss_giou_aux_2: 0.7308 (0.8512)  loss_fgl_aux_2: 1.2878 (1.2065)  loss_ddf_aux_2: 0.0049 (0.0036)  loss_mal_aux_3: 1.6055 (1.5279)  loss_bbox_aux_3: 0.3691 (0.4800)  loss_giou_aux_3: 0.7325 (0.8446)  loss_fgl_aux_3: 1.2957 (1.2034)  loss_ddf_aux_3: 0.0025 (0.0018)  loss_mal_aux_4: 1.6191 (1.5368)  loss_bbox_aux_4: 0.3776 (0.4786)  loss_giou_aux_4: 0.7325 (0.8406)  loss_fgl_aux_4: 1.2870 (1.1978)  loss_ddf_aux_4: 0.0007 (0.0005)  loss_mal_pre: 1.6514 (1.5539)  loss_bbox_pre: 0.3804 (0.5001)  loss_giou_pre: 0.7511 (0.8767)  loss_mal_enc_0: 1.6826 (1.6104)  loss_bbox_enc_0: 0.4109 (0.5178)  loss_giou_enc_0: 0.8113 (0.9069)  loss_mal_dn_0: 0.6289 (0.6254)  loss_bbox_dn_0: 0.7247 (0.7746)  loss_giou_dn_0: 1.3559 (1.3740)  loss_fgl_dn_0: 0.7939 (0.7881)  loss_ddf_dn_0: 0.0425 (0.0289)  loss_mal_dn_1: 0.6260 (0.6174)  loss_bbox_dn_1: 0.7246 (0.7676)  loss_giou_dn_1: 1.3393 (1.3683)  loss_fgl_dn_1: 0.8011 (0.7860)  loss_ddf_dn_1: 0.0263 (0.0176)  loss_mal_dn_2: 0.6387 (0.6218)  loss_bbox_dn_2: 0.7132 (0.7588)  loss_giou_dn_2: 1.3129 (1.3560)  loss_fgl_dn_2: 0.8139 (0.7919)  loss_ddf_dn_2: 0.0127 (0.0073)  loss_mal_dn_3: 0.6504 (0.6314)  loss_bbox_dn_3: 0.6897 (0.7504)  loss_giou_dn_3: 1.2874 (1.3420)  loss_fgl_dn_3: 0.8284 (0.7992)  loss_ddf_dn_3: 0.0059 (0.0033)  loss_mal_dn_4: 0.6680 (0.6433)  loss_bbox_dn_4: 0.6619 (0.7404)  loss_giou_dn_4: 1.2506 (1.3226)  loss_fgl_dn_4: 0.8453 (0.8101)  loss_ddf_dn_4: 0.0015 (0.0009)  loss_mal_dn_5: 0.6802 (0.6566)  loss_bbox_dn_5: 0.6480 (0.7320)  loss_giou_dn_5: 1.2251 (1.3054)  loss_fgl_dn_5: 0.8567 (0.8195)  loss_mal_dn_pre: 0.6313 (0.6293)  loss_bbox_dn_pre: 0.7335 (0.7874)  loss_giou_dn_pre: 1.3511 (1.3706)  time: 1.1741  data: 0.0110  max mem: 13413\nEpoch: [7] Total time: 0:05:06 (1.2225 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7990  data: 0.4830  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3542  data: 0.0651  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3068  data: 0.0213  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2940  data: 0.0193  max mem: 13413\nTest: Total time: 0:00:07 (0.3198 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.05s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.061\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.160\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.033\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.149\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.060\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.150\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.462\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.472\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.828\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.507\nbest_stat: {'epoch': 7, 'coco_eval_bbox': 0.060638533235956193}\nEpoch: [8]  [  0/251]  eta: 0:08:54  lr: 0.000003  loss: 58.6808 (58.6808)  loss_mal: 1.8135 (1.8135)  loss_bbox: 0.6466 (0.6466)  loss_giou: 0.9129 (0.9129)  loss_fgl: 1.1714 (1.1714)  loss_mal_aux_0: 1.5264 (1.5264)  loss_bbox_aux_0: 0.5810 (0.5810)  loss_giou_aux_0: 0.8370 (0.8370)  loss_fgl_aux_0: 1.2826 (1.2826)  loss_ddf_aux_0: 0.0214 (0.0214)  loss_mal_aux_1: 1.9570 (1.9570)  loss_bbox_aux_1: 0.5562 (0.5562)  loss_giou_aux_1: 0.8136 (0.8136)  loss_fgl_aux_1: 1.2857 (1.2857)  loss_ddf_aux_1: 0.0155 (0.0155)  loss_mal_aux_2: 1.8984 (1.8984)  loss_bbox_aux_2: 0.5536 (0.5536)  loss_giou_aux_2: 0.8233 (0.8233)  loss_fgl_aux_2: 1.2570 (1.2570)  loss_ddf_aux_2: 0.0078 (0.0078)  loss_mal_aux_3: 1.7510 (1.7510)  loss_bbox_aux_3: 0.5707 (0.5707)  loss_giou_aux_3: 0.8254 (0.8254)  loss_fgl_aux_3: 1.2455 (1.2455)  loss_ddf_aux_3: 0.0038 (0.0038)  loss_mal_aux_4: 1.7988 (1.7988)  loss_bbox_aux_4: 0.6142 (0.6142)  loss_giou_aux_4: 0.8750 (0.8750)  loss_fgl_aux_4: 1.2003 (1.2003)  loss_ddf_aux_4: 0.0009 (0.0009)  loss_mal_pre: 1.4971 (1.4971)  loss_bbox_pre: 0.5970 (0.5970)  loss_giou_pre: 0.8541 (0.8541)  loss_mal_enc_0: 1.3301 (1.3301)  loss_bbox_enc_0: 0.6475 (0.6475)  loss_giou_enc_0: 0.9548 (0.9548)  loss_mal_dn_0: 0.6343 (0.6343)  loss_bbox_dn_0: 1.0641 (1.0641)  loss_giou_dn_0: 1.3468 (1.3468)  loss_fgl_dn_0: 0.8055 (0.8055)  loss_ddf_dn_0: 0.0598 (0.0598)  loss_mal_dn_1: 0.6245 (0.6245)  loss_bbox_dn_1: 1.0473 (1.0473)  loss_giou_dn_1: 1.3345 (1.3345)  loss_fgl_dn_1: 0.8106 (0.8106)  loss_ddf_dn_1: 0.0383 (0.0383)  loss_mal_dn_2: 0.6348 (0.6348)  loss_bbox_dn_2: 1.0231 (1.0231)  loss_giou_dn_2: 1.3137 (1.3137)  loss_fgl_dn_2: 0.8227 (0.8227)  loss_ddf_dn_2: 0.0175 (0.0175)  loss_mal_dn_3: 0.6431 (0.6431)  loss_bbox_dn_3: 1.0042 (1.0042)  loss_giou_dn_3: 1.2924 (1.2924)  loss_fgl_dn_3: 0.8349 (0.8349)  loss_ddf_dn_3: 0.0083 (0.0083)  loss_mal_dn_4: 0.6592 (0.6592)  loss_bbox_dn_4: 0.9872 (0.9872)  loss_giou_dn_4: 1.2693 (1.2693)  loss_fgl_dn_4: 0.8487 (0.8487)  loss_ddf_dn_4: 0.0021 (0.0021)  loss_mal_dn_5: 0.6646 (0.6646)  loss_bbox_dn_5: 0.9766 (0.9766)  loss_giou_dn_5: 1.2504 (1.2504)  loss_fgl_dn_5: 0.8599 (0.8599)  loss_mal_dn_pre: 0.6362 (0.6362)  loss_bbox_dn_pre: 1.0917 (1.0917)  loss_giou_dn_pre: 1.3473 (1.3473)  time: 2.1286  data: 0.8649  max mem: 13413\nEpoch: [8]  [100/251]  eta: 0:03:03  lr: 0.000003  loss: 52.3759 (53.9987)  loss_mal: 1.6387 (1.6518)  loss_bbox: 0.3383 (0.4270)  loss_giou: 0.7368 (0.7575)  loss_fgl: 1.2292 (1.2409)  loss_mal_aux_0: 1.5371 (1.5940)  loss_bbox_aux_0: 0.3366 (0.4404)  loss_giou_aux_0: 0.7792 (0.7810)  loss_fgl_aux_0: 1.2656 (1.2924)  loss_ddf_aux_0: 0.0231 (0.0215)  loss_mal_aux_1: 1.5225 (1.5922)  loss_bbox_aux_1: 0.3362 (0.4310)  loss_giou_aux_1: 0.7739 (0.7676)  loss_fgl_aux_1: 1.2614 (1.2841)  loss_ddf_aux_1: 0.0152 (0.0144)  loss_mal_aux_2: 1.5391 (1.5928)  loss_bbox_aux_2: 0.3225 (0.4240)  loss_giou_aux_2: 0.7516 (0.7582)  loss_fgl_aux_2: 1.2638 (1.2693)  loss_ddf_aux_2: 0.0068 (0.0068)  loss_mal_aux_3: 1.5508 (1.5978)  loss_bbox_aux_3: 0.3228 (0.4227)  loss_giou_aux_3: 0.7609 (0.7544)  loss_fgl_aux_3: 1.2449 (1.2606)  loss_ddf_aux_3: 0.0032 (0.0032)  loss_mal_aux_4: 1.5869 (1.6037)  loss_bbox_aux_4: 0.3315 (0.4252)  loss_giou_aux_4: 0.7594 (0.7549)  loss_fgl_aux_4: 1.2294 (1.2497)  loss_ddf_aux_4: 0.0007 (0.0008)  loss_mal_pre: 1.5449 (1.5801)  loss_bbox_pre: 0.3498 (0.4462)  loss_giou_pre: 0.7833 (0.7863)  loss_mal_enc_0: 1.6357 (1.5916)  loss_bbox_enc_0: 0.4172 (0.5008)  loss_giou_enc_0: 0.8807 (0.8786)  loss_mal_dn_0: 0.6714 (0.6547)  loss_bbox_dn_0: 0.7455 (0.7458)  loss_giou_dn_0: 1.2732 (1.3029)  loss_fgl_dn_0: 0.8647 (0.8392)  loss_ddf_dn_0: 0.0743 (0.0603)  loss_mal_dn_1: 0.6792 (0.6583)  loss_bbox_dn_1: 0.7287 (0.7302)  loss_giou_dn_1: 1.2480 (1.2783)  loss_fgl_dn_1: 0.8800 (0.8526)  loss_ddf_dn_1: 0.0494 (0.0388)  loss_mal_dn_2: 0.6904 (0.6731)  loss_bbox_dn_2: 0.7160 (0.7111)  loss_giou_dn_2: 1.2109 (1.2479)  loss_fgl_dn_2: 0.8975 (0.8691)  loss_ddf_dn_2: 0.0224 (0.0187)  loss_mal_dn_3: 0.7051 (0.6906)  loss_bbox_dn_3: 0.7055 (0.6912)  loss_giou_dn_3: 1.1699 (1.2121)  loss_fgl_dn_3: 0.9178 (0.8859)  loss_ddf_dn_3: 0.0102 (0.0088)  loss_mal_dn_4: 0.7261 (0.7075)  loss_bbox_dn_4: 0.6926 (0.6716)  loss_giou_dn_4: 1.1300 (1.1758)  loss_fgl_dn_4: 0.9339 (0.9032)  loss_ddf_dn_4: 0.0024 (0.0021)  loss_mal_dn_5: 0.7363 (0.7194)  loss_bbox_dn_5: 0.6850 (0.6591)  loss_giou_dn_5: 1.1026 (1.1515)  loss_fgl_dn_5: 0.9448 (0.9146)  loss_mal_dn_pre: 0.6704 (0.6552)  loss_bbox_dn_pre: 0.7571 (0.7606)  loss_giou_dn_pre: 1.2734 (1.3052)  time: 1.2432  data: 0.0109  max mem: 13413\nEpoch: [8]  [200/251]  eta: 0:01:03  lr: 0.000003  loss: 52.9453 (53.7913)  loss_mal: 1.6299 (1.6569)  loss_bbox: 0.3466 (0.4088)  loss_giou: 0.6675 (0.7435)  loss_fgl: 1.2830 (1.2437)  loss_mal_aux_0: 1.6738 (1.6057)  loss_bbox_aux_0: 0.3306 (0.4201)  loss_giou_aux_0: 0.6598 (0.7633)  loss_fgl_aux_0: 1.3610 (1.3035)  loss_ddf_aux_0: 0.0430 (0.0278)  loss_mal_aux_1: 1.7295 (1.6104)  loss_bbox_aux_1: 0.3406 (0.4141)  loss_giou_aux_1: 0.6842 (0.7545)  loss_fgl_aux_1: 1.3317 (1.2866)  loss_ddf_aux_1: 0.0251 (0.0177)  loss_mal_aux_2: 1.6895 (1.6137)  loss_bbox_aux_2: 0.3314 (0.4086)  loss_giou_aux_2: 0.6690 (0.7475)  loss_fgl_aux_2: 1.3002 (1.2690)  loss_ddf_aux_2: 0.0112 (0.0081)  loss_mal_aux_3: 1.6396 (1.6264)  loss_bbox_aux_3: 0.3330 (0.4061)  loss_giou_aux_3: 0.6635 (0.7435)  loss_fgl_aux_3: 1.2863 (1.2601)  loss_ddf_aux_3: 0.0048 (0.0037)  loss_mal_aux_4: 1.6377 (1.6275)  loss_bbox_aux_4: 0.3389 (0.4076)  loss_giou_aux_4: 0.6726 (0.7427)  loss_fgl_aux_4: 1.2852 (1.2507)  loss_ddf_aux_4: 0.0011 (0.0009)  loss_mal_pre: 1.6729 (1.6007)  loss_bbox_pre: 0.3408 (0.4237)  loss_giou_pre: 0.6758 (0.7660)  loss_mal_enc_0: 1.7178 (1.6200)  loss_bbox_enc_0: 0.4102 (0.4866)  loss_giou_enc_0: 0.7983 (0.8792)  loss_mal_dn_0: 0.7207 (0.6796)  loss_bbox_dn_0: 0.6667 (0.7131)  loss_giou_dn_0: 1.1891 (1.2595)  loss_fgl_dn_0: 0.9306 (0.8756)  loss_ddf_dn_0: 0.1356 (0.0842)  loss_mal_dn_1: 0.7183 (0.6817)  loss_bbox_dn_1: 0.6524 (0.6955)  loss_giou_dn_1: 1.1206 (1.2280)  loss_fgl_dn_1: 0.9525 (0.8931)  loss_ddf_dn_1: 0.0863 (0.0545)  loss_mal_dn_2: 0.7368 (0.6983)  loss_bbox_dn_2: 0.6231 (0.6747)  loss_giou_dn_2: 1.0806 (1.1927)  loss_fgl_dn_2: 0.9766 (0.9106)  loss_ddf_dn_2: 0.0441 (0.0270)  loss_mal_dn_3: 0.7686 (0.7173)  loss_bbox_dn_3: 0.6001 (0.6529)  loss_giou_dn_3: 1.0154 (1.1501)  loss_fgl_dn_3: 1.0105 (0.9285)  loss_ddf_dn_3: 0.0185 (0.0119)  loss_mal_dn_4: 0.7798 (0.7320)  loss_bbox_dn_4: 0.5837 (0.6355)  loss_giou_dn_4: 0.9646 (1.1147)  loss_fgl_dn_4: 1.0266 (0.9436)  loss_ddf_dn_4: 0.0042 (0.0027)  loss_mal_dn_5: 0.7886 (0.7437)  loss_bbox_dn_5: 0.5653 (0.6249)  loss_giou_dn_5: 0.9393 (1.0927)  loss_fgl_dn_5: 1.0363 (0.9531)  loss_mal_dn_pre: 0.7173 (0.6785)  loss_bbox_dn_pre: 0.6846 (0.7277)  loss_giou_dn_pre: 1.1983 (1.2643)  time: 1.2633  data: 0.0112  max mem: 13413\nEpoch: [8]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 54.1654 (53.7744)  loss_mal: 1.5596 (1.6517)  loss_bbox: 0.3617 (0.4077)  loss_giou: 0.7376 (0.7466)  loss_fgl: 1.2162 (1.2399)  loss_mal_aux_0: 1.5312 (1.6096)  loss_bbox_aux_0: 0.3713 (0.4180)  loss_giou_aux_0: 0.7620 (0.7659)  loss_fgl_aux_0: 1.2499 (1.2978)  loss_ddf_aux_0: 0.0484 (0.0318)  loss_mal_aux_1: 1.5498 (1.6144)  loss_bbox_aux_1: 0.3742 (0.4123)  loss_giou_aux_1: 0.7772 (0.7575)  loss_fgl_aux_1: 1.2258 (1.2786)  loss_ddf_aux_1: 0.0260 (0.0196)  loss_mal_aux_2: 1.6289 (1.6157)  loss_bbox_aux_2: 0.3693 (0.4073)  loss_giou_aux_2: 0.7720 (0.7511)  loss_fgl_aux_2: 1.2131 (1.2615)  loss_ddf_aux_2: 0.0103 (0.0087)  loss_mal_aux_3: 1.6582 (1.6263)  loss_bbox_aux_3: 0.3640 (0.4052)  loss_giou_aux_3: 0.7553 (0.7475)  loss_fgl_aux_3: 1.2177 (1.2534)  loss_ddf_aux_3: 0.0041 (0.0039)  loss_mal_aux_4: 1.6514 (1.6246)  loss_bbox_aux_4: 0.3638 (0.4067)  loss_giou_aux_4: 0.7452 (0.7464)  loss_fgl_aux_4: 1.2211 (1.2456)  loss_ddf_aux_4: 0.0010 (0.0009)  loss_mal_pre: 1.5215 (1.6048)  loss_bbox_pre: 0.3833 (0.4214)  loss_giou_pre: 0.7652 (0.7683)  loss_mal_enc_0: 1.5459 (1.6175)  loss_bbox_enc_0: 0.4587 (0.4882)  loss_giou_enc_0: 0.9295 (0.8875)  loss_mal_dn_0: 0.7202 (0.6884)  loss_bbox_dn_0: 0.7428 (0.7061)  loss_giou_dn_0: 1.1893 (1.2444)  loss_fgl_dn_0: 0.9405 (0.8890)  loss_ddf_dn_0: 0.1398 (0.0943)  loss_mal_dn_1: 0.7344 (0.6905)  loss_bbox_dn_1: 0.7263 (0.6879)  loss_giou_dn_1: 1.1446 (1.2111)  loss_fgl_dn_1: 0.9572 (0.9073)  loss_ddf_dn_1: 0.0906 (0.0609)  loss_mal_dn_2: 0.7388 (0.7074)  loss_bbox_dn_2: 0.6952 (0.6666)  loss_giou_dn_2: 1.1087 (1.1741)  loss_fgl_dn_2: 0.9730 (0.9252)  loss_ddf_dn_2: 0.0429 (0.0303)  loss_mal_dn_3: 0.7661 (0.7274)  loss_bbox_dn_3: 0.6577 (0.6440)  loss_giou_dn_3: 1.0618 (1.1294)  loss_fgl_dn_3: 0.9902 (0.9432)  loss_ddf_dn_3: 0.0170 (0.0130)  loss_mal_dn_4: 0.7729 (0.7417)  loss_bbox_dn_4: 0.6481 (0.6272)  loss_giou_dn_4: 1.0249 (1.0944)  loss_fgl_dn_4: 1.0029 (0.9576)  loss_ddf_dn_4: 0.0034 (0.0029)  loss_mal_dn_5: 0.7822 (0.7525)  loss_bbox_dn_5: 0.6402 (0.6172)  loss_giou_dn_5: 1.0030 (1.0732)  loss_fgl_dn_5: 1.0150 (0.9665)  loss_mal_dn_pre: 0.7158 (0.6869)  loss_bbox_dn_pre: 0.7456 (0.7202)  loss_giou_dn_pre: 1.1974 (1.2496)  time: 1.2020  data: 0.0123  max mem: 13413\nEpoch: [8] Total time: 0:05:08 (1.2305 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8124  data: 0.4960  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3516  data: 0.0635  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3041  data: 0.0197  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2927  data: 0.0187  max mem: 13413\nTest: Total time: 0:00:07 (0.3184 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.066\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.182\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.030\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.052\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.432\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.523\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.596\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.498\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.822\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.602\nbest_stat: {'epoch': 8, 'coco_eval_bbox': 0.06649724967695149}\nEpoch: [9]  [  0/251]  eta: 0:10:37  lr: 0.000003  loss: 53.4963 (53.4963)  loss_mal: 1.7920 (1.7920)  loss_bbox: 0.2762 (0.2762)  loss_giou: 0.6180 (0.6180)  loss_fgl: 1.2972 (1.2972)  loss_mal_aux_0: 1.7285 (1.7285)  loss_bbox_aux_0: 0.2854 (0.2854)  loss_giou_aux_0: 0.6635 (0.6635)  loss_fgl_aux_0: 1.3483 (1.3483)  loss_ddf_aux_0: 0.0689 (0.0689)  loss_mal_aux_1: 1.9639 (1.9639)  loss_bbox_aux_1: 0.2806 (0.2806)  loss_giou_aux_1: 0.6431 (0.6431)  loss_fgl_aux_1: 1.3209 (1.3209)  loss_ddf_aux_1: 0.0361 (0.0361)  loss_mal_aux_2: 1.7656 (1.7656)  loss_bbox_aux_2: 0.2741 (0.2741)  loss_giou_aux_2: 0.6270 (0.6270)  loss_fgl_aux_2: 1.3077 (1.3077)  loss_ddf_aux_2: 0.0155 (0.0155)  loss_mal_aux_3: 1.7715 (1.7715)  loss_bbox_aux_3: 0.2713 (0.2713)  loss_giou_aux_3: 0.6098 (0.6098)  loss_fgl_aux_3: 1.3074 (1.3074)  loss_ddf_aux_3: 0.0069 (0.0069)  loss_mal_aux_4: 1.8066 (1.8066)  loss_bbox_aux_4: 0.2717 (0.2717)  loss_giou_aux_4: 0.6181 (0.6181)  loss_fgl_aux_4: 1.2977 (1.2977)  loss_ddf_aux_4: 0.0017 (0.0017)  loss_mal_pre: 1.6973 (1.6973)  loss_bbox_pre: 0.2908 (0.2908)  loss_giou_pre: 0.6733 (0.6733)  loss_mal_enc_0: 2.4004 (2.4004)  loss_bbox_enc_0: 0.4002 (0.4002)  loss_giou_enc_0: 0.9185 (0.9185)  loss_mal_dn_0: 0.7505 (0.7505)  loss_bbox_dn_0: 0.5325 (0.5325)  loss_giou_dn_0: 1.1442 (1.1442)  loss_fgl_dn_0: 0.9776 (0.9776)  loss_ddf_dn_0: 0.1686 (0.1686)  loss_mal_dn_1: 0.7671 (0.7671)  loss_bbox_dn_1: 0.5057 (0.5057)  loss_giou_dn_1: 1.0774 (1.0774)  loss_fgl_dn_1: 1.0088 (1.0088)  loss_ddf_dn_1: 0.1078 (0.1078)  loss_mal_dn_2: 0.7905 (0.7905)  loss_bbox_dn_2: 0.4838 (0.4838)  loss_giou_dn_2: 1.0240 (1.0240)  loss_fgl_dn_2: 1.0322 (1.0322)  loss_ddf_dn_2: 0.0577 (0.0577)  loss_mal_dn_3: 0.8467 (0.8467)  loss_bbox_dn_3: 0.4688 (0.4688)  loss_giou_dn_3: 0.9707 (0.9707)  loss_fgl_dn_3: 1.0484 (1.0484)  loss_ddf_dn_3: 0.0212 (0.0212)  loss_mal_dn_4: 0.8535 (0.8535)  loss_bbox_dn_4: 0.4580 (0.4580)  loss_giou_dn_4: 0.9357 (0.9357)  loss_fgl_dn_4: 1.0596 (1.0596)  loss_ddf_dn_4: 0.0042 (0.0042)  loss_mal_dn_5: 0.8774 (0.8774)  loss_bbox_dn_5: 0.4505 (0.4505)  loss_giou_dn_5: 0.9134 (0.9134)  loss_fgl_dn_5: 1.0691 (1.0691)  loss_mal_dn_pre: 0.7461 (0.7461)  loss_bbox_dn_pre: 0.5373 (0.5373)  loss_giou_dn_pre: 1.1516 (1.1516)  time: 2.5386  data: 0.9450  max mem: 13413\nEpoch: [9]  [100/251]  eta: 0:03:06  lr: 0.000003  loss: 50.1398 (52.3454)  loss_mal: 1.4629 (1.5805)  loss_bbox: 0.2342 (0.3447)  loss_giou: 0.5762 (0.6742)  loss_fgl: 1.3160 (1.2617)  loss_mal_aux_0: 1.6133 (1.6728)  loss_bbox_aux_0: 0.2468 (0.3509)  loss_giou_aux_0: 0.5869 (0.6902)  loss_fgl_aux_0: 1.3833 (1.3198)  loss_ddf_aux_0: 0.0540 (0.0540)  loss_mal_aux_1: 1.6221 (1.6195)  loss_bbox_aux_1: 0.2466 (0.3491)  loss_giou_aux_1: 0.5958 (0.6887)  loss_fgl_aux_1: 1.3321 (1.2837)  loss_ddf_aux_1: 0.0277 (0.0277)  loss_mal_aux_2: 1.5801 (1.5951)  loss_bbox_aux_2: 0.2355 (0.3445)  loss_giou_aux_2: 0.5808 (0.6815)  loss_fgl_aux_2: 1.3109 (1.2701)  loss_ddf_aux_2: 0.0109 (0.0111)  loss_mal_aux_3: 1.5000 (1.5718)  loss_bbox_aux_3: 0.2382 (0.3429)  loss_giou_aux_3: 0.5773 (0.6767)  loss_fgl_aux_3: 1.3025 (1.2661)  loss_ddf_aux_3: 0.0044 (0.0044)  loss_mal_aux_4: 1.4697 (1.5728)  loss_bbox_aux_4: 0.2355 (0.3438)  loss_giou_aux_4: 0.5766 (0.6748)  loss_fgl_aux_4: 1.3140 (1.2633)  loss_ddf_aux_4: 0.0009 (0.0010)  loss_mal_pre: 1.5938 (1.6698)  loss_bbox_pre: 0.2561 (0.3501)  loss_giou_pre: 0.5920 (0.6881)  loss_mal_enc_0: 1.4932 (1.6356)  loss_bbox_enc_0: 0.3751 (0.4457)  loss_giou_enc_0: 0.8001 (0.8407)  loss_mal_dn_0: 0.7676 (0.7418)  loss_bbox_dn_0: 0.4590 (0.6297)  loss_giou_dn_0: 1.0432 (1.1310)  loss_fgl_dn_0: 1.0389 (0.9835)  loss_ddf_dn_0: 0.1853 (0.1652)  loss_mal_dn_1: 0.7661 (0.7422)  loss_bbox_dn_1: 0.4465 (0.6067)  loss_giou_dn_1: 0.9959 (1.0847)  loss_fgl_dn_1: 1.0571 (1.0038)  loss_ddf_dn_1: 0.1157 (0.1047)  loss_mal_dn_2: 0.7769 (0.7596)  loss_bbox_dn_2: 0.4228 (0.5806)  loss_giou_dn_2: 0.9354 (1.0345)  loss_fgl_dn_2: 1.0734 (1.0221)  loss_ddf_dn_2: 0.0592 (0.0539)  loss_mal_dn_3: 0.7920 (0.7774)  loss_bbox_dn_3: 0.4047 (0.5569)  loss_giou_dn_3: 0.8719 (0.9827)  loss_fgl_dn_3: 1.0913 (1.0369)  loss_ddf_dn_3: 0.0228 (0.0205)  loss_mal_dn_4: 0.7886 (0.7860)  loss_bbox_dn_4: 0.3872 (0.5422)  loss_giou_dn_4: 0.8304 (0.9520)  loss_fgl_dn_4: 1.1020 (1.0457)  loss_ddf_dn_4: 0.0047 (0.0042)  loss_mal_dn_5: 0.7983 (0.7913)  loss_bbox_dn_5: 0.3769 (0.5333)  loss_giou_dn_5: 0.8071 (0.9351)  loss_fgl_dn_5: 1.1082 (1.0502)  loss_mal_dn_pre: 0.7598 (0.7369)  loss_bbox_dn_pre: 0.4648 (0.6415)  loss_giou_dn_pre: 1.0591 (1.1409)  time: 1.2338  data: 0.0111  max mem: 13413\nEpoch: [9]  [200/251]  eta: 0:01:01  lr: 0.000003  loss: 51.9890 (52.3146)  loss_mal: 1.4424 (1.5718)  loss_bbox: 0.3385 (0.3571)  loss_giou: 0.6485 (0.6764)  loss_fgl: 1.2675 (1.2597)  loss_mal_aux_0: 1.5674 (1.6484)  loss_bbox_aux_0: 0.3704 (0.3675)  loss_giou_aux_0: 0.6716 (0.6940)  loss_fgl_aux_0: 1.2745 (1.2999)  loss_ddf_aux_0: 0.0612 (0.0566)  loss_mal_aux_1: 1.4697 (1.5955)  loss_bbox_aux_1: 0.3599 (0.3649)  loss_giou_aux_1: 0.6605 (0.6919)  loss_fgl_aux_1: 1.2492 (1.2705)  loss_ddf_aux_1: 0.0293 (0.0281)  loss_mal_aux_2: 1.5039 (1.5769)  loss_bbox_aux_2: 0.3492 (0.3598)  loss_giou_aux_2: 0.6542 (0.6848)  loss_fgl_aux_2: 1.2445 (1.2621)  loss_ddf_aux_2: 0.0116 (0.0111)  loss_mal_aux_3: 1.4629 (1.5513)  loss_bbox_aux_3: 0.3422 (0.3577)  loss_giou_aux_3: 0.6461 (0.6800)  loss_fgl_aux_3: 1.2593 (1.2605)  loss_ddf_aux_3: 0.0048 (0.0044)  loss_mal_aux_4: 1.5107 (1.5596)  loss_bbox_aux_4: 0.3391 (0.3569)  loss_giou_aux_4: 0.6407 (0.6771)  loss_fgl_aux_4: 1.2632 (1.2598)  loss_ddf_aux_4: 0.0010 (0.0009)  loss_mal_pre: 1.6045 (1.6542)  loss_bbox_pre: 0.3588 (0.3652)  loss_giou_pre: 0.6615 (0.6921)  loss_mal_enc_0: 1.5928 (1.6101)  loss_bbox_enc_0: 0.4803 (0.4632)  loss_giou_enc_0: 0.8031 (0.8468)  loss_mal_dn_0: 0.7407 (0.7483)  loss_bbox_dn_0: 0.6295 (0.6335)  loss_giou_dn_0: 1.0941 (1.1070)  loss_fgl_dn_0: 1.0157 (1.0023)  loss_ddf_dn_0: 0.2242 (0.1861)  loss_mal_dn_1: 0.7427 (0.7448)  loss_bbox_dn_1: 0.6030 (0.6102)  loss_giou_dn_1: 1.0554 (1.0600)  loss_fgl_dn_1: 1.0337 (1.0211)  loss_ddf_dn_1: 0.1481 (0.1184)  loss_mal_dn_2: 0.7568 (0.7626)  loss_bbox_dn_2: 0.5738 (0.5836)  loss_giou_dn_2: 0.9859 (1.0077)  loss_fgl_dn_2: 1.0515 (1.0389)  loss_ddf_dn_2: 0.0772 (0.0612)  loss_mal_dn_3: 0.7686 (0.7787)  loss_bbox_dn_3: 0.5483 (0.5614)  loss_giou_dn_3: 0.9131 (0.9577)  loss_fgl_dn_3: 1.0727 (1.0525)  loss_ddf_dn_3: 0.0282 (0.0230)  loss_mal_dn_4: 0.7764 (0.7844)  loss_bbox_dn_4: 0.5332 (0.5483)  loss_giou_dn_4: 0.8889 (0.9294)  loss_fgl_dn_4: 1.0758 (1.0600)  loss_ddf_dn_4: 0.0056 (0.0046)  loss_mal_dn_5: 0.7769 (0.7905)  loss_bbox_dn_5: 0.5251 (0.5406)  loss_giou_dn_5: 0.8794 (0.9139)  loss_fgl_dn_5: 1.0747 (1.0637)  loss_mal_dn_pre: 0.7373 (0.7440)  loss_bbox_dn_pre: 0.6385 (0.6435)  loss_giou_dn_pre: 1.0969 (1.1158)  time: 1.2915  data: 0.0112  max mem: 13413\nEpoch: [9]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 51.7479 (52.3091)  loss_mal: 1.6182 (1.5767)  loss_bbox: 0.2777 (0.3526)  loss_giou: 0.6341 (0.6767)  loss_fgl: 1.3089 (1.2599)  loss_mal_aux_0: 1.6309 (1.6566)  loss_bbox_aux_0: 0.2850 (0.3628)  loss_giou_aux_0: 0.6399 (0.6937)  loss_fgl_aux_0: 1.3328 (1.2944)  loss_ddf_aux_0: 0.0502 (0.0561)  loss_mal_aux_1: 1.5518 (1.6026)  loss_bbox_aux_1: 0.2869 (0.3604)  loss_giou_aux_1: 0.6662 (0.6919)  loss_fgl_aux_1: 1.3119 (1.2675)  loss_ddf_aux_1: 0.0235 (0.0274)  loss_mal_aux_2: 1.4932 (1.5816)  loss_bbox_aux_2: 0.2837 (0.3557)  loss_giou_aux_2: 0.6641 (0.6854)  loss_fgl_aux_2: 1.2997 (1.2606)  loss_ddf_aux_2: 0.0090 (0.0108)  loss_mal_aux_3: 1.4990 (1.5550)  loss_bbox_aux_3: 0.2765 (0.3537)  loss_giou_aux_3: 0.6449 (0.6808)  loss_fgl_aux_3: 1.2989 (1.2596)  loss_ddf_aux_3: 0.0036 (0.0043)  loss_mal_aux_4: 1.5459 (1.5629)  loss_bbox_aux_4: 0.2744 (0.3526)  loss_giou_aux_4: 0.6305 (0.6777)  loss_fgl_aux_4: 1.3054 (1.2596)  loss_ddf_aux_4: 0.0008 (0.0009)  loss_mal_pre: 1.6152 (1.6627)  loss_bbox_pre: 0.2728 (0.3601)  loss_giou_pre: 0.6436 (0.6917)  loss_mal_enc_0: 1.7041 (1.6192)  loss_bbox_enc_0: 0.3823 (0.4561)  loss_giou_enc_0: 0.7596 (0.8437)  loss_mal_dn_0: 0.7598 (0.7511)  loss_bbox_dn_0: 0.6106 (0.6309)  loss_giou_dn_0: 1.0835 (1.1006)  loss_fgl_dn_0: 1.0081 (1.0073)  loss_ddf_dn_0: 0.2097 (0.1918)  loss_mal_dn_1: 0.7583 (0.7477)  loss_bbox_dn_1: 0.5803 (0.6075)  loss_giou_dn_1: 1.0251 (1.0525)  loss_fgl_dn_1: 1.0319 (1.0263)  loss_ddf_dn_1: 0.1345 (0.1219)  loss_mal_dn_2: 0.7729 (0.7662)  loss_bbox_dn_2: 0.5420 (0.5808)  loss_giou_dn_2: 0.9632 (0.9993)  loss_fgl_dn_2: 1.0517 (1.0441)  loss_ddf_dn_2: 0.0678 (0.0628)  loss_mal_dn_3: 0.7754 (0.7816)  loss_bbox_dn_3: 0.5325 (0.5597)  loss_giou_dn_3: 0.9119 (0.9512)  loss_fgl_dn_3: 1.0670 (1.0570)  loss_ddf_dn_3: 0.0261 (0.0235)  loss_mal_dn_4: 0.7900 (0.7870)  loss_bbox_dn_4: 0.5130 (0.5465)  loss_giou_dn_4: 0.8859 (0.9236)  loss_fgl_dn_4: 1.0777 (1.0643)  loss_ddf_dn_4: 0.0050 (0.0047)  loss_mal_dn_5: 0.7871 (0.7935)  loss_bbox_dn_5: 0.5017 (0.5386)  loss_giou_dn_5: 0.8735 (0.9084)  loss_fgl_dn_5: 1.0821 (1.0680)  loss_mal_dn_pre: 0.7500 (0.7467)  loss_bbox_dn_pre: 0.6169 (0.6405)  loss_giou_dn_pre: 1.0987 (1.1094)  time: 1.0674  data: 0.0117  max mem: 13413\nEpoch: [9] Total time: 0:05:02 (1.2043 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8010  data: 0.4791  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3519  data: 0.0624  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3053  data: 0.0200  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2937  data: 0.0194  max mem: 13413\nTest: Total time: 0:00:07 (0.3189 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.246\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.083\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.116\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.252\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.473\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.550\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.548\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.831\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.623\nbest_stat: {'epoch': 9, 'coco_eval_bbox': 0.10628329934324574}\nEpoch: [10]  [  0/251]  eta: 0:09:38  lr: 0.000003  loss: 52.8740 (52.8740)  loss_mal: 1.6777 (1.6777)  loss_bbox: 0.2987 (0.2987)  loss_giou: 0.5614 (0.5614)  loss_fgl: 1.3528 (1.3528)  loss_mal_aux_0: 1.5986 (1.5986)  loss_bbox_aux_0: 0.2928 (0.2928)  loss_giou_aux_0: 0.5780 (0.5780)  loss_fgl_aux_0: 1.3553 (1.3553)  loss_ddf_aux_0: 0.0813 (0.0813)  loss_mal_aux_1: 1.4277 (1.4277)  loss_bbox_aux_1: 0.2919 (0.2919)  loss_giou_aux_1: 0.5696 (0.5696)  loss_fgl_aux_1: 1.3414 (1.3414)  loss_ddf_aux_1: 0.0387 (0.0387)  loss_mal_aux_2: 1.6045 (1.6045)  loss_bbox_aux_2: 0.2971 (0.2971)  loss_giou_aux_2: 0.5702 (0.5702)  loss_fgl_aux_2: 1.3440 (1.3440)  loss_ddf_aux_2: 0.0132 (0.0132)  loss_mal_aux_3: 1.5908 (1.5908)  loss_bbox_aux_3: 0.2995 (0.2995)  loss_giou_aux_3: 0.5708 (0.5708)  loss_fgl_aux_3: 1.3496 (1.3496)  loss_ddf_aux_3: 0.0050 (0.0050)  loss_mal_aux_4: 1.7168 (1.7168)  loss_bbox_aux_4: 0.2995 (0.2995)  loss_giou_aux_4: 0.5676 (0.5676)  loss_fgl_aux_4: 1.3516 (1.3516)  loss_ddf_aux_4: 0.0011 (0.0011)  loss_mal_pre: 1.8291 (1.8291)  loss_bbox_pre: 0.2940 (0.2940)  loss_giou_pre: 0.5743 (0.5743)  loss_mal_enc_0: 2.1562 (2.1562)  loss_bbox_enc_0: 0.4524 (0.4524)  loss_giou_enc_0: 0.8031 (0.8031)  loss_mal_dn_0: 0.7812 (0.7812)  loss_bbox_dn_0: 0.6665 (0.6665)  loss_giou_dn_0: 1.0794 (1.0794)  loss_fgl_dn_0: 1.0371 (1.0371)  loss_ddf_dn_0: 0.2104 (0.2104)  loss_mal_dn_1: 0.7583 (0.7583)  loss_bbox_dn_1: 0.6472 (0.6472)  loss_giou_dn_1: 1.0379 (1.0379)  loss_fgl_dn_1: 1.0518 (1.0518)  loss_ddf_dn_1: 0.1368 (0.1368)  loss_mal_dn_2: 0.7817 (0.7817)  loss_bbox_dn_2: 0.6234 (0.6234)  loss_giou_dn_2: 0.9864 (0.9864)  loss_fgl_dn_2: 1.0737 (1.0737)  loss_ddf_dn_2: 0.0684 (0.0684)  loss_mal_dn_3: 0.7988 (0.7988)  loss_bbox_dn_3: 0.6098 (0.6098)  loss_giou_dn_3: 0.9448 (0.9448)  loss_fgl_dn_3: 1.0886 (1.0886)  loss_ddf_dn_3: 0.0268 (0.0268)  loss_mal_dn_4: 0.7817 (0.7817)  loss_bbox_dn_4: 0.5981 (0.5981)  loss_giou_dn_4: 0.9158 (0.9158)  loss_fgl_dn_4: 1.0994 (1.0994)  loss_ddf_dn_4: 0.0054 (0.0054)  loss_mal_dn_5: 0.7808 (0.7808)  loss_bbox_dn_5: 0.5885 (0.5885)  loss_giou_dn_5: 0.8961 (0.8961)  loss_fgl_dn_5: 1.1057 (1.1057)  loss_mal_dn_pre: 0.7744 (0.7744)  loss_bbox_dn_pre: 0.6735 (0.6735)  loss_giou_dn_pre: 1.0893 (1.0893)  time: 2.3047  data: 0.7101  max mem: 13413\nEpoch: [10]  [100/251]  eta: 0:03:08  lr: 0.000003  loss: 51.1952 (50.7526)  loss_mal: 1.2930 (1.4405)  loss_bbox: 0.3949 (0.3160)  loss_giou: 0.6376 (0.6065)  loss_fgl: 1.2729 (1.2825)  loss_mal_aux_0: 1.5137 (1.6447)  loss_bbox_aux_0: 0.3848 (0.3331)  loss_giou_aux_0: 0.6539 (0.6357)  loss_fgl_aux_0: 1.2448 (1.2910)  loss_ddf_aux_0: 0.0502 (0.0598)  loss_mal_aux_1: 1.4385 (1.5314)  loss_bbox_aux_1: 0.3930 (0.3302)  loss_giou_aux_1: 0.6606 (0.6323)  loss_fgl_aux_1: 1.2573 (1.2780)  loss_ddf_aux_1: 0.0239 (0.0276)  loss_mal_aux_2: 1.4248 (1.4888)  loss_bbox_aux_2: 0.3982 (0.3245)  loss_giou_aux_2: 0.6689 (0.6230)  loss_fgl_aux_2: 1.2622 (1.2789)  loss_ddf_aux_2: 0.0100 (0.0111)  loss_mal_aux_3: 1.3535 (1.4493)  loss_bbox_aux_3: 0.3977 (0.3216)  loss_giou_aux_3: 0.6612 (0.6158)  loss_fgl_aux_3: 1.2584 (1.2800)  loss_ddf_aux_3: 0.0041 (0.0046)  loss_mal_aux_4: 1.3115 (1.4496)  loss_bbox_aux_4: 0.3955 (0.3180)  loss_giou_aux_4: 0.6475 (0.6097)  loss_fgl_aux_4: 1.2658 (1.2815)  loss_ddf_aux_4: 0.0009 (0.0009)  loss_mal_pre: 1.5176 (1.6434)  loss_bbox_pre: 0.3878 (0.3290)  loss_giou_pre: 0.6422 (0.6322)  loss_mal_enc_0: 1.5488 (1.6640)  loss_bbox_enc_0: 0.4277 (0.4268)  loss_giou_enc_0: 0.8070 (0.7881)  loss_mal_dn_0: 0.7910 (0.7843)  loss_bbox_dn_0: 0.6227 (0.5859)  loss_giou_dn_0: 0.9610 (0.9890)  loss_fgl_dn_0: 1.1052 (1.0872)  loss_ddf_dn_0: 0.2468 (0.2619)  loss_mal_dn_1: 0.7837 (0.7747)  loss_bbox_dn_1: 0.6064 (0.5614)  loss_giou_dn_1: 0.9011 (0.9363)  loss_fgl_dn_1: 1.1241 (1.1027)  loss_ddf_dn_1: 0.1642 (0.1694)  loss_mal_dn_2: 0.8140 (0.7942)  loss_bbox_dn_2: 0.5418 (0.5308)  loss_giou_dn_2: 0.8235 (0.8751)  loss_fgl_dn_2: 1.1350 (1.1189)  loss_ddf_dn_2: 0.0833 (0.0853)  loss_mal_dn_3: 0.8140 (0.8045)  loss_bbox_dn_3: 0.5090 (0.5085)  loss_giou_dn_3: 0.7670 (0.8307)  loss_fgl_dn_3: 1.1416 (1.1281)  loss_ddf_dn_3: 0.0333 (0.0322)  loss_mal_dn_4: 0.8130 (0.8089)  loss_bbox_dn_4: 0.5036 (0.4945)  loss_giou_dn_4: 0.7366 (0.8054)  loss_fgl_dn_4: 1.1427 (1.1331)  loss_ddf_dn_4: 0.0061 (0.0062)  loss_mal_dn_5: 0.8032 (0.8113)  loss_bbox_dn_5: 0.5016 (0.4864)  loss_giou_dn_5: 0.7154 (0.7901)  loss_fgl_dn_5: 1.1445 (1.1359)  loss_mal_dn_pre: 0.7852 (0.7803)  loss_bbox_dn_pre: 0.6326 (0.5926)  loss_giou_dn_pre: 0.9588 (0.9970)  time: 1.2550  data: 0.0127  max mem: 13413\nEpoch: [10]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 50.5910 (50.5274)  loss_mal: 1.3467 (1.4037)  loss_bbox: 0.3248 (0.3214)  loss_giou: 0.6834 (0.6276)  loss_fgl: 1.2465 (1.2774)  loss_mal_aux_0: 1.4561 (1.5982)  loss_bbox_aux_0: 0.3472 (0.3364)  loss_giou_aux_0: 0.7004 (0.6551)  loss_fgl_aux_0: 1.2222 (1.2775)  loss_ddf_aux_0: 0.0523 (0.0555)  loss_mal_aux_1: 1.4229 (1.4929)  loss_bbox_aux_1: 0.3409 (0.3342)  loss_giou_aux_1: 0.7123 (0.6530)  loss_fgl_aux_1: 1.2301 (1.2691)  loss_ddf_aux_1: 0.0252 (0.0261)  loss_mal_aux_2: 1.4102 (1.4401)  loss_bbox_aux_2: 0.3332 (0.3286)  loss_giou_aux_2: 0.7064 (0.6441)  loss_fgl_aux_2: 1.2453 (1.2715)  loss_ddf_aux_2: 0.0107 (0.0107)  loss_mal_aux_3: 1.3428 (1.4033)  loss_bbox_aux_3: 0.3259 (0.3253)  loss_giou_aux_3: 0.7030 (0.6366)  loss_fgl_aux_3: 1.2427 (1.2732)  loss_ddf_aux_3: 0.0044 (0.0044)  loss_mal_aux_4: 1.3193 (1.3938)  loss_bbox_aux_4: 0.3204 (0.3225)  loss_giou_aux_4: 0.6925 (0.6303)  loss_fgl_aux_4: 1.2450 (1.2756)  loss_ddf_aux_4: 0.0008 (0.0009)  loss_mal_pre: 1.4434 (1.5927)  loss_bbox_pre: 0.3351 (0.3315)  loss_giou_pre: 0.7017 (0.6511)  loss_mal_enc_0: 1.6230 (1.6340)  loss_bbox_enc_0: 0.3885 (0.4230)  loss_giou_enc_0: 0.8173 (0.8003)  loss_mal_dn_0: 0.7817 (0.7895)  loss_bbox_dn_0: 0.4938 (0.5758)  loss_giou_dn_0: 1.0364 (0.9820)  loss_fgl_dn_0: 1.0624 (1.0929)  loss_ddf_dn_0: 0.2668 (0.2776)  loss_mal_dn_1: 0.7720 (0.7795)  loss_bbox_dn_1: 0.4786 (0.5531)  loss_giou_dn_1: 0.9994 (0.9335)  loss_fgl_dn_1: 1.0648 (1.1057)  loss_ddf_dn_1: 0.1802 (0.1812)  loss_mal_dn_2: 0.7856 (0.7984)  loss_bbox_dn_2: 0.4368 (0.5224)  loss_giou_dn_2: 0.9434 (0.8720)  loss_fgl_dn_2: 1.0883 (1.1217)  loss_ddf_dn_2: 0.0868 (0.0902)  loss_mal_dn_3: 0.7817 (0.8083)  loss_bbox_dn_3: 0.4311 (0.5005)  loss_giou_dn_3: 0.8957 (0.8294)  loss_fgl_dn_3: 1.0982 (1.1304)  loss_ddf_dn_3: 0.0300 (0.0333)  loss_mal_dn_4: 0.7881 (0.8121)  loss_bbox_dn_4: 0.4314 (0.4873)  loss_giou_dn_4: 0.8603 (0.8049)  loss_fgl_dn_4: 1.1126 (1.1355)  loss_ddf_dn_4: 0.0054 (0.0062)  loss_mal_dn_5: 0.8032 (0.8173)  loss_bbox_dn_5: 0.4312 (0.4800)  loss_giou_dn_5: 0.8351 (0.7911)  loss_fgl_dn_5: 1.1210 (1.1384)  loss_mal_dn_pre: 0.7827 (0.7858)  loss_bbox_dn_pre: 0.4938 (0.5816)  loss_giou_dn_pre: 1.0341 (0.9883)  time: 1.2408  data: 0.0124  max mem: 13413\nEpoch: [10]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 50.1836 (50.4433)  loss_mal: 1.1904 (1.3883)  loss_bbox: 0.2436 (0.3198)  loss_giou: 0.5610 (0.6323)  loss_fgl: 1.3082 (1.2755)  loss_mal_aux_0: 1.5820 (1.6009)  loss_bbox_aux_0: 0.2599 (0.3341)  loss_giou_aux_0: 0.5843 (0.6580)  loss_fgl_aux_0: 1.3065 (1.2756)  loss_ddf_aux_0: 0.0441 (0.0537)  loss_mal_aux_1: 1.4531 (1.4952)  loss_bbox_aux_1: 0.2575 (0.3317)  loss_giou_aux_1: 0.5876 (0.6559)  loss_fgl_aux_1: 1.3017 (1.2678)  loss_ddf_aux_1: 0.0230 (0.0256)  loss_mal_aux_2: 1.3506 (1.4305)  loss_bbox_aux_2: 0.2523 (0.3262)  loss_giou_aux_2: 0.5762 (0.6470)  loss_fgl_aux_2: 1.3048 (1.2702)  loss_ddf_aux_2: 0.0093 (0.0106)  loss_mal_aux_3: 1.3105 (1.3892)  loss_bbox_aux_3: 0.2444 (0.3230)  loss_giou_aux_3: 0.5673 (0.6398)  loss_fgl_aux_3: 1.3077 (1.2718)  loss_ddf_aux_3: 0.0035 (0.0043)  loss_mal_aux_4: 1.3555 (1.3822)  loss_bbox_aux_4: 0.2443 (0.3207)  loss_giou_aux_4: 0.5632 (0.6343)  loss_fgl_aux_4: 1.3077 (1.2740)  loss_ddf_aux_4: 0.0006 (0.0009)  loss_mal_pre: 1.5596 (1.5940)  loss_bbox_pre: 0.2510 (0.3291)  loss_giou_pre: 0.5790 (0.6546)  loss_mal_enc_0: 1.5967 (1.6397)  loss_bbox_enc_0: 0.3514 (0.4211)  loss_giou_enc_0: 0.7763 (0.8035)  loss_mal_dn_0: 0.8027 (0.7907)  loss_bbox_dn_0: 0.5046 (0.5697)  loss_giou_dn_0: 0.9409 (0.9792)  loss_fgl_dn_0: 1.1115 (1.0941)  loss_ddf_dn_0: 0.2863 (0.2823)  loss_mal_dn_1: 0.7690 (0.7787)  loss_bbox_dn_1: 0.4936 (0.5474)  loss_giou_dn_1: 0.8906 (0.9315)  loss_fgl_dn_1: 1.1193 (1.1061)  loss_ddf_dn_1: 0.1881 (0.1850)  loss_mal_dn_2: 0.7910 (0.7973)  loss_bbox_dn_2: 0.4765 (0.5166)  loss_giou_dn_2: 0.8159 (0.8694)  loss_fgl_dn_2: 1.1333 (1.1223)  loss_ddf_dn_2: 0.0922 (0.0915)  loss_mal_dn_3: 0.7886 (0.8063)  loss_bbox_dn_3: 0.4671 (0.4953)  loss_giou_dn_3: 0.7711 (0.8282)  loss_fgl_dn_3: 1.1397 (1.1307)  loss_ddf_dn_3: 0.0325 (0.0336)  loss_mal_dn_4: 0.8027 (0.8095)  loss_bbox_dn_4: 0.4550 (0.4827)  loss_giou_dn_4: 0.7502 (0.8046)  loss_fgl_dn_4: 1.1489 (1.1359)  loss_ddf_dn_4: 0.0057 (0.0062)  loss_mal_dn_5: 0.8164 (0.8141)  loss_bbox_dn_5: 0.4481 (0.4759)  loss_giou_dn_5: 0.7439 (0.7915)  loss_fgl_dn_5: 1.1502 (1.1387)  loss_mal_dn_pre: 0.7998 (0.7873)  loss_bbox_dn_pre: 0.5081 (0.5750)  loss_giou_dn_pre: 0.9403 (0.9850)  time: 1.2197  data: 0.0116  max mem: 13413\nEpoch: [10] Total time: 0:05:07 (1.2241 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8272  data: 0.5093  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3556  data: 0.0665  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3053  data: 0.0201  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2927  data: 0.0184  max mem: 13413\nTest: Total time: 0:00:07 (0.3198 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.143\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.269\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.141\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.269\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.148\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.284\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.459\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.533\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.525\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.531\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.857\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.570\nbest_stat: {'epoch': 10, 'coco_eval_bbox': 0.14303282974172637}\nEpoch: [11]  [  0/251]  eta: 0:07:48  lr: 0.000003  loss: 54.5618 (54.5618)  loss_mal: 1.5664 (1.5664)  loss_bbox: 0.5024 (0.5024)  loss_giou: 0.6487 (0.6487)  loss_fgl: 1.2248 (1.2248)  loss_mal_aux_0: 2.0625 (2.0625)  loss_bbox_aux_0: 0.5464 (0.5464)  loss_giou_aux_0: 0.6849 (0.6849)  loss_fgl_aux_0: 1.2571 (1.2571)  loss_ddf_aux_0: 0.0583 (0.0583)  loss_mal_aux_1: 1.5449 (1.5449)  loss_bbox_aux_1: 0.5296 (0.5296)  loss_giou_aux_1: 0.6801 (0.6801)  loss_fgl_aux_1: 1.2473 (1.2473)  loss_ddf_aux_1: 0.0332 (0.0332)  loss_mal_aux_2: 1.7754 (1.7754)  loss_bbox_aux_2: 0.5156 (0.5156)  loss_giou_aux_2: 0.6654 (0.6654)  loss_fgl_aux_2: 1.2433 (1.2433)  loss_ddf_aux_2: 0.0142 (0.0142)  loss_mal_aux_3: 1.4941 (1.4941)  loss_bbox_aux_3: 0.5115 (0.5115)  loss_giou_aux_3: 0.6536 (0.6536)  loss_fgl_aux_3: 1.2406 (1.2406)  loss_ddf_aux_3: 0.0057 (0.0057)  loss_mal_aux_4: 1.6445 (1.6445)  loss_bbox_aux_4: 0.5074 (0.5074)  loss_giou_aux_4: 0.6527 (0.6527)  loss_fgl_aux_4: 1.2323 (1.2323)  loss_ddf_aux_4: 0.0012 (0.0012)  loss_mal_pre: 2.0332 (2.0332)  loss_bbox_pre: 0.5284 (0.5284)  loss_giou_pre: 0.6777 (0.6777)  loss_mal_enc_0: 1.6758 (1.6758)  loss_bbox_enc_0: 0.7095 (0.7095)  loss_giou_enc_0: 0.8492 (0.8492)  loss_mal_dn_0: 0.7871 (0.7871)  loss_bbox_dn_0: 0.7126 (0.7126)  loss_giou_dn_0: 0.9845 (0.9845)  loss_fgl_dn_0: 1.0955 (1.0955)  loss_ddf_dn_0: 0.2684 (0.2684)  loss_mal_dn_1: 0.7861 (0.7861)  loss_bbox_dn_1: 0.6749 (0.6749)  loss_giou_dn_1: 0.9183 (0.9183)  loss_fgl_dn_1: 1.1160 (1.1160)  loss_ddf_dn_1: 0.1746 (0.1746)  loss_mal_dn_2: 0.8125 (0.8125)  loss_bbox_dn_2: 0.6242 (0.6242)  loss_giou_dn_2: 0.8269 (0.8269)  loss_fgl_dn_2: 1.1425 (1.1425)  loss_ddf_dn_2: 0.0822 (0.0822)  loss_mal_dn_3: 0.7817 (0.7817)  loss_bbox_dn_3: 0.5961 (0.5961)  loss_giou_dn_3: 0.7834 (0.7834)  loss_fgl_dn_3: 1.1474 (1.1474)  loss_ddf_dn_3: 0.0302 (0.0302)  loss_mal_dn_4: 0.7676 (0.7676)  loss_bbox_dn_4: 0.5808 (0.5808)  loss_giou_dn_4: 0.7639 (0.7639)  loss_fgl_dn_4: 1.1451 (1.1451)  loss_ddf_dn_4: 0.0053 (0.0053)  loss_mal_dn_5: 0.7744 (0.7744)  loss_bbox_dn_5: 0.5673 (0.5673)  loss_giou_dn_5: 0.7469 (0.7469)  loss_fgl_dn_5: 1.1457 (1.1457)  loss_mal_dn_pre: 0.7788 (0.7788)  loss_bbox_dn_pre: 0.7223 (0.7223)  loss_giou_dn_pre: 1.0001 (1.0001)  time: 1.8677  data: 0.7477  max mem: 13413\nEpoch: [11]  [100/251]  eta: 0:03:06  lr: 0.000003  loss: 49.0978 (49.0979)  loss_mal: 1.2100 (1.2767)  loss_bbox: 0.2504 (0.3041)  loss_giou: 0.5169 (0.5990)  loss_fgl: 1.3065 (1.2759)  loss_mal_aux_0: 1.5107 (1.5549)  loss_bbox_aux_0: 0.2886 (0.3191)  loss_giou_aux_0: 0.5872 (0.6269)  loss_fgl_aux_0: 1.3086 (1.2777)  loss_ddf_aux_0: 0.0454 (0.0505)  loss_mal_aux_1: 1.3652 (1.3991)  loss_bbox_aux_1: 0.2833 (0.3168)  loss_giou_aux_1: 0.5726 (0.6226)  loss_fgl_aux_1: 1.3106 (1.2730)  loss_ddf_aux_1: 0.0253 (0.0260)  loss_mal_aux_2: 1.3730 (1.3603)  loss_bbox_aux_2: 0.2671 (0.3098)  loss_giou_aux_2: 0.5279 (0.6107)  loss_fgl_aux_2: 1.3080 (1.2740)  loss_ddf_aux_2: 0.0110 (0.0112)  loss_mal_aux_3: 1.2568 (1.2979)  loss_bbox_aux_3: 0.2568 (0.3062)  loss_giou_aux_3: 0.5204 (0.6035)  loss_fgl_aux_3: 1.3072 (1.2747)  loss_ddf_aux_3: 0.0044 (0.0042)  loss_mal_aux_4: 1.2559 (1.2909)  loss_bbox_aux_4: 0.2526 (0.3046)  loss_giou_aux_4: 0.5118 (0.5999)  loss_fgl_aux_4: 1.3062 (1.2752)  loss_ddf_aux_4: 0.0008 (0.0008)  loss_mal_pre: 1.5068 (1.5404)  loss_bbox_pre: 0.2838 (0.3160)  loss_giou_pre: 0.6037 (0.6249)  loss_mal_enc_0: 1.5654 (1.6023)  loss_bbox_enc_0: 0.4130 (0.4067)  loss_giou_enc_0: 0.7453 (0.7749)  loss_mal_dn_0: 0.8081 (0.8058)  loss_bbox_dn_0: 0.6022 (0.5430)  loss_giou_dn_0: 0.9129 (0.9270)  loss_fgl_dn_0: 1.1208 (1.1250)  loss_ddf_dn_0: 0.3437 (0.3244)  loss_mal_dn_1: 0.7842 (0.7871)  loss_bbox_dn_1: 0.5592 (0.5167)  loss_giou_dn_1: 0.8551 (0.8750)  loss_fgl_dn_1: 1.1228 (1.1366)  loss_ddf_dn_1: 0.2244 (0.2167)  loss_mal_dn_2: 0.7944 (0.8023)  loss_bbox_dn_2: 0.5131 (0.4779)  loss_giou_dn_2: 0.7880 (0.7999)  loss_fgl_dn_2: 1.1554 (1.1536)  loss_ddf_dn_2: 0.1046 (0.1016)  loss_mal_dn_3: 0.8042 (0.8061)  loss_bbox_dn_3: 0.4703 (0.4550)  loss_giou_dn_3: 0.7415 (0.7592)  loss_fgl_dn_3: 1.1619 (1.1597)  loss_ddf_dn_3: 0.0351 (0.0350)  loss_mal_dn_4: 0.7920 (0.8088)  loss_bbox_dn_4: 0.4526 (0.4429)  loss_giou_dn_4: 0.7086 (0.7374)  loss_fgl_dn_4: 1.1585 (1.1634)  loss_ddf_dn_4: 0.0058 (0.0060)  loss_mal_dn_5: 0.7983 (0.8096)  loss_bbox_dn_5: 0.4472 (0.4362)  loss_giou_dn_5: 0.6968 (0.7257)  loss_fgl_dn_5: 1.1574 (1.1656)  loss_mal_dn_pre: 0.8066 (0.8024)  loss_bbox_dn_pre: 0.6071 (0.5488)  loss_giou_dn_pre: 0.9189 (0.9323)  time: 1.2339  data: 0.0120  max mem: 13413\nEpoch: [11]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 47.2280 (48.9611)  loss_mal: 1.2041 (1.2744)  loss_bbox: 0.2523 (0.3043)  loss_giou: 0.5094 (0.5925)  loss_fgl: 1.3005 (1.2781)  loss_mal_aux_0: 1.3926 (1.5285)  loss_bbox_aux_0: 0.2840 (0.3191)  loss_giou_aux_0: 0.5272 (0.6226)  loss_fgl_aux_0: 1.2947 (1.2776)  loss_ddf_aux_0: 0.0472 (0.0510)  loss_mal_aux_1: 1.3076 (1.3867)  loss_bbox_aux_1: 0.2746 (0.3167)  loss_giou_aux_1: 0.5373 (0.6186)  loss_fgl_aux_1: 1.2973 (1.2738)  loss_ddf_aux_1: 0.0276 (0.0270)  loss_mal_aux_2: 1.2490 (1.3358)  loss_bbox_aux_2: 0.2616 (0.3095)  loss_giou_aux_2: 0.5008 (0.6053)  loss_fgl_aux_2: 1.2945 (1.2750)  loss_ddf_aux_2: 0.0113 (0.0115)  loss_mal_aux_3: 1.2520 (1.2914)  loss_bbox_aux_3: 0.2510 (0.3056)  loss_giou_aux_3: 0.4841 (0.5969)  loss_fgl_aux_3: 1.2980 (1.2761)  loss_ddf_aux_3: 0.0041 (0.0042)  loss_mal_aux_4: 1.2432 (1.2886)  loss_bbox_aux_4: 0.2508 (0.3043)  loss_giou_aux_4: 0.4956 (0.5932)  loss_fgl_aux_4: 1.3008 (1.2770)  loss_ddf_aux_4: 0.0007 (0.0008)  loss_mal_pre: 1.4229 (1.5246)  loss_bbox_pre: 0.2760 (0.3156)  loss_giou_pre: 0.5363 (0.6196)  loss_mal_enc_0: 1.5293 (1.6093)  loss_bbox_enc_0: 0.3215 (0.4053)  loss_giou_enc_0: 0.6931 (0.7643)  loss_mal_dn_0: 0.8164 (0.8102)  loss_bbox_dn_0: 0.4567 (0.5331)  loss_giou_dn_0: 0.8508 (0.9139)  loss_fgl_dn_0: 1.1398 (1.1346)  loss_ddf_dn_0: 0.3903 (0.3547)  loss_mal_dn_1: 0.7856 (0.7916)  loss_bbox_dn_1: 0.4244 (0.5060)  loss_giou_dn_1: 0.8052 (0.8608)  loss_fgl_dn_1: 1.1609 (1.1450)  loss_ddf_dn_1: 0.2626 (0.2371)  loss_mal_dn_2: 0.7920 (0.8085)  loss_bbox_dn_2: 0.3831 (0.4669)  loss_giou_dn_2: 0.7089 (0.7847)  loss_fgl_dn_2: 1.1818 (1.1614)  loss_ddf_dn_2: 0.1163 (0.1085)  loss_mal_dn_3: 0.7949 (0.8130)  loss_bbox_dn_3: 0.3536 (0.4456)  loss_giou_dn_3: 0.6684 (0.7462)  loss_fgl_dn_3: 1.1842 (1.1669)  loss_ddf_dn_3: 0.0384 (0.0366)  loss_mal_dn_4: 0.7886 (0.8150)  loss_bbox_dn_4: 0.3419 (0.4341)  loss_giou_dn_4: 0.6410 (0.7253)  loss_fgl_dn_4: 1.1822 (1.1710)  loss_ddf_dn_4: 0.0065 (0.0062)  loss_mal_dn_5: 0.7896 (0.8199)  loss_bbox_dn_5: 0.3348 (0.4280)  loss_giou_dn_5: 0.6237 (0.7148)  loss_fgl_dn_5: 1.1805 (1.1733)  loss_mal_dn_pre: 0.8125 (0.8070)  loss_bbox_dn_pre: 0.4592 (0.5384)  loss_giou_dn_pre: 0.8502 (0.9179)  time: 1.1343  data: 0.0133  max mem: 13413\nEpoch: [11]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 48.4656 (48.9940)  loss_mal: 1.3594 (1.2900)  loss_bbox: 0.2248 (0.3017)  loss_giou: 0.5104 (0.5911)  loss_fgl: 1.2880 (1.2793)  loss_mal_aux_0: 1.4795 (1.5311)  loss_bbox_aux_0: 0.2794 (0.3177)  loss_giou_aux_0: 0.5724 (0.6224)  loss_fgl_aux_0: 1.3062 (1.2783)  loss_ddf_aux_0: 0.0529 (0.0517)  loss_mal_aux_1: 1.3271 (1.3917)  loss_bbox_aux_1: 0.2737 (0.3149)  loss_giou_aux_1: 0.5677 (0.6182)  loss_fgl_aux_1: 1.3015 (1.2751)  loss_ddf_aux_1: 0.0295 (0.0276)  loss_mal_aux_2: 1.3057 (1.3472)  loss_bbox_aux_2: 0.2599 (0.3071)  loss_giou_aux_2: 0.5339 (0.6037)  loss_fgl_aux_2: 1.3117 (1.2766)  loss_ddf_aux_2: 0.0120 (0.0117)  loss_mal_aux_3: 1.3633 (1.3076)  loss_bbox_aux_3: 0.2194 (0.3031)  loss_giou_aux_3: 0.5238 (0.5952)  loss_fgl_aux_3: 1.3056 (1.2775)  loss_ddf_aux_3: 0.0044 (0.0043)  loss_mal_aux_4: 1.3008 (1.3028)  loss_bbox_aux_4: 0.2193 (0.3017)  loss_giou_aux_4: 0.5181 (0.5917)  loss_fgl_aux_4: 1.2958 (1.2783)  loss_ddf_aux_4: 0.0008 (0.0008)  loss_mal_pre: 1.4844 (1.5265)  loss_bbox_pre: 0.2617 (0.3142)  loss_giou_pre: 0.5776 (0.6197)  loss_mal_enc_0: 1.6494 (1.6171)  loss_bbox_enc_0: 0.3488 (0.4017)  loss_giou_enc_0: 0.7715 (0.7626)  loss_mal_dn_0: 0.8120 (0.8107)  loss_bbox_dn_0: 0.4923 (0.5268)  loss_giou_dn_0: 0.8888 (0.9126)  loss_fgl_dn_0: 1.1454 (1.1359)  loss_ddf_dn_0: 0.4234 (0.3670)  loss_mal_dn_1: 0.7939 (0.7925)  loss_bbox_dn_1: 0.4581 (0.4994)  loss_giou_dn_1: 0.8279 (0.8584)  loss_fgl_dn_1: 1.1664 (1.1464)  loss_ddf_dn_1: 0.2838 (0.2456)  loss_mal_dn_2: 0.8184 (0.8107)  loss_bbox_dn_2: 0.4285 (0.4596)  loss_giou_dn_2: 0.7198 (0.7802)  loss_fgl_dn_2: 1.1851 (1.1629)  loss_ddf_dn_2: 0.1221 (0.1113)  loss_mal_dn_3: 0.8184 (0.8150)  loss_bbox_dn_3: 0.3972 (0.4389)  loss_giou_dn_3: 0.6655 (0.7422)  loss_fgl_dn_3: 1.1889 (1.1680)  loss_ddf_dn_3: 0.0400 (0.0372)  loss_mal_dn_4: 0.8262 (0.8177)  loss_bbox_dn_4: 0.3766 (0.4277)  loss_giou_dn_4: 0.6414 (0.7216)  loss_fgl_dn_4: 1.1945 (1.1721)  loss_ddf_dn_4: 0.0064 (0.0063)  loss_mal_dn_5: 0.8208 (0.8224)  loss_bbox_dn_5: 0.3723 (0.4219)  loss_giou_dn_5: 0.6260 (0.7113)  loss_fgl_dn_5: 1.1961 (1.1744)  loss_mal_dn_pre: 0.8076 (0.8077)  loss_bbox_dn_pre: 0.4923 (0.5315)  loss_giou_dn_pre: 0.8959 (0.9161)  time: 1.2261  data: 0.0108  max mem: 13413\nEpoch: [11] Total time: 0:05:05 (1.2181 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8253  data: 0.5277  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3569  data: 0.0692  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3085  data: 0.0221  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2967  data: 0.0208  max mem: 13413\nTest: Total time: 0:00:08 (0.3221 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.05s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.219\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.394\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.236\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.226\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.370\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.526\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.588\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.617\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.569\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.858\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.623\nbest_stat: {'epoch': 11, 'coco_eval_bbox': 0.21924533822039444}\nEpoch: [12]  [  0/251]  eta: 0:06:53  lr: 0.000003  loss: 45.8988 (45.8988)  loss_mal: 1.3008 (1.3008)  loss_bbox: 0.1637 (0.1637)  loss_giou: 0.3481 (0.3481)  loss_fgl: 1.3183 (1.3183)  loss_mal_aux_0: 1.5605 (1.5605)  loss_bbox_aux_0: 0.2034 (0.2034)  loss_giou_aux_0: 0.3914 (0.3914)  loss_fgl_aux_0: 1.3502 (1.3502)  loss_ddf_aux_0: 0.0802 (0.0802)  loss_mal_aux_1: 1.3779 (1.3779)  loss_bbox_aux_1: 0.1950 (0.1950)  loss_giou_aux_1: 0.3802 (0.3802)  loss_fgl_aux_1: 1.3332 (1.3332)  loss_ddf_aux_1: 0.0488 (0.0488)  loss_mal_aux_2: 1.2939 (1.2939)  loss_bbox_aux_2: 0.1798 (0.1798)  loss_giou_aux_2: 0.3483 (0.3483)  loss_fgl_aux_2: 1.3387 (1.3387)  loss_ddf_aux_2: 0.0196 (0.0196)  loss_mal_aux_3: 1.2783 (1.2783)  loss_bbox_aux_3: 0.1768 (0.1768)  loss_giou_aux_3: 0.3573 (0.3573)  loss_fgl_aux_3: 1.3246 (1.3246)  loss_ddf_aux_3: 0.0057 (0.0057)  loss_mal_aux_4: 1.2158 (1.2158)  loss_bbox_aux_4: 0.1699 (0.1699)  loss_giou_aux_4: 0.3520 (0.3520)  loss_fgl_aux_4: 1.3210 (1.3210)  loss_ddf_aux_4: 0.0007 (0.0007)  loss_mal_pre: 1.5742 (1.5742)  loss_bbox_pre: 0.1937 (0.1937)  loss_giou_pre: 0.3926 (0.3926)  loss_mal_enc_0: 1.6895 (1.6895)  loss_bbox_enc_0: 0.4028 (0.4028)  loss_giou_enc_0: 0.7345 (0.7345)  loss_mal_dn_0: 0.8936 (0.8936)  loss_bbox_dn_0: 0.4585 (0.4585)  loss_giou_dn_0: 0.7777 (0.7777)  loss_fgl_dn_0: 1.1956 (1.1956)  loss_ddf_dn_0: 0.4443 (0.4443)  loss_mal_dn_1: 0.8662 (0.8662)  loss_bbox_dn_1: 0.4138 (0.4138)  loss_giou_dn_1: 0.7004 (0.7004)  loss_fgl_dn_1: 1.2153 (1.2153)  loss_ddf_dn_1: 0.3043 (0.3043)  loss_mal_dn_2: 0.8579 (0.8579)  loss_bbox_dn_2: 0.3634 (0.3634)  loss_giou_dn_2: 0.6147 (0.6147)  loss_fgl_dn_2: 1.2251 (1.2251)  loss_ddf_dn_2: 0.1281 (0.1281)  loss_mal_dn_3: 0.8555 (0.8555)  loss_bbox_dn_3: 0.3420 (0.3420)  loss_giou_dn_3: 0.5781 (0.5781)  loss_fgl_dn_3: 1.2174 (1.2174)  loss_ddf_dn_3: 0.0403 (0.0403)  loss_mal_dn_4: 0.8394 (0.8394)  loss_bbox_dn_4: 0.3259 (0.3259)  loss_giou_dn_4: 0.5422 (0.5422)  loss_fgl_dn_4: 1.2195 (1.2195)  loss_ddf_dn_4: 0.0071 (0.0071)  loss_mal_dn_5: 0.8511 (0.8511)  loss_bbox_dn_5: 0.3167 (0.3167)  loss_giou_dn_5: 0.5229 (0.5229)  loss_fgl_dn_5: 1.2196 (1.2196)  loss_mal_dn_pre: 0.8901 (0.8901)  loss_bbox_dn_pre: 0.4648 (0.4648)  loss_giou_dn_pre: 0.7861 (0.7861)  time: 1.6471  data: 0.5249  max mem: 13413\nEpoch: [12]  [100/251]  eta: 0:03:05  lr: 0.000003  loss: 47.4184 (47.9783)  loss_mal: 1.2500 (1.2626)  loss_bbox: 0.2576 (0.2691)  loss_giou: 0.5227 (0.5292)  loss_fgl: 1.3039 (1.2970)  loss_mal_aux_0: 1.4072 (1.5002)  loss_bbox_aux_0: 0.2757 (0.2909)  loss_giou_aux_0: 0.5353 (0.5623)  loss_fgl_aux_0: 1.3233 (1.2993)  loss_ddf_aux_0: 0.0601 (0.0592)  loss_mal_aux_1: 1.3213 (1.3830)  loss_bbox_aux_1: 0.2812 (0.2866)  loss_giou_aux_1: 0.5399 (0.5571)  loss_fgl_aux_1: 1.3183 (1.2964)  loss_ddf_aux_1: 0.0332 (0.0330)  loss_mal_aux_2: 1.2529 (1.3127)  loss_bbox_aux_2: 0.2676 (0.2758)  loss_giou_aux_2: 0.5262 (0.5398)  loss_fgl_aux_2: 1.3236 (1.2956)  loss_ddf_aux_2: 0.0124 (0.0133)  loss_mal_aux_3: 1.3135 (1.2821)  loss_bbox_aux_3: 0.2598 (0.2711)  loss_giou_aux_3: 0.5282 (0.5320)  loss_fgl_aux_3: 1.3095 (1.2954)  loss_ddf_aux_3: 0.0042 (0.0045)  loss_mal_aux_4: 1.2490 (1.2563)  loss_bbox_aux_4: 0.2539 (0.2694)  loss_giou_aux_4: 0.5261 (0.5295)  loss_fgl_aux_4: 1.3038 (1.2962)  loss_ddf_aux_4: 0.0008 (0.0008)  loss_mal_pre: 1.4609 (1.5001)  loss_bbox_pre: 0.2810 (0.2869)  loss_giou_pre: 0.5418 (0.5589)  loss_mal_enc_0: 1.5107 (1.6523)  loss_bbox_enc_0: 0.4041 (0.3777)  loss_giou_enc_0: 0.7000 (0.7126)  loss_mal_dn_0: 0.8052 (0.8192)  loss_bbox_dn_0: 0.4903 (0.5128)  loss_giou_dn_0: 0.8634 (0.8630)  loss_fgl_dn_0: 1.1680 (1.1636)  loss_ddf_dn_0: 0.4225 (0.4553)  loss_mal_dn_1: 0.7812 (0.7993)  loss_bbox_dn_1: 0.4502 (0.4781)  loss_giou_dn_1: 0.7877 (0.7975)  loss_fgl_dn_1: 1.1717 (1.1735)  loss_ddf_dn_1: 0.2828 (0.3048)  loss_mal_dn_2: 0.8076 (0.8170)  loss_bbox_dn_2: 0.3973 (0.4310)  loss_giou_dn_2: 0.6955 (0.7116)  loss_fgl_dn_2: 1.1753 (1.1865)  loss_ddf_dn_2: 0.1152 (0.1277)  loss_mal_dn_3: 0.7861 (0.8113)  loss_bbox_dn_3: 0.3831 (0.4102)  loss_giou_dn_3: 0.6534 (0.6787)  loss_fgl_dn_3: 1.1670 (1.1880)  loss_ddf_dn_3: 0.0367 (0.0400)  loss_mal_dn_4: 0.7988 (0.8119)  loss_bbox_dn_4: 0.3717 (0.3987)  loss_giou_dn_4: 0.6353 (0.6590)  loss_fgl_dn_4: 1.1674 (1.1910)  loss_ddf_dn_4: 0.0059 (0.0065)  loss_mal_dn_5: 0.8071 (0.8189)  loss_bbox_dn_5: 0.3631 (0.3931)  loss_giou_dn_5: 0.6258 (0.6496)  loss_fgl_dn_5: 1.1722 (1.1928)  loss_mal_dn_pre: 0.7998 (0.8163)  loss_bbox_dn_pre: 0.4955 (0.5172)  loss_giou_dn_pre: 0.8635 (0.8654)  time: 1.2347  data: 0.0123  max mem: 13413\nEpoch: [12]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 47.4160 (47.6047)  loss_mal: 1.1406 (1.2098)  loss_bbox: 0.2307 (0.2721)  loss_giou: 0.5647 (0.5457)  loss_fgl: 1.2984 (1.2886)  loss_mal_aux_0: 1.3457 (1.4666)  loss_bbox_aux_0: 0.2469 (0.2922)  loss_giou_aux_0: 0.5757 (0.5794)  loss_fgl_aux_0: 1.3019 (1.2901)  loss_ddf_aux_0: 0.0497 (0.0561)  loss_mal_aux_1: 1.2197 (1.3406)  loss_bbox_aux_1: 0.2382 (0.2879)  loss_giou_aux_1: 0.5763 (0.5735)  loss_fgl_aux_1: 1.3138 (1.2890)  loss_ddf_aux_1: 0.0288 (0.0314)  loss_mal_aux_2: 1.1670 (1.2792)  loss_bbox_aux_2: 0.2260 (0.2776)  loss_giou_aux_2: 0.5657 (0.5554)  loss_fgl_aux_2: 1.3048 (1.2883)  loss_ddf_aux_2: 0.0102 (0.0123)  loss_mal_aux_3: 1.1523 (1.2401)  loss_bbox_aux_3: 0.2260 (0.2738)  loss_giou_aux_3: 0.5698 (0.5487)  loss_fgl_aux_3: 1.3011 (1.2877)  loss_ddf_aux_3: 0.0033 (0.0040)  loss_mal_aux_4: 1.1270 (1.2103)  loss_bbox_aux_4: 0.2287 (0.2724)  loss_giou_aux_4: 0.5686 (0.5460)  loss_fgl_aux_4: 1.3012 (1.2881)  loss_ddf_aux_4: 0.0005 (0.0007)  loss_mal_pre: 1.3389 (1.4632)  loss_bbox_pre: 0.2412 (0.2886)  loss_giou_pre: 0.5766 (0.5769)  loss_mal_enc_0: 1.5508 (1.6011)  loss_bbox_enc_0: 0.3233 (0.3830)  loss_giou_enc_0: 0.7136 (0.7330)  loss_mal_dn_0: 0.8242 (0.8196)  loss_bbox_dn_0: 0.3982 (0.4928)  loss_giou_dn_0: 0.8136 (0.8580)  loss_fgl_dn_0: 1.1764 (1.1688)  loss_ddf_dn_0: 0.5216 (0.4698)  loss_mal_dn_1: 0.7974 (0.7963)  loss_bbox_dn_1: 0.3663 (0.4584)  loss_giou_dn_1: 0.7495 (0.7914)  loss_fgl_dn_1: 1.1829 (1.1787)  loss_ddf_dn_1: 0.3296 (0.3106)  loss_mal_dn_2: 0.8140 (0.8118)  loss_bbox_dn_2: 0.3394 (0.4135)  loss_giou_dn_2: 0.6803 (0.7055)  loss_fgl_dn_2: 1.1927 (1.1908)  loss_ddf_dn_2: 0.1263 (0.1257)  loss_mal_dn_3: 0.8018 (0.8057)  loss_bbox_dn_3: 0.3326 (0.3948)  loss_giou_dn_3: 0.6512 (0.6748)  loss_fgl_dn_3: 1.1938 (1.1920)  loss_ddf_dn_3: 0.0381 (0.0387)  loss_mal_dn_4: 0.7954 (0.8044)  loss_bbox_dn_4: 0.3237 (0.3844)  loss_giou_dn_4: 0.6315 (0.6564)  loss_fgl_dn_4: 1.1954 (1.1949)  loss_ddf_dn_4: 0.0057 (0.0061)  loss_mal_dn_5: 0.8013 (0.8092)  loss_bbox_dn_5: 0.3184 (0.3795)  loss_giou_dn_5: 0.6229 (0.6476)  loss_fgl_dn_5: 1.1961 (1.1968)  loss_mal_dn_pre: 0.8188 (0.8166)  loss_bbox_dn_pre: 0.4171 (0.4973)  loss_giou_dn_pre: 0.8207 (0.8603)  time: 1.0861  data: 0.0103  max mem: 13413\nEpoch: [12]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 48.6481 (47.4994)  loss_mal: 1.2061 (1.2000)  loss_bbox: 0.2623 (0.2722)  loss_giou: 0.5041 (0.5457)  loss_fgl: 1.2784 (1.2878)  loss_mal_aux_0: 1.4229 (1.4610)  loss_bbox_aux_0: 0.2911 (0.2932)  loss_giou_aux_0: 0.5738 (0.5817)  loss_fgl_aux_0: 1.2908 (1.2891)  loss_ddf_aux_0: 0.0574 (0.0561)  loss_mal_aux_1: 1.2764 (1.3267)  loss_bbox_aux_1: 0.2877 (0.2886)  loss_giou_aux_1: 0.5575 (0.5753)  loss_fgl_aux_1: 1.2917 (1.2884)  loss_ddf_aux_1: 0.0339 (0.0316)  loss_mal_aux_2: 1.2861 (1.2643)  loss_bbox_aux_2: 0.2777 (0.2779)  loss_giou_aux_2: 0.5296 (0.5565)  loss_fgl_aux_2: 1.2808 (1.2874)  loss_ddf_aux_2: 0.0122 (0.0123)  loss_mal_aux_3: 1.2295 (1.2269)  loss_bbox_aux_3: 0.2674 (0.2740)  loss_giou_aux_3: 0.5076 (0.5491)  loss_fgl_aux_3: 1.2745 (1.2868)  loss_ddf_aux_3: 0.0037 (0.0040)  loss_mal_aux_4: 1.1738 (1.1984)  loss_bbox_aux_4: 0.2652 (0.2724)  loss_giou_aux_4: 0.5034 (0.5462)  loss_fgl_aux_4: 1.2825 (1.2872)  loss_ddf_aux_4: 0.0005 (0.0007)  loss_mal_pre: 1.3994 (1.4571)  loss_bbox_pre: 0.2982 (0.2896)  loss_giou_pre: 0.5863 (0.5792)  loss_mal_enc_0: 1.5156 (1.5927)  loss_bbox_enc_0: 0.4284 (0.3851)  loss_giou_enc_0: 0.7459 (0.7338)  loss_mal_dn_0: 0.8242 (0.8214)  loss_bbox_dn_0: 0.5422 (0.4927)  loss_giou_dn_0: 0.8552 (0.8536)  loss_fgl_dn_0: 1.1652 (1.1714)  loss_ddf_dn_0: 0.4463 (0.4722)  loss_mal_dn_1: 0.7910 (0.7974)  loss_bbox_dn_1: 0.4944 (0.4569)  loss_giou_dn_1: 0.7419 (0.7857)  loss_fgl_dn_1: 1.1873 (1.1815)  loss_ddf_dn_1: 0.2901 (0.3104)  loss_mal_dn_2: 0.8096 (0.8107)  loss_bbox_dn_2: 0.4527 (0.4114)  loss_giou_dn_2: 0.6427 (0.7002)  loss_fgl_dn_2: 1.2092 (1.1931)  loss_ddf_dn_2: 0.1118 (0.1238)  loss_mal_dn_3: 0.8057 (0.8044)  loss_bbox_dn_3: 0.4277 (0.3929)  loss_giou_dn_3: 0.6043 (0.6702)  loss_fgl_dn_3: 1.2082 (1.1943)  loss_ddf_dn_3: 0.0328 (0.0378)  loss_mal_dn_4: 0.7886 (0.8018)  loss_bbox_dn_4: 0.4139 (0.3828)  loss_giou_dn_4: 0.5933 (0.6522)  loss_fgl_dn_4: 1.2034 (1.1973)  loss_ddf_dn_4: 0.0050 (0.0059)  loss_mal_dn_5: 0.8013 (0.8059)  loss_bbox_dn_5: 0.4084 (0.3782)  loss_giou_dn_5: 0.5840 (0.6438)  loss_fgl_dn_5: 1.1994 (1.1992)  loss_mal_dn_pre: 0.8184 (0.8184)  loss_bbox_dn_pre: 0.5638 (0.4970)  loss_giou_dn_pre: 0.8511 (0.8556)  time: 1.2398  data: 0.0120  max mem: 13413\nEpoch: [12] Total time: 0:05:09 (1.2315 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8112  data: 0.4992  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3563  data: 0.0656  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3062  data: 0.0201  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2931  data: 0.0189  max mem: 13413\nTest: Total time: 0:00:07 (0.3195 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.203\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.371\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.219\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.205\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.357\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.543\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.610\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.598\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.921\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.692\nbest_stat: {'epoch': 11, 'coco_eval_bbox': 0.21924533822039444}\nEpoch: [13]  [  0/251]  eta: 0:07:53  lr: 0.000003  loss: 46.2708 (46.2708)  loss_mal: 0.9150 (0.9150)  loss_bbox: 0.3882 (0.3882)  loss_giou: 0.3306 (0.3306)  loss_fgl: 1.3431 (1.3431)  loss_mal_aux_0: 1.3604 (1.3604)  loss_bbox_aux_0: 0.3993 (0.3993)  loss_giou_aux_0: 0.3875 (0.3875)  loss_fgl_aux_0: 1.3651 (1.3651)  loss_ddf_aux_0: 0.0672 (0.0672)  loss_mal_aux_1: 1.1221 (1.1221)  loss_bbox_aux_1: 0.3943 (0.3943)  loss_giou_aux_1: 0.3745 (0.3745)  loss_fgl_aux_1: 1.3505 (1.3505)  loss_ddf_aux_1: 0.0369 (0.0369)  loss_mal_aux_2: 0.9653 (0.9653)  loss_bbox_aux_2: 0.3792 (0.3792)  loss_giou_aux_2: 0.3484 (0.3484)  loss_fgl_aux_2: 1.3421 (1.3421)  loss_ddf_aux_2: 0.0133 (0.0133)  loss_mal_aux_3: 0.9258 (0.9258)  loss_bbox_aux_3: 0.3790 (0.3790)  loss_giou_aux_3: 0.3299 (0.3299)  loss_fgl_aux_3: 1.3427 (1.3427)  loss_ddf_aux_3: 0.0042 (0.0042)  loss_mal_aux_4: 0.8716 (0.8716)  loss_bbox_aux_4: 0.3827 (0.3827)  loss_giou_aux_4: 0.3273 (0.3273)  loss_fgl_aux_4: 1.3415 (1.3415)  loss_ddf_aux_4: 0.0007 (0.0007)  loss_mal_pre: 1.3311 (1.3311)  loss_bbox_pre: 0.4153 (0.4153)  loss_giou_pre: 0.4078 (0.4078)  loss_mal_enc_0: 1.3174 (1.3174)  loss_bbox_enc_0: 0.6210 (0.6210)  loss_giou_enc_0: 0.6344 (0.6344)  loss_mal_dn_0: 0.7910 (0.7910)  loss_bbox_dn_0: 0.8803 (0.8803)  loss_giou_dn_0: 0.8781 (0.8781)  loss_fgl_dn_0: 1.1473 (1.1473)  loss_ddf_dn_0: 0.4433 (0.4433)  loss_mal_dn_1: 0.7681 (0.7681)  loss_bbox_dn_1: 0.7787 (0.7787)  loss_giou_dn_1: 0.7474 (0.7474)  loss_fgl_dn_1: 1.1798 (1.1798)  loss_ddf_dn_1: 0.2896 (0.2896)  loss_mal_dn_2: 0.7485 (0.7485)  loss_bbox_dn_2: 0.6470 (0.6470)  loss_giou_dn_2: 0.6014 (0.6014)  loss_fgl_dn_2: 1.2072 (1.2072)  loss_ddf_dn_2: 0.1115 (0.1115)  loss_mal_dn_3: 0.7144 (0.7144)  loss_bbox_dn_3: 0.5812 (0.5812)  loss_giou_dn_3: 0.5401 (0.5401)  loss_fgl_dn_3: 1.2085 (1.2085)  loss_ddf_dn_3: 0.0341 (0.0341)  loss_mal_dn_4: 0.6938 (0.6938)  loss_bbox_dn_4: 0.5491 (0.5491)  loss_giou_dn_4: 0.5130 (0.5130)  loss_fgl_dn_4: 1.2067 (1.2067)  loss_ddf_dn_4: 0.0051 (0.0051)  loss_mal_dn_5: 0.6787 (0.6787)  loss_bbox_dn_5: 0.5387 (0.5387)  loss_giou_dn_5: 0.5060 (0.5060)  loss_fgl_dn_5: 1.2044 (1.2044)  loss_mal_dn_pre: 0.7852 (0.7852)  loss_bbox_dn_pre: 0.8902 (0.8902)  loss_giou_dn_pre: 0.8869 (0.8869)  time: 1.8869  data: 0.6146  max mem: 13413\nEpoch: [13]  [100/251]  eta: 0:03:03  lr: 0.000003  loss: 47.2625 (46.7682)  loss_mal: 1.1426 (1.1734)  loss_bbox: 0.2830 (0.2672)  loss_giou: 0.4701 (0.4988)  loss_fgl: 1.2966 (1.2995)  loss_mal_aux_0: 1.4629 (1.4520)  loss_bbox_aux_0: 0.2947 (0.2874)  loss_giou_aux_0: 0.5204 (0.5410)  loss_fgl_aux_0: 1.3113 (1.3007)  loss_ddf_aux_0: 0.0616 (0.0596)  loss_mal_aux_1: 1.3447 (1.3028)  loss_bbox_aux_1: 0.2988 (0.2827)  loss_giou_aux_1: 0.5049 (0.5323)  loss_fgl_aux_1: 1.3055 (1.3003)  loss_ddf_aux_1: 0.0382 (0.0350)  loss_mal_aux_2: 1.2666 (1.2401)  loss_bbox_aux_2: 0.2877 (0.2726)  loss_giou_aux_2: 0.4861 (0.5114)  loss_fgl_aux_2: 1.2877 (1.2976)  loss_ddf_aux_2: 0.0139 (0.0128)  loss_mal_aux_3: 1.1738 (1.1992)  loss_bbox_aux_3: 0.2852 (0.2688)  loss_giou_aux_3: 0.4597 (0.5033)  loss_fgl_aux_3: 1.2958 (1.2975)  loss_ddf_aux_3: 0.0039 (0.0039)  loss_mal_aux_4: 1.0996 (1.1880)  loss_bbox_aux_4: 0.2847 (0.2676)  loss_giou_aux_4: 0.4625 (0.4996)  loss_fgl_aux_4: 1.2977 (1.2988)  loss_ddf_aux_4: 0.0005 (0.0006)  loss_mal_pre: 1.4600 (1.4470)  loss_bbox_pre: 0.2896 (0.2851)  loss_giou_pre: 0.5290 (0.5380)  loss_mal_enc_0: 1.6162 (1.5663)  loss_bbox_enc_0: 0.3821 (0.3796)  loss_giou_enc_0: 0.6927 (0.6953)  loss_mal_dn_0: 0.8218 (0.8296)  loss_bbox_dn_0: 0.4871 (0.4834)  loss_giou_dn_0: 0.8011 (0.8159)  loss_fgl_dn_0: 1.1867 (1.1893)  loss_ddf_dn_0: 0.5610 (0.5437)  loss_mal_dn_1: 0.7910 (0.7993)  loss_bbox_dn_1: 0.4585 (0.4421)  loss_giou_dn_1: 0.7279 (0.7378)  loss_fgl_dn_1: 1.1849 (1.1988)  loss_ddf_dn_1: 0.3587 (0.3466)  loss_mal_dn_2: 0.7939 (0.8006)  loss_bbox_dn_2: 0.4067 (0.3945)  loss_giou_dn_2: 0.6609 (0.6506)  loss_fgl_dn_2: 1.1909 (1.2054)  loss_ddf_dn_2: 0.1310 (0.1268)  loss_mal_dn_3: 0.7910 (0.7893)  loss_bbox_dn_3: 0.3811 (0.3768)  loss_giou_dn_3: 0.6526 (0.6228)  loss_fgl_dn_3: 1.1867 (1.2051)  loss_ddf_dn_3: 0.0381 (0.0371)  loss_mal_dn_4: 0.7954 (0.7875)  loss_bbox_dn_4: 0.3675 (0.3674)  loss_giou_dn_4: 0.6443 (0.6066)  loss_fgl_dn_4: 1.1907 (1.2078)  loss_ddf_dn_4: 0.0055 (0.0055)  loss_mal_dn_5: 0.8052 (0.7887)  loss_bbox_dn_5: 0.3687 (0.3633)  loss_giou_dn_5: 0.6360 (0.5997)  loss_fgl_dn_5: 1.1990 (1.2092)  loss_mal_dn_pre: 0.8164 (0.8265)  loss_bbox_dn_pre: 0.4878 (0.4871)  loss_giou_dn_pre: 0.8022 (0.8173)  time: 1.2623  data: 0.0125  max mem: 13413\nEpoch: [13]  [200/251]  eta: 0:01:01  lr: 0.000003  loss: 43.4671 (46.5641)  loss_mal: 0.9785 (1.1314)  loss_bbox: 0.2007 (0.2683)  loss_giou: 0.4240 (0.5263)  loss_fgl: 1.2965 (1.2934)  loss_mal_aux_0: 1.3730 (1.4185)  loss_bbox_aux_0: 0.1939 (0.2885)  loss_giou_aux_0: 0.4738 (0.5682)  loss_fgl_aux_0: 1.3084 (1.2907)  loss_ddf_aux_0: 0.0584 (0.0601)  loss_mal_aux_1: 1.2070 (1.2789)  loss_bbox_aux_1: 0.1889 (0.2833)  loss_giou_aux_1: 0.4603 (0.5593)  loss_fgl_aux_1: 1.2940 (1.2921)  loss_ddf_aux_1: 0.0341 (0.0358)  loss_mal_aux_2: 1.0928 (1.2031)  loss_bbox_aux_2: 0.1873 (0.2726)  loss_giou_aux_2: 0.4294 (0.5373)  loss_fgl_aux_2: 1.2830 (1.2898)  loss_ddf_aux_2: 0.0110 (0.0128)  loss_mal_aux_3: 0.9741 (1.1649)  loss_bbox_aux_3: 0.1953 (0.2694)  loss_giou_aux_3: 0.4207 (0.5299)  loss_fgl_aux_3: 1.2950 (1.2904)  loss_ddf_aux_3: 0.0032 (0.0038)  loss_mal_aux_4: 0.9790 (1.1417)  loss_bbox_aux_4: 0.2014 (0.2686)  loss_giou_aux_4: 0.4223 (0.5270)  loss_fgl_aux_4: 1.2980 (1.2922)  loss_ddf_aux_4: 0.0005 (0.0006)  loss_mal_pre: 1.3594 (1.4145)  loss_bbox_pre: 0.1985 (0.2859)  loss_giou_pre: 0.4651 (0.5654)  loss_mal_enc_0: 1.4766 (1.5366)  loss_bbox_enc_0: 0.3357 (0.3822)  loss_giou_enc_0: 0.6687 (0.7230)  loss_mal_dn_0: 0.8252 (0.8305)  loss_bbox_dn_0: 0.3546 (0.4656)  loss_giou_dn_0: 0.7525 (0.8164)  loss_fgl_dn_0: 1.2216 (1.1924)  loss_ddf_dn_0: 0.6084 (0.5536)  loss_mal_dn_1: 0.8027 (0.7997)  loss_bbox_dn_1: 0.3387 (0.4231)  loss_giou_dn_1: 0.6570 (0.7366)  loss_fgl_dn_1: 1.2298 (1.2019)  loss_ddf_dn_1: 0.3724 (0.3493)  loss_mal_dn_2: 0.7827 (0.7985)  loss_bbox_dn_2: 0.2847 (0.3766)  loss_giou_dn_2: 0.5607 (0.6518)  loss_fgl_dn_2: 1.2160 (1.2075)  loss_ddf_dn_2: 0.1366 (0.1246)  loss_mal_dn_3: 0.7637 (0.7849)  loss_bbox_dn_3: 0.2612 (0.3605)  loss_giou_dn_3: 0.5296 (0.6259)  loss_fgl_dn_3: 1.2161 (1.2081)  loss_ddf_dn_3: 0.0363 (0.0358)  loss_mal_dn_4: 0.7329 (0.7773)  loss_bbox_dn_4: 0.2543 (0.3520)  loss_giou_dn_4: 0.5161 (0.6110)  loss_fgl_dn_4: 1.2219 (1.2115)  loss_ddf_dn_4: 0.0054 (0.0052)  loss_mal_dn_5: 0.7363 (0.7770)  loss_bbox_dn_5: 0.2497 (0.3484)  loss_giou_dn_5: 0.5130 (0.6048)  loss_fgl_dn_5: 1.2237 (1.2133)  loss_mal_dn_pre: 0.8218 (0.8275)  loss_bbox_dn_pre: 0.3589 (0.4692)  loss_giou_dn_pre: 0.7543 (0.8174)  time: 1.1898  data: 0.0122  max mem: 13413\nEpoch: [13]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 47.7443 (46.5676)  loss_mal: 1.2480 (1.1347)  loss_bbox: 0.2404 (0.2691)  loss_giou: 0.5062 (0.5256)  loss_fgl: 1.2992 (1.2935)  loss_mal_aux_0: 1.4160 (1.4179)  loss_bbox_aux_0: 0.3073 (0.2911)  loss_giou_aux_0: 0.5685 (0.5669)  loss_fgl_aux_0: 1.3180 (1.2922)  loss_ddf_aux_0: 0.0595 (0.0606)  loss_mal_aux_1: 1.2646 (1.2731)  loss_bbox_aux_1: 0.3011 (0.2856)  loss_giou_aux_1: 0.5537 (0.5578)  loss_fgl_aux_1: 1.3133 (1.2937)  loss_ddf_aux_1: 0.0364 (0.0361)  loss_mal_aux_2: 1.2578 (1.2030)  loss_bbox_aux_2: 0.2620 (0.2740)  loss_giou_aux_2: 0.5212 (0.5360)  loss_fgl_aux_2: 1.3036 (1.2906)  loss_ddf_aux_2: 0.0124 (0.0128)  loss_mal_aux_3: 1.2520 (1.1685)  loss_bbox_aux_3: 0.2571 (0.2704)  loss_giou_aux_3: 0.5147 (0.5289)  loss_fgl_aux_3: 1.3007 (1.2910)  loss_ddf_aux_3: 0.0036 (0.0038)  loss_mal_aux_4: 1.1816 (1.1398)  loss_bbox_aux_4: 0.2461 (0.2695)  loss_giou_aux_4: 0.5091 (0.5262)  loss_fgl_aux_4: 1.3004 (1.2925)  loss_ddf_aux_4: 0.0005 (0.0006)  loss_mal_pre: 1.4111 (1.4139)  loss_bbox_pre: 0.2916 (0.2883)  loss_giou_pre: 0.5665 (0.5643)  loss_mal_enc_0: 1.5889 (1.5437)  loss_bbox_enc_0: 0.3302 (0.3841)  loss_giou_enc_0: 0.6861 (0.7214)  loss_mal_dn_0: 0.8276 (0.8308)  loss_bbox_dn_0: 0.4459 (0.4669)  loss_giou_dn_0: 0.8185 (0.8155)  loss_fgl_dn_0: 1.1910 (1.1931)  loss_ddf_dn_0: 0.4932 (0.5539)  loss_mal_dn_1: 0.7998 (0.7999)  loss_bbox_dn_1: 0.4159 (0.4237)  loss_giou_dn_1: 0.7153 (0.7336)  loss_fgl_dn_1: 1.2041 (1.2027)  loss_ddf_dn_1: 0.3092 (0.3474)  loss_mal_dn_2: 0.7954 (0.7979)  loss_bbox_dn_2: 0.3725 (0.3774)  loss_giou_dn_2: 0.6351 (0.6490)  loss_fgl_dn_2: 1.2188 (1.2077)  loss_ddf_dn_2: 0.1069 (0.1226)  loss_mal_dn_3: 0.7808 (0.7847)  loss_bbox_dn_3: 0.3604 (0.3617)  loss_giou_dn_3: 0.5992 (0.6232)  loss_fgl_dn_3: 1.2180 (1.2083)  loss_ddf_dn_3: 0.0299 (0.0349)  loss_mal_dn_4: 0.7739 (0.7761)  loss_bbox_dn_4: 0.3603 (0.3534)  loss_giou_dn_4: 0.5885 (0.6086)  loss_fgl_dn_4: 1.2139 (1.2116)  loss_ddf_dn_4: 0.0043 (0.0050)  loss_mal_dn_5: 0.7773 (0.7766)  loss_bbox_dn_5: 0.3571 (0.3498)  loss_giou_dn_5: 0.5822 (0.6026)  loss_fgl_dn_5: 1.2116 (1.2133)  loss_mal_dn_pre: 0.8223 (0.8277)  loss_bbox_dn_pre: 0.4559 (0.4705)  loss_giou_dn_pre: 0.8217 (0.8164)  time: 1.1908  data: 0.0116  max mem: 13413\nEpoch: [13] Total time: 0:05:04 (1.2149 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7791  data: 0.4662  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3524  data: 0.0632  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3079  data: 0.0222  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2960  data: 0.0208  max mem: 13413\nTest: Total time: 0:00:08 (0.3204 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.486\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.243\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.273\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.403\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.523\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.613\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.885\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.691\nbest_stat: {'epoch': 13, 'coco_eval_bbox': 0.2619907178070537}\nEpoch: [14]  [  0/251]  eta: 0:07:16  lr: 0.000003  loss: 51.8738 (51.8738)  loss_mal: 1.2451 (1.2451)  loss_bbox: 0.4396 (0.4396)  loss_giou: 0.6395 (0.6395)  loss_fgl: 1.3004 (1.3004)  loss_mal_aux_0: 1.7510 (1.7510)  loss_bbox_aux_0: 0.4313 (0.4313)  loss_giou_aux_0: 0.6371 (0.6371)  loss_fgl_aux_0: 1.2596 (1.2596)  loss_ddf_aux_0: 0.0766 (0.0766)  loss_mal_aux_1: 1.4668 (1.4668)  loss_bbox_aux_1: 0.4351 (0.4351)  loss_giou_aux_1: 0.6334 (0.6334)  loss_fgl_aux_1: 1.2645 (1.2645)  loss_ddf_aux_1: 0.0466 (0.0466)  loss_mal_aux_2: 1.3975 (1.3975)  loss_bbox_aux_2: 0.4371 (0.4371)  loss_giou_aux_2: 0.6243 (0.6243)  loss_fgl_aux_2: 1.2805 (1.2805)  loss_ddf_aux_2: 0.0166 (0.0166)  loss_mal_aux_3: 1.3623 (1.3623)  loss_bbox_aux_3: 0.4362 (0.4362)  loss_giou_aux_3: 0.6295 (0.6295)  loss_fgl_aux_3: 1.2937 (1.2937)  loss_ddf_aux_3: 0.0053 (0.0053)  loss_mal_aux_4: 1.3252 (1.3252)  loss_bbox_aux_4: 0.4353 (0.4353)  loss_giou_aux_4: 0.6347 (0.6347)  loss_fgl_aux_4: 1.2972 (1.2972)  loss_ddf_aux_4: 0.0008 (0.0008)  loss_mal_pre: 1.8447 (1.8447)  loss_bbox_pre: 0.4189 (0.4189)  loss_giou_pre: 0.6326 (0.6326)  loss_mal_enc_0: 1.5107 (1.5107)  loss_bbox_enc_0: 0.5391 (0.5391)  loss_giou_enc_0: 0.7752 (0.7752)  loss_mal_dn_0: 0.8374 (0.8374)  loss_bbox_dn_0: 0.5955 (0.5955)  loss_giou_dn_0: 0.8344 (0.8344)  loss_fgl_dn_0: 1.1967 (1.1967)  loss_ddf_dn_0: 0.7609 (0.7609)  loss_mal_dn_1: 0.8154 (0.8154)  loss_bbox_dn_1: 0.5286 (0.5286)  loss_giou_dn_1: 0.7554 (0.7554)  loss_fgl_dn_1: 1.2034 (1.2034)  loss_ddf_dn_1: 0.4632 (0.4632)  loss_mal_dn_2: 0.8252 (0.8252)  loss_bbox_dn_2: 0.4809 (0.4809)  loss_giou_dn_2: 0.7147 (0.7147)  loss_fgl_dn_2: 1.2072 (1.2072)  loss_ddf_dn_2: 0.1597 (0.1597)  loss_mal_dn_3: 0.8027 (0.8027)  loss_bbox_dn_3: 0.4721 (0.4721)  loss_giou_dn_3: 0.7187 (0.7187)  loss_fgl_dn_3: 1.2113 (1.2113)  loss_ddf_dn_3: 0.0462 (0.0462)  loss_mal_dn_4: 0.7998 (0.7998)  loss_bbox_dn_4: 0.4761 (0.4761)  loss_giou_dn_4: 0.7172 (0.7172)  loss_fgl_dn_4: 1.2219 (1.2219)  loss_ddf_dn_4: 0.0066 (0.0066)  loss_mal_dn_5: 0.8062 (0.8062)  loss_bbox_dn_5: 0.4787 (0.4787)  loss_giou_dn_5: 0.7174 (0.7174)  loss_fgl_dn_5: 1.2272 (1.2272)  loss_mal_dn_pre: 0.8345 (0.8345)  loss_bbox_dn_pre: 0.5986 (0.5986)  loss_giou_dn_pre: 0.8359 (0.8359)  time: 1.7398  data: 0.6691  max mem: 13413\nEpoch: [14]  [100/251]  eta: 0:03:04  lr: 0.000003  loss: 44.8154 (45.5633)  loss_mal: 1.0068 (1.0833)  loss_bbox: 0.2287 (0.2474)  loss_giou: 0.4680 (0.5055)  loss_fgl: 1.2799 (1.2816)  loss_mal_aux_0: 1.3848 (1.4138)  loss_bbox_aux_0: 0.2244 (0.2692)  loss_giou_aux_0: 0.4875 (0.5515)  loss_fgl_aux_0: 1.3236 (1.2875)  loss_ddf_aux_0: 0.0650 (0.0650)  loss_mal_aux_1: 1.1865 (1.2192)  loss_bbox_aux_1: 0.2216 (0.2625)  loss_giou_aux_1: 0.4765 (0.5399)  loss_fgl_aux_1: 1.3076 (1.2869)  loss_ddf_aux_1: 0.0379 (0.0390)  loss_mal_aux_2: 1.0811 (1.1485)  loss_bbox_aux_2: 0.2209 (0.2501)  loss_giou_aux_2: 0.4682 (0.5151)  loss_fgl_aux_2: 1.2902 (1.2814)  loss_ddf_aux_2: 0.0119 (0.0122)  loss_mal_aux_3: 1.0273 (1.0944)  loss_bbox_aux_3: 0.2248 (0.2479)  loss_giou_aux_3: 0.4697 (0.5088)  loss_fgl_aux_3: 1.2849 (1.2802)  loss_ddf_aux_3: 0.0027 (0.0033)  loss_mal_aux_4: 0.9917 (1.0819)  loss_bbox_aux_4: 0.2269 (0.2476)  loss_giou_aux_4: 0.4684 (0.5063)  loss_fgl_aux_4: 1.2815 (1.2811)  loss_ddf_aux_4: 0.0003 (0.0004)  loss_mal_pre: 1.3828 (1.4054)  loss_bbox_pre: 0.2298 (0.2654)  loss_giou_pre: 0.4888 (0.5486)  loss_mal_enc_0: 1.6367 (1.6155)  loss_bbox_enc_0: 0.3163 (0.3734)  loss_giou_enc_0: 0.6711 (0.7185)  loss_mal_dn_0: 0.8311 (0.8350)  loss_bbox_dn_0: 0.4240 (0.4419)  loss_giou_dn_0: 0.7360 (0.7858)  loss_fgl_dn_0: 1.2316 (1.2086)  loss_ddf_dn_0: 0.5469 (0.5903)  loss_mal_dn_1: 0.7925 (0.7989)  loss_bbox_dn_1: 0.3869 (0.3888)  loss_giou_dn_1: 0.6220 (0.6950)  loss_fgl_dn_1: 1.2427 (1.2164)  loss_ddf_dn_1: 0.3327 (0.3560)  loss_mal_dn_2: 0.7832 (0.7894)  loss_bbox_dn_2: 0.3481 (0.3406)  loss_giou_dn_2: 0.5723 (0.6102)  loss_fgl_dn_2: 1.2289 (1.2158)  loss_ddf_dn_2: 0.1014 (0.1145)  loss_mal_dn_3: 0.7715 (0.7730)  loss_bbox_dn_3: 0.3281 (0.3260)  loss_giou_dn_3: 0.5667 (0.5873)  loss_fgl_dn_3: 1.2123 (1.2140)  loss_ddf_dn_3: 0.0261 (0.0304)  loss_mal_dn_4: 0.7515 (0.7623)  loss_bbox_dn_4: 0.3098 (0.3187)  loss_giou_dn_4: 0.5525 (0.5749)  loss_fgl_dn_4: 1.2120 (1.2154)  loss_ddf_dn_4: 0.0034 (0.0042)  loss_mal_dn_5: 0.7617 (0.7661)  loss_bbox_dn_5: 0.2995 (0.3154)  loss_giou_dn_5: 0.5464 (0.5697)  loss_fgl_dn_5: 1.2166 (1.2162)  loss_mal_dn_pre: 0.8276 (0.8320)  loss_bbox_dn_pre: 0.4382 (0.4459)  loss_giou_dn_pre: 0.7309 (0.7868)  time: 1.3572  data: 0.0120  max mem: 13413\nEpoch: [14]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 43.6013 (45.6556)  loss_mal: 1.0898 (1.0893)  loss_bbox: 0.1842 (0.2573)  loss_giou: 0.4317 (0.5048)  loss_fgl: 1.2969 (1.2889)  loss_mal_aux_0: 1.2998 (1.3999)  loss_bbox_aux_0: 0.2094 (0.2804)  loss_giou_aux_0: 0.5029 (0.5491)  loss_fgl_aux_0: 1.3019 (1.2914)  loss_ddf_aux_0: 0.0619 (0.0652)  loss_mal_aux_1: 1.0898 (1.2326)  loss_bbox_aux_1: 0.1997 (0.2728)  loss_giou_aux_1: 0.4836 (0.5370)  loss_fgl_aux_1: 1.3039 (1.2912)  loss_ddf_aux_1: 0.0337 (0.0388)  loss_mal_aux_2: 1.0469 (1.1415)  loss_bbox_aux_2: 0.1869 (0.2603)  loss_giou_aux_2: 0.4376 (0.5132)  loss_fgl_aux_2: 1.2972 (1.2870)  loss_ddf_aux_2: 0.0091 (0.0118)  loss_mal_aux_3: 1.0195 (1.0936)  loss_bbox_aux_3: 0.1837 (0.2577)  loss_giou_aux_3: 0.4321 (0.5077)  loss_fgl_aux_3: 1.2994 (1.2869)  loss_ddf_aux_3: 0.0029 (0.0032)  loss_mal_aux_4: 1.0635 (1.0860)  loss_bbox_aux_4: 0.1836 (0.2572)  loss_giou_aux_4: 0.4320 (0.5055)  loss_fgl_aux_4: 1.2986 (1.2881)  loss_ddf_aux_4: 0.0004 (0.0004)  loss_mal_pre: 1.2695 (1.3898)  loss_bbox_pre: 0.2008 (0.2775)  loss_giou_pre: 0.4955 (0.5469)  loss_mal_enc_0: 1.3936 (1.5770)  loss_bbox_enc_0: 0.2764 (0.3829)  loss_giou_enc_0: 0.7054 (0.7183)  loss_mal_dn_0: 0.8428 (0.8347)  loss_bbox_dn_0: 0.3494 (0.4450)  loss_giou_dn_0: 0.7317 (0.7815)  loss_fgl_dn_0: 1.2268 (1.2113)  loss_ddf_dn_0: 0.6123 (0.6008)  loss_mal_dn_1: 0.7998 (0.8005)  loss_bbox_dn_1: 0.3036 (0.3937)  loss_giou_dn_1: 0.6405 (0.6887)  loss_fgl_dn_1: 1.2283 (1.2183)  loss_ddf_dn_1: 0.3480 (0.3543)  loss_mal_dn_2: 0.7642 (0.7903)  loss_bbox_dn_2: 0.2686 (0.3482)  loss_giou_dn_2: 0.5453 (0.6064)  loss_fgl_dn_2: 1.2183 (1.2179)  loss_ddf_dn_2: 0.1074 (0.1118)  loss_mal_dn_3: 0.7495 (0.7721)  loss_bbox_dn_3: 0.2578 (0.3343)  loss_giou_dn_3: 0.5370 (0.5841)  loss_fgl_dn_3: 1.2314 (1.2175)  loss_ddf_dn_3: 0.0285 (0.0295)  loss_mal_dn_4: 0.7441 (0.7624)  loss_bbox_dn_4: 0.2564 (0.3275)  loss_giou_dn_4: 0.5342 (0.5714)  loss_fgl_dn_4: 1.2353 (1.2197)  loss_ddf_dn_4: 0.0036 (0.0041)  loss_mal_dn_5: 0.7373 (0.7642)  loss_bbox_dn_5: 0.2524 (0.3246)  loss_giou_dn_5: 0.5305 (0.5665)  loss_fgl_dn_5: 1.2382 (1.2208)  loss_mal_dn_pre: 0.8394 (0.8318)  loss_bbox_dn_pre: 0.3451 (0.4486)  loss_giou_dn_pre: 0.7280 (0.7817)  time: 1.1158  data: 0.0110  max mem: 13413\nEpoch: [14]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 44.3046 (45.4960)  loss_mal: 1.0195 (1.0835)  loss_bbox: 0.1756 (0.2537)  loss_giou: 0.4217 (0.4994)  loss_fgl: 1.2994 (1.2885)  loss_mal_aux_0: 1.3652 (1.3942)  loss_bbox_aux_0: 0.2327 (0.2772)  loss_giou_aux_0: 0.4673 (0.5454)  loss_fgl_aux_0: 1.3299 (1.2918)  loss_ddf_aux_0: 0.0677 (0.0661)  loss_mal_aux_1: 1.2666 (1.2271)  loss_bbox_aux_1: 0.2259 (0.2694)  loss_giou_aux_1: 0.4610 (0.5328)  loss_fgl_aux_1: 1.3216 (1.2912)  loss_ddf_aux_1: 0.0388 (0.0394)  loss_mal_aux_2: 1.1152 (1.1371)  loss_bbox_aux_2: 0.2019 (0.2564)  loss_giou_aux_2: 0.4261 (0.5080)  loss_fgl_aux_2: 1.3092 (1.2867)  loss_ddf_aux_2: 0.0109 (0.0119)  loss_mal_aux_3: 1.0488 (1.0921)  loss_bbox_aux_3: 0.1880 (0.2539)  loss_giou_aux_3: 0.4251 (0.5023)  loss_fgl_aux_3: 1.3027 (1.2866)  loss_ddf_aux_3: 0.0029 (0.0032)  loss_mal_aux_4: 1.0049 (1.0812)  loss_bbox_aux_4: 0.1801 (0.2536)  loss_giou_aux_4: 0.4219 (0.5001)  loss_fgl_aux_4: 1.2986 (1.2877)  loss_ddf_aux_4: 0.0004 (0.0004)  loss_mal_pre: 1.3633 (1.3851)  loss_bbox_pre: 0.2391 (0.2747)  loss_giou_pre: 0.4808 (0.5432)  loss_mal_enc_0: 1.4287 (1.5644)  loss_bbox_enc_0: 0.3876 (0.3811)  loss_giou_enc_0: 0.6338 (0.7140)  loss_mal_dn_0: 0.8188 (0.8339)  loss_bbox_dn_0: 0.4032 (0.4442)  loss_giou_dn_0: 0.7473 (0.7796)  loss_fgl_dn_0: 1.2153 (1.2119)  loss_ddf_dn_0: 0.6462 (0.6033)  loss_mal_dn_1: 0.7798 (0.7988)  loss_bbox_dn_1: 0.3720 (0.3914)  loss_giou_dn_1: 0.6325 (0.6844)  loss_fgl_dn_1: 1.2287 (1.2192)  loss_ddf_dn_1: 0.3633 (0.3534)  loss_mal_dn_2: 0.7573 (0.7876)  loss_bbox_dn_2: 0.3356 (0.3457)  loss_giou_dn_2: 0.5340 (0.6016)  loss_fgl_dn_2: 1.2390 (1.2185)  loss_ddf_dn_2: 0.1109 (0.1108)  loss_mal_dn_3: 0.7441 (0.7693)  loss_bbox_dn_3: 0.3226 (0.3319)  loss_giou_dn_3: 0.5041 (0.5795)  loss_fgl_dn_3: 1.2264 (1.2176)  loss_ddf_dn_3: 0.0282 (0.0291)  loss_mal_dn_4: 0.7407 (0.7598)  loss_bbox_dn_4: 0.3132 (0.3250)  loss_giou_dn_4: 0.4869 (0.5668)  loss_fgl_dn_4: 1.2189 (1.2196)  loss_ddf_dn_4: 0.0037 (0.0040)  loss_mal_dn_5: 0.7349 (0.7622)  loss_bbox_dn_5: 0.3088 (0.3220)  loss_giou_dn_5: 0.4805 (0.5618)  loss_fgl_dn_5: 1.2152 (1.2205)  loss_mal_dn_pre: 0.8169 (0.8310)  loss_bbox_dn_pre: 0.4108 (0.4479)  loss_giou_dn_pre: 0.7410 (0.7798)  time: 1.1813  data: 0.0113  max mem: 13413\nEpoch: [14] Total time: 0:05:07 (1.2255 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7853  data: 0.4842  max mem: 13413\nTest:  [10/25]  eta: 0:00:06    time: 0.4041  data: 0.0632  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3357  data: 0.0207  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.3241  data: 0.0203  max mem: 13413\nTest: Total time: 0:00:08 (0.3427 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.267\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.439\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.305\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.305\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.291\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.402\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.528\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.610\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.604\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.594\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.897\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.684\nbest_stat: {'epoch': 14, 'coco_eval_bbox': 0.2667668358996345}\nEpoch: [15]  [  0/251]  eta: 0:08:16  lr: 0.000003  loss: 39.7710 (39.7710)  loss_mal: 0.8364 (0.8364)  loss_bbox: 0.0894 (0.0894)  loss_giou: 0.3962 (0.3962)  loss_fgl: 1.2473 (1.2473)  loss_mal_aux_0: 1.1943 (1.1943)  loss_bbox_aux_0: 0.1086 (0.1086)  loss_giou_aux_0: 0.4616 (0.4616)  loss_fgl_aux_0: 1.2777 (1.2777)  loss_ddf_aux_0: 0.0658 (0.0658)  loss_mal_aux_1: 1.1494 (1.1494)  loss_bbox_aux_1: 0.1003 (0.1003)  loss_giou_aux_1: 0.4445 (0.4445)  loss_fgl_aux_1: 1.2683 (1.2683)  loss_ddf_aux_1: 0.0374 (0.0374)  loss_mal_aux_2: 0.9487 (0.9487)  loss_bbox_aux_2: 0.0897 (0.0897)  loss_giou_aux_2: 0.4049 (0.4049)  loss_fgl_aux_2: 1.2552 (1.2552)  loss_ddf_aux_2: 0.0097 (0.0097)  loss_mal_aux_3: 0.8325 (0.8325)  loss_bbox_aux_3: 0.0899 (0.0899)  loss_giou_aux_3: 0.3923 (0.3923)  loss_fgl_aux_3: 1.2518 (1.2518)  loss_ddf_aux_3: 0.0021 (0.0021)  loss_mal_aux_4: 0.8027 (0.8027)  loss_bbox_aux_4: 0.0900 (0.0900)  loss_giou_aux_4: 0.3945 (0.3945)  loss_fgl_aux_4: 1.2497 (1.2497)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.1846 (1.1846)  loss_bbox_pre: 0.1065 (0.1065)  loss_giou_pre: 0.4679 (0.4679)  loss_mal_enc_0: 1.3770 (1.3770)  loss_bbox_enc_0: 0.2152 (0.2152)  loss_giou_enc_0: 0.6933 (0.6933)  loss_mal_dn_0: 0.9121 (0.9121)  loss_bbox_dn_0: 0.1850 (0.1850)  loss_giou_dn_0: 0.6030 (0.6030)  loss_fgl_dn_0: 1.2666 (1.2666)  loss_ddf_dn_0: 0.9028 (0.9028)  loss_mal_dn_1: 0.8750 (0.8750)  loss_bbox_dn_1: 0.1520 (0.1520)  loss_giou_dn_1: 0.5072 (0.5072)  loss_fgl_dn_1: 1.2735 (1.2735)  loss_ddf_dn_1: 0.5156 (0.5156)  loss_mal_dn_2: 0.8374 (0.8374)  loss_bbox_dn_2: 0.1184 (0.1184)  loss_giou_dn_2: 0.4498 (0.4498)  loss_fgl_dn_2: 1.2313 (1.2313)  loss_ddf_dn_2: 0.1520 (0.1520)  loss_mal_dn_3: 0.7842 (0.7842)  loss_bbox_dn_3: 0.1091 (0.1091)  loss_giou_dn_3: 0.4369 (0.4369)  loss_fgl_dn_3: 1.2130 (1.2130)  loss_ddf_dn_3: 0.0377 (0.0377)  loss_mal_dn_4: 0.7192 (0.7192)  loss_bbox_dn_4: 0.1091 (0.1091)  loss_giou_dn_4: 0.4400 (0.4400)  loss_fgl_dn_4: 1.2074 (1.2074)  loss_ddf_dn_4: 0.0054 (0.0054)  loss_mal_dn_5: 0.7246 (0.7246)  loss_bbox_dn_5: 0.1084 (0.1084)  loss_giou_dn_5: 0.4406 (0.4406)  loss_fgl_dn_5: 1.2052 (1.2052)  loss_mal_dn_pre: 0.9092 (0.9092)  loss_bbox_dn_pre: 0.1930 (0.1930)  loss_giou_dn_pre: 0.6101 (0.6101)  time: 1.9790  data: 0.9318  max mem: 13413\nEpoch: [15]  [100/251]  eta: 0:03:01  lr: 0.000003  loss: 42.5791 (44.3283)  loss_mal: 0.9668 (1.0342)  loss_bbox: 0.1724 (0.2276)  loss_giou: 0.4128 (0.4545)  loss_fgl: 1.2793 (1.2978)  loss_mal_aux_0: 1.3477 (1.4096)  loss_bbox_aux_0: 0.1858 (0.2520)  loss_giou_aux_0: 0.4443 (0.4986)  loss_fgl_aux_0: 1.3136 (1.3071)  loss_ddf_aux_0: 0.0591 (0.0721)  loss_mal_aux_1: 1.1309 (1.2211)  loss_bbox_aux_1: 0.1868 (0.2439)  loss_giou_aux_1: 0.4310 (0.4832)  loss_fgl_aux_1: 1.3030 (1.3058)  loss_ddf_aux_1: 0.0329 (0.0418)  loss_mal_aux_2: 0.9907 (1.0996)  loss_bbox_aux_2: 0.1814 (0.2314)  loss_giou_aux_2: 0.4154 (0.4605)  loss_fgl_aux_2: 1.2838 (1.2987)  loss_ddf_aux_2: 0.0083 (0.0117)  loss_mal_aux_3: 0.9517 (1.0620)  loss_bbox_aux_3: 0.1771 (0.2285)  loss_giou_aux_3: 0.4129 (0.4568)  loss_fgl_aux_3: 1.2757 (1.2973)  loss_ddf_aux_3: 0.0022 (0.0031)  loss_mal_aux_4: 0.9595 (1.0469)  loss_bbox_aux_4: 0.1725 (0.2278)  loss_giou_aux_4: 0.4130 (0.4550)  loss_fgl_aux_4: 1.2786 (1.2975)  loss_ddf_aux_4: 0.0003 (0.0004)  loss_mal_pre: 1.3398 (1.4007)  loss_bbox_pre: 0.1829 (0.2510)  loss_giou_pre: 0.4446 (0.4971)  loss_mal_enc_0: 1.3965 (1.5350)  loss_bbox_enc_0: 0.3015 (0.3544)  loss_giou_enc_0: 0.6437 (0.6809)  loss_mal_dn_0: 0.8320 (0.8433)  loss_bbox_dn_0: 0.3313 (0.3973)  loss_giou_dn_0: 0.6881 (0.7311)  loss_fgl_dn_0: 1.2455 (1.2324)  loss_ddf_dn_0: 0.6050 (0.6747)  loss_mal_dn_1: 0.7681 (0.8020)  loss_bbox_dn_1: 0.2625 (0.3410)  loss_giou_dn_1: 0.5864 (0.6277)  loss_fgl_dn_1: 1.2476 (1.2371)  loss_ddf_dn_1: 0.3321 (0.3750)  loss_mal_dn_2: 0.7456 (0.7809)  loss_bbox_dn_2: 0.2153 (0.2984)  loss_giou_dn_2: 0.5234 (0.5516)  loss_fgl_dn_2: 1.2255 (1.2293)  loss_ddf_dn_2: 0.0924 (0.1099)  loss_mal_dn_3: 0.7090 (0.7579)  loss_bbox_dn_3: 0.2047 (0.2853)  loss_giou_dn_3: 0.5041 (0.5310)  loss_fgl_dn_3: 1.2235 (1.2285)  loss_ddf_dn_3: 0.0236 (0.0278)  loss_mal_dn_4: 0.7261 (0.7461)  loss_bbox_dn_4: 0.2024 (0.2788)  loss_giou_dn_4: 0.5023 (0.5193)  loss_fgl_dn_4: 1.2312 (1.2302)  loss_ddf_dn_4: 0.0031 (0.0037)  loss_mal_dn_5: 0.7334 (0.7474)  loss_bbox_dn_5: 0.1999 (0.2764)  loss_giou_dn_5: 0.5009 (0.5147)  loss_fgl_dn_5: 1.2293 (1.2311)  loss_mal_dn_pre: 0.8286 (0.8400)  loss_bbox_dn_pre: 0.3364 (0.4009)  loss_giou_dn_pre: 0.6826 (0.7316)  time: 1.1142  data: 0.0111  max mem: 13413\nEpoch: [15]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 42.9803 (44.4282)  loss_mal: 0.9917 (1.0310)  loss_bbox: 0.1885 (0.2368)  loss_giou: 0.4540 (0.4643)  loss_fgl: 1.2946 (1.2930)  loss_mal_aux_0: 1.4580 (1.3858)  loss_bbox_aux_0: 0.2110 (0.2618)  loss_giou_aux_0: 0.4616 (0.5097)  loss_fgl_aux_0: 1.3177 (1.3031)  loss_ddf_aux_0: 0.0653 (0.0721)  loss_mal_aux_1: 1.1602 (1.2136)  loss_bbox_aux_1: 0.2006 (0.2528)  loss_giou_aux_1: 0.4476 (0.4935)  loss_fgl_aux_1: 1.3038 (1.3013)  loss_ddf_aux_1: 0.0380 (0.0420)  loss_mal_aux_2: 1.0645 (1.1008)  loss_bbox_aux_2: 0.1850 (0.2403)  loss_giou_aux_2: 0.4425 (0.4704)  loss_fgl_aux_2: 1.3010 (1.2937)  loss_ddf_aux_2: 0.0102 (0.0114)  loss_mal_aux_3: 0.9360 (1.0543)  loss_bbox_aux_3: 0.1879 (0.2379)  loss_giou_aux_3: 0.4442 (0.4666)  loss_fgl_aux_3: 1.2999 (1.2925)  loss_ddf_aux_3: 0.0027 (0.0030)  loss_mal_aux_4: 0.9644 (1.0423)  loss_bbox_aux_4: 0.1889 (0.2371)  loss_giou_aux_4: 0.4571 (0.4648)  loss_fgl_aux_4: 1.2963 (1.2928)  loss_ddf_aux_4: 0.0003 (0.0004)  loss_mal_pre: 1.4639 (1.3773)  loss_bbox_pre: 0.2070 (0.2596)  loss_giou_pre: 0.4631 (0.5082)  loss_mal_enc_0: 1.7383 (1.5321)  loss_bbox_enc_0: 0.2968 (0.3645)  loss_giou_enc_0: 0.6221 (0.6907)  loss_mal_dn_0: 0.8521 (0.8390)  loss_bbox_dn_0: 0.3720 (0.4057)  loss_giou_dn_0: 0.7297 (0.7370)  loss_fgl_dn_0: 1.2321 (1.2306)  loss_ddf_dn_0: 0.6427 (0.6691)  loss_mal_dn_1: 0.7744 (0.7974)  loss_bbox_dn_1: 0.3002 (0.3496)  loss_giou_dn_1: 0.6261 (0.6329)  loss_fgl_dn_1: 1.2386 (1.2339)  loss_ddf_dn_1: 0.3421 (0.3662)  loss_mal_dn_2: 0.7642 (0.7747)  loss_bbox_dn_2: 0.2355 (0.3087)  loss_giou_dn_2: 0.5546 (0.5597)  loss_fgl_dn_2: 1.2183 (1.2264)  loss_ddf_dn_2: 0.0915 (0.1044)  loss_mal_dn_3: 0.7217 (0.7499)  loss_bbox_dn_3: 0.2246 (0.2961)  loss_giou_dn_3: 0.5358 (0.5393)  loss_fgl_dn_3: 1.2259 (1.2264)  loss_ddf_dn_3: 0.0226 (0.0263)  loss_mal_dn_4: 0.7051 (0.7402)  loss_bbox_dn_4: 0.2190 (0.2902)  loss_giou_dn_4: 0.5293 (0.5283)  loss_fgl_dn_4: 1.2220 (1.2284)  loss_ddf_dn_4: 0.0029 (0.0035)  loss_mal_dn_5: 0.7051 (0.7400)  loss_bbox_dn_5: 0.2181 (0.2880)  loss_giou_dn_5: 0.5269 (0.5239)  loss_fgl_dn_5: 1.2187 (1.2294)  loss_mal_dn_pre: 0.8477 (0.8359)  loss_bbox_dn_pre: 0.3851 (0.4087)  loss_giou_dn_pre: 0.7345 (0.7371)  time: 1.3237  data: 0.0117  max mem: 13413\nEpoch: [15]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 45.5096 (44.6184)  loss_mal: 1.0576 (1.0427)  loss_bbox: 0.2284 (0.2387)  loss_giou: 0.4713 (0.4630)  loss_fgl: 1.2862 (1.2959)  loss_mal_aux_0: 1.5703 (1.4000)  loss_bbox_aux_0: 0.2303 (0.2649)  loss_giou_aux_0: 0.5149 (0.5087)  loss_fgl_aux_0: 1.3096 (1.3058)  loss_ddf_aux_0: 0.0692 (0.0729)  loss_mal_aux_1: 1.2793 (1.2286)  loss_bbox_aux_1: 0.2219 (0.2552)  loss_giou_aux_1: 0.4846 (0.4923)  loss_fgl_aux_1: 1.2979 (1.3039)  loss_ddf_aux_1: 0.0389 (0.0423)  loss_mal_aux_2: 1.1221 (1.1160)  loss_bbox_aux_2: 0.2160 (0.2426)  loss_giou_aux_2: 0.4712 (0.4694)  loss_fgl_aux_2: 1.2896 (1.2962)  loss_ddf_aux_2: 0.0099 (0.0115)  loss_mal_aux_3: 1.0732 (1.0676)  loss_bbox_aux_3: 0.2180 (0.2400)  loss_giou_aux_3: 0.4784 (0.4654)  loss_fgl_aux_3: 1.2883 (1.2952)  loss_ddf_aux_3: 0.0025 (0.0030)  loss_mal_aux_4: 1.0215 (1.0516)  loss_bbox_aux_4: 0.2253 (0.2389)  loss_giou_aux_4: 0.4695 (0.4634)  loss_fgl_aux_4: 1.2871 (1.2957)  loss_ddf_aux_4: 0.0003 (0.0004)  loss_mal_pre: 1.5703 (1.3895)  loss_bbox_pre: 0.2276 (0.2628)  loss_giou_pre: 0.5094 (0.5075)  loss_mal_enc_0: 1.6045 (1.5368)  loss_bbox_enc_0: 0.3236 (0.3679)  loss_giou_enc_0: 0.6738 (0.6875)  loss_mal_dn_0: 0.8506 (0.8382)  loss_bbox_dn_0: 0.4473 (0.4171)  loss_giou_dn_0: 0.7435 (0.7418)  loss_fgl_dn_0: 1.2195 (1.2286)  loss_ddf_dn_0: 0.6972 (0.6679)  loss_mal_dn_1: 0.8062 (0.7976)  loss_bbox_dn_1: 0.3356 (0.3584)  loss_giou_dn_1: 0.6272 (0.6349)  loss_fgl_dn_1: 1.2193 (1.2326)  loss_ddf_dn_1: 0.3561 (0.3628)  loss_mal_dn_2: 0.7974 (0.7750)  loss_bbox_dn_2: 0.2944 (0.3161)  loss_giou_dn_2: 0.5548 (0.5613)  loss_fgl_dn_2: 1.2241 (1.2258)  loss_ddf_dn_2: 0.1028 (0.1030)  loss_mal_dn_3: 0.7764 (0.7504)  loss_bbox_dn_3: 0.2877 (0.3028)  loss_giou_dn_3: 0.5366 (0.5405)  loss_fgl_dn_3: 1.2146 (1.2261)  loss_ddf_dn_3: 0.0256 (0.0259)  loss_mal_dn_4: 0.7798 (0.7417)  loss_bbox_dn_4: 0.2977 (0.2967)  loss_giou_dn_4: 0.5231 (0.5296)  loss_fgl_dn_4: 1.2201 (1.2282)  loss_ddf_dn_4: 0.0033 (0.0035)  loss_mal_dn_5: 0.7808 (0.7418)  loss_bbox_dn_5: 0.2969 (0.2943)  loss_giou_dn_5: 0.5232 (0.5254)  loss_fgl_dn_5: 1.2222 (1.2291)  loss_mal_dn_pre: 0.8477 (0.8352)  loss_bbox_dn_pre: 0.4434 (0.4204)  loss_giou_dn_pre: 0.7448 (0.7419)  time: 1.2336  data: 0.0115  max mem: 13413\nEpoch: [15] Total time: 0:05:09 (1.2328 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7864  data: 0.4772  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3541  data: 0.0657  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3367  data: 0.0218  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.3232  data: 0.0192  max mem: 13413\nTest: Total time: 0:00:08 (0.3434 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.232\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.403\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.228\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.366\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.267\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.399\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.541\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.605\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.579\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.593\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.898\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.677\nbest_stat: {'epoch': 14, 'coco_eval_bbox': 0.2667668358996345}\nEpoch: [16]  [  0/251]  eta: 0:08:51  lr: 0.000003  loss: 40.6704 (40.6704)  loss_mal: 0.8047 (0.8047)  loss_bbox: 0.1580 (0.1580)  loss_giou: 0.4541 (0.4541)  loss_fgl: 1.3368 (1.3368)  loss_mal_aux_0: 1.3516 (1.3516)  loss_bbox_aux_0: 0.1816 (0.1816)  loss_giou_aux_0: 0.5377 (0.5377)  loss_fgl_aux_0: 1.3356 (1.3356)  loss_ddf_aux_0: 0.0407 (0.0407)  loss_mal_aux_1: 0.9067 (0.9067)  loss_bbox_aux_1: 0.1797 (0.1797)  loss_giou_aux_1: 0.5260 (0.5260)  loss_fgl_aux_1: 1.3413 (1.3413)  loss_ddf_aux_1: 0.0237 (0.0237)  loss_mal_aux_2: 0.8325 (0.8325)  loss_bbox_aux_2: 0.1667 (0.1667)  loss_giou_aux_2: 0.4849 (0.4849)  loss_fgl_aux_2: 1.3390 (1.3390)  loss_ddf_aux_2: 0.0063 (0.0063)  loss_mal_aux_3: 0.8164 (0.8164)  loss_bbox_aux_3: 0.1610 (0.1610)  loss_giou_aux_3: 0.4649 (0.4649)  loss_fgl_aux_3: 1.3402 (1.3402)  loss_ddf_aux_3: 0.0016 (0.0016)  loss_mal_aux_4: 0.7861 (0.7861)  loss_bbox_aux_4: 0.1585 (0.1585)  loss_giou_aux_4: 0.4555 (0.4555)  loss_fgl_aux_4: 1.3374 (1.3374)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 1.3359 (1.3359)  loss_bbox_pre: 0.1839 (0.1839)  loss_giou_pre: 0.5409 (0.5409)  loss_mal_enc_0: 1.6201 (1.6201)  loss_bbox_enc_0: 0.2293 (0.2293)  loss_giou_enc_0: 0.6433 (0.6433)  loss_mal_dn_0: 0.8325 (0.8325)  loss_bbox_dn_0: 0.2159 (0.2159)  loss_giou_dn_0: 0.6154 (0.6154)  loss_fgl_dn_0: 1.3155 (1.3155)  loss_ddf_dn_0: 0.6296 (0.6296)  loss_mal_dn_1: 0.7700 (0.7700)  loss_bbox_dn_1: 0.1865 (0.1865)  loss_giou_dn_1: 0.5301 (0.5301)  loss_fgl_dn_1: 1.3182 (1.3182)  loss_ddf_dn_1: 0.3194 (0.3194)  loss_mal_dn_2: 0.7017 (0.7017)  loss_bbox_dn_2: 0.1537 (0.1537)  loss_giou_dn_2: 0.4441 (0.4441)  loss_fgl_dn_2: 1.3065 (1.3065)  loss_ddf_dn_2: 0.0874 (0.0874)  loss_mal_dn_3: 0.6660 (0.6660)  loss_bbox_dn_3: 0.1425 (0.1425)  loss_giou_dn_3: 0.4163 (0.4163)  loss_fgl_dn_3: 1.3072 (1.3072)  loss_ddf_dn_3: 0.0204 (0.0204)  loss_mal_dn_4: 0.6489 (0.6489)  loss_bbox_dn_4: 0.1355 (0.1355)  loss_giou_dn_4: 0.3968 (0.3968)  loss_fgl_dn_4: 1.3067 (1.3067)  loss_ddf_dn_4: 0.0028 (0.0028)  loss_mal_dn_5: 0.6392 (0.6392)  loss_bbox_dn_5: 0.1335 (0.1335)  loss_giou_dn_5: 0.3906 (0.3906)  loss_fgl_dn_5: 1.3069 (1.3069)  loss_mal_dn_pre: 0.8311 (0.8311)  loss_bbox_dn_pre: 0.2125 (0.2125)  loss_giou_dn_pre: 0.6040 (0.6040)  time: 2.1174  data: 0.7118  max mem: 13413\nEpoch: [16]  [100/251]  eta: 0:03:01  lr: 0.000003  loss: 43.3294 (42.7563)  loss_mal: 0.9863 (0.9471)  loss_bbox: 0.1952 (0.2095)  loss_giou: 0.4153 (0.4376)  loss_fgl: 1.2937 (1.2863)  loss_mal_aux_0: 1.2715 (1.2911)  loss_bbox_aux_0: 0.2347 (0.2334)  loss_giou_aux_0: 0.5027 (0.4929)  loss_fgl_aux_0: 1.3165 (1.3006)  loss_ddf_aux_0: 0.0756 (0.0703)  loss_mal_aux_1: 1.1602 (1.1321)  loss_bbox_aux_1: 0.2208 (0.2235)  loss_giou_aux_1: 0.4798 (0.4720)  loss_fgl_aux_1: 1.3055 (1.2962)  loss_ddf_aux_1: 0.0407 (0.0395)  loss_mal_aux_2: 1.0908 (1.0088)  loss_bbox_aux_2: 0.2033 (0.2122)  loss_giou_aux_2: 0.4422 (0.4457)  loss_fgl_aux_2: 1.2939 (1.2871)  loss_ddf_aux_2: 0.0098 (0.0094)  loss_mal_aux_3: 1.0605 (0.9601)  loss_bbox_aux_3: 0.1999 (0.2105)  loss_giou_aux_3: 0.4231 (0.4406)  loss_fgl_aux_3: 1.2954 (1.2862)  loss_ddf_aux_3: 0.0025 (0.0023)  loss_mal_aux_4: 0.9629 (0.9495)  loss_bbox_aux_4: 0.1994 (0.2098)  loss_giou_aux_4: 0.4171 (0.4383)  loss_fgl_aux_4: 1.2939 (1.2864)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.2627 (1.2781)  loss_bbox_pre: 0.2378 (0.2313)  loss_giou_pre: 0.4847 (0.4902)  loss_mal_enc_0: 1.5049 (1.5086)  loss_bbox_enc_0: 0.3101 (0.3233)  loss_giou_enc_0: 0.6534 (0.6558)  loss_mal_dn_0: 0.8276 (0.8338)  loss_bbox_dn_0: 0.4235 (0.3849)  loss_giou_dn_0: 0.6781 (0.7152)  loss_fgl_dn_0: 1.2542 (1.2400)  loss_ddf_dn_0: 0.7413 (0.6693)  loss_mal_dn_1: 0.7783 (0.7872)  loss_bbox_dn_1: 0.3321 (0.3215)  loss_giou_dn_1: 0.5508 (0.5950)  loss_fgl_dn_1: 1.2511 (1.2422)  loss_ddf_dn_1: 0.3655 (0.3405)  loss_mal_dn_2: 0.7578 (0.7516)  loss_bbox_dn_2: 0.2817 (0.2823)  loss_giou_dn_2: 0.4927 (0.5231)  loss_fgl_dn_2: 1.2402 (1.2306)  loss_ddf_dn_2: 0.0939 (0.0904)  loss_mal_dn_3: 0.7246 (0.7261)  loss_bbox_dn_3: 0.2702 (0.2703)  loss_giou_dn_3: 0.4780 (0.5023)  loss_fgl_dn_3: 1.2253 (1.2293)  loss_ddf_dn_3: 0.0223 (0.0217)  loss_mal_dn_4: 0.7124 (0.7139)  loss_bbox_dn_4: 0.2644 (0.2647)  loss_giou_dn_4: 0.4765 (0.4922)  loss_fgl_dn_4: 1.2214 (1.2302)  loss_ddf_dn_4: 0.0028 (0.0028)  loss_mal_dn_5: 0.7036 (0.7122)  loss_bbox_dn_5: 0.2639 (0.2624)  loss_giou_dn_5: 0.4762 (0.4881)  loss_fgl_dn_5: 1.2248 (1.2305)  loss_mal_dn_pre: 0.8242 (0.8310)  loss_bbox_dn_pre: 0.4361 (0.3884)  loss_giou_dn_pre: 0.6783 (0.7159)  time: 1.1176  data: 0.0114  max mem: 13413\nEpoch: [16]  [200/251]  eta: 0:01:01  lr: 0.000003  loss: 42.0606 (42.9972)  loss_mal: 0.9917 (0.9481)  loss_bbox: 0.1782 (0.2180)  loss_giou: 0.3717 (0.4353)  loss_fgl: 1.2878 (1.2873)  loss_mal_aux_0: 1.3643 (1.3325)  loss_bbox_aux_0: 0.2346 (0.2434)  loss_giou_aux_0: 0.4583 (0.4910)  loss_fgl_aux_0: 1.3082 (1.3011)  loss_ddf_aux_0: 0.0693 (0.0746)  loss_mal_aux_1: 1.1777 (1.1524)  loss_bbox_aux_1: 0.2177 (0.2332)  loss_giou_aux_1: 0.4304 (0.4693)  loss_fgl_aux_1: 1.2925 (1.2970)  loss_ddf_aux_1: 0.0365 (0.0415)  loss_mal_aux_2: 0.9893 (1.0157)  loss_bbox_aux_2: 0.1998 (0.2215)  loss_giou_aux_2: 0.3887 (0.4435)  loss_fgl_aux_2: 1.2817 (1.2879)  loss_ddf_aux_2: 0.0088 (0.0099)  loss_mal_aux_3: 1.0352 (0.9633)  loss_bbox_aux_3: 0.1876 (0.2194)  loss_giou_aux_3: 0.3798 (0.4384)  loss_fgl_aux_3: 1.2823 (1.2868)  loss_ddf_aux_3: 0.0018 (0.0024)  loss_mal_aux_4: 1.0293 (0.9491)  loss_bbox_aux_4: 0.1801 (0.2184)  loss_giou_aux_4: 0.3747 (0.4362)  loss_fgl_aux_4: 1.2855 (1.2871)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.3594 (1.3247)  loss_bbox_pre: 0.2375 (0.2425)  loss_giou_pre: 0.4561 (0.4891)  loss_mal_enc_0: 1.5332 (1.4955)  loss_bbox_enc_0: 0.3468 (0.3429)  loss_giou_enc_0: 0.5789 (0.6596)  loss_mal_dn_0: 0.8403 (0.8389)  loss_bbox_dn_0: 0.3869 (0.3976)  loss_giou_dn_0: 0.6779 (0.7097)  loss_fgl_dn_0: 1.2579 (1.2415)  loss_ddf_dn_0: 0.6078 (0.6812)  loss_mal_dn_1: 0.7627 (0.7879)  loss_bbox_dn_1: 0.3204 (0.3296)  loss_giou_dn_1: 0.5290 (0.5873)  loss_fgl_dn_1: 1.2567 (1.2422)  loss_ddf_dn_1: 0.2940 (0.3426)  loss_mal_dn_2: 0.7275 (0.7530)  loss_bbox_dn_2: 0.3044 (0.2896)  loss_giou_dn_2: 0.4478 (0.5168)  loss_fgl_dn_2: 1.2390 (1.2301)  loss_ddf_dn_2: 0.0715 (0.0902)  loss_mal_dn_3: 0.6982 (0.7261)  loss_bbox_dn_3: 0.2746 (0.2772)  loss_giou_dn_3: 0.4325 (0.4964)  loss_fgl_dn_3: 1.2286 (1.2287)  loss_ddf_dn_3: 0.0160 (0.0217)  loss_mal_dn_4: 0.6973 (0.7157)  loss_bbox_dn_4: 0.2569 (0.2715)  loss_giou_dn_4: 0.4236 (0.4866)  loss_fgl_dn_4: 1.2280 (1.2294)  loss_ddf_dn_4: 0.0019 (0.0028)  loss_mal_dn_5: 0.6890 (0.7149)  loss_bbox_dn_5: 0.2472 (0.2691)  loss_giou_dn_5: 0.4184 (0.4826)  loss_fgl_dn_5: 1.2262 (1.2298)  loss_mal_dn_pre: 0.8379 (0.8360)  loss_bbox_dn_pre: 0.3897 (0.4012)  loss_giou_dn_pre: 0.6784 (0.7102)  time: 1.1887  data: 0.0122  max mem: 13413\nEpoch: [16]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 43.0133 (43.0823)  loss_mal: 0.9062 (0.9546)  loss_bbox: 0.2508 (0.2185)  loss_giou: 0.4343 (0.4395)  loss_fgl: 1.2461 (1.2822)  loss_mal_aux_0: 1.2656 (1.3347)  loss_bbox_aux_0: 0.2724 (0.2450)  loss_giou_aux_0: 0.5103 (0.4959)  loss_fgl_aux_0: 1.3087 (1.2968)  loss_ddf_aux_0: 0.0819 (0.0750)  loss_mal_aux_1: 1.0654 (1.1490)  loss_bbox_aux_1: 0.2348 (0.2345)  loss_giou_aux_1: 0.4706 (0.4742)  loss_fgl_aux_1: 1.2820 (1.2923)  loss_ddf_aux_1: 0.0423 (0.0416)  loss_mal_aux_2: 1.0527 (1.0210)  loss_bbox_aux_2: 0.2203 (0.2219)  loss_giou_aux_2: 0.4401 (0.4479)  loss_fgl_aux_2: 1.2631 (1.2830)  loss_ddf_aux_2: 0.0107 (0.0098)  loss_mal_aux_3: 0.9272 (0.9683)  loss_bbox_aux_3: 0.2452 (0.2198)  loss_giou_aux_3: 0.4272 (0.4427)  loss_fgl_aux_3: 1.2505 (1.2818)  loss_ddf_aux_3: 0.0028 (0.0024)  loss_mal_aux_4: 0.9087 (0.9566)  loss_bbox_aux_4: 0.2520 (0.2188)  loss_giou_aux_4: 0.4337 (0.4404)  loss_fgl_aux_4: 1.2471 (1.2820)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.2598 (1.3280)  loss_bbox_pre: 0.2826 (0.2437)  loss_giou_pre: 0.5148 (0.4938)  loss_mal_enc_0: 1.5020 (1.4996)  loss_bbox_enc_0: 0.3776 (0.3455)  loss_giou_enc_0: 0.6956 (0.6642)  loss_mal_dn_0: 0.8223 (0.8371)  loss_bbox_dn_0: 0.4379 (0.4016)  loss_giou_dn_0: 0.7451 (0.7159)  loss_fgl_dn_0: 1.2315 (1.2385)  loss_ddf_dn_0: 0.7317 (0.6812)  loss_mal_dn_1: 0.7798 (0.7871)  loss_bbox_dn_1: 0.3462 (0.3335)  loss_giou_dn_1: 0.5993 (0.5935)  loss_fgl_dn_1: 1.2279 (1.2384)  loss_ddf_dn_1: 0.3625 (0.3412)  loss_mal_dn_2: 0.7417 (0.7528)  loss_bbox_dn_2: 0.3160 (0.2935)  loss_giou_dn_2: 0.5136 (0.5229)  loss_fgl_dn_2: 1.2170 (1.2265)  loss_ddf_dn_2: 0.0990 (0.0897)  loss_mal_dn_3: 0.7129 (0.7240)  loss_bbox_dn_3: 0.2989 (0.2809)  loss_giou_dn_3: 0.4958 (0.5024)  loss_fgl_dn_3: 1.2086 (1.2255)  loss_ddf_dn_3: 0.0238 (0.0215)  loss_mal_dn_4: 0.7046 (0.7140)  loss_bbox_dn_4: 0.2931 (0.2752)  loss_giou_dn_4: 0.4898 (0.4927)  loss_fgl_dn_4: 1.2054 (1.2264)  loss_ddf_dn_4: 0.0031 (0.0028)  loss_mal_dn_5: 0.7017 (0.7137)  loss_bbox_dn_5: 0.2917 (0.2729)  loss_giou_dn_5: 0.4896 (0.4889)  loss_fgl_dn_5: 1.2051 (1.2269)  loss_mal_dn_pre: 0.8188 (0.8342)  loss_bbox_dn_pre: 0.4421 (0.4053)  loss_giou_dn_pre: 0.7460 (0.7164)  time: 1.3159  data: 0.0124  max mem: 13413\nEpoch: [16] Total time: 0:05:04 (1.2148 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7874  data: 0.4691  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3534  data: 0.0651  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3076  data: 0.0222  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2949  data: 0.0202  max mem: 13413\nTest: Total time: 0:00:07 (0.3197 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.254\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.453\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.238\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.383\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.271\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.403\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.518\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.579\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.583\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.559\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.896\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.639\nbest_stat: {'epoch': 14, 'coco_eval_bbox': 0.2667668358996345}\nEpoch: [17]  [  0/251]  eta: 0:06:41  lr: 0.000003  loss: 44.1589 (44.1589)  loss_mal: 1.3779 (1.3779)  loss_bbox: 0.2322 (0.2322)  loss_giou: 0.3832 (0.3832)  loss_fgl: 1.3001 (1.3001)  loss_mal_aux_0: 1.3721 (1.3721)  loss_bbox_aux_0: 0.2979 (0.2979)  loss_giou_aux_0: 0.4252 (0.4252)  loss_fgl_aux_0: 1.3358 (1.3358)  loss_ddf_aux_0: 0.0952 (0.0952)  loss_mal_aux_1: 1.1992 (1.1992)  loss_bbox_aux_1: 0.2838 (0.2838)  loss_giou_aux_1: 0.4101 (0.4101)  loss_fgl_aux_1: 1.3313 (1.3313)  loss_ddf_aux_1: 0.0488 (0.0488)  loss_mal_aux_2: 1.1875 (1.1875)  loss_bbox_aux_2: 0.2534 (0.2534)  loss_giou_aux_2: 0.3938 (0.3938)  loss_fgl_aux_2: 1.3139 (1.3139)  loss_ddf_aux_2: 0.0108 (0.0108)  loss_mal_aux_3: 1.1387 (1.1387)  loss_bbox_aux_3: 0.2411 (0.2411)  loss_giou_aux_3: 0.3901 (0.3901)  loss_fgl_aux_3: 1.3040 (1.3040)  loss_ddf_aux_3: 0.0025 (0.0025)  loss_mal_aux_4: 1.2812 (1.2812)  loss_bbox_aux_4: 0.2348 (0.2348)  loss_giou_aux_4: 0.3858 (0.3858)  loss_fgl_aux_4: 1.3010 (1.3010)  loss_ddf_aux_4: 0.0004 (0.0004)  loss_mal_pre: 1.3594 (1.3594)  loss_bbox_pre: 0.2934 (0.2934)  loss_giou_pre: 0.4238 (0.4238)  loss_mal_enc_0: 1.2461 (1.2461)  loss_bbox_enc_0: 0.3908 (0.3908)  loss_giou_enc_0: 0.5911 (0.5911)  loss_mal_dn_0: 0.8511 (0.8511)  loss_bbox_dn_0: 0.4735 (0.4735)  loss_giou_dn_0: 0.6738 (0.6738)  loss_fgl_dn_0: 1.2655 (1.2655)  loss_ddf_dn_0: 0.8588 (0.8588)  loss_mal_dn_1: 0.8037 (0.8037)  loss_bbox_dn_1: 0.3469 (0.3469)  loss_giou_dn_1: 0.5003 (0.5003)  loss_fgl_dn_1: 1.2653 (1.2653)  loss_ddf_dn_1: 0.4268 (0.4268)  loss_mal_dn_2: 0.7817 (0.7817)  loss_bbox_dn_2: 0.2836 (0.2836)  loss_giou_dn_2: 0.4351 (0.4351)  loss_fgl_dn_2: 1.2390 (1.2390)  loss_ddf_dn_2: 0.1113 (0.1113)  loss_mal_dn_3: 0.7681 (0.7681)  loss_bbox_dn_3: 0.2606 (0.2606)  loss_giou_dn_3: 0.4120 (0.4120)  loss_fgl_dn_3: 1.2314 (1.2314)  loss_ddf_dn_3: 0.0259 (0.0259)  loss_mal_dn_4: 0.7627 (0.7627)  loss_bbox_dn_4: 0.2532 (0.2532)  loss_giou_dn_4: 0.4042 (0.4042)  loss_fgl_dn_4: 1.2298 (1.2298)  loss_ddf_dn_4: 0.0036 (0.0036)  loss_mal_dn_5: 0.7749 (0.7749)  loss_bbox_dn_5: 0.2486 (0.2486)  loss_giou_dn_5: 0.4004 (0.4004)  loss_fgl_dn_5: 1.2294 (1.2294)  loss_mal_dn_pre: 0.8462 (0.8462)  loss_bbox_dn_pre: 0.4789 (0.4789)  loss_giou_dn_pre: 0.6762 (0.6762)  time: 1.5985  data: 0.5867  max mem: 13413\nEpoch: [17]  [100/251]  eta: 0:03:05  lr: 0.000003  loss: 41.6150 (42.5870)  loss_mal: 0.8447 (0.9452)  loss_bbox: 0.1755 (0.2051)  loss_giou: 0.4043 (0.4233)  loss_fgl: 1.2661 (1.2852)  loss_mal_aux_0: 1.2988 (1.3216)  loss_bbox_aux_0: 0.2184 (0.2320)  loss_giou_aux_0: 0.4621 (0.4757)  loss_fgl_aux_0: 1.3106 (1.3023)  loss_ddf_aux_0: 0.0837 (0.0781)  loss_mal_aux_1: 1.0576 (1.1200)  loss_bbox_aux_1: 0.1977 (0.2224)  loss_giou_aux_1: 0.4385 (0.4555)  loss_fgl_aux_1: 1.2912 (1.2952)  loss_ddf_aux_1: 0.0433 (0.0418)  loss_mal_aux_2: 0.8984 (1.0040)  loss_bbox_aux_2: 0.1726 (0.2091)  loss_giou_aux_2: 0.4089 (0.4302)  loss_fgl_aux_2: 1.2773 (1.2858)  loss_ddf_aux_2: 0.0094 (0.0092)  loss_mal_aux_3: 0.8926 (0.9615)  loss_bbox_aux_3: 0.1706 (0.2063)  loss_giou_aux_3: 0.3994 (0.4255)  loss_fgl_aux_3: 1.2724 (1.2847)  loss_ddf_aux_3: 0.0019 (0.0022)  loss_mal_aux_4: 0.8223 (0.9472)  loss_bbox_aux_4: 0.1744 (0.2053)  loss_giou_aux_4: 0.4023 (0.4239)  loss_fgl_aux_4: 1.2681 (1.2849)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.3027 (1.3135)  loss_bbox_pre: 0.2132 (0.2297)  loss_giou_pre: 0.4564 (0.4740)  loss_mal_enc_0: 1.4277 (1.5176)  loss_bbox_enc_0: 0.3100 (0.3193)  loss_giou_enc_0: 0.6231 (0.6252)  loss_mal_dn_0: 0.8501 (0.8399)  loss_bbox_dn_0: 0.3467 (0.3908)  loss_giou_dn_0: 0.6738 (0.7009)  loss_fgl_dn_0: 1.2556 (1.2488)  loss_ddf_dn_0: 0.7327 (0.7664)  loss_mal_dn_1: 0.8096 (0.7934)  loss_bbox_dn_1: 0.2724 (0.3137)  loss_giou_dn_1: 0.5477 (0.5670)  loss_fgl_dn_1: 1.2514 (1.2418)  loss_ddf_dn_1: 0.3612 (0.3676)  loss_mal_dn_2: 0.7793 (0.7532)  loss_bbox_dn_2: 0.2270 (0.2738)  loss_giou_dn_2: 0.4710 (0.4979)  loss_fgl_dn_2: 1.2283 (1.2263)  loss_ddf_dn_2: 0.0945 (0.0936)  loss_mal_dn_3: 0.7295 (0.7198)  loss_bbox_dn_3: 0.2233 (0.2610)  loss_giou_dn_3: 0.4556 (0.4778)  loss_fgl_dn_3: 1.2166 (1.2246)  loss_ddf_dn_3: 0.0220 (0.0220)  loss_mal_dn_4: 0.7261 (0.7077)  loss_bbox_dn_4: 0.2206 (0.2553)  loss_giou_dn_4: 0.4441 (0.4682)  loss_fgl_dn_4: 1.2203 (1.2251)  loss_ddf_dn_4: 0.0029 (0.0028)  loss_mal_dn_5: 0.7090 (0.7082)  loss_bbox_dn_5: 0.2181 (0.2531)  loss_giou_dn_5: 0.4363 (0.4643)  loss_fgl_dn_5: 1.2224 (1.2256)  loss_mal_dn_pre: 0.8462 (0.8370)  loss_bbox_dn_pre: 0.3397 (0.3960)  loss_giou_dn_pre: 0.6745 (0.7009)  time: 1.2089  data: 0.0128  max mem: 13413\nEpoch: [17]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 42.7561 (42.7632)  loss_mal: 0.8501 (0.9307)  loss_bbox: 0.2081 (0.2164)  loss_giou: 0.4422 (0.4388)  loss_fgl: 1.2864 (1.2856)  loss_mal_aux_0: 1.3262 (1.3094)  loss_bbox_aux_0: 0.2351 (0.2413)  loss_giou_aux_0: 0.4909 (0.4872)  loss_fgl_aux_0: 1.3029 (1.2982)  loss_ddf_aux_0: 0.0823 (0.0795)  loss_mal_aux_1: 1.0771 (1.1118)  loss_bbox_aux_1: 0.2047 (0.2314)  loss_giou_aux_1: 0.4544 (0.4666)  loss_fgl_aux_1: 1.2925 (1.2925)  loss_ddf_aux_1: 0.0406 (0.0422)  loss_mal_aux_2: 0.9795 (1.0009)  loss_bbox_aux_2: 0.2033 (0.2194)  loss_giou_aux_2: 0.4346 (0.4441)  loss_fgl_aux_2: 1.2895 (1.2848)  loss_ddf_aux_2: 0.0080 (0.0092)  loss_mal_aux_3: 0.9199 (0.9515)  loss_bbox_aux_3: 0.2034 (0.2173)  loss_giou_aux_3: 0.4401 (0.4404)  loss_fgl_aux_3: 1.2889 (1.2850)  loss_ddf_aux_3: 0.0019 (0.0022)  loss_mal_aux_4: 0.8428 (0.9342)  loss_bbox_aux_4: 0.2065 (0.2166)  loss_giou_aux_4: 0.4422 (0.4391)  loss_fgl_aux_4: 1.2875 (1.2854)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.3203 (1.3068)  loss_bbox_pre: 0.2327 (0.2389)  loss_giou_pre: 0.4919 (0.4852)  loss_mal_enc_0: 1.5088 (1.4967)  loss_bbox_enc_0: 0.3258 (0.3293)  loss_giou_enc_0: 0.6415 (0.6428)  loss_mal_dn_0: 0.8198 (0.8347)  loss_bbox_dn_0: 0.3761 (0.3925)  loss_giou_dn_0: 0.7152 (0.7029)  loss_fgl_dn_0: 1.2522 (1.2466)  loss_ddf_dn_0: 0.6571 (0.7732)  loss_mal_dn_1: 0.7583 (0.7862)  loss_bbox_dn_1: 0.3482 (0.3197)  loss_giou_dn_1: 0.5951 (0.5723)  loss_fgl_dn_1: 1.2486 (1.2403)  loss_ddf_dn_1: 0.3239 (0.3627)  loss_mal_dn_2: 0.7104 (0.7443)  loss_bbox_dn_2: 0.3058 (0.2833)  loss_giou_dn_2: 0.5192 (0.5096)  loss_fgl_dn_2: 1.2335 (1.2271)  loss_ddf_dn_2: 0.0788 (0.0911)  loss_mal_dn_3: 0.6948 (0.7142)  loss_bbox_dn_3: 0.2938 (0.2711)  loss_giou_dn_3: 0.4994 (0.4909)  loss_fgl_dn_3: 1.2290 (1.2276)  loss_ddf_dn_3: 0.0179 (0.0213)  loss_mal_dn_4: 0.6899 (0.7036)  loss_bbox_dn_4: 0.2955 (0.2658)  loss_giou_dn_4: 0.4875 (0.4822)  loss_fgl_dn_4: 1.2451 (1.2287)  loss_ddf_dn_4: 0.0024 (0.0027)  loss_mal_dn_5: 0.6851 (0.7031)  loss_bbox_dn_5: 0.2973 (0.2640)  loss_giou_dn_5: 0.4852 (0.4789)  loss_fgl_dn_5: 1.2437 (1.2294)  loss_mal_dn_pre: 0.8154 (0.8319)  loss_bbox_dn_pre: 0.3904 (0.3971)  loss_giou_dn_pre: 0.7155 (0.7024)  time: 1.2487  data: 0.0119  max mem: 13413\nEpoch: [17]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 41.2627 (42.7205)  loss_mal: 0.8252 (0.9370)  loss_bbox: 0.1722 (0.2152)  loss_giou: 0.3562 (0.4399)  loss_fgl: 1.2807 (1.2845)  loss_mal_aux_0: 1.3379 (1.3071)  loss_bbox_aux_0: 0.1856 (0.2409)  loss_giou_aux_0: 0.3994 (0.4890)  loss_fgl_aux_0: 1.3199 (1.2969)  loss_ddf_aux_0: 0.0911 (0.0805)  loss_mal_aux_1: 1.1279 (1.1116)  loss_bbox_aux_1: 0.1594 (0.2304)  loss_giou_aux_1: 0.3707 (0.4680)  loss_fgl_aux_1: 1.3048 (1.2909)  loss_ddf_aux_1: 0.0438 (0.0425)  loss_mal_aux_2: 0.8760 (0.9985)  loss_bbox_aux_2: 0.1582 (0.2183)  loss_giou_aux_2: 0.3596 (0.4458)  loss_fgl_aux_2: 1.2832 (1.2833)  loss_ddf_aux_2: 0.0095 (0.0093)  loss_mal_aux_3: 0.8696 (0.9539)  loss_bbox_aux_3: 0.1684 (0.2163)  loss_giou_aux_3: 0.3594 (0.4419)  loss_fgl_aux_3: 1.2801 (1.2838)  loss_ddf_aux_3: 0.0020 (0.0022)  loss_mal_aux_4: 0.8535 (0.9380)  loss_bbox_aux_4: 0.1730 (0.2155)  loss_giou_aux_4: 0.3580 (0.4404)  loss_fgl_aux_4: 1.2788 (1.2842)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.3223 (1.3033)  loss_bbox_pre: 0.1823 (0.2385)  loss_giou_pre: 0.3971 (0.4871)  loss_mal_enc_0: 1.5107 (1.4903)  loss_bbox_enc_0: 0.2587 (0.3288)  loss_giou_enc_0: 0.5660 (0.6434)  loss_mal_dn_0: 0.8511 (0.8361)  loss_bbox_dn_0: 0.3231 (0.3876)  loss_giou_dn_0: 0.6279 (0.7010)  loss_fgl_dn_0: 1.2674 (1.2470)  loss_ddf_dn_0: 0.9065 (0.7761)  loss_mal_dn_1: 0.7900 (0.7887)  loss_bbox_dn_1: 0.2575 (0.3145)  loss_giou_dn_1: 0.4907 (0.5689)  loss_fgl_dn_1: 1.2569 (1.2406)  loss_ddf_dn_1: 0.4093 (0.3618)  loss_mal_dn_2: 0.7451 (0.7469)  loss_bbox_dn_2: 0.2307 (0.2782)  loss_giou_dn_2: 0.4354 (0.5066)  loss_fgl_dn_2: 1.2437 (1.2270)  loss_ddf_dn_2: 0.0977 (0.0905)  loss_mal_dn_3: 0.7212 (0.7167)  loss_bbox_dn_3: 0.2163 (0.2659)  loss_giou_dn_3: 0.4091 (0.4877)  loss_fgl_dn_3: 1.2379 (1.2275)  loss_ddf_dn_3: 0.0217 (0.0211)  loss_mal_dn_4: 0.7114 (0.7064)  loss_bbox_dn_4: 0.2085 (0.2606)  loss_giou_dn_4: 0.3982 (0.4788)  loss_fgl_dn_4: 1.2407 (1.2286)  loss_ddf_dn_4: 0.0030 (0.0027)  loss_mal_dn_5: 0.7124 (0.7058)  loss_bbox_dn_5: 0.2042 (0.2586)  loss_giou_dn_5: 0.3926 (0.4754)  loss_fgl_dn_5: 1.2425 (1.2293)  loss_mal_dn_pre: 0.8496 (0.8334)  loss_bbox_dn_pre: 0.3271 (0.3924)  loss_giou_dn_pre: 0.6262 (0.7005)  time: 1.3202  data: 0.0131  max mem: 13413\nEpoch: [17] Total time: 0:05:09 (1.2315 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7859  data: 0.4750  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3549  data: 0.0655  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3082  data: 0.0225  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2957  data: 0.0211  max mem: 13413\nTest: Total time: 0:00:08 (0.3204 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.469\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.313\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.430\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.558\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.637\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.608\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.906\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.750\nbest_stat: {'epoch': 17, 'coco_eval_bbox': 0.29462486930314535}\nEpoch: [18]  [  0/251]  eta: 0:07:59  lr: 0.000003  loss: 48.6726 (48.6726)  loss_mal: 1.1494 (1.1494)  loss_bbox: 0.3618 (0.3618)  loss_giou: 0.8361 (0.8361)  loss_fgl: 1.3238 (1.3238)  loss_mal_aux_0: 1.0137 (1.0137)  loss_bbox_aux_0: 0.4077 (0.4077)  loss_giou_aux_0: 0.8143 (0.8143)  loss_fgl_aux_0: 1.2711 (1.2711)  loss_ddf_aux_0: 0.0639 (0.0639)  loss_mal_aux_1: 1.0293 (1.0293)  loss_bbox_aux_1: 0.3883 (0.3883)  loss_giou_aux_1: 0.8294 (0.8294)  loss_fgl_aux_1: 1.2950 (1.2950)  loss_ddf_aux_1: 0.0337 (0.0337)  loss_mal_aux_2: 1.1328 (1.1328)  loss_bbox_aux_2: 0.3655 (0.3655)  loss_giou_aux_2: 0.8309 (0.8309)  loss_fgl_aux_2: 1.3098 (1.3098)  loss_ddf_aux_2: 0.0085 (0.0085)  loss_mal_aux_3: 1.0557 (1.0557)  loss_bbox_aux_3: 0.3629 (0.3629)  loss_giou_aux_3: 0.8376 (0.8376)  loss_fgl_aux_3: 1.3205 (1.3205)  loss_ddf_aux_3: 0.0022 (0.0022)  loss_mal_aux_4: 1.1348 (1.1348)  loss_bbox_aux_4: 0.3594 (0.3594)  loss_giou_aux_4: 0.8369 (0.8369)  loss_fgl_aux_4: 1.3239 (1.3239)  loss_ddf_aux_4: 0.0004 (0.0004)  loss_mal_pre: 1.0068 (1.0068)  loss_bbox_pre: 0.3920 (0.3920)  loss_giou_pre: 0.8088 (0.8088)  loss_mal_enc_0: 1.2373 (1.2373)  loss_bbox_enc_0: 0.4116 (0.4116)  loss_giou_enc_0: 0.8808 (0.8808)  loss_mal_dn_0: 0.8442 (0.8442)  loss_bbox_dn_0: 0.3593 (0.3593)  loss_giou_dn_0: 0.8188 (0.8188)  loss_fgl_dn_0: 1.1991 (1.1991)  loss_ddf_dn_0: 0.6255 (0.6255)  loss_mal_dn_1: 0.8501 (0.8501)  loss_bbox_dn_1: 0.3706 (0.3706)  loss_giou_dn_1: 0.7740 (0.7740)  loss_fgl_dn_1: 1.2061 (1.2061)  loss_ddf_dn_1: 0.2689 (0.2689)  loss_mal_dn_2: 0.7944 (0.7944)  loss_bbox_dn_2: 0.3631 (0.3631)  loss_giou_dn_2: 0.7646 (0.7646)  loss_fgl_dn_2: 1.2638 (1.2638)  loss_ddf_dn_2: 0.0662 (0.0662)  loss_mal_dn_3: 0.7686 (0.7686)  loss_bbox_dn_3: 0.3607 (0.3607)  loss_giou_dn_3: 0.7659 (0.7659)  loss_fgl_dn_3: 1.2972 (1.2972)  loss_ddf_dn_3: 0.0151 (0.0151)  loss_mal_dn_4: 0.7891 (0.7891)  loss_bbox_dn_4: 0.3593 (0.3593)  loss_giou_dn_4: 0.7648 (0.7648)  loss_fgl_dn_4: 1.3102 (1.3102)  loss_ddf_dn_4: 0.0022 (0.0022)  loss_mal_dn_5: 0.7739 (0.7739)  loss_bbox_dn_5: 0.3602 (0.3602)  loss_giou_dn_5: 0.7659 (0.7659)  loss_fgl_dn_5: 1.3142 (1.3142)  loss_mal_dn_pre: 0.8428 (0.8428)  loss_bbox_dn_pre: 0.3622 (0.3622)  loss_giou_dn_pre: 0.8154 (0.8154)  time: 1.9119  data: 0.4831  max mem: 13413\nEpoch: [18]  [100/251]  eta: 0:03:02  lr: 0.000003  loss: 40.1386 (42.0799)  loss_mal: 0.7671 (0.9216)  loss_bbox: 0.1489 (0.2127)  loss_giou: 0.3805 (0.4145)  loss_fgl: 1.2987 (1.2865)  loss_mal_aux_0: 1.2129 (1.2859)  loss_bbox_aux_0: 0.1724 (0.2373)  loss_giou_aux_0: 0.4755 (0.4686)  loss_fgl_aux_0: 1.3006 (1.3019)  loss_ddf_aux_0: 0.0712 (0.0830)  loss_mal_aux_1: 1.0293 (1.0825)  loss_bbox_aux_1: 0.1680 (0.2260)  loss_giou_aux_1: 0.4310 (0.4448)  loss_fgl_aux_1: 1.3020 (1.2944)  loss_ddf_aux_1: 0.0356 (0.0428)  loss_mal_aux_2: 0.8623 (0.9910)  loss_bbox_aux_2: 0.1552 (0.2155)  loss_giou_aux_2: 0.3889 (0.4223)  loss_fgl_aux_2: 1.2939 (1.2868)  loss_ddf_aux_2: 0.0073 (0.0092)  loss_mal_aux_3: 0.7832 (0.9331)  loss_bbox_aux_3: 0.1541 (0.2136)  loss_giou_aux_3: 0.3889 (0.4173)  loss_fgl_aux_3: 1.2970 (1.2869)  loss_ddf_aux_3: 0.0018 (0.0022)  loss_mal_aux_4: 0.7896 (0.9158)  loss_bbox_aux_4: 0.1513 (0.2129)  loss_giou_aux_4: 0.3847 (0.4152)  loss_fgl_aux_4: 1.2989 (1.2866)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.2051 (1.2821)  loss_bbox_pre: 0.1710 (0.2360)  loss_giou_pre: 0.4699 (0.4671)  loss_mal_enc_0: 1.4004 (1.4737)  loss_bbox_enc_0: 0.2574 (0.3246)  loss_giou_enc_0: 0.5990 (0.6230)  loss_mal_dn_0: 0.8364 (0.8361)  loss_bbox_dn_0: 0.2524 (0.3705)  loss_giou_dn_0: 0.6247 (0.6779)  loss_fgl_dn_0: 1.2716 (1.2577)  loss_ddf_dn_0: 0.6412 (0.7976)  loss_mal_dn_1: 0.7983 (0.7830)  loss_bbox_dn_1: 0.2083 (0.2964)  loss_giou_dn_1: 0.4972 (0.5395)  loss_fgl_dn_1: 1.2571 (1.2492)  loss_ddf_dn_1: 0.2736 (0.3494)  loss_mal_dn_2: 0.7251 (0.7336)  loss_bbox_dn_2: 0.1733 (0.2646)  loss_giou_dn_2: 0.4417 (0.4808)  loss_fgl_dn_2: 1.2412 (1.2354)  loss_ddf_dn_2: 0.0690 (0.0847)  loss_mal_dn_3: 0.6973 (0.6989)  loss_bbox_dn_3: 0.1673 (0.2529)  loss_giou_dn_3: 0.4297 (0.4626)  loss_fgl_dn_3: 1.2414 (1.2351)  loss_ddf_dn_3: 0.0154 (0.0199)  loss_mal_dn_4: 0.6792 (0.6883)  loss_bbox_dn_4: 0.1638 (0.2484)  loss_giou_dn_4: 0.4307 (0.4540)  loss_fgl_dn_4: 1.2424 (1.2351)  loss_ddf_dn_4: 0.0019 (0.0026)  loss_mal_dn_5: 0.6846 (0.6895)  loss_bbox_dn_5: 0.1621 (0.2468)  loss_giou_dn_5: 0.4266 (0.4508)  loss_fgl_dn_5: 1.2414 (1.2352)  loss_mal_dn_pre: 0.8335 (0.8339)  loss_bbox_dn_pre: 0.2593 (0.3747)  loss_giou_dn_pre: 0.6189 (0.6767)  time: 1.1793  data: 0.0116  max mem: 13413\nEpoch: [18]  [200/251]  eta: 0:01:01  lr: 0.000003  loss: 41.5826 (42.0679)  loss_mal: 0.8809 (0.9105)  loss_bbox: 0.1770 (0.2071)  loss_giou: 0.3799 (0.4114)  loss_fgl: 1.2797 (1.2899)  loss_mal_aux_0: 1.3027 (1.3072)  loss_bbox_aux_0: 0.2216 (0.2322)  loss_giou_aux_0: 0.4565 (0.4660)  loss_fgl_aux_0: 1.3222 (1.3074)  loss_ddf_aux_0: 0.0767 (0.0840)  loss_mal_aux_1: 1.0332 (1.0855)  loss_bbox_aux_1: 0.2039 (0.2193)  loss_giou_aux_1: 0.4262 (0.4400)  loss_fgl_aux_1: 1.2975 (1.2990)  loss_ddf_aux_1: 0.0381 (0.0431)  loss_mal_aux_2: 0.9351 (0.9833)  loss_bbox_aux_2: 0.1888 (0.2089)  loss_giou_aux_2: 0.3901 (0.4174)  loss_fgl_aux_2: 1.2753 (1.2905)  loss_ddf_aux_2: 0.0086 (0.0092)  loss_mal_aux_3: 0.8916 (0.9302)  loss_bbox_aux_3: 0.1820 (0.2074)  loss_giou_aux_3: 0.3869 (0.4132)  loss_fgl_aux_3: 1.2699 (1.2902)  loss_ddf_aux_3: 0.0021 (0.0022)  loss_mal_aux_4: 0.8813 (0.9154)  loss_bbox_aux_4: 0.1782 (0.2071)  loss_giou_aux_4: 0.3821 (0.4118)  loss_fgl_aux_4: 1.2764 (1.2899)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.3027 (1.3024)  loss_bbox_pre: 0.2202 (0.2308)  loss_giou_pre: 0.4578 (0.4647)  loss_mal_enc_0: 1.4902 (1.4688)  loss_bbox_enc_0: 0.2867 (0.3192)  loss_giou_enc_0: 0.6025 (0.6216)  loss_mal_dn_0: 0.8418 (0.8353)  loss_bbox_dn_0: 0.3286 (0.3697)  loss_giou_dn_0: 0.7085 (0.6790)  loss_fgl_dn_0: 1.2631 (1.2569)  loss_ddf_dn_0: 0.8545 (0.8075)  loss_mal_dn_1: 0.7993 (0.7822)  loss_bbox_dn_1: 0.2510 (0.2946)  loss_giou_dn_1: 0.5474 (0.5403)  loss_fgl_dn_1: 1.2568 (1.2474)  loss_ddf_dn_1: 0.3671 (0.3501)  loss_mal_dn_2: 0.7402 (0.7333)  loss_bbox_dn_2: 0.2196 (0.2635)  loss_giou_dn_2: 0.4990 (0.4843)  loss_fgl_dn_2: 1.2436 (1.2340)  loss_ddf_dn_2: 0.0920 (0.0854)  loss_mal_dn_3: 0.7192 (0.7003)  loss_bbox_dn_3: 0.2109 (0.2522)  loss_giou_dn_3: 0.4769 (0.4664)  loss_fgl_dn_3: 1.2514 (1.2344)  loss_ddf_dn_3: 0.0221 (0.0200)  loss_mal_dn_4: 0.6860 (0.6896)  loss_bbox_dn_4: 0.2101 (0.2481)  loss_giou_dn_4: 0.4745 (0.4585)  loss_fgl_dn_4: 1.2491 (1.2348)  loss_ddf_dn_4: 0.0028 (0.0026)  loss_mal_dn_5: 0.6724 (0.6880)  loss_bbox_dn_5: 0.2094 (0.2467)  loss_giou_dn_5: 0.4769 (0.4557)  loss_fgl_dn_5: 1.2494 (1.2352)  loss_mal_dn_pre: 0.8394 (0.8334)  loss_bbox_dn_pre: 0.3359 (0.3734)  loss_giou_dn_pre: 0.7045 (0.6783)  time: 1.2405  data: 0.0116  max mem: 13413\nEpoch: [18]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 41.7488 (42.0558)  loss_mal: 0.9146 (0.9128)  loss_bbox: 0.1904 (0.2066)  loss_giou: 0.4077 (0.4074)  loss_fgl: 1.2424 (1.2871)  loss_mal_aux_0: 1.3438 (1.3115)  loss_bbox_aux_0: 0.2080 (0.2333)  loss_giou_aux_0: 0.4792 (0.4644)  loss_fgl_aux_0: 1.2995 (1.3068)  loss_ddf_aux_0: 0.0920 (0.0865)  loss_mal_aux_1: 1.0361 (1.0890)  loss_bbox_aux_1: 0.1974 (0.2197)  loss_giou_aux_1: 0.4503 (0.4370)  loss_fgl_aux_1: 1.2726 (1.2976)  loss_ddf_aux_1: 0.0477 (0.0441)  loss_mal_aux_2: 0.9419 (0.9834)  loss_bbox_aux_2: 0.1898 (0.2091)  loss_giou_aux_2: 0.4369 (0.4138)  loss_fgl_aux_2: 1.2694 (1.2880)  loss_ddf_aux_2: 0.0094 (0.0093)  loss_mal_aux_3: 0.8960 (0.9325)  loss_bbox_aux_3: 0.1889 (0.2072)  loss_giou_aux_3: 0.4221 (0.4095)  loss_fgl_aux_3: 1.2513 (1.2873)  loss_ddf_aux_3: 0.0020 (0.0023)  loss_mal_aux_4: 0.9136 (0.9162)  loss_bbox_aux_4: 0.1901 (0.2067)  loss_giou_aux_4: 0.4113 (0.4079)  loss_fgl_aux_4: 1.2441 (1.2869)  loss_ddf_aux_4: 0.0004 (0.0003)  loss_mal_pre: 1.3467 (1.3064)  loss_bbox_pre: 0.2043 (0.2324)  loss_giou_pre: 0.4714 (0.4633)  loss_mal_enc_0: 1.3662 (1.4590)  loss_bbox_enc_0: 0.3323 (0.3249)  loss_giou_enc_0: 0.6385 (0.6280)  loss_mal_dn_0: 0.8213 (0.8335)  loss_bbox_dn_0: 0.3570 (0.3751)  loss_giou_dn_0: 0.6668 (0.6775)  loss_fgl_dn_0: 1.2706 (1.2572)  loss_ddf_dn_0: 0.9083 (0.8288)  loss_mal_dn_1: 0.7656 (0.7810)  loss_bbox_dn_1: 0.2518 (0.2981)  loss_giou_dn_1: 0.5432 (0.5364)  loss_fgl_dn_1: 1.2584 (1.2471)  loss_ddf_dn_1: 0.3559 (0.3559)  loss_mal_dn_2: 0.7251 (0.7300)  loss_bbox_dn_2: 0.2241 (0.2665)  loss_giou_dn_2: 0.4896 (0.4798)  loss_fgl_dn_2: 1.2376 (1.2326)  loss_ddf_dn_2: 0.0848 (0.0869)  loss_mal_dn_3: 0.6807 (0.6962)  loss_bbox_dn_3: 0.2194 (0.2549)  loss_giou_dn_3: 0.4755 (0.4615)  loss_fgl_dn_3: 1.2248 (1.2325)  loss_ddf_dn_3: 0.0193 (0.0203)  loss_mal_dn_4: 0.6689 (0.6844)  loss_bbox_dn_4: 0.2194 (0.2506)  loss_giou_dn_4: 0.4692 (0.4536)  loss_fgl_dn_4: 1.2203 (1.2329)  loss_ddf_dn_4: 0.0025 (0.0026)  loss_mal_dn_5: 0.6577 (0.6821)  loss_bbox_dn_5: 0.2158 (0.2493)  loss_giou_dn_5: 0.4661 (0.4508)  loss_fgl_dn_5: 1.2207 (1.2332)  loss_mal_dn_pre: 0.8193 (0.8315)  loss_bbox_dn_pre: 0.3718 (0.3787)  loss_giou_dn_pre: 0.6660 (0.6767)  time: 1.1581  data: 0.0109  max mem: 13413\nEpoch: [18] Total time: 0:05:02 (1.2055 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7886  data: 0.4720  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3509  data: 0.0626  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3056  data: 0.0209  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2940  data: 0.0201  max mem: 13413\nTest: Total time: 0:00:07 (0.3187 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.273\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.472\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.273\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.301\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.275\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.393\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.540\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.645\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.579\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.638\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.915\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.702\nbest_stat: {'epoch': 17, 'coco_eval_bbox': 0.29462486930314535}\nEpoch: [19]  [  0/251]  eta: 0:07:38  lr: 0.000003  loss: 38.3289 (38.3289)  loss_mal: 0.7119 (0.7119)  loss_bbox: 0.1255 (0.1255)  loss_giou: 0.3419 (0.3419)  loss_fgl: 1.2849 (1.2849)  loss_mal_aux_0: 1.3984 (1.3984)  loss_bbox_aux_0: 0.1203 (0.1203)  loss_giou_aux_0: 0.3362 (0.3362)  loss_fgl_aux_0: 1.3232 (1.3232)  loss_ddf_aux_0: 0.0757 (0.0757)  loss_mal_aux_1: 1.0186 (1.0186)  loss_bbox_aux_1: 0.1187 (0.1187)  loss_giou_aux_1: 0.3471 (0.3471)  loss_fgl_aux_1: 1.3048 (1.3048)  loss_ddf_aux_1: 0.0332 (0.0332)  loss_mal_aux_2: 0.8403 (0.8403)  loss_bbox_aux_2: 0.1177 (0.1177)  loss_giou_aux_2: 0.3414 (0.3414)  loss_fgl_aux_2: 1.2861 (1.2861)  loss_ddf_aux_2: 0.0058 (0.0058)  loss_mal_aux_3: 0.7563 (0.7563)  loss_bbox_aux_3: 0.1201 (0.1201)  loss_giou_aux_3: 0.3378 (0.3378)  loss_fgl_aux_3: 1.2813 (1.2813)  loss_ddf_aux_3: 0.0015 (0.0015)  loss_mal_aux_4: 0.7100 (0.7100)  loss_bbox_aux_4: 0.1243 (0.1243)  loss_giou_aux_4: 0.3403 (0.3403)  loss_fgl_aux_4: 1.2836 (1.2836)  loss_ddf_aux_4: 0.0004 (0.0004)  loss_mal_pre: 1.3359 (1.3359)  loss_bbox_pre: 0.1212 (0.1212)  loss_giou_pre: 0.3371 (0.3371)  loss_mal_enc_0: 1.3008 (1.3008)  loss_bbox_enc_0: 0.2417 (0.2417)  loss_giou_enc_0: 0.6115 (0.6115)  loss_mal_dn_0: 0.8345 (0.8345)  loss_bbox_dn_0: 0.2751 (0.2751)  loss_giou_dn_0: 0.5394 (0.5394)  loss_fgl_dn_0: 1.2985 (1.2985)  loss_ddf_dn_0: 0.8529 (0.8529)  loss_mal_dn_1: 0.7524 (0.7524)  loss_bbox_dn_1: 0.1766 (0.1766)  loss_giou_dn_1: 0.3949 (0.3949)  loss_fgl_dn_1: 1.2756 (1.2756)  loss_ddf_dn_1: 0.3442 (0.3442)  loss_mal_dn_2: 0.7236 (0.7236)  loss_bbox_dn_2: 0.1614 (0.1614)  loss_giou_dn_2: 0.3778 (0.3778)  loss_fgl_dn_2: 1.2234 (1.2234)  loss_ddf_dn_2: 0.0725 (0.0725)  loss_mal_dn_3: 0.7095 (0.7095)  loss_bbox_dn_3: 0.1519 (0.1519)  loss_giou_dn_3: 0.3656 (0.3656)  loss_fgl_dn_3: 1.2121 (1.2121)  loss_ddf_dn_3: 0.0154 (0.0154)  loss_mal_dn_4: 0.6992 (0.6992)  loss_bbox_dn_4: 0.1543 (0.1543)  loss_giou_dn_4: 0.3611 (0.3611)  loss_fgl_dn_4: 1.2120 (1.2120)  loss_ddf_dn_4: 0.0019 (0.0019)  loss_mal_dn_5: 0.7080 (0.7080)  loss_bbox_dn_5: 0.1567 (0.1567)  loss_giou_dn_5: 0.3613 (0.3613)  loss_fgl_dn_5: 1.2125 (1.2125)  loss_mal_dn_pre: 0.8320 (0.8320)  loss_bbox_dn_pre: 0.2903 (0.2903)  loss_giou_dn_pre: 0.5465 (0.5465)  time: 1.8279  data: 0.6255  max mem: 13413\nEpoch: [19]  [100/251]  eta: 0:03:06  lr: 0.000003  loss: 39.2028 (41.1711)  loss_mal: 0.7080 (0.8502)  loss_bbox: 0.1409 (0.2006)  loss_giou: 0.3454 (0.4090)  loss_fgl: 1.2738 (1.2771)  loss_mal_aux_0: 1.2051 (1.2736)  loss_bbox_aux_0: 0.1895 (0.2281)  loss_giou_aux_0: 0.4230 (0.4638)  loss_fgl_aux_0: 1.3154 (1.2981)  loss_ddf_aux_0: 0.0813 (0.0911)  loss_mal_aux_1: 0.9297 (1.0371)  loss_bbox_aux_1: 0.1732 (0.2132)  loss_giou_aux_1: 0.3795 (0.4376)  loss_fgl_aux_1: 1.2902 (1.2853)  loss_ddf_aux_1: 0.0410 (0.0437)  loss_mal_aux_2: 0.7817 (0.9094)  loss_bbox_aux_2: 0.1475 (0.2024)  loss_giou_aux_2: 0.3500 (0.4150)  loss_fgl_aux_2: 1.2790 (1.2768)  loss_ddf_aux_2: 0.0078 (0.0088)  loss_mal_aux_3: 0.7139 (0.8562)  loss_bbox_aux_3: 0.1439 (0.2011)  loss_giou_aux_3: 0.3493 (0.4116)  loss_fgl_aux_3: 1.2734 (1.2762)  loss_ddf_aux_3: 0.0016 (0.0021)  loss_mal_aux_4: 0.7134 (0.8430)  loss_bbox_aux_4: 0.1418 (0.2006)  loss_giou_aux_4: 0.3467 (0.4097)  loss_fgl_aux_4: 1.2735 (1.2766)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.1914 (1.2681)  loss_bbox_pre: 0.1878 (0.2261)  loss_giou_pre: 0.4258 (0.4622)  loss_mal_enc_0: 1.3574 (1.4424)  loss_bbox_enc_0: 0.2745 (0.3113)  loss_giou_enc_0: 0.5717 (0.6181)  loss_mal_dn_0: 0.8330 (0.8334)  loss_bbox_dn_0: 0.2964 (0.3580)  loss_giou_dn_0: 0.6204 (0.6564)  loss_fgl_dn_0: 1.2955 (1.2689)  loss_ddf_dn_0: 0.8659 (0.8124)  loss_mal_dn_1: 0.7754 (0.7736)  loss_bbox_dn_1: 0.2126 (0.2784)  loss_giou_dn_1: 0.4584 (0.5144)  loss_fgl_dn_1: 1.2629 (1.2510)  loss_ddf_dn_1: 0.3344 (0.3276)  loss_mal_dn_2: 0.7046 (0.7160)  loss_bbox_dn_2: 0.1866 (0.2489)  loss_giou_dn_2: 0.3937 (0.4611)  loss_fgl_dn_2: 1.2234 (1.2357)  loss_ddf_dn_2: 0.0819 (0.0776)  loss_mal_dn_3: 0.6592 (0.6855)  loss_bbox_dn_3: 0.1755 (0.2383)  loss_giou_dn_3: 0.3854 (0.4434)  loss_fgl_dn_3: 1.2214 (1.2360)  loss_ddf_dn_3: 0.0184 (0.0179)  loss_mal_dn_4: 0.6372 (0.6754)  loss_bbox_dn_4: 0.1664 (0.2343)  loss_giou_dn_4: 0.3815 (0.4356)  loss_fgl_dn_4: 1.2189 (1.2366)  loss_ddf_dn_4: 0.0022 (0.0023)  loss_mal_dn_5: 0.6274 (0.6743)  loss_bbox_dn_5: 0.1639 (0.2330)  loss_giou_dn_5: 0.3768 (0.4326)  loss_fgl_dn_5: 1.2179 (1.2374)  loss_mal_dn_pre: 0.8311 (0.8312)  loss_bbox_dn_pre: 0.3040 (0.3622)  loss_giou_dn_pre: 0.6146 (0.6553)  time: 1.2520  data: 0.0106  max mem: 13413\nEpoch: [19]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 41.4525 (41.6448)  loss_mal: 0.8760 (0.8879)  loss_bbox: 0.1790 (0.2101)  loss_giou: 0.4507 (0.4160)  loss_fgl: 1.2773 (1.2809)  loss_mal_aux_0: 1.1650 (1.2770)  loss_bbox_aux_0: 0.2024 (0.2340)  loss_giou_aux_0: 0.4595 (0.4692)  loss_fgl_aux_0: 1.3116 (1.2995)  loss_ddf_aux_0: 0.0848 (0.0906)  loss_mal_aux_1: 1.0322 (1.0534)  loss_bbox_aux_1: 0.1995 (0.2211)  loss_giou_aux_1: 0.4437 (0.4421)  loss_fgl_aux_1: 1.2950 (1.2879)  loss_ddf_aux_1: 0.0420 (0.0435)  loss_mal_aux_2: 0.9224 (0.9265)  loss_bbox_aux_2: 0.1804 (0.2117)  loss_giou_aux_2: 0.4341 (0.4216)  loss_fgl_aux_2: 1.2896 (1.2800)  loss_ddf_aux_2: 0.0091 (0.0088)  loss_mal_aux_3: 0.8521 (0.8920)  loss_bbox_aux_3: 0.1791 (0.2106)  loss_giou_aux_3: 0.4369 (0.4180)  loss_fgl_aux_3: 1.2788 (1.2800)  loss_ddf_aux_3: 0.0019 (0.0021)  loss_mal_aux_4: 0.8823 (0.8803)  loss_bbox_aux_4: 0.1793 (0.2102)  loss_giou_aux_4: 0.4472 (0.4165)  loss_fgl_aux_4: 1.2765 (1.2805)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.1680 (1.2710)  loss_bbox_pre: 0.1973 (0.2325)  loss_giou_pre: 0.4549 (0.4679)  loss_mal_enc_0: 1.3906 (1.4713)  loss_bbox_enc_0: 0.2575 (0.3198)  loss_giou_enc_0: 0.5997 (0.6235)  loss_mal_dn_0: 0.8486 (0.8375)  loss_bbox_dn_0: 0.2989 (0.3683)  loss_giou_dn_0: 0.6332 (0.6667)  loss_fgl_dn_0: 1.2769 (1.2626)  loss_ddf_dn_0: 0.8195 (0.8183)  loss_mal_dn_1: 0.7827 (0.7780)  loss_bbox_dn_1: 0.2434 (0.2891)  loss_giou_dn_1: 0.5302 (0.5236)  loss_fgl_dn_1: 1.2613 (1.2455)  loss_ddf_dn_1: 0.3019 (0.3250)  loss_mal_dn_2: 0.7246 (0.7178)  loss_bbox_dn_2: 0.2261 (0.2603)  loss_giou_dn_2: 0.4921 (0.4733)  loss_fgl_dn_2: 1.2357 (1.2325)  loss_ddf_dn_2: 0.0716 (0.0771)  loss_mal_dn_3: 0.6860 (0.6885)  loss_bbox_dn_3: 0.2133 (0.2495)  loss_giou_dn_3: 0.4754 (0.4562)  loss_fgl_dn_3: 1.2384 (1.2334)  loss_ddf_dn_3: 0.0158 (0.0178)  loss_mal_dn_4: 0.6787 (0.6787)  loss_bbox_dn_4: 0.2076 (0.2453)  loss_giou_dn_4: 0.4641 (0.4490)  loss_fgl_dn_4: 1.2387 (1.2344)  loss_ddf_dn_4: 0.0020 (0.0023)  loss_mal_dn_5: 0.6812 (0.6778)  loss_bbox_dn_5: 0.2078 (0.2440)  loss_giou_dn_5: 0.4632 (0.4461)  loss_fgl_dn_5: 1.2408 (1.2353)  loss_mal_dn_pre: 0.8467 (0.8354)  loss_bbox_dn_pre: 0.3031 (0.3717)  loss_giou_dn_pre: 0.6344 (0.6657)  time: 1.1644  data: 0.0116  max mem: 13413\nEpoch: [19]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 40.8438 (41.5989)  loss_mal: 0.9067 (0.8916)  loss_bbox: 0.1544 (0.2053)  loss_giou: 0.3773 (0.4125)  loss_fgl: 1.2628 (1.2828)  loss_mal_aux_0: 1.1670 (1.2790)  loss_bbox_aux_0: 0.1911 (0.2319)  loss_giou_aux_0: 0.4308 (0.4679)  loss_fgl_aux_0: 1.3062 (1.3023)  loss_ddf_aux_0: 0.0973 (0.0918)  loss_mal_aux_1: 1.0498 (1.0565)  loss_bbox_aux_1: 0.1710 (0.2175)  loss_giou_aux_1: 0.4078 (0.4391)  loss_fgl_aux_1: 1.2940 (1.2909)  loss_ddf_aux_1: 0.0456 (0.0440)  loss_mal_aux_2: 0.9028 (0.9331)  loss_bbox_aux_2: 0.1513 (0.2072)  loss_giou_aux_2: 0.3757 (0.4185)  loss_fgl_aux_2: 1.2630 (1.2821)  loss_ddf_aux_2: 0.0086 (0.0087)  loss_mal_aux_3: 0.8184 (0.8952)  loss_bbox_aux_3: 0.1565 (0.2058)  loss_giou_aux_3: 0.3803 (0.4147)  loss_fgl_aux_3: 1.2624 (1.2820)  loss_ddf_aux_3: 0.0020 (0.0021)  loss_mal_aux_4: 0.9058 (0.8861)  loss_bbox_aux_4: 0.1538 (0.2054)  loss_giou_aux_4: 0.3790 (0.4131)  loss_fgl_aux_4: 1.2631 (1.2824)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.1592 (1.2753)  loss_bbox_pre: 0.1880 (0.2304)  loss_giou_pre: 0.4306 (0.4666)  loss_mal_enc_0: 1.3438 (1.4605)  loss_bbox_enc_0: 0.2894 (0.3187)  loss_giou_enc_0: 0.6056 (0.6229)  loss_mal_dn_0: 0.8066 (0.8345)  loss_bbox_dn_0: 0.3642 (0.3679)  loss_giou_dn_0: 0.6619 (0.6693)  loss_fgl_dn_0: 1.2680 (1.2613)  loss_ddf_dn_0: 0.8539 (0.8185)  loss_mal_dn_1: 0.7598 (0.7769)  loss_bbox_dn_1: 0.2293 (0.2863)  loss_giou_dn_1: 0.4602 (0.5241)  loss_fgl_dn_1: 1.2558 (1.2455)  loss_ddf_dn_1: 0.3208 (0.3233)  loss_mal_dn_2: 0.6890 (0.7164)  loss_bbox_dn_2: 0.1898 (0.2566)  loss_giou_dn_2: 0.4256 (0.4737)  loss_fgl_dn_2: 1.2339 (1.2322)  loss_ddf_dn_2: 0.0780 (0.0770)  loss_mal_dn_3: 0.6636 (0.6874)  loss_bbox_dn_3: 0.1791 (0.2455)  loss_giou_dn_3: 0.4118 (0.4560)  loss_fgl_dn_3: 1.2267 (1.2329)  loss_ddf_dn_3: 0.0174 (0.0177)  loss_mal_dn_4: 0.6733 (0.6779)  loss_bbox_dn_4: 0.1775 (0.2413)  loss_giou_dn_4: 0.4034 (0.4486)  loss_fgl_dn_4: 1.2215 (1.2336)  loss_ddf_dn_4: 0.0021 (0.0023)  loss_mal_dn_5: 0.6523 (0.6769)  loss_bbox_dn_5: 0.1747 (0.2398)  loss_giou_dn_5: 0.3977 (0.4456)  loss_fgl_dn_5: 1.2194 (1.2344)  loss_mal_dn_pre: 0.8066 (0.8324)  loss_bbox_dn_pre: 0.3758 (0.3710)  loss_giou_dn_pre: 0.6642 (0.6679)  time: 1.2596  data: 0.0114  max mem: 13413\nEpoch: [19] Total time: 0:05:07 (1.2267 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7946  data: 0.4864  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3551  data: 0.0661  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3072  data: 0.0218  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2936  data: 0.0194  max mem: 13413\nTest: Total time: 0:00:08 (0.3203 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.473\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.288\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.265\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.374\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.519\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.640\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.875\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.725\nbest_stat: {'epoch': 17, 'coco_eval_bbox': 0.29462486930314535}\nEpoch: [20]  [  0/251]  eta: 0:07:15  lr: 0.000003  loss: 41.2348 (41.2348)  loss_mal: 0.6270 (0.6270)  loss_bbox: 0.2227 (0.2227)  loss_giou: 0.4920 (0.4920)  loss_fgl: 1.4041 (1.4041)  loss_mal_aux_0: 1.2275 (1.2275)  loss_bbox_aux_0: 0.2309 (0.2309)  loss_giou_aux_0: 0.4960 (0.4960)  loss_fgl_aux_0: 1.3627 (1.3627)  loss_ddf_aux_0: 0.0910 (0.0910)  loss_mal_aux_1: 0.9336 (0.9336)  loss_bbox_aux_1: 0.2314 (0.2314)  loss_giou_aux_1: 0.4959 (0.4959)  loss_fgl_aux_1: 1.3759 (1.3759)  loss_ddf_aux_1: 0.0403 (0.0403)  loss_mal_aux_2: 0.7593 (0.7593)  loss_bbox_aux_2: 0.2223 (0.2223)  loss_giou_aux_2: 0.4878 (0.4878)  loss_fgl_aux_2: 1.3926 (1.3926)  loss_ddf_aux_2: 0.0065 (0.0065)  loss_mal_aux_3: 0.6421 (0.6421)  loss_bbox_aux_3: 0.2219 (0.2219)  loss_giou_aux_3: 0.4907 (0.4907)  loss_fgl_aux_3: 1.3992 (1.3992)  loss_ddf_aux_3: 0.0014 (0.0014)  loss_mal_aux_4: 0.6230 (0.6230)  loss_bbox_aux_4: 0.2236 (0.2236)  loss_giou_aux_4: 0.4926 (0.4926)  loss_fgl_aux_4: 1.4018 (1.4018)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.2266 (1.2266)  loss_bbox_pre: 0.2265 (0.2265)  loss_giou_pre: 0.4935 (0.4935)  loss_mal_enc_0: 1.1973 (1.1973)  loss_bbox_enc_0: 0.3897 (0.3897)  loss_giou_enc_0: 0.6992 (0.6992)  loss_mal_dn_0: 0.8496 (0.8496)  loss_bbox_dn_0: 0.3914 (0.3914)  loss_giou_dn_0: 0.6332 (0.6332)  loss_fgl_dn_0: 1.2931 (1.2931)  loss_ddf_dn_0: 0.7340 (0.7340)  loss_mal_dn_1: 0.7671 (0.7671)  loss_bbox_dn_1: 0.2785 (0.2785)  loss_giou_dn_1: 0.4932 (0.4932)  loss_fgl_dn_1: 1.2791 (1.2791)  loss_ddf_dn_1: 0.2838 (0.2838)  loss_mal_dn_2: 0.6934 (0.6934)  loss_bbox_dn_2: 0.2471 (0.2471)  loss_giou_dn_2: 0.4630 (0.4630)  loss_fgl_dn_2: 1.2776 (1.2776)  loss_ddf_dn_2: 0.0646 (0.0646)  loss_mal_dn_3: 0.6182 (0.6182)  loss_bbox_dn_3: 0.2355 (0.2355)  loss_giou_dn_3: 0.4510 (0.4510)  loss_fgl_dn_3: 1.2841 (1.2841)  loss_ddf_dn_3: 0.0147 (0.0147)  loss_mal_dn_4: 0.6133 (0.6133)  loss_bbox_dn_4: 0.2378 (0.2378)  loss_giou_dn_4: 0.4508 (0.4508)  loss_fgl_dn_4: 1.2865 (1.2865)  loss_ddf_dn_4: 0.0019 (0.0019)  loss_mal_dn_5: 0.6060 (0.6060)  loss_bbox_dn_5: 0.2372 (0.2372)  loss_giou_dn_5: 0.4481 (0.4481)  loss_fgl_dn_5: 1.2879 (1.2879)  loss_mal_dn_pre: 0.8452 (0.8452)  loss_bbox_dn_pre: 0.4027 (0.4027)  loss_giou_dn_pre: 0.6371 (0.6371)  time: 1.7338  data: 0.6014  max mem: 13413\nEpoch: [20]  [100/251]  eta: 0:03:09  lr: 0.000003  loss: 40.8738 (40.3621)  loss_mal: 0.8188 (0.8378)  loss_bbox: 0.1556 (0.1715)  loss_giou: 0.3608 (0.3654)  loss_fgl: 1.2712 (1.2786)  loss_mal_aux_0: 1.2695 (1.2906)  loss_bbox_aux_0: 0.1868 (0.2042)  loss_giou_aux_0: 0.4223 (0.4282)  loss_fgl_aux_0: 1.3003 (1.3065)  loss_ddf_aux_0: 0.0827 (0.0978)  loss_mal_aux_1: 1.0400 (1.0382)  loss_bbox_aux_1: 0.1706 (0.1863)  loss_giou_aux_1: 0.3971 (0.3933)  loss_fgl_aux_1: 1.2910 (1.2912)  loss_ddf_aux_1: 0.0355 (0.0448)  loss_mal_aux_2: 0.8667 (0.9027)  loss_bbox_aux_2: 0.1574 (0.1752)  loss_giou_aux_2: 0.3692 (0.3720)  loss_fgl_aux_2: 1.2817 (1.2791)  loss_ddf_aux_2: 0.0069 (0.0085)  loss_mal_aux_3: 0.8501 (0.8471)  loss_bbox_aux_3: 0.1554 (0.1727)  loss_giou_aux_3: 0.3622 (0.3679)  loss_fgl_aux_3: 1.2760 (1.2787)  loss_ddf_aux_3: 0.0017 (0.0020)  loss_mal_aux_4: 0.8345 (0.8348)  loss_bbox_aux_4: 0.1560 (0.1720)  loss_giou_aux_4: 0.3618 (0.3661)  loss_fgl_aux_4: 1.2738 (1.2788)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.2627 (1.2878)  loss_bbox_pre: 0.1869 (0.2026)  loss_giou_pre: 0.4153 (0.4269)  loss_mal_enc_0: 1.4092 (1.4195)  loss_bbox_enc_0: 0.2578 (0.2972)  loss_giou_enc_0: 0.5599 (0.6054)  loss_mal_dn_0: 0.8438 (0.8290)  loss_bbox_dn_0: 0.3237 (0.3427)  loss_giou_dn_0: 0.6763 (0.6499)  loss_fgl_dn_0: 1.2745 (1.2693)  loss_ddf_dn_0: 0.9730 (0.8559)  loss_mal_dn_1: 0.7769 (0.7695)  loss_bbox_dn_1: 0.2426 (0.2564)  loss_giou_dn_1: 0.5026 (0.4918)  loss_fgl_dn_1: 1.2392 (1.2489)  loss_ddf_dn_1: 0.3622 (0.3275)  loss_mal_dn_2: 0.7212 (0.7062)  loss_bbox_dn_2: 0.2157 (0.2268)  loss_giou_dn_2: 0.4392 (0.4386)  loss_fgl_dn_2: 1.2205 (1.2331)  loss_ddf_dn_2: 0.0875 (0.0780)  loss_mal_dn_3: 0.7036 (0.6725)  loss_bbox_dn_3: 0.2010 (0.2146)  loss_giou_dn_3: 0.4157 (0.4186)  loss_fgl_dn_3: 1.2175 (1.2335)  loss_ddf_dn_3: 0.0200 (0.0173)  loss_mal_dn_4: 0.6670 (0.6598)  loss_bbox_dn_4: 0.1976 (0.2104)  loss_giou_dn_4: 0.4155 (0.4109)  loss_fgl_dn_4: 1.2172 (1.2338)  loss_ddf_dn_4: 0.0025 (0.0022)  loss_mal_dn_5: 0.6646 (0.6586)  loss_bbox_dn_5: 0.1980 (0.2088)  loss_giou_dn_5: 0.4163 (0.4080)  loss_fgl_dn_5: 1.2169 (1.2342)  loss_mal_dn_pre: 0.8418 (0.8270)  loss_bbox_dn_pre: 0.3271 (0.3465)  loss_giou_dn_pre: 0.6721 (0.6498)  time: 1.2312  data: 0.0112  max mem: 13413\nEpoch: [20]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 41.2209 (40.6543)  loss_mal: 0.7549 (0.8502)  loss_bbox: 0.1313 (0.1907)  loss_giou: 0.3405 (0.3756)  loss_fgl: 1.2618 (1.2736)  loss_mal_aux_0: 1.2432 (1.2767)  loss_bbox_aux_0: 0.1945 (0.2234)  loss_giou_aux_0: 0.4243 (0.4416)  loss_fgl_aux_0: 1.3111 (1.3006)  loss_ddf_aux_0: 0.1075 (0.1012)  loss_mal_aux_1: 1.0615 (1.0376)  loss_bbox_aux_1: 0.1769 (0.2042)  loss_giou_aux_1: 0.3868 (0.4039)  loss_fgl_aux_1: 1.2905 (1.2847)  loss_ddf_aux_1: 0.0464 (0.0464)  loss_mal_aux_2: 0.8076 (0.9037)  loss_bbox_aux_2: 0.1363 (0.1935)  loss_giou_aux_2: 0.3452 (0.3819)  loss_fgl_aux_2: 1.2628 (1.2736)  loss_ddf_aux_2: 0.0103 (0.0089)  loss_mal_aux_3: 0.7983 (0.8593)  loss_bbox_aux_3: 0.1335 (0.1915)  loss_giou_aux_3: 0.3419 (0.3777)  loss_fgl_aux_3: 1.2580 (1.2732)  loss_ddf_aux_3: 0.0023 (0.0021)  loss_mal_aux_4: 0.7603 (0.8505)  loss_bbox_aux_4: 0.1317 (0.1909)  loss_giou_aux_4: 0.3413 (0.3760)  loss_fgl_aux_4: 1.2538 (1.2736)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.2373 (1.2705)  loss_bbox_pre: 0.1960 (0.2222)  loss_giou_pre: 0.4261 (0.4405)  loss_mal_enc_0: 1.3848 (1.4195)  loss_bbox_enc_0: 0.3230 (0.3206)  loss_giou_enc_0: 0.5927 (0.6185)  loss_mal_dn_0: 0.8267 (0.8279)  loss_bbox_dn_0: 0.3194 (0.3530)  loss_giou_dn_0: 0.6007 (0.6447)  loss_fgl_dn_0: 1.2928 (1.2718)  loss_ddf_dn_0: 1.0106 (0.8860)  loss_mal_dn_1: 0.7671 (0.7667)  loss_bbox_dn_1: 0.2682 (0.2663)  loss_giou_dn_1: 0.4563 (0.4868)  loss_fgl_dn_1: 1.2583 (1.2488)  loss_ddf_dn_1: 0.3743 (0.3332)  loss_mal_dn_2: 0.6987 (0.7003)  loss_bbox_dn_2: 0.2367 (0.2382)  loss_giou_dn_2: 0.3904 (0.4366)  loss_fgl_dn_2: 1.2270 (1.2310)  loss_ddf_dn_2: 0.0890 (0.0798)  loss_mal_dn_3: 0.6704 (0.6691)  loss_bbox_dn_3: 0.2217 (0.2263)  loss_giou_dn_3: 0.3696 (0.4175)  loss_fgl_dn_3: 1.2229 (1.2303)  loss_ddf_dn_3: 0.0196 (0.0178)  loss_mal_dn_4: 0.6533 (0.6570)  loss_bbox_dn_4: 0.2191 (0.2222)  loss_giou_dn_4: 0.3619 (0.4102)  loss_fgl_dn_4: 1.2222 (1.2304)  loss_ddf_dn_4: 0.0024 (0.0022)  loss_mal_dn_5: 0.6538 (0.6550)  loss_bbox_dn_5: 0.2146 (0.2207)  loss_giou_dn_5: 0.3594 (0.4073)  loss_fgl_dn_5: 1.2228 (1.2308)  loss_mal_dn_pre: 0.8252 (0.8259)  loss_bbox_dn_pre: 0.3257 (0.3569)  loss_giou_dn_pre: 0.5981 (0.6447)  time: 1.2357  data: 0.0117  max mem: 13413\nEpoch: [20]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 41.5803 (40.6226)  loss_mal: 0.7925 (0.8467)  loss_bbox: 0.1527 (0.1860)  loss_giou: 0.3950 (0.3763)  loss_fgl: 1.2868 (1.2742)  loss_mal_aux_0: 1.2227 (1.2820)  loss_bbox_aux_0: 0.1840 (0.2185)  loss_giou_aux_0: 0.4384 (0.4404)  loss_fgl_aux_0: 1.3143 (1.3008)  loss_ddf_aux_0: 0.1026 (0.1028)  loss_mal_aux_1: 1.0771 (1.0407)  loss_bbox_aux_1: 0.1802 (0.1994)  loss_giou_aux_1: 0.4240 (0.4033)  loss_fgl_aux_1: 1.2903 (1.2850)  loss_ddf_aux_1: 0.0488 (0.0468)  loss_mal_aux_2: 0.8584 (0.9026)  loss_bbox_aux_2: 0.1515 (0.1887)  loss_giou_aux_2: 0.4043 (0.3825)  loss_fgl_aux_2: 1.2802 (1.2740)  loss_ddf_aux_2: 0.0092 (0.0089)  loss_mal_aux_3: 0.8345 (0.8574)  loss_bbox_aux_3: 0.1492 (0.1868)  loss_giou_aux_3: 0.3989 (0.3784)  loss_fgl_aux_3: 1.2834 (1.2736)  loss_ddf_aux_3: 0.0020 (0.0021)  loss_mal_aux_4: 0.7871 (0.8467)  loss_bbox_aux_4: 0.1540 (0.1862)  loss_giou_aux_4: 0.3998 (0.3767)  loss_fgl_aux_4: 1.2831 (1.2740)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.2051 (1.2768)  loss_bbox_pre: 0.1835 (0.2175)  loss_giou_pre: 0.4342 (0.4395)  loss_mal_enc_0: 1.4277 (1.4223)  loss_bbox_enc_0: 0.2644 (0.3165)  loss_giou_enc_0: 0.6594 (0.6168)  loss_mal_dn_0: 0.8188 (0.8278)  loss_bbox_dn_0: 0.2762 (0.3486)  loss_giou_dn_0: 0.6617 (0.6439)  loss_fgl_dn_0: 1.2714 (1.2715)  loss_ddf_dn_0: 0.9493 (0.8862)  loss_mal_dn_1: 0.7783 (0.7693)  loss_bbox_dn_1: 0.1998 (0.2633)  loss_giou_dn_1: 0.5436 (0.4883)  loss_fgl_dn_1: 1.2446 (1.2477)  loss_ddf_dn_1: 0.3390 (0.3319)  loss_mal_dn_2: 0.7207 (0.7007)  loss_bbox_dn_2: 0.1851 (0.2359)  loss_giou_dn_2: 0.5048 (0.4392)  loss_fgl_dn_2: 1.2315 (1.2312)  loss_ddf_dn_2: 0.0801 (0.0797)  loss_mal_dn_3: 0.6875 (0.6692)  loss_bbox_dn_3: 0.1744 (0.2245)  loss_giou_dn_3: 0.4874 (0.4206)  loss_fgl_dn_3: 1.2357 (1.2308)  loss_ddf_dn_3: 0.0179 (0.0179)  loss_mal_dn_4: 0.6743 (0.6570)  loss_bbox_dn_4: 0.1735 (0.2206)  loss_giou_dn_4: 0.4791 (0.4137)  loss_fgl_dn_4: 1.2360 (1.2311)  loss_ddf_dn_4: 0.0022 (0.0022)  loss_mal_dn_5: 0.6704 (0.6550)  loss_bbox_dn_5: 0.1733 (0.2192)  loss_giou_dn_5: 0.4784 (0.4110)  loss_fgl_dn_5: 1.2368 (1.2317)  loss_mal_dn_pre: 0.8169 (0.8258)  loss_bbox_dn_pre: 0.2786 (0.3524)  loss_giou_dn_pre: 0.6602 (0.6435)  time: 1.2662  data: 0.0122  max mem: 13413\nEpoch: [20] Total time: 0:05:09 (1.2344 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8038  data: 0.4826  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3512  data: 0.0631  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3052  data: 0.0203  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2936  data: 0.0195  max mem: 13413\nTest: Total time: 0:00:07 (0.3191 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.271\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.459\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.263\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.275\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.403\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.529\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.635\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.613\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.628\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.871\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.727\nbest_stat: {'epoch': 17, 'coco_eval_bbox': 0.29462486930314535}\nEpoch: [21]  [  0/251]  eta: 0:06:25  lr: 0.000003  loss: 41.9512 (41.9512)  loss_mal: 0.9849 (0.9849)  loss_bbox: 0.1393 (0.1393)  loss_giou: 0.4060 (0.4060)  loss_fgl: 1.2962 (1.2962)  loss_mal_aux_0: 1.2656 (1.2656)  loss_bbox_aux_0: 0.1580 (0.1580)  loss_giou_aux_0: 0.5288 (0.5288)  loss_fgl_aux_0: 1.2933 (1.2933)  loss_ddf_aux_0: 0.1302 (0.1302)  loss_mal_aux_1: 0.9565 (0.9565)  loss_bbox_aux_1: 0.1518 (0.1518)  loss_giou_aux_1: 0.4707 (0.4707)  loss_fgl_aux_1: 1.2800 (1.2800)  loss_ddf_aux_1: 0.0591 (0.0591)  loss_mal_aux_2: 1.0176 (1.0176)  loss_bbox_aux_2: 0.1434 (0.1434)  loss_giou_aux_2: 0.4226 (0.4226)  loss_fgl_aux_2: 1.2920 (1.2920)  loss_ddf_aux_2: 0.0114 (0.0114)  loss_mal_aux_3: 0.9692 (0.9692)  loss_bbox_aux_3: 0.1416 (0.1416)  loss_giou_aux_3: 0.4118 (0.4118)  loss_fgl_aux_3: 1.2981 (1.2981)  loss_ddf_aux_3: 0.0022 (0.0022)  loss_mal_aux_4: 0.9062 (0.9062)  loss_bbox_aux_4: 0.1404 (0.1404)  loss_giou_aux_4: 0.4086 (0.4086)  loss_fgl_aux_4: 1.2984 (1.2984)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 1.2637 (1.2637)  loss_bbox_pre: 0.1566 (0.1566)  loss_giou_pre: 0.5273 (0.5273)  loss_mal_enc_0: 1.2852 (1.2852)  loss_bbox_enc_0: 0.2356 (0.2356)  loss_giou_enc_0: 0.7452 (0.7452)  loss_mal_dn_0: 0.9136 (0.9136)  loss_bbox_dn_0: 0.2025 (0.2025)  loss_giou_dn_0: 0.5632 (0.5632)  loss_fgl_dn_0: 1.3013 (1.3013)  loss_ddf_dn_0: 1.4080 (1.4080)  loss_mal_dn_1: 0.8311 (0.8311)  loss_bbox_dn_1: 0.1673 (0.1673)  loss_giou_dn_1: 0.4525 (0.4525)  loss_fgl_dn_1: 1.2833 (1.2833)  loss_ddf_dn_1: 0.4973 (0.4973)  loss_mal_dn_2: 0.8208 (0.8208)  loss_bbox_dn_2: 0.1553 (0.1553)  loss_giou_dn_2: 0.4273 (0.4273)  loss_fgl_dn_2: 1.2692 (1.2692)  loss_ddf_dn_2: 0.1134 (0.1134)  loss_mal_dn_3: 0.8252 (0.8252)  loss_bbox_dn_3: 0.1531 (0.1531)  loss_giou_dn_3: 0.4221 (0.4221)  loss_fgl_dn_3: 1.2772 (1.2772)  loss_ddf_dn_3: 0.0238 (0.0238)  loss_mal_dn_4: 0.7998 (0.7998)  loss_bbox_dn_4: 0.1543 (0.1543)  loss_giou_dn_4: 0.4210 (0.4210)  loss_fgl_dn_4: 1.2815 (1.2815)  loss_ddf_dn_4: 0.0029 (0.0029)  loss_mal_dn_5: 0.8433 (0.8433)  loss_bbox_dn_5: 0.1540 (0.1540)  loss_giou_dn_5: 0.4193 (0.4193)  loss_fgl_dn_5: 1.2787 (1.2787)  loss_mal_dn_pre: 0.9155 (0.9155)  loss_bbox_dn_pre: 0.2068 (0.2068)  loss_giou_dn_pre: 0.5688 (0.5688)  time: 1.5368  data: 0.5565  max mem: 13413\nEpoch: [21]  [100/251]  eta: 0:03:07  lr: 0.000003  loss: 37.9145 (39.7830)  loss_mal: 0.6934 (0.7719)  loss_bbox: 0.1457 (0.1863)  loss_giou: 0.3058 (0.3774)  loss_fgl: 1.2389 (1.2653)  loss_mal_aux_0: 1.1143 (1.2466)  loss_bbox_aux_0: 0.1803 (0.2147)  loss_giou_aux_0: 0.3504 (0.4363)  loss_fgl_aux_0: 1.2989 (1.2956)  loss_ddf_aux_0: 0.0972 (0.1009)  loss_mal_aux_1: 0.9014 (0.9788)  loss_bbox_aux_1: 0.1596 (0.1970)  loss_giou_aux_1: 0.3312 (0.3992)  loss_fgl_aux_1: 1.2758 (1.2773)  loss_ddf_aux_1: 0.0427 (0.0437)  loss_mal_aux_2: 0.7124 (0.8371)  loss_bbox_aux_2: 0.1511 (0.1879)  loss_giou_aux_2: 0.3082 (0.3828)  loss_fgl_aux_2: 1.2483 (1.2664)  loss_ddf_aux_2: 0.0077 (0.0083)  loss_mal_aux_3: 0.6597 (0.7893)  loss_bbox_aux_3: 0.1481 (0.1863)  loss_giou_aux_3: 0.3074 (0.3792)  loss_fgl_aux_3: 1.2422 (1.2658)  loss_ddf_aux_3: 0.0017 (0.0019)  loss_mal_aux_4: 0.6836 (0.7844)  loss_bbox_aux_4: 0.1458 (0.1861)  loss_giou_aux_4: 0.3067 (0.3780)  loss_fgl_aux_4: 1.2407 (1.2653)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.1104 (1.2428)  loss_bbox_pre: 0.1752 (0.2137)  loss_giou_pre: 0.3533 (0.4354)  loss_mal_enc_0: 1.2715 (1.3673)  loss_bbox_enc_0: 0.2595 (0.3074)  loss_giou_enc_0: 0.5344 (0.6017)  loss_mal_dn_0: 0.8184 (0.8250)  loss_bbox_dn_0: 0.2960 (0.3307)  loss_giou_dn_0: 0.5771 (0.6228)  loss_fgl_dn_0: 1.2919 (1.2740)  loss_ddf_dn_0: 0.8982 (0.9252)  loss_mal_dn_1: 0.7412 (0.7605)  loss_bbox_dn_1: 0.2070 (0.2471)  loss_giou_dn_1: 0.4313 (0.4707)  loss_fgl_dn_1: 1.2418 (1.2421)  loss_ddf_dn_1: 0.3238 (0.3282)  loss_mal_dn_2: 0.6655 (0.6845)  loss_bbox_dn_2: 0.1715 (0.2220)  loss_giou_dn_2: 0.3671 (0.4265)  loss_fgl_dn_2: 1.2067 (1.2230)  loss_ddf_dn_2: 0.0815 (0.0820)  loss_mal_dn_3: 0.6338 (0.6549)  loss_bbox_dn_3: 0.1576 (0.2115)  loss_giou_dn_3: 0.3465 (0.4095)  loss_fgl_dn_3: 1.1968 (1.2205)  loss_ddf_dn_3: 0.0167 (0.0185)  loss_mal_dn_4: 0.6226 (0.6438)  loss_bbox_dn_4: 0.1562 (0.2082)  loss_giou_dn_4: 0.3379 (0.4031)  loss_fgl_dn_4: 1.1924 (1.2195)  loss_ddf_dn_4: 0.0020 (0.0022)  loss_mal_dn_5: 0.6025 (0.6412)  loss_bbox_dn_5: 0.1576 (0.2071)  loss_giou_dn_5: 0.3337 (0.4008)  loss_fgl_dn_5: 1.1896 (1.2195)  loss_mal_dn_pre: 0.8145 (0.8232)  loss_bbox_dn_pre: 0.3035 (0.3334)  loss_giou_dn_pre: 0.5731 (0.6228)  time: 1.2030  data: 0.0115  max mem: 13413\nEpoch: [21]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 39.3615 (39.9171)  loss_mal: 0.7949 (0.8024)  loss_bbox: 0.1442 (0.1860)  loss_giou: 0.3531 (0.3748)  loss_fgl: 1.2505 (1.2618)  loss_mal_aux_0: 1.2432 (1.2472)  loss_bbox_aux_0: 0.1840 (0.2156)  loss_giou_aux_0: 0.4315 (0.4340)  loss_fgl_aux_0: 1.2935 (1.2965)  loss_ddf_aux_0: 0.1065 (0.1058)  loss_mal_aux_1: 1.0312 (0.9901)  loss_bbox_aux_1: 0.1542 (0.1972)  loss_giou_aux_1: 0.4062 (0.3968)  loss_fgl_aux_1: 1.2692 (1.2761)  loss_ddf_aux_1: 0.0446 (0.0451)  loss_mal_aux_2: 0.7969 (0.8537)  loss_bbox_aux_2: 0.1457 (0.1880)  loss_giou_aux_2: 0.3553 (0.3802)  loss_fgl_aux_2: 1.2545 (1.2634)  loss_ddf_aux_2: 0.0083 (0.0088)  loss_mal_aux_3: 0.7803 (0.8173)  loss_bbox_aux_3: 0.1439 (0.1865)  loss_giou_aux_3: 0.3467 (0.3768)  loss_fgl_aux_3: 1.2432 (1.2623)  loss_ddf_aux_3: 0.0018 (0.0020)  loss_mal_aux_4: 0.7905 (0.8093)  loss_bbox_aux_4: 0.1445 (0.1859)  loss_giou_aux_4: 0.3518 (0.3753)  loss_fgl_aux_4: 1.2460 (1.2618)  loss_ddf_aux_4: 0.0002 (0.0003)  loss_mal_pre: 1.2373 (1.2430)  loss_bbox_pre: 0.1827 (0.2149)  loss_giou_pre: 0.4370 (0.4338)  loss_mal_enc_0: 1.3564 (1.3822)  loss_bbox_enc_0: 0.2943 (0.3088)  loss_giou_enc_0: 0.5862 (0.5978)  loss_mal_dn_0: 0.8281 (0.8237)  loss_bbox_dn_0: 0.3156 (0.3366)  loss_giou_dn_0: 0.6058 (0.6248)  loss_fgl_dn_0: 1.2803 (1.2722)  loss_ddf_dn_0: 1.0119 (0.9348)  loss_mal_dn_1: 0.7798 (0.7638)  loss_bbox_dn_1: 0.2058 (0.2522)  loss_giou_dn_1: 0.4281 (0.4696)  loss_fgl_dn_1: 1.2482 (1.2391)  loss_ddf_dn_1: 0.3373 (0.3255)  loss_mal_dn_2: 0.6948 (0.6848)  loss_bbox_dn_2: 0.1749 (0.2274)  loss_giou_dn_2: 0.3770 (0.4256)  loss_fgl_dn_2: 1.2023 (1.2201)  loss_ddf_dn_2: 0.0825 (0.0803)  loss_mal_dn_3: 0.6567 (0.6555)  loss_bbox_dn_3: 0.1522 (0.2173)  loss_giou_dn_3: 0.3618 (0.4090)  loss_fgl_dn_3: 1.1970 (1.2178)  loss_ddf_dn_3: 0.0192 (0.0180)  loss_mal_dn_4: 0.6538 (0.6438)  loss_bbox_dn_4: 0.1518 (0.2139)  loss_giou_dn_4: 0.3557 (0.4028)  loss_fgl_dn_4: 1.1949 (1.2172)  loss_ddf_dn_4: 0.0023 (0.0022)  loss_mal_dn_5: 0.6465 (0.6407)  loss_bbox_dn_5: 0.1519 (0.2127)  loss_giou_dn_5: 0.3538 (0.4005)  loss_fgl_dn_5: 1.1946 (1.2175)  loss_mal_dn_pre: 0.8267 (0.8220)  loss_bbox_dn_pre: 0.3174 (0.3392)  loss_giou_dn_pre: 0.6109 (0.6248)  time: 1.2172  data: 0.0134  max mem: 13413\nEpoch: [21]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 40.1525 (40.0704)  loss_mal: 0.7529 (0.8042)  loss_bbox: 0.1429 (0.1887)  loss_giou: 0.3202 (0.3744)  loss_fgl: 1.2943 (1.2655)  loss_mal_aux_0: 1.3779 (1.2541)  loss_bbox_aux_0: 0.1770 (0.2177)  loss_giou_aux_0: 0.4052 (0.4333)  loss_fgl_aux_0: 1.3192 (1.2996)  loss_ddf_aux_0: 0.1140 (0.1075)  loss_mal_aux_1: 1.0371 (0.9984)  loss_bbox_aux_1: 0.1592 (0.1998)  loss_giou_aux_1: 0.3506 (0.3963)  loss_fgl_aux_1: 1.2934 (1.2790)  loss_ddf_aux_1: 0.0406 (0.0457)  loss_mal_aux_2: 0.8994 (0.8641)  loss_bbox_aux_2: 0.1506 (0.1904)  loss_giou_aux_2: 0.3320 (0.3793)  loss_fgl_aux_2: 1.2875 (1.2668)  loss_ddf_aux_2: 0.0073 (0.0087)  loss_mal_aux_3: 0.7827 (0.8202)  loss_bbox_aux_3: 0.1443 (0.1890)  loss_giou_aux_3: 0.3179 (0.3760)  loss_fgl_aux_3: 1.2850 (1.2656)  loss_ddf_aux_3: 0.0015 (0.0020)  loss_mal_aux_4: 0.7598 (0.8108)  loss_bbox_aux_4: 0.1432 (0.1887)  loss_giou_aux_4: 0.3172 (0.3748)  loss_fgl_aux_4: 1.2902 (1.2654)  loss_ddf_aux_4: 0.0002 (0.0003)  loss_mal_pre: 1.3672 (1.2502)  loss_bbox_pre: 0.1741 (0.2169)  loss_giou_pre: 0.4054 (0.4329)  loss_mal_enc_0: 1.4141 (1.3884)  loss_bbox_enc_0: 0.2829 (0.3128)  loss_giou_enc_0: 0.5361 (0.5971)  loss_mal_dn_0: 0.8325 (0.8245)  loss_bbox_dn_0: 0.3305 (0.3433)  loss_giou_dn_0: 0.6315 (0.6279)  loss_fgl_dn_0: 1.2828 (1.2734)  loss_ddf_dn_0: 0.9404 (0.9440)  loss_mal_dn_1: 0.8013 (0.7664)  loss_bbox_dn_1: 0.2386 (0.2566)  loss_giou_dn_1: 0.4488 (0.4720)  loss_fgl_dn_1: 1.2483 (1.2401)  loss_ddf_dn_1: 0.3241 (0.3268)  loss_mal_dn_2: 0.7051 (0.6873)  loss_bbox_dn_2: 0.2044 (0.2309)  loss_giou_dn_2: 0.3973 (0.4271)  loss_fgl_dn_2: 1.2295 (1.2210)  loss_ddf_dn_2: 0.0759 (0.0806)  loss_mal_dn_3: 0.6475 (0.6574)  loss_bbox_dn_3: 0.1885 (0.2202)  loss_giou_dn_3: 0.3726 (0.4097)  loss_fgl_dn_3: 1.2265 (1.2184)  loss_ddf_dn_3: 0.0164 (0.0181)  loss_mal_dn_4: 0.6255 (0.6456)  loss_bbox_dn_4: 0.1827 (0.2169)  loss_giou_dn_4: 0.3618 (0.4035)  loss_fgl_dn_4: 1.2220 (1.2180)  loss_ddf_dn_4: 0.0021 (0.0022)  loss_mal_dn_5: 0.6172 (0.6425)  loss_bbox_dn_5: 0.1798 (0.2158)  loss_giou_dn_5: 0.3603 (0.4013)  loss_fgl_dn_5: 1.2203 (1.2183)  loss_mal_dn_pre: 0.8311 (0.8228)  loss_bbox_dn_pre: 0.3439 (0.3456)  loss_giou_dn_pre: 0.6265 (0.6274)  time: 1.2454  data: 0.0120  max mem: 13413\nEpoch: [21] Total time: 0:05:07 (1.2249 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7766  data: 0.4557  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3505  data: 0.0609  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3345  data: 0.0204  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.3227  data: 0.0196  max mem: 13413\nTest: Total time: 0:00:08 (0.3412 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.287\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.456\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.312\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.255\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.309\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.407\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.535\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.629\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.617\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.862\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.714\nbest_stat: {'epoch': 17, 'coco_eval_bbox': 0.29462486930314535}\nEpoch: [22]  [  0/251]  eta: 0:05:54  lr: 0.000003  loss: 46.2588 (46.2588)  loss_mal: 0.8721 (0.8721)  loss_bbox: 0.5606 (0.5606)  loss_giou: 0.6314 (0.6314)  loss_fgl: 1.1241 (1.1241)  loss_mal_aux_0: 1.3779 (1.3779)  loss_bbox_aux_0: 0.5276 (0.5276)  loss_giou_aux_0: 0.5970 (0.5970)  loss_fgl_aux_0: 1.2030 (1.2030)  loss_ddf_aux_0: 0.0831 (0.0831)  loss_mal_aux_1: 1.0410 (1.0410)  loss_bbox_aux_1: 0.5562 (0.5562)  loss_giou_aux_1: 0.6355 (0.6355)  loss_fgl_aux_1: 1.1612 (1.1612)  loss_ddf_aux_1: 0.0350 (0.0350)  loss_mal_aux_2: 0.9761 (0.9761)  loss_bbox_aux_2: 0.5602 (0.5602)  loss_giou_aux_2: 0.6384 (0.6384)  loss_fgl_aux_2: 1.1313 (1.1313)  loss_ddf_aux_2: 0.0062 (0.0062)  loss_mal_aux_3: 0.8516 (0.8516)  loss_bbox_aux_3: 0.5588 (0.5588)  loss_giou_aux_3: 0.6302 (0.6302)  loss_fgl_aux_3: 1.1283 (1.1283)  loss_ddf_aux_3: 0.0015 (0.0015)  loss_mal_aux_4: 0.8818 (0.8818)  loss_bbox_aux_4: 0.5604 (0.5604)  loss_giou_aux_4: 0.6311 (0.6311)  loss_fgl_aux_4: 1.1257 (1.1257)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.3926 (1.3926)  loss_bbox_pre: 0.5181 (0.5181)  loss_giou_pre: 0.5948 (0.5948)  loss_mal_enc_0: 1.4521 (1.4521)  loss_bbox_enc_0: 0.5975 (0.5975)  loss_giou_enc_0: 0.7555 (0.7555)  loss_mal_dn_0: 0.7656 (0.7656)  loss_bbox_dn_0: 0.5922 (0.5922)  loss_giou_dn_0: 0.7321 (0.7321)  loss_fgl_dn_0: 1.1947 (1.1947)  loss_ddf_dn_0: 0.8186 (0.8186)  loss_mal_dn_1: 0.6470 (0.6470)  loss_bbox_dn_1: 0.5523 (0.5523)  loss_giou_dn_1: 0.6315 (0.6315)  loss_fgl_dn_1: 1.1493 (1.1493)  loss_ddf_dn_1: 0.2629 (0.2629)  loss_mal_dn_2: 0.5752 (0.5752)  loss_bbox_dn_2: 0.5417 (0.5417)  loss_giou_dn_2: 0.6301 (0.6301)  loss_fgl_dn_2: 1.1181 (1.1181)  loss_ddf_dn_2: 0.0614 (0.0614)  loss_mal_dn_3: 0.5532 (0.5532)  loss_bbox_dn_3: 0.5377 (0.5377)  loss_giou_dn_3: 0.6207 (0.6207)  loss_fgl_dn_3: 1.1226 (1.1226)  loss_ddf_dn_3: 0.0139 (0.0139)  loss_mal_dn_4: 0.5532 (0.5532)  loss_bbox_dn_4: 0.5324 (0.5324)  loss_giou_dn_4: 0.6134 (0.6134)  loss_fgl_dn_4: 1.1276 (1.1276)  loss_ddf_dn_4: 0.0017 (0.0017)  loss_mal_dn_5: 0.5532 (0.5532)  loss_bbox_dn_5: 0.5297 (0.5297)  loss_giou_dn_5: 0.6092 (0.6092)  loss_fgl_dn_5: 1.1302 (1.1302)  loss_mal_dn_pre: 0.7729 (0.7729)  loss_bbox_dn_pre: 0.5936 (0.5936)  loss_giou_dn_pre: 0.7231 (0.7231)  time: 1.4127  data: 0.4380  max mem: 13413\nEpoch: [22]  [100/251]  eta: 0:03:06  lr: 0.000003  loss: 37.0684 (39.2122)  loss_mal: 0.5850 (0.7848)  loss_bbox: 0.1146 (0.1746)  loss_giou: 0.2932 (0.3507)  loss_fgl: 1.2394 (1.2607)  loss_mal_aux_0: 1.1729 (1.2404)  loss_bbox_aux_0: 0.1607 (0.2090)  loss_giou_aux_0: 0.3900 (0.4225)  loss_fgl_aux_0: 1.2858 (1.2986)  loss_ddf_aux_0: 0.1130 (0.1116)  loss_mal_aux_1: 0.8311 (0.9767)  loss_bbox_aux_1: 0.1297 (0.1888)  loss_giou_aux_1: 0.3508 (0.3805)  loss_fgl_aux_1: 1.2604 (1.2760)  loss_ddf_aux_1: 0.0477 (0.0456)  loss_mal_aux_2: 0.7231 (0.8170)  loss_bbox_aux_2: 0.1158 (0.1785)  loss_giou_aux_2: 0.3260 (0.3590)  loss_fgl_aux_2: 1.2316 (1.2630)  loss_ddf_aux_2: 0.0076 (0.0085)  loss_mal_aux_3: 0.6484 (0.7838)  loss_bbox_aux_3: 0.1136 (0.1762)  loss_giou_aux_3: 0.3044 (0.3537)  loss_fgl_aux_3: 1.2396 (1.2615)  loss_ddf_aux_3: 0.0017 (0.0019)  loss_mal_aux_4: 0.6167 (0.7816)  loss_bbox_aux_4: 0.1140 (0.1750)  loss_giou_aux_4: 0.2927 (0.3514)  loss_fgl_aux_4: 1.2396 (1.2609)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.1719 (1.2419)  loss_bbox_pre: 0.1585 (0.2079)  loss_giou_pre: 0.3859 (0.4206)  loss_mal_enc_0: 1.2920 (1.3616)  loss_bbox_enc_0: 0.2288 (0.3013)  loss_giou_enc_0: 0.5288 (0.5839)  loss_mal_dn_0: 0.8125 (0.8216)  loss_bbox_dn_0: 0.2734 (0.3303)  loss_giou_dn_0: 0.5794 (0.6033)  loss_fgl_dn_0: 1.2859 (1.2833)  loss_ddf_dn_0: 0.9983 (0.9448)  loss_mal_dn_1: 0.7339 (0.7519)  loss_bbox_dn_1: 0.1716 (0.2392)  loss_giou_dn_1: 0.4265 (0.4413)  loss_fgl_dn_1: 1.2351 (1.2469)  loss_ddf_dn_1: 0.3472 (0.3134)  loss_mal_dn_2: 0.6558 (0.6678)  loss_bbox_dn_2: 0.1471 (0.2128)  loss_giou_dn_2: 0.3662 (0.3969)  loss_fgl_dn_2: 1.2126 (1.2266)  loss_ddf_dn_2: 0.0848 (0.0761)  loss_mal_dn_3: 0.6099 (0.6358)  loss_bbox_dn_3: 0.1391 (0.2012)  loss_giou_dn_3: 0.3509 (0.3785)  loss_fgl_dn_3: 1.2030 (1.2233)  loss_ddf_dn_3: 0.0178 (0.0165)  loss_mal_dn_4: 0.5981 (0.6273)  loss_bbox_dn_4: 0.1434 (0.1969)  loss_giou_dn_4: 0.3421 (0.3714)  loss_fgl_dn_4: 1.2026 (1.2225)  loss_ddf_dn_4: 0.0021 (0.0020)  loss_mal_dn_5: 0.5952 (0.6280)  loss_bbox_dn_5: 0.1439 (0.1955)  loss_giou_dn_5: 0.3407 (0.3690)  loss_fgl_dn_5: 1.2019 (1.2225)  loss_mal_dn_pre: 0.8125 (0.8200)  loss_bbox_dn_pre: 0.2739 (0.3330)  loss_giou_dn_pre: 0.5651 (0.6026)  time: 1.2917  data: 0.0111  max mem: 13413\nEpoch: [22]  [200/251]  eta: 0:01:03  lr: 0.000003  loss: 39.6434 (39.4467)  loss_mal: 0.7646 (0.8065)  loss_bbox: 0.1559 (0.1759)  loss_giou: 0.3336 (0.3526)  loss_fgl: 1.2663 (1.2615)  loss_mal_aux_0: 1.2178 (1.2350)  loss_bbox_aux_0: 0.1745 (0.2084)  loss_giou_aux_0: 0.3963 (0.4226)  loss_fgl_aux_0: 1.2913 (1.2991)  loss_ddf_aux_0: 0.1034 (0.1129)  loss_mal_aux_1: 0.9678 (0.9885)  loss_bbox_aux_1: 0.1500 (0.1891)  loss_giou_aux_1: 0.3412 (0.3810)  loss_fgl_aux_1: 1.2762 (1.2762)  loss_ddf_aux_1: 0.0428 (0.0459)  loss_mal_aux_2: 0.8604 (0.8504)  loss_bbox_aux_2: 0.1506 (0.1794)  loss_giou_aux_2: 0.3269 (0.3602)  loss_fgl_aux_2: 1.2592 (1.2639)  loss_ddf_aux_2: 0.0074 (0.0087)  loss_mal_aux_3: 0.8032 (0.8179)  loss_bbox_aux_3: 0.1573 (0.1772)  loss_giou_aux_3: 0.3314 (0.3552)  loss_fgl_aux_3: 1.2627 (1.2623)  loss_ddf_aux_3: 0.0016 (0.0020)  loss_mal_aux_4: 0.7900 (0.8076)  loss_bbox_aux_4: 0.1563 (0.1763)  loss_giou_aux_4: 0.3331 (0.3533)  loss_fgl_aux_4: 1.2637 (1.2617)  loss_ddf_aux_4: 0.0002 (0.0003)  loss_mal_pre: 1.2158 (1.2356)  loss_bbox_pre: 0.1755 (0.2079)  loss_giou_pre: 0.3954 (0.4215)  loss_mal_enc_0: 1.3965 (1.3785)  loss_bbox_enc_0: 0.2529 (0.2990)  loss_giou_enc_0: 0.5812 (0.5808)  loss_mal_dn_0: 0.8096 (0.8234)  loss_bbox_dn_0: 0.3306 (0.3271)  loss_giou_dn_0: 0.6111 (0.6066)  loss_fgl_dn_0: 1.2742 (1.2831)  loss_ddf_dn_0: 1.0324 (0.9915)  loss_mal_dn_1: 0.7246 (0.7576)  loss_bbox_dn_1: 0.2456 (0.2381)  loss_giou_dn_1: 0.4146 (0.4435)  loss_fgl_dn_1: 1.2365 (1.2433)  loss_ddf_dn_1: 0.3355 (0.3281)  loss_mal_dn_2: 0.6602 (0.6707)  loss_bbox_dn_2: 0.2247 (0.2131)  loss_giou_dn_2: 0.3721 (0.3998)  loss_fgl_dn_2: 1.2025 (1.2237)  loss_ddf_dn_2: 0.0874 (0.0807)  loss_mal_dn_3: 0.6328 (0.6386)  loss_bbox_dn_3: 0.2198 (0.2021)  loss_giou_dn_3: 0.3520 (0.3819)  loss_fgl_dn_3: 1.1977 (1.2209)  loss_ddf_dn_3: 0.0177 (0.0174)  loss_mal_dn_4: 0.6401 (0.6283)  loss_bbox_dn_4: 0.2156 (0.1982)  loss_giou_dn_4: 0.3428 (0.3755)  loss_fgl_dn_4: 1.1969 (1.2207)  loss_ddf_dn_4: 0.0020 (0.0021)  loss_mal_dn_5: 0.6240 (0.6275)  loss_bbox_dn_5: 0.2149 (0.1969)  loss_giou_dn_5: 0.3414 (0.3732)  loss_fgl_dn_5: 1.1987 (1.2211)  loss_mal_dn_pre: 0.8037 (0.8219)  loss_bbox_dn_pre: 0.3341 (0.3298)  loss_giou_dn_pre: 0.6035 (0.6054)  time: 1.2316  data: 0.0118  max mem: 13413\nEpoch: [22]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 37.6368 (39.5273)  loss_mal: 0.6572 (0.7977)  loss_bbox: 0.1408 (0.1796)  loss_giou: 0.3505 (0.3575)  loss_fgl: 1.2806 (1.2623)  loss_mal_aux_0: 1.2041 (1.2415)  loss_bbox_aux_0: 0.1617 (0.2113)  loss_giou_aux_0: 0.3858 (0.4255)  loss_fgl_aux_0: 1.2943 (1.2977)  loss_ddf_aux_0: 0.1065 (0.1128)  loss_mal_aux_1: 0.9644 (0.9949)  loss_bbox_aux_1: 0.1457 (0.1926)  loss_giou_aux_1: 0.3241 (0.3851)  loss_fgl_aux_1: 1.2859 (1.2751)  loss_ddf_aux_1: 0.0434 (0.0457)  loss_mal_aux_2: 0.7666 (0.8491)  loss_bbox_aux_2: 0.1344 (0.1831)  loss_giou_aux_2: 0.3353 (0.3651)  loss_fgl_aux_2: 1.2893 (1.2639)  loss_ddf_aux_2: 0.0078 (0.0087)  loss_mal_aux_3: 0.6782 (0.8096)  loss_bbox_aux_3: 0.1393 (0.1809)  loss_giou_aux_3: 0.3426 (0.3601)  loss_fgl_aux_3: 1.2846 (1.2626)  loss_ddf_aux_3: 0.0017 (0.0020)  loss_mal_aux_4: 0.6660 (0.7987)  loss_bbox_aux_4: 0.1410 (0.1800)  loss_giou_aux_4: 0.3486 (0.3582)  loss_fgl_aux_4: 1.2799 (1.2623)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.1924 (1.2414)  loss_bbox_pre: 0.1604 (0.2107)  loss_giou_pre: 0.3833 (0.4248)  loss_mal_enc_0: 1.3359 (1.3749)  loss_bbox_enc_0: 0.2645 (0.3025)  loss_giou_enc_0: 0.5680 (0.5845)  loss_mal_dn_0: 0.8130 (0.8227)  loss_bbox_dn_0: 0.2849 (0.3290)  loss_giou_dn_0: 0.5799 (0.6084)  loss_fgl_dn_0: 1.3023 (1.2833)  loss_ddf_dn_0: 0.9989 (1.0063)  loss_mal_dn_1: 0.7471 (0.7565)  loss_bbox_dn_1: 0.1816 (0.2386)  loss_giou_dn_1: 0.3878 (0.4446)  loss_fgl_dn_1: 1.2528 (1.2434)  loss_ddf_dn_1: 0.3312 (0.3325)  loss_mal_dn_2: 0.6523 (0.6706)  loss_bbox_dn_2: 0.1592 (0.2132)  loss_giou_dn_2: 0.3537 (0.4008)  loss_fgl_dn_2: 1.2281 (1.2239)  loss_ddf_dn_2: 0.0887 (0.0824)  loss_mal_dn_3: 0.6372 (0.6381)  loss_bbox_dn_3: 0.1484 (0.2023)  loss_giou_dn_3: 0.3508 (0.3832)  loss_fgl_dn_3: 1.2217 (1.2212)  loss_ddf_dn_3: 0.0202 (0.0177)  loss_mal_dn_4: 0.6260 (0.6280)  loss_bbox_dn_4: 0.1454 (0.1986)  loss_giou_dn_4: 0.3527 (0.3769)  loss_fgl_dn_4: 1.2188 (1.2210)  loss_ddf_dn_4: 0.0024 (0.0021)  loss_mal_dn_5: 0.6206 (0.6266)  loss_bbox_dn_5: 0.1442 (0.1972)  loss_giou_dn_5: 0.3529 (0.3746)  loss_fgl_dn_5: 1.2203 (1.2215)  loss_mal_dn_pre: 0.8120 (0.8212)  loss_bbox_dn_pre: 0.2789 (0.3315)  loss_giou_dn_pre: 0.5745 (0.6068)  time: 1.1578  data: 0.0114  max mem: 13413\nEpoch: [22] Total time: 0:05:09 (1.2326 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7712  data: 0.4608  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3518  data: 0.0634  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3064  data: 0.0215  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2941  data: 0.0201  max mem: 13413\nTest: Total time: 0:00:07 (0.3188 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.297\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.506\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.315\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.303\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.319\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.412\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.528\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.638\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.692\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.621\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.862\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.729\nbest_stat: {'epoch': 22, 'coco_eval_bbox': 0.2968194754239913}\nEpoch: [23]  [  0/251]  eta: 0:10:54  lr: 0.000003  loss: 38.2819 (38.2819)  loss_mal: 0.6724 (0.6724)  loss_bbox: 0.1528 (0.1528)  loss_giou: 0.2701 (0.2701)  loss_fgl: 1.2362 (1.2362)  loss_mal_aux_0: 1.2529 (1.2529)  loss_bbox_aux_0: 0.1440 (0.1440)  loss_giou_aux_0: 0.2915 (0.2915)  loss_fgl_aux_0: 1.2840 (1.2840)  loss_ddf_aux_0: 0.1421 (0.1421)  loss_mal_aux_1: 0.8394 (0.8394)  loss_bbox_aux_1: 0.1478 (0.1478)  loss_giou_aux_1: 0.2730 (0.2730)  loss_fgl_aux_1: 1.2418 (1.2418)  loss_ddf_aux_1: 0.0553 (0.0553)  loss_mal_aux_2: 0.7563 (0.7563)  loss_bbox_aux_2: 0.1367 (0.1367)  loss_giou_aux_2: 0.2588 (0.2588)  loss_fgl_aux_2: 1.2286 (1.2286)  loss_ddf_aux_2: 0.0103 (0.0103)  loss_mal_aux_3: 0.6792 (0.6792)  loss_bbox_aux_3: 0.1438 (0.1438)  loss_giou_aux_3: 0.2642 (0.2642)  loss_fgl_aux_3: 1.2327 (1.2327)  loss_ddf_aux_3: 0.0022 (0.0022)  loss_mal_aux_4: 0.6650 (0.6650)  loss_bbox_aux_4: 0.1493 (0.1493)  loss_giou_aux_4: 0.2667 (0.2667)  loss_fgl_aux_4: 1.2352 (1.2352)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 1.2510 (1.2510)  loss_bbox_pre: 0.1429 (0.1429)  loss_giou_pre: 0.2907 (0.2907)  loss_mal_enc_0: 1.4297 (1.4297)  loss_bbox_enc_0: 0.3881 (0.3881)  loss_giou_enc_0: 0.5737 (0.5737)  loss_mal_dn_0: 0.8169 (0.8169)  loss_bbox_dn_0: 0.4775 (0.4775)  loss_giou_dn_0: 0.6280 (0.6280)  loss_fgl_dn_0: 1.2636 (1.2636)  loss_ddf_dn_0: 1.3063 (1.3063)  loss_mal_dn_1: 0.7383 (0.7383)  loss_bbox_dn_1: 0.3143 (0.3143)  loss_giou_dn_1: 0.4204 (0.4204)  loss_fgl_dn_1: 1.2271 (1.2271)  loss_ddf_dn_1: 0.4573 (0.4573)  loss_mal_dn_2: 0.6875 (0.6875)  loss_bbox_dn_2: 0.2458 (0.2458)  loss_giou_dn_2: 0.3475 (0.3475)  loss_fgl_dn_2: 1.1838 (1.1838)  loss_ddf_dn_2: 0.1288 (0.1288)  loss_mal_dn_3: 0.6470 (0.6470)  loss_bbox_dn_3: 0.2150 (0.2150)  loss_giou_dn_3: 0.3203 (0.3203)  loss_fgl_dn_3: 1.1678 (1.1678)  loss_ddf_dn_3: 0.0292 (0.0292)  loss_mal_dn_4: 0.6328 (0.6328)  loss_bbox_dn_4: 0.2019 (0.2019)  loss_giou_dn_4: 0.3077 (0.3077)  loss_fgl_dn_4: 1.1627 (1.1627)  loss_ddf_dn_4: 0.0037 (0.0037)  loss_mal_dn_5: 0.6279 (0.6279)  loss_bbox_dn_5: 0.1990 (0.1990)  loss_giou_dn_5: 0.3046 (0.3046)  loss_fgl_dn_5: 1.1610 (1.1610)  loss_mal_dn_pre: 0.8140 (0.8140)  loss_bbox_dn_pre: 0.4955 (0.4955)  loss_giou_dn_pre: 0.6405 (0.6405)  time: 2.6076  data: 1.0647  max mem: 13413\nEpoch: [23]  [100/251]  eta: 0:03:03  lr: 0.000003  loss: 37.7610 (38.6153)  loss_mal: 0.6948 (0.7369)  loss_bbox: 0.1274 (0.1671)  loss_giou: 0.3214 (0.3447)  loss_fgl: 1.2539 (1.2658)  loss_mal_aux_0: 1.1826 (1.2003)  loss_bbox_aux_0: 0.1484 (0.1944)  loss_giou_aux_0: 0.3866 (0.4002)  loss_fgl_aux_0: 1.3024 (1.2997)  loss_ddf_aux_0: 0.0991 (0.1098)  loss_mal_aux_1: 0.9082 (0.8987)  loss_bbox_aux_1: 0.1362 (0.1759)  loss_giou_aux_1: 0.3492 (0.3629)  loss_fgl_aux_1: 1.2643 (1.2745)  loss_ddf_aux_1: 0.0392 (0.0429)  loss_mal_aux_2: 0.7622 (0.7908)  loss_bbox_aux_2: 0.1231 (0.1686)  loss_giou_aux_2: 0.3244 (0.3485)  loss_fgl_aux_2: 1.2542 (1.2649)  loss_ddf_aux_2: 0.0073 (0.0080)  loss_mal_aux_3: 0.7461 (0.7509)  loss_bbox_aux_3: 0.1230 (0.1673)  loss_giou_aux_3: 0.3221 (0.3457)  loss_fgl_aux_3: 1.2517 (1.2646)  loss_ddf_aux_3: 0.0015 (0.0018)  loss_mal_aux_4: 0.6992 (0.7329)  loss_bbox_aux_4: 0.1253 (0.1673)  loss_giou_aux_4: 0.3210 (0.3451)  loss_fgl_aux_4: 1.2515 (1.2653)  loss_ddf_aux_4: 0.0002 (0.0003)  loss_mal_pre: 1.1934 (1.1977)  loss_bbox_pre: 0.1454 (0.1940)  loss_giou_pre: 0.3812 (0.3994)  loss_mal_enc_0: 1.3711 (1.3397)  loss_bbox_enc_0: 0.2401 (0.2952)  loss_giou_enc_0: 0.5652 (0.5680)  loss_mal_dn_0: 0.8296 (0.8199)  loss_bbox_dn_0: 0.3032 (0.3201)  loss_giou_dn_0: 0.5422 (0.5830)  loss_fgl_dn_0: 1.2956 (1.2918)  loss_ddf_dn_0: 0.9517 (1.0375)  loss_mal_dn_1: 0.7427 (0.7413)  loss_bbox_dn_1: 0.1795 (0.2288)  loss_giou_dn_1: 0.3922 (0.4210)  loss_fgl_dn_1: 1.2370 (1.2448)  loss_ddf_dn_1: 0.2910 (0.3298)  loss_mal_dn_2: 0.6470 (0.6616)  loss_bbox_dn_2: 0.1543 (0.2054)  loss_giou_dn_2: 0.3678 (0.3798)  loss_fgl_dn_2: 1.2115 (1.2273)  loss_ddf_dn_2: 0.0702 (0.0828)  loss_mal_dn_3: 0.6157 (0.6293)  loss_bbox_dn_3: 0.1396 (0.1960)  loss_giou_dn_3: 0.3555 (0.3646)  loss_fgl_dn_3: 1.2035 (1.2248)  loss_ddf_dn_3: 0.0144 (0.0173)  loss_mal_dn_4: 0.5928 (0.6197)  loss_bbox_dn_4: 0.1392 (0.1932)  loss_giou_dn_4: 0.3528 (0.3599)  loss_fgl_dn_4: 1.2001 (1.2246)  loss_ddf_dn_4: 0.0018 (0.0021)  loss_mal_dn_5: 0.6064 (0.6177)  loss_bbox_dn_5: 0.1389 (0.1921)  loss_giou_dn_5: 0.3503 (0.3581)  loss_fgl_dn_5: 1.1995 (1.2251)  loss_mal_dn_pre: 0.8286 (0.8186)  loss_bbox_dn_pre: 0.3011 (0.3242)  loss_giou_dn_pre: 0.5482 (0.5832)  time: 1.2380  data: 0.0112  max mem: 13413\nEpoch: [23]  [200/251]  eta: 0:01:01  lr: 0.000003  loss: 36.6339 (38.9793)  loss_mal: 0.6118 (0.7745)  loss_bbox: 0.1114 (0.1676)  loss_giou: 0.2787 (0.3454)  loss_fgl: 1.2290 (1.2654)  loss_mal_aux_0: 1.1670 (1.1948)  loss_bbox_aux_0: 0.1536 (0.1966)  loss_giou_aux_0: 0.3579 (0.4060)  loss_fgl_aux_0: 1.2989 (1.3024)  loss_ddf_aux_0: 0.1248 (0.1195)  loss_mal_aux_1: 0.8926 (0.9314)  loss_bbox_aux_1: 0.1146 (0.1770)  loss_giou_aux_1: 0.2888 (0.3655)  loss_fgl_aux_1: 1.2516 (1.2763)  loss_ddf_aux_1: 0.0477 (0.0470)  loss_mal_aux_2: 0.6870 (0.8296)  loss_bbox_aux_2: 0.1127 (0.1694)  loss_giou_aux_2: 0.2755 (0.3498)  loss_fgl_aux_2: 1.2343 (1.2662)  loss_ddf_aux_2: 0.0073 (0.0088)  loss_mal_aux_3: 0.6514 (0.7864)  loss_bbox_aux_3: 0.1124 (0.1679)  loss_giou_aux_3: 0.2799 (0.3466)  loss_fgl_aux_3: 1.2272 (1.2652)  loss_ddf_aux_3: 0.0015 (0.0020)  loss_mal_aux_4: 0.6172 (0.7680)  loss_bbox_aux_4: 0.1117 (0.1677)  loss_giou_aux_4: 0.2798 (0.3458)  loss_fgl_aux_4: 1.2275 (1.2651)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.1719 (1.1933)  loss_bbox_pre: 0.1533 (0.1960)  loss_giou_pre: 0.3569 (0.4051)  loss_mal_enc_0: 1.3301 (1.3460)  loss_bbox_enc_0: 0.2557 (0.2985)  loss_giou_enc_0: 0.5278 (0.5790)  loss_mal_dn_0: 0.8164 (0.8230)  loss_bbox_dn_0: 0.3017 (0.3222)  loss_giou_dn_0: 0.5654 (0.5975)  loss_fgl_dn_0: 1.3000 (1.2877)  loss_ddf_dn_0: 1.0304 (1.0646)  loss_mal_dn_1: 0.7471 (0.7470)  loss_bbox_dn_1: 0.1824 (0.2300)  loss_giou_dn_1: 0.3866 (0.4312)  loss_fgl_dn_1: 1.2291 (1.2412)  loss_ddf_dn_1: 0.3407 (0.3360)  loss_mal_dn_2: 0.6348 (0.6693)  loss_bbox_dn_2: 0.1495 (0.2063)  loss_giou_dn_2: 0.3214 (0.3894)  loss_fgl_dn_2: 1.1944 (1.2224)  loss_ddf_dn_2: 0.0826 (0.0847)  loss_mal_dn_3: 0.6021 (0.6377)  loss_bbox_dn_3: 0.1365 (0.1967)  loss_giou_dn_3: 0.3038 (0.3731)  loss_fgl_dn_3: 1.1853 (1.2190)  loss_ddf_dn_3: 0.0171 (0.0177)  loss_mal_dn_4: 0.5928 (0.6274)  loss_bbox_dn_4: 0.1331 (0.1937)  loss_giou_dn_4: 0.2933 (0.3678)  loss_fgl_dn_4: 1.1818 (1.2185)  loss_ddf_dn_4: 0.0020 (0.0021)  loss_mal_dn_5: 0.5889 (0.6260)  loss_bbox_dn_5: 0.1313 (0.1926)  loss_giou_dn_5: 0.2909 (0.3658)  loss_fgl_dn_5: 1.1809 (1.2188)  loss_mal_dn_pre: 0.8154 (0.8214)  loss_bbox_dn_pre: 0.2993 (0.3257)  loss_giou_dn_pre: 0.5595 (0.5963)  time: 1.2401  data: 0.0119  max mem: 13413\nEpoch: [23]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 38.0396 (38.8822)  loss_mal: 0.7427 (0.7699)  loss_bbox: 0.1300 (0.1665)  loss_giou: 0.3012 (0.3433)  loss_fgl: 1.2388 (1.2637)  loss_mal_aux_0: 1.1377 (1.1965)  loss_bbox_aux_0: 0.1437 (0.1964)  loss_giou_aux_0: 0.3484 (0.4044)  loss_fgl_aux_0: 1.3026 (1.3005)  loss_ddf_aux_0: 0.1309 (0.1217)  loss_mal_aux_1: 0.8652 (0.9318)  loss_bbox_aux_1: 0.1344 (0.1763)  loss_giou_aux_1: 0.3185 (0.3632)  loss_fgl_aux_1: 1.2566 (1.2735)  loss_ddf_aux_1: 0.0455 (0.0472)  loss_mal_aux_2: 0.8091 (0.8293)  loss_bbox_aux_2: 0.1298 (0.1685)  loss_giou_aux_2: 0.3136 (0.3479)  loss_fgl_aux_2: 1.2312 (1.2643)  loss_ddf_aux_2: 0.0076 (0.0087)  loss_mal_aux_3: 0.7598 (0.7834)  loss_bbox_aux_3: 0.1313 (0.1669)  loss_giou_aux_3: 0.3168 (0.3446)  loss_fgl_aux_3: 1.2372 (1.2635)  loss_ddf_aux_3: 0.0018 (0.0019)  loss_mal_aux_4: 0.7139 (0.7660)  loss_bbox_aux_4: 0.1302 (0.1666)  loss_giou_aux_4: 0.3066 (0.3437)  loss_fgl_aux_4: 1.2399 (1.2634)  loss_ddf_aux_4: 0.0002 (0.0003)  loss_mal_pre: 1.1348 (1.1949)  loss_bbox_pre: 0.1437 (0.1956)  loss_giou_pre: 0.3428 (0.4035)  loss_mal_enc_0: 1.3320 (1.3509)  loss_bbox_enc_0: 0.2502 (0.2978)  loss_giou_enc_0: 0.5188 (0.5776)  loss_mal_dn_0: 0.8188 (0.8221)  loss_bbox_dn_0: 0.2711 (0.3198)  loss_giou_dn_0: 0.5643 (0.5971)  loss_fgl_dn_0: 1.3043 (1.2864)  loss_ddf_dn_0: 1.0456 (1.0577)  loss_mal_dn_1: 0.7524 (0.7474)  loss_bbox_dn_1: 0.1749 (0.2270)  loss_giou_dn_1: 0.3838 (0.4301)  loss_fgl_dn_1: 1.2336 (1.2391)  loss_ddf_dn_1: 0.3092 (0.3320)  loss_mal_dn_2: 0.6626 (0.6667)  loss_bbox_dn_2: 0.1532 (0.2031)  loss_giou_dn_2: 0.3353 (0.3881)  loss_fgl_dn_2: 1.1993 (1.2205)  loss_ddf_dn_2: 0.0810 (0.0837)  loss_mal_dn_3: 0.6279 (0.6346)  loss_bbox_dn_3: 0.1438 (0.1932)  loss_giou_dn_3: 0.3221 (0.3718)  loss_fgl_dn_3: 1.1927 (1.2170)  loss_ddf_dn_3: 0.0168 (0.0175)  loss_mal_dn_4: 0.6079 (0.6244)  loss_bbox_dn_4: 0.1421 (0.1902)  loss_giou_dn_4: 0.3098 (0.3665)  loss_fgl_dn_4: 1.1910 (1.2165)  loss_ddf_dn_4: 0.0019 (0.0021)  loss_mal_dn_5: 0.6045 (0.6233)  loss_bbox_dn_5: 0.1414 (0.1891)  loss_giou_dn_5: 0.3073 (0.3644)  loss_fgl_dn_5: 1.1968 (1.2169)  loss_mal_dn_pre: 0.8184 (0.8207)  loss_bbox_dn_pre: 0.2688 (0.3233)  loss_giou_dn_pre: 0.5674 (0.5957)  time: 1.2117  data: 0.0114  max mem: 13413\nEpoch: [23] Total time: 0:05:05 (1.2182 s / it)\nTest:  [ 0/25]  eta: 0:00:21    time: 0.8795  data: 0.5645  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3640  data: 0.0725  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3097  data: 0.0224  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2961  data: 0.0210  max mem: 13413\nTest: Total time: 0:00:08 (0.3253 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.306\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.518\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.327\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.345\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.333\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.429\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.519\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.632\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.671\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.862\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.702\nbest_stat: {'epoch': 23, 'coco_eval_bbox': 0.30641699943756173}\nEpoch: [24]  [  0/251]  eta: 0:08:15  lr: 0.000003  loss: 35.4623 (35.4623)  loss_mal: 0.5254 (0.5254)  loss_bbox: 0.1389 (0.1389)  loss_giou: 0.2431 (0.2431)  loss_fgl: 1.2092 (1.2092)  loss_mal_aux_0: 1.2559 (1.2559)  loss_bbox_aux_0: 0.1649 (0.1649)  loss_giou_aux_0: 0.2531 (0.2531)  loss_fgl_aux_0: 1.2621 (1.2621)  loss_ddf_aux_0: 0.0937 (0.0937)  loss_mal_aux_1: 0.8057 (0.8057)  loss_bbox_aux_1: 0.1433 (0.1433)  loss_giou_aux_1: 0.2413 (0.2413)  loss_fgl_aux_1: 1.2367 (1.2367)  loss_ddf_aux_1: 0.0333 (0.0333)  loss_mal_aux_2: 0.5894 (0.5894)  loss_bbox_aux_2: 0.1397 (0.1397)  loss_giou_aux_2: 0.2419 (0.2419)  loss_fgl_aux_2: 1.2141 (1.2141)  loss_ddf_aux_2: 0.0062 (0.0062)  loss_mal_aux_3: 0.5454 (0.5454)  loss_bbox_aux_3: 0.1410 (0.1410)  loss_giou_aux_3: 0.2447 (0.2447)  loss_fgl_aux_3: 1.2117 (1.2117)  loss_ddf_aux_3: 0.0019 (0.0019)  loss_mal_aux_4: 0.5239 (0.5239)  loss_bbox_aux_4: 0.1400 (0.1400)  loss_giou_aux_4: 0.2452 (0.2452)  loss_fgl_aux_4: 1.2101 (1.2101)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.2529 (1.2529)  loss_bbox_pre: 0.1652 (0.1652)  loss_giou_pre: 0.2531 (0.2531)  loss_mal_enc_0: 1.3398 (1.3398)  loss_bbox_enc_0: 0.1902 (0.1902)  loss_giou_enc_0: 0.4446 (0.4446)  loss_mal_dn_0: 0.7783 (0.7783)  loss_bbox_dn_0: 0.4052 (0.4052)  loss_giou_dn_0: 0.5211 (0.5211)  loss_fgl_dn_0: 1.3023 (1.3023)  loss_ddf_dn_0: 0.9567 (0.9567)  loss_mal_dn_1: 0.7114 (0.7114)  loss_bbox_dn_1: 0.2635 (0.2635)  loss_giou_dn_1: 0.3335 (0.3335)  loss_fgl_dn_1: 1.2263 (1.2263)  loss_ddf_dn_1: 0.3010 (0.3010)  loss_mal_dn_2: 0.6113 (0.6113)  loss_bbox_dn_2: 0.2368 (0.2368)  loss_giou_dn_2: 0.3068 (0.3068)  loss_fgl_dn_2: 1.1806 (1.1806)  loss_ddf_dn_2: 0.0811 (0.0811)  loss_mal_dn_3: 0.5889 (0.5889)  loss_bbox_dn_3: 0.2315 (0.2315)  loss_giou_dn_3: 0.3029 (0.3029)  loss_fgl_dn_3: 1.1705 (1.1705)  loss_ddf_dn_3: 0.0172 (0.0172)  loss_mal_dn_4: 0.5698 (0.5698)  loss_bbox_dn_4: 0.2244 (0.2244)  loss_giou_dn_4: 0.3005 (0.3005)  loss_fgl_dn_4: 1.1678 (1.1678)  loss_ddf_dn_4: 0.0019 (0.0019)  loss_mal_dn_5: 0.5620 (0.5620)  loss_bbox_dn_5: 0.2223 (0.2223)  loss_giou_dn_5: 0.2991 (0.2991)  loss_fgl_dn_5: 1.1672 (1.1672)  loss_mal_dn_pre: 0.7764 (0.7764)  loss_bbox_dn_pre: 0.4130 (0.4130)  loss_giou_dn_pre: 0.5227 (0.5227)  time: 1.9733  data: 0.6997  max mem: 13413\nEpoch: [24]  [100/251]  eta: 0:03:08  lr: 0.000003  loss: 36.5750 (38.1642)  loss_mal: 0.6152 (0.7418)  loss_bbox: 0.1287 (0.1546)  loss_giou: 0.2993 (0.3254)  loss_fgl: 1.2348 (1.2523)  loss_mal_aux_0: 1.1768 (1.2359)  loss_bbox_aux_0: 0.1385 (0.1834)  loss_giou_aux_0: 0.3777 (0.3816)  loss_fgl_aux_0: 1.3149 (1.3036)  loss_ddf_aux_0: 0.1245 (0.1360)  loss_mal_aux_1: 0.9077 (0.9925)  loss_bbox_aux_1: 0.1122 (0.1641)  loss_giou_aux_1: 0.3120 (0.3432)  loss_fgl_aux_1: 1.2547 (1.2674)  loss_ddf_aux_1: 0.0425 (0.0488)  loss_mal_aux_2: 0.7217 (0.8100)  loss_bbox_aux_2: 0.1253 (0.1570)  loss_giou_aux_2: 0.2980 (0.3293)  loss_fgl_aux_2: 1.2380 (1.2550)  loss_ddf_aux_2: 0.0066 (0.0088)  loss_mal_aux_3: 0.6519 (0.7578)  loss_bbox_aux_3: 0.1289 (0.1554)  loss_giou_aux_3: 0.2977 (0.3262)  loss_fgl_aux_3: 1.2308 (1.2528)  loss_ddf_aux_3: 0.0015 (0.0019)  loss_mal_aux_4: 0.6235 (0.7407)  loss_bbox_aux_4: 0.1292 (0.1549)  loss_giou_aux_4: 0.2985 (0.3257)  loss_fgl_aux_4: 1.2337 (1.2521)  loss_ddf_aux_4: 0.0002 (0.0003)  loss_mal_pre: 1.1738 (1.2333)  loss_bbox_pre: 0.1389 (0.1825)  loss_giou_pre: 0.3755 (0.3807)  loss_mal_enc_0: 1.1807 (1.2857)  loss_bbox_enc_0: 0.2459 (0.2884)  loss_giou_enc_0: 0.5697 (0.5742)  loss_mal_dn_0: 0.8169 (0.8155)  loss_bbox_dn_0: 0.2462 (0.3026)  loss_giou_dn_0: 0.5815 (0.5788)  loss_fgl_dn_0: 1.3084 (1.2913)  loss_ddf_dn_0: 0.9283 (1.0378)  loss_mal_dn_1: 0.7461 (0.7375)  loss_bbox_dn_1: 0.1682 (0.2112)  loss_giou_dn_1: 0.4180 (0.4128)  loss_fgl_dn_1: 1.2450 (1.2340)  loss_ddf_dn_1: 0.2743 (0.3090)  loss_mal_dn_2: 0.6587 (0.6429)  loss_bbox_dn_2: 0.1453 (0.1866)  loss_giou_dn_2: 0.3569 (0.3722)  loss_fgl_dn_2: 1.2313 (1.2130)  loss_ddf_dn_2: 0.0683 (0.0777)  loss_mal_dn_3: 0.6138 (0.6120)  loss_bbox_dn_3: 0.1381 (0.1764)  loss_giou_dn_3: 0.3286 (0.3561)  loss_fgl_dn_3: 1.2226 (1.2092)  loss_ddf_dn_3: 0.0128 (0.0158)  loss_mal_dn_4: 0.6138 (0.6032)  loss_bbox_dn_4: 0.1346 (0.1734)  loss_giou_dn_4: 0.3128 (0.3514)  loss_fgl_dn_4: 1.2248 (1.2087)  loss_ddf_dn_4: 0.0016 (0.0018)  loss_mal_dn_5: 0.6147 (0.6035)  loss_bbox_dn_5: 0.1338 (0.1723)  loss_giou_dn_5: 0.3076 (0.3499)  loss_fgl_dn_5: 1.2260 (1.2088)  loss_mal_dn_pre: 0.8140 (0.8145)  loss_bbox_dn_pre: 0.2486 (0.3045)  loss_giou_dn_pre: 0.5794 (0.5764)  time: 1.2990  data: 0.0116  max mem: 13413\nEpoch: [24]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 36.3592 (38.1164)  loss_mal: 0.7163 (0.7376)  loss_bbox: 0.1300 (0.1647)  loss_giou: 0.3034 (0.3268)  loss_fgl: 1.2137 (1.2518)  loss_mal_aux_0: 1.1250 (1.1902)  loss_bbox_aux_0: 0.1627 (0.1962)  loss_giou_aux_0: 0.3528 (0.3903)  loss_fgl_aux_0: 1.2920 (1.3004)  loss_ddf_aux_0: 0.1247 (0.1342)  loss_mal_aux_1: 0.8882 (0.9487)  loss_bbox_aux_1: 0.1315 (0.1752)  loss_giou_aux_1: 0.3152 (0.3470)  loss_fgl_aux_1: 1.2551 (1.2657)  loss_ddf_aux_1: 0.0493 (0.0491)  loss_mal_aux_2: 0.8164 (0.7949)  loss_bbox_aux_2: 0.1296 (0.1673)  loss_giou_aux_2: 0.3045 (0.3311)  loss_fgl_aux_2: 1.2144 (1.2545)  loss_ddf_aux_2: 0.0082 (0.0090)  loss_mal_aux_3: 0.7129 (0.7484)  loss_bbox_aux_3: 0.1307 (0.1655)  loss_giou_aux_3: 0.2991 (0.3277)  loss_fgl_aux_3: 1.2113 (1.2522)  loss_ddf_aux_3: 0.0019 (0.0020)  loss_mal_aux_4: 0.7090 (0.7351)  loss_bbox_aux_4: 0.1298 (0.1649)  loss_giou_aux_4: 0.3020 (0.3270)  loss_fgl_aux_4: 1.2133 (1.2517)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.1240 (1.1873)  loss_bbox_pre: 0.1629 (0.1957)  loss_giou_pre: 0.3530 (0.3896)  loss_mal_enc_0: 1.2910 (1.2936)  loss_bbox_enc_0: 0.2486 (0.3006)  loss_giou_enc_0: 0.5238 (0.5781)  loss_mal_dn_0: 0.8184 (0.8101)  loss_bbox_dn_0: 0.2641 (0.3068)  loss_giou_dn_0: 0.5247 (0.5740)  loss_fgl_dn_0: 1.3003 (1.2918)  loss_ddf_dn_0: 1.0136 (1.0617)  loss_mal_dn_1: 0.7261 (0.7299)  loss_bbox_dn_1: 0.1652 (0.2159)  loss_giou_dn_1: 0.3762 (0.4074)  loss_fgl_dn_1: 1.2175 (1.2339)  loss_ddf_dn_1: 0.3157 (0.3157)  loss_mal_dn_2: 0.6279 (0.6373)  loss_bbox_dn_2: 0.1440 (0.1926)  loss_giou_dn_2: 0.3311 (0.3679)  loss_fgl_dn_2: 1.1765 (1.2127)  loss_ddf_dn_2: 0.0808 (0.0800)  loss_mal_dn_3: 0.5898 (0.6069)  loss_bbox_dn_3: 0.1397 (0.1830)  loss_giou_dn_3: 0.3037 (0.3519)  loss_fgl_dn_3: 1.1722 (1.2089)  loss_ddf_dn_3: 0.0171 (0.0164)  loss_mal_dn_4: 0.5918 (0.5988)  loss_bbox_dn_4: 0.1404 (0.1802)  loss_giou_dn_4: 0.2949 (0.3470)  loss_fgl_dn_4: 1.1698 (1.2084)  loss_ddf_dn_4: 0.0019 (0.0019)  loss_mal_dn_5: 0.5996 (0.5980)  loss_bbox_dn_5: 0.1414 (0.1792)  loss_giou_dn_5: 0.2929 (0.3452)  loss_fgl_dn_5: 1.1709 (1.2086)  loss_mal_dn_pre: 0.8174 (0.8092)  loss_bbox_dn_pre: 0.2636 (0.3090)  loss_giou_dn_pre: 0.5238 (0.5720)  time: 1.1813  data: 0.0110  max mem: 13413\nEpoch: [24]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 35.6132 (38.2561)  loss_mal: 0.5669 (0.7416)  loss_bbox: 0.1079 (0.1636)  loss_giou: 0.3047 (0.3300)  loss_fgl: 1.2587 (1.2539)  loss_mal_aux_0: 1.1289 (1.1958)  loss_bbox_aux_0: 0.1569 (0.1948)  loss_giou_aux_0: 0.3424 (0.3919)  loss_fgl_aux_0: 1.3059 (1.3010)  loss_ddf_aux_0: 0.1187 (0.1342)  loss_mal_aux_1: 0.7812 (0.9478)  loss_bbox_aux_1: 0.1161 (0.1741)  loss_giou_aux_1: 0.3089 (0.3496)  loss_fgl_aux_1: 1.2773 (1.2673)  loss_ddf_aux_1: 0.0418 (0.0496)  loss_mal_aux_2: 0.6494 (0.8024)  loss_bbox_aux_2: 0.1087 (0.1665)  loss_giou_aux_2: 0.3023 (0.3346)  loss_fgl_aux_2: 1.2667 (1.2563)  loss_ddf_aux_2: 0.0071 (0.0091)  loss_mal_aux_3: 0.5913 (0.7546)  loss_bbox_aux_3: 0.1070 (0.1646)  loss_giou_aux_3: 0.3053 (0.3312)  loss_fgl_aux_3: 1.2569 (1.2543)  loss_ddf_aux_3: 0.0016 (0.0020)  loss_mal_aux_4: 0.5781 (0.7394)  loss_bbox_aux_4: 0.1078 (0.1639)  loss_giou_aux_4: 0.3031 (0.3303)  loss_fgl_aux_4: 1.2575 (1.2537)  loss_ddf_aux_4: 0.0002 (0.0003)  loss_mal_pre: 1.1260 (1.1929)  loss_bbox_pre: 0.1570 (0.1942)  loss_giou_pre: 0.3417 (0.3911)  loss_mal_enc_0: 1.3047 (1.3128)  loss_bbox_enc_0: 0.2526 (0.2977)  loss_giou_enc_0: 0.5448 (0.5746)  loss_mal_dn_0: 0.8184 (0.8114)  loss_bbox_dn_0: 0.2814 (0.3091)  loss_giou_dn_0: 0.5220 (0.5781)  loss_fgl_dn_0: 1.2992 (1.2913)  loss_ddf_dn_0: 0.9860 (1.0584)  loss_mal_dn_1: 0.7305 (0.7322)  loss_bbox_dn_1: 0.1851 (0.2180)  loss_giou_dn_1: 0.3468 (0.4133)  loss_fgl_dn_1: 1.2299 (1.2348)  loss_ddf_dn_1: 0.2891 (0.3148)  loss_mal_dn_2: 0.6367 (0.6412)  loss_bbox_dn_2: 0.1555 (0.1945)  loss_giou_dn_2: 0.3242 (0.3735)  loss_fgl_dn_2: 1.1955 (1.2150)  loss_ddf_dn_2: 0.0750 (0.0798)  loss_mal_dn_3: 0.6011 (0.6100)  loss_bbox_dn_3: 0.1422 (0.1848)  loss_giou_dn_3: 0.3132 (0.3575)  loss_fgl_dn_3: 1.1927 (1.2112)  loss_ddf_dn_3: 0.0156 (0.0163)  loss_mal_dn_4: 0.5776 (0.6010)  loss_bbox_dn_4: 0.1390 (0.1819)  loss_giou_dn_4: 0.3040 (0.3523)  loss_fgl_dn_4: 1.1942 (1.2109)  loss_ddf_dn_4: 0.0017 (0.0019)  loss_mal_dn_5: 0.5742 (0.6003)  loss_bbox_dn_5: 0.1366 (0.1809)  loss_giou_dn_5: 0.2983 (0.3505)  loss_fgl_dn_5: 1.1927 (1.2112)  loss_mal_dn_pre: 0.8154 (0.8104)  loss_bbox_dn_pre: 0.2854 (0.3117)  loss_giou_dn_pre: 0.5283 (0.5763)  time: 1.2273  data: 0.0114  max mem: 13413\nEpoch: [24] Total time: 0:05:05 (1.2169 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7771  data: 0.4619  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3525  data: 0.0620  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3064  data: 0.0203  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2935  data: 0.0194  max mem: 13413\nTest: Total time: 0:00:07 (0.3190 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.547\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.322\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.406\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.345\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.429\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.530\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.692\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.866\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.777\nbest_stat: {'epoch': 24, 'coco_eval_bbox': 0.32428701118007214}\n     ### Attention --- Mixup is closed after epoch@ 25 ###\n     ### Attention --- Mixup is closed after epoch@ 25 ###\nEpoch: [25]  [  0/251]  eta: 0:09:12  lr: 0.000003  loss: 34.6185 (34.6185)  loss_mal: 0.5532 (0.5532)  loss_bbox: 0.0969 (0.0969)  loss_giou: 0.3083 (0.3083)  loss_fgl: 1.2638 (1.2638)  loss_mal_aux_0: 1.0801 (1.0801)  loss_bbox_aux_0: 0.1302 (0.1302)  loss_giou_aux_0: 0.3604 (0.3604)  loss_fgl_aux_0: 1.3421 (1.3421)  loss_ddf_aux_0: 0.0916 (0.0916)  loss_mal_aux_1: 0.8018 (0.8018)  loss_bbox_aux_1: 0.1172 (0.1172)  loss_giou_aux_1: 0.3375 (0.3375)  loss_fgl_aux_1: 1.2985 (1.2985)  loss_ddf_aux_1: 0.0332 (0.0332)  loss_mal_aux_2: 0.6572 (0.6572)  loss_bbox_aux_2: 0.1046 (0.1046)  loss_giou_aux_2: 0.3201 (0.3201)  loss_fgl_aux_2: 1.2773 (1.2773)  loss_ddf_aux_2: 0.0057 (0.0057)  loss_mal_aux_3: 0.5757 (0.5757)  loss_bbox_aux_3: 0.1005 (0.1005)  loss_giou_aux_3: 0.3143 (0.3143)  loss_fgl_aux_3: 1.2701 (1.2701)  loss_ddf_aux_3: 0.0010 (0.0010)  loss_mal_aux_4: 0.5640 (0.5640)  loss_bbox_aux_4: 0.0974 (0.0974)  loss_giou_aux_4: 0.3096 (0.3096)  loss_fgl_aux_4: 1.2655 (1.2655)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.0771 (1.0771)  loss_bbox_pre: 0.1322 (0.1322)  loss_giou_pre: 0.3650 (0.3650)  loss_mal_enc_0: 1.0361 (1.0361)  loss_bbox_enc_0: 0.1492 (0.1492)  loss_giou_enc_0: 0.4725 (0.4725)  loss_mal_dn_0: 0.7539 (0.7539)  loss_bbox_dn_0: 0.1764 (0.1764)  loss_giou_dn_0: 0.5770 (0.5770)  loss_fgl_dn_0: 1.3479 (1.3479)  loss_ddf_dn_0: 0.7009 (0.7009)  loss_mal_dn_1: 0.7681 (0.7681)  loss_bbox_dn_1: 0.1292 (0.1292)  loss_giou_dn_1: 0.4058 (0.4058)  loss_fgl_dn_1: 1.2591 (1.2591)  loss_ddf_dn_1: 0.2239 (0.2239)  loss_mal_dn_2: 0.6133 (0.6133)  loss_bbox_dn_2: 0.1045 (0.1045)  loss_giou_dn_2: 0.3459 (0.3459)  loss_fgl_dn_2: 1.2212 (1.2212)  loss_ddf_dn_2: 0.0570 (0.0570)  loss_mal_dn_3: 0.5757 (0.5757)  loss_bbox_dn_3: 0.0939 (0.0939)  loss_giou_dn_3: 0.3227 (0.3227)  loss_fgl_dn_3: 1.2055 (1.2055)  loss_ddf_dn_3: 0.0107 (0.0107)  loss_mal_dn_4: 0.5669 (0.5669)  loss_bbox_dn_4: 0.0896 (0.0896)  loss_giou_dn_4: 0.3144 (0.3144)  loss_fgl_dn_4: 1.2007 (1.2007)  loss_ddf_dn_4: 0.0012 (0.0012)  loss_mal_dn_5: 0.5601 (0.5601)  loss_bbox_dn_5: 0.0883 (0.0883)  loss_giou_dn_5: 0.3106 (0.3106)  loss_fgl_dn_5: 1.1989 (1.1989)  loss_mal_dn_pre: 0.7515 (0.7515)  loss_bbox_dn_pre: 0.1713 (0.1713)  loss_giou_dn_pre: 0.5624 (0.5624)  time: 2.1996  data: 0.6199  max mem: 13413\nEpoch: [25]  [100/251]  eta: 0:03:06  lr: 0.000003  loss: 37.6028 (37.6918)  loss_mal: 0.6348 (0.7093)  loss_bbox: 0.1256 (0.1641)  loss_giou: 0.3237 (0.3158)  loss_fgl: 1.2755 (1.2478)  loss_mal_aux_0: 1.1670 (1.1676)  loss_bbox_aux_0: 0.1475 (0.1930)  loss_giou_aux_0: 0.3794 (0.3811)  loss_fgl_aux_0: 1.3018 (1.2916)  loss_ddf_aux_0: 0.1167 (0.1307)  loss_mal_aux_1: 0.9150 (0.9073)  loss_bbox_aux_1: 0.1289 (0.1703)  loss_giou_aux_1: 0.3423 (0.3370)  loss_fgl_aux_1: 1.2818 (1.2567)  loss_ddf_aux_1: 0.0411 (0.0472)  loss_mal_aux_2: 0.7236 (0.7720)  loss_bbox_aux_2: 0.1232 (0.1650)  loss_giou_aux_2: 0.3279 (0.3221)  loss_fgl_aux_2: 1.2810 (1.2470)  loss_ddf_aux_2: 0.0080 (0.0090)  loss_mal_aux_3: 0.6558 (0.7287)  loss_bbox_aux_3: 0.1243 (0.1639)  loss_giou_aux_3: 0.3195 (0.3176)  loss_fgl_aux_3: 1.2743 (1.2466)  loss_ddf_aux_3: 0.0016 (0.0019)  loss_mal_aux_4: 0.6533 (0.7153)  loss_bbox_aux_4: 0.1250 (0.1639)  loss_giou_aux_4: 0.3227 (0.3162)  loss_fgl_aux_4: 1.2739 (1.2473)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 1.1670 (1.1617)  loss_bbox_pre: 0.1457 (0.1929)  loss_giou_pre: 0.3792 (0.3805)  loss_mal_enc_0: 1.2637 (1.2963)  loss_bbox_enc_0: 0.2155 (0.2840)  loss_giou_enc_0: 0.5251 (0.5466)  loss_mal_dn_0: 0.8076 (0.8118)  loss_bbox_dn_0: 0.2489 (0.3112)  loss_giou_dn_0: 0.5513 (0.5660)  loss_fgl_dn_0: 1.2869 (1.2964)  loss_ddf_dn_0: 1.0227 (1.0645)  loss_mal_dn_1: 0.7363 (0.7291)  loss_bbox_dn_1: 0.1691 (0.2170)  loss_giou_dn_1: 0.3961 (0.3973)  loss_fgl_dn_1: 1.2370 (1.2343)  loss_ddf_dn_1: 0.2835 (0.3082)  loss_mal_dn_2: 0.6304 (0.6385)  loss_bbox_dn_2: 0.1453 (0.1935)  loss_giou_dn_2: 0.3552 (0.3569)  loss_fgl_dn_2: 1.2138 (1.2136)  loss_ddf_dn_2: 0.0682 (0.0786)  loss_mal_dn_3: 0.6045 (0.6046)  loss_bbox_dn_3: 0.1390 (0.1838)  loss_giou_dn_3: 0.3394 (0.3407)  loss_fgl_dn_3: 1.2239 (1.2093)  loss_ddf_dn_3: 0.0128 (0.0159)  loss_mal_dn_4: 0.5923 (0.5905)  loss_bbox_dn_4: 0.1377 (0.1816)  loss_giou_dn_4: 0.3296 (0.3355)  loss_fgl_dn_4: 1.2191 (1.2094)  loss_ddf_dn_4: 0.0016 (0.0019)  loss_mal_dn_5: 0.5913 (0.5882)  loss_bbox_dn_5: 0.1388 (0.1808)  loss_giou_dn_5: 0.3271 (0.3336)  loss_fgl_dn_5: 1.2185 (1.2099)  loss_mal_dn_pre: 0.8096 (0.8105)  loss_bbox_dn_pre: 0.2411 (0.3148)  loss_giou_dn_pre: 0.5519 (0.5658)  time: 1.2337  data: 0.0116  max mem: 13413\nEpoch: [25]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 34.9255 (37.5733)  loss_mal: 0.5308 (0.6970)  loss_bbox: 0.1305 (0.1565)  loss_giou: 0.2953 (0.3187)  loss_fgl: 1.2671 (1.2594)  loss_mal_aux_0: 1.1230 (1.1560)  loss_bbox_aux_0: 0.1440 (0.1827)  loss_giou_aux_0: 0.3453 (0.3787)  loss_fgl_aux_0: 1.3011 (1.2993)  loss_ddf_aux_0: 0.1047 (0.1264)  loss_mal_aux_1: 0.8262 (0.9013)  loss_bbox_aux_1: 0.1381 (0.1636)  loss_giou_aux_1: 0.3047 (0.3375)  loss_fgl_aux_1: 1.2854 (1.2671)  loss_ddf_aux_1: 0.0307 (0.0437)  loss_mal_aux_2: 0.5903 (0.7531)  loss_bbox_aux_2: 0.1286 (0.1580)  loss_giou_aux_2: 0.2939 (0.3236)  loss_fgl_aux_2: 1.2812 (1.2596)  loss_ddf_aux_2: 0.0053 (0.0080)  loss_mal_aux_3: 0.5430 (0.7097)  loss_bbox_aux_3: 0.1270 (0.1568)  loss_giou_aux_3: 0.2948 (0.3200)  loss_fgl_aux_3: 1.2764 (1.2589)  loss_ddf_aux_3: 0.0012 (0.0017)  loss_mal_aux_4: 0.5273 (0.6964)  loss_bbox_aux_4: 0.1292 (0.1565)  loss_giou_aux_4: 0.2952 (0.3190)  loss_fgl_aux_4: 1.2702 (1.2591)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 1.1162 (1.1520)  loss_bbox_pre: 0.1443 (0.1825)  loss_giou_pre: 0.3434 (0.3782)  loss_mal_enc_0: 1.3535 (1.3049)  loss_bbox_enc_0: 0.2361 (0.2679)  loss_giou_enc_0: 0.4928 (0.5387)  loss_mal_dn_0: 0.8120 (0.8115)  loss_bbox_dn_0: 0.2913 (0.2991)  loss_giou_dn_0: 0.5046 (0.5611)  loss_fgl_dn_0: 1.3189 (1.2994)  loss_ddf_dn_0: 0.9802 (1.0789)  loss_mal_dn_1: 0.7212 (0.7321)  loss_bbox_dn_1: 0.1899 (0.2069)  loss_giou_dn_1: 0.3330 (0.3947)  loss_fgl_dn_1: 1.2507 (1.2390)  loss_ddf_dn_1: 0.2712 (0.3087)  loss_mal_dn_2: 0.5996 (0.6385)  loss_bbox_dn_2: 0.1567 (0.1847)  loss_giou_dn_2: 0.3133 (0.3560)  loss_fgl_dn_2: 1.2310 (1.2206)  loss_ddf_dn_2: 0.0715 (0.0788)  loss_mal_dn_3: 0.5767 (0.6064)  loss_bbox_dn_3: 0.1414 (0.1760)  loss_giou_dn_3: 0.3034 (0.3413)  loss_fgl_dn_3: 1.2282 (1.2168)  loss_ddf_dn_3: 0.0143 (0.0157)  loss_mal_dn_4: 0.5625 (0.5953)  loss_bbox_dn_4: 0.1397 (0.1736)  loss_giou_dn_4: 0.3014 (0.3365)  loss_fgl_dn_4: 1.2341 (1.2167)  loss_ddf_dn_4: 0.0017 (0.0019)  loss_mal_dn_5: 0.5654 (0.5935)  loss_bbox_dn_5: 0.1409 (0.1727)  loss_giou_dn_5: 0.3023 (0.3346)  loss_fgl_dn_5: 1.2349 (1.2171)  loss_mal_dn_pre: 0.8110 (0.8105)  loss_bbox_dn_pre: 0.2920 (0.3019)  loss_giou_dn_pre: 0.5019 (0.5599)  time: 1.2725  data: 0.0111  max mem: 13413\nEpoch: [25]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 38.7324 (37.6732)  loss_mal: 0.7119 (0.7039)  loss_bbox: 0.1451 (0.1585)  loss_giou: 0.3088 (0.3212)  loss_fgl: 1.2320 (1.2599)  loss_mal_aux_0: 1.0518 (1.1479)  loss_bbox_aux_0: 0.1564 (0.1866)  loss_giou_aux_0: 0.3658 (0.3816)  loss_fgl_aux_0: 1.2899 (1.2991)  loss_ddf_aux_0: 0.1306 (0.1258)  loss_mal_aux_1: 0.8037 (0.9066)  loss_bbox_aux_1: 0.1502 (0.1658)  loss_giou_aux_1: 0.3135 (0.3393)  loss_fgl_aux_1: 1.2525 (1.2670)  loss_ddf_aux_1: 0.0468 (0.0436)  loss_mal_aux_2: 0.7749 (0.7607)  loss_bbox_aux_2: 0.1465 (0.1599)  loss_giou_aux_2: 0.3039 (0.3255)  loss_fgl_aux_2: 1.2322 (1.2601)  loss_ddf_aux_2: 0.0082 (0.0081)  loss_mal_aux_3: 0.7583 (0.7183)  loss_bbox_aux_3: 0.1461 (0.1588)  loss_giou_aux_3: 0.3063 (0.3223)  loss_fgl_aux_3: 1.2304 (1.2594)  loss_ddf_aux_3: 0.0017 (0.0017)  loss_mal_aux_4: 0.7236 (0.7043)  loss_bbox_aux_4: 0.1460 (0.1584)  loss_giou_aux_4: 0.3086 (0.3214)  loss_fgl_aux_4: 1.2304 (1.2596)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 1.0488 (1.1445)  loss_bbox_pre: 0.1554 (0.1864)  loss_giou_pre: 0.3599 (0.3813)  loss_mal_enc_0: 1.2793 (1.3108)  loss_bbox_enc_0: 0.2704 (0.2759)  loss_giou_enc_0: 0.5437 (0.5464)  loss_mal_dn_0: 0.8188 (0.8112)  loss_bbox_dn_0: 0.2958 (0.3009)  loss_giou_dn_0: 0.5829 (0.5643)  loss_fgl_dn_0: 1.3013 (1.2991)  loss_ddf_dn_0: 1.0636 (1.0760)  loss_mal_dn_1: 0.7627 (0.7317)  loss_bbox_dn_1: 0.2020 (0.2084)  loss_giou_dn_1: 0.3754 (0.3978)  loss_fgl_dn_1: 1.2311 (1.2379)  loss_ddf_dn_1: 0.3047 (0.3066)  loss_mal_dn_2: 0.6621 (0.6388)  loss_bbox_dn_2: 0.1732 (0.1858)  loss_giou_dn_2: 0.3277 (0.3587)  loss_fgl_dn_2: 1.2130 (1.2193)  loss_ddf_dn_2: 0.0758 (0.0786)  loss_mal_dn_3: 0.6108 (0.6069)  loss_bbox_dn_3: 0.1582 (0.1772)  loss_giou_dn_3: 0.3209 (0.3440)  loss_fgl_dn_3: 1.2061 (1.2156)  loss_ddf_dn_3: 0.0158 (0.0158)  loss_mal_dn_4: 0.6030 (0.5968)  loss_bbox_dn_4: 0.1483 (0.1748)  loss_giou_dn_4: 0.3213 (0.3392)  loss_fgl_dn_4: 1.2059 (1.2155)  loss_ddf_dn_4: 0.0019 (0.0019)  loss_mal_dn_5: 0.6118 (0.5950)  loss_bbox_dn_5: 0.1467 (0.1740)  loss_giou_dn_5: 0.3212 (0.3373)  loss_fgl_dn_5: 1.2057 (1.2161)  loss_mal_dn_pre: 0.8184 (0.8104)  loss_bbox_dn_pre: 0.3080 (0.3038)  loss_giou_dn_pre: 0.5887 (0.5628)  time: 1.2275  data: 0.0114  max mem: 13413\nEpoch: [25] Total time: 0:05:05 (1.2179 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7717  data: 0.4561  max mem: 13413\nTest:  [10/25]  eta: 0:00:06    time: 0.4017  data: 0.0603  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3327  data: 0.0194  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2917  data: 0.0184  max mem: 13413\nTest: Total time: 0:00:08 (0.3396 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.518\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.325\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.412\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.337\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.438\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.524\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.653\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.667\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.866\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.779\nbest_stat: {'epoch': 24, 'coco_eval_bbox': 0.32428701118007214}\nEpoch: [26]  [  0/251]  eta: 0:07:10  lr: 0.000003  loss: 31.7115 (31.7115)  loss_mal: 0.4302 (0.4302)  loss_bbox: 0.0695 (0.0695)  loss_giou: 0.1874 (0.1874)  loss_fgl: 1.1618 (1.1618)  loss_mal_aux_0: 1.0459 (1.0459)  loss_bbox_aux_0: 0.1199 (0.1199)  loss_giou_aux_0: 0.2670 (0.2670)  loss_fgl_aux_0: 1.2528 (1.2528)  loss_ddf_aux_0: 0.1035 (0.1035)  loss_mal_aux_1: 0.7720 (0.7720)  loss_bbox_aux_1: 0.0925 (0.0925)  loss_giou_aux_1: 0.2178 (0.2178)  loss_fgl_aux_1: 1.1975 (1.1975)  loss_ddf_aux_1: 0.0309 (0.0309)  loss_mal_aux_2: 0.4546 (0.4546)  loss_bbox_aux_2: 0.0734 (0.0734)  loss_giou_aux_2: 0.1972 (0.1972)  loss_fgl_aux_2: 1.1674 (1.1674)  loss_ddf_aux_2: 0.0052 (0.0052)  loss_mal_aux_3: 0.4346 (0.4346)  loss_bbox_aux_3: 0.0702 (0.0702)  loss_giou_aux_3: 0.1891 (0.1891)  loss_fgl_aux_3: 1.1627 (1.1627)  loss_ddf_aux_3: 0.0010 (0.0010)  loss_mal_aux_4: 0.4316 (0.4316)  loss_bbox_aux_4: 0.0699 (0.0699)  loss_giou_aux_4: 0.1872 (0.1872)  loss_fgl_aux_4: 1.1619 (1.1619)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.0420 (1.0420)  loss_bbox_pre: 0.1203 (0.1203)  loss_giou_pre: 0.2668 (0.2668)  loss_mal_enc_0: 1.1064 (1.1064)  loss_bbox_enc_0: 0.2130 (0.2130)  loss_giou_enc_0: 0.4693 (0.4693)  loss_mal_dn_0: 0.7539 (0.7539)  loss_bbox_dn_0: 0.2269 (0.2269)  loss_giou_dn_0: 0.4514 (0.4514)  loss_fgl_dn_0: 1.2938 (1.2938)  loss_ddf_dn_0: 1.2954 (1.2954)  loss_mal_dn_1: 0.6367 (0.6367)  loss_bbox_dn_1: 0.1248 (0.1248)  loss_giou_dn_1: 0.2741 (0.2741)  loss_fgl_dn_1: 1.1979 (1.1979)  loss_ddf_dn_1: 0.3288 (0.3288)  loss_mal_dn_2: 0.5454 (0.5454)  loss_bbox_dn_2: 0.0990 (0.0990)  loss_giou_dn_2: 0.2251 (0.2251)  loss_fgl_dn_2: 1.1540 (1.1540)  loss_ddf_dn_2: 0.0865 (0.0865)  loss_mal_dn_3: 0.5020 (0.5020)  loss_bbox_dn_3: 0.0884 (0.0884)  loss_giou_dn_3: 0.2047 (0.2047)  loss_fgl_dn_3: 1.1400 (1.1400)  loss_ddf_dn_3: 0.0167 (0.0167)  loss_mal_dn_4: 0.4993 (0.4993)  loss_bbox_dn_4: 0.0844 (0.0844)  loss_giou_dn_4: 0.1995 (0.1995)  loss_fgl_dn_4: 1.1381 (1.1381)  loss_ddf_dn_4: 0.0019 (0.0019)  loss_mal_dn_5: 0.4885 (0.4885)  loss_bbox_dn_5: 0.0834 (0.0834)  loss_giou_dn_5: 0.1992 (0.1992)  loss_fgl_dn_5: 1.1381 (1.1381)  loss_mal_dn_pre: 0.7559 (0.7559)  loss_bbox_dn_pre: 0.2413 (0.2413)  loss_giou_dn_pre: 0.4638 (0.4638)  time: 1.7162  data: 0.6241  max mem: 13413\nEpoch: [26]  [100/251]  eta: 0:03:05  lr: 0.000003  loss: 35.2824 (37.4742)  loss_mal: 0.5723 (0.7016)  loss_bbox: 0.1064 (0.1409)  loss_giou: 0.2768 (0.3105)  loss_fgl: 1.2391 (1.2598)  loss_mal_aux_0: 1.0664 (1.1498)  loss_bbox_aux_0: 0.1270 (0.1691)  loss_giou_aux_0: 0.3237 (0.3601)  loss_fgl_aux_0: 1.2943 (1.2979)  loss_ddf_aux_0: 0.1158 (0.1265)  loss_mal_aux_1: 0.7749 (0.8845)  loss_bbox_aux_1: 0.1059 (0.1477)  loss_giou_aux_1: 0.2929 (0.3200)  loss_fgl_aux_1: 1.2598 (1.2661)  loss_ddf_aux_1: 0.0363 (0.0426)  loss_mal_aux_2: 0.6709 (0.7583)  loss_bbox_aux_2: 0.1051 (0.1425)  loss_giou_aux_2: 0.2830 (0.3118)  loss_fgl_aux_2: 1.2409 (1.2599)  loss_ddf_aux_2: 0.0062 (0.0078)  loss_mal_aux_3: 0.6191 (0.7172)  loss_bbox_aux_3: 0.1065 (0.1413)  loss_giou_aux_3: 0.2763 (0.3107)  loss_fgl_aux_3: 1.2376 (1.2592)  loss_ddf_aux_3: 0.0012 (0.0017)  loss_mal_aux_4: 0.5781 (0.7037)  loss_bbox_aux_4: 0.1062 (0.1409)  loss_giou_aux_4: 0.2766 (0.3105)  loss_fgl_aux_4: 1.2388 (1.2595)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 1.0645 (1.1526)  loss_bbox_pre: 0.1270 (0.1687)  loss_giou_pre: 0.3213 (0.3596)  loss_mal_enc_0: 1.3193 (1.3574)  loss_bbox_enc_0: 0.2314 (0.2621)  loss_giou_enc_0: 0.5584 (0.5247)  loss_mal_dn_0: 0.7920 (0.8077)  loss_bbox_dn_0: 0.2800 (0.3009)  loss_giou_dn_0: 0.5349 (0.5656)  loss_fgl_dn_0: 1.3096 (1.3013)  loss_ddf_dn_0: 1.0666 (1.1399)  loss_mal_dn_1: 0.7129 (0.7285)  loss_bbox_dn_1: 0.1752 (0.2041)  loss_giou_dn_1: 0.3387 (0.3951)  loss_fgl_dn_1: 1.2296 (1.2399)  loss_ddf_dn_1: 0.2920 (0.3161)  loss_mal_dn_2: 0.5977 (0.6349)  loss_bbox_dn_2: 0.1589 (0.1811)  loss_giou_dn_2: 0.3115 (0.3564)  loss_fgl_dn_2: 1.1974 (1.2228)  loss_ddf_dn_2: 0.0763 (0.0842)  loss_mal_dn_3: 0.5640 (0.6020)  loss_bbox_dn_3: 0.1450 (0.1721)  loss_giou_dn_3: 0.3040 (0.3424)  loss_fgl_dn_3: 1.1854 (1.2193)  loss_ddf_dn_3: 0.0148 (0.0169)  loss_mal_dn_4: 0.5601 (0.5940)  loss_bbox_dn_4: 0.1431 (0.1693)  loss_giou_dn_4: 0.2896 (0.3381)  loss_fgl_dn_4: 1.1801 (1.2196)  loss_ddf_dn_4: 0.0017 (0.0019)  loss_mal_dn_5: 0.5454 (0.5922)  loss_bbox_dn_5: 0.1434 (0.1685)  loss_giou_dn_5: 0.2849 (0.3367)  loss_fgl_dn_5: 1.1811 (1.2205)  loss_mal_dn_pre: 0.7910 (0.8067)  loss_bbox_dn_pre: 0.2731 (0.3047)  loss_giou_dn_pre: 0.5274 (0.5634)  time: 1.1293  data: 0.0116  max mem: 13413\nEpoch: [26]  [200/251]  eta: 0:01:01  lr: 0.000003  loss: 34.9440 (37.0027)  loss_mal: 0.5586 (0.6843)  loss_bbox: 0.1081 (0.1383)  loss_giou: 0.2522 (0.2985)  loss_fgl: 1.1923 (1.2522)  loss_mal_aux_0: 1.1562 (1.1331)  loss_bbox_aux_0: 0.1228 (0.1684)  loss_giou_aux_0: 0.3008 (0.3535)  loss_fgl_aux_0: 1.2657 (1.2964)  loss_ddf_aux_0: 0.1193 (0.1268)  loss_mal_aux_1: 0.7153 (0.8748)  loss_bbox_aux_1: 0.1095 (0.1468)  loss_giou_aux_1: 0.2618 (0.3125)  loss_fgl_aux_1: 1.2278 (1.2616)  loss_ddf_aux_1: 0.0369 (0.0421)  loss_mal_aux_2: 0.5986 (0.7396)  loss_bbox_aux_2: 0.1040 (0.1408)  loss_giou_aux_2: 0.2536 (0.3012)  loss_fgl_aux_2: 1.2040 (1.2534)  loss_ddf_aux_2: 0.0070 (0.0077)  loss_mal_aux_3: 0.5806 (0.6991)  loss_bbox_aux_3: 0.1089 (0.1391)  loss_giou_aux_3: 0.2505 (0.2992)  loss_fgl_aux_3: 1.1966 (1.2520)  loss_ddf_aux_3: 0.0015 (0.0017)  loss_mal_aux_4: 0.5825 (0.6868)  loss_bbox_aux_4: 0.1087 (0.1385)  loss_giou_aux_4: 0.2537 (0.2987)  loss_fgl_aux_4: 1.1941 (1.2520)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 1.1514 (1.1336)  loss_bbox_pre: 0.1218 (0.1683)  loss_giou_pre: 0.3005 (0.3529)  loss_mal_enc_0: 1.2295 (1.3182)  loss_bbox_enc_0: 0.2039 (0.2648)  loss_giou_enc_0: 0.4971 (0.5219)  loss_mal_dn_0: 0.7998 (0.8104)  loss_bbox_dn_0: 0.2166 (0.2943)  loss_giou_dn_0: 0.4956 (0.5523)  loss_fgl_dn_0: 1.3055 (1.3031)  loss_ddf_dn_0: 1.1066 (1.1394)  loss_mal_dn_1: 0.7056 (0.7257)  loss_bbox_dn_1: 0.1365 (0.1994)  loss_giou_dn_1: 0.3109 (0.3806)  loss_fgl_dn_1: 1.2056 (1.2347)  loss_ddf_dn_1: 0.2846 (0.3128)  loss_mal_dn_2: 0.6304 (0.6302)  loss_bbox_dn_2: 0.1116 (0.1766)  loss_giou_dn_2: 0.2809 (0.3417)  loss_fgl_dn_2: 1.1792 (1.2150)  loss_ddf_dn_2: 0.0818 (0.0843)  loss_mal_dn_3: 0.5923 (0.5959)  loss_bbox_dn_3: 0.1069 (0.1676)  loss_giou_dn_3: 0.2669 (0.3278)  loss_fgl_dn_3: 1.1758 (1.2105)  loss_ddf_dn_3: 0.0157 (0.0167)  loss_mal_dn_4: 0.5752 (0.5860)  loss_bbox_dn_4: 0.1071 (0.1649)  loss_giou_dn_4: 0.2631 (0.3236)  loss_fgl_dn_4: 1.1764 (1.2103)  loss_ddf_dn_4: 0.0020 (0.0019)  loss_mal_dn_5: 0.5640 (0.5841)  loss_bbox_dn_5: 0.1072 (0.1640)  loss_giou_dn_5: 0.2603 (0.3222)  loss_fgl_dn_5: 1.1759 (1.2108)  loss_mal_dn_pre: 0.7969 (0.8093)  loss_bbox_dn_pre: 0.2230 (0.2974)  loss_giou_dn_pre: 0.4899 (0.5499)  time: 1.1934  data: 0.0123  max mem: 13413\nEpoch: [26]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 36.5622 (37.1021)  loss_mal: 0.6133 (0.6932)  loss_bbox: 0.1137 (0.1415)  loss_giou: 0.2857 (0.3025)  loss_fgl: 1.2320 (1.2534)  loss_mal_aux_0: 1.0488 (1.1252)  loss_bbox_aux_0: 0.1386 (0.1724)  loss_giou_aux_0: 0.3459 (0.3599)  loss_fgl_aux_0: 1.2969 (1.2971)  loss_ddf_aux_0: 0.1131 (0.1265)  loss_mal_aux_1: 0.7896 (0.8750)  loss_bbox_aux_1: 0.1305 (0.1500)  loss_giou_aux_1: 0.3041 (0.3176)  loss_fgl_aux_1: 1.2561 (1.2630)  loss_ddf_aux_1: 0.0340 (0.0422)  loss_mal_aux_2: 0.7212 (0.7491)  loss_bbox_aux_2: 0.1110 (0.1437)  loss_giou_aux_2: 0.2855 (0.3057)  loss_fgl_aux_2: 1.2493 (1.2549)  loss_ddf_aux_2: 0.0068 (0.0078)  loss_mal_aux_3: 0.6504 (0.7085)  loss_bbox_aux_3: 0.1133 (0.1422)  loss_giou_aux_3: 0.2871 (0.3034)  loss_fgl_aux_3: 1.2411 (1.2533)  loss_ddf_aux_3: 0.0014 (0.0017)  loss_mal_aux_4: 0.6172 (0.6960)  loss_bbox_aux_4: 0.1140 (0.1416)  loss_giou_aux_4: 0.2853 (0.3027)  loss_fgl_aux_4: 1.2355 (1.2532)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 1.0459 (1.1254)  loss_bbox_pre: 0.1383 (0.1722)  loss_giou_pre: 0.3446 (0.3594)  loss_mal_enc_0: 1.3057 (1.3142)  loss_bbox_enc_0: 0.2183 (0.2695)  loss_giou_enc_0: 0.5027 (0.5284)  loss_mal_dn_0: 0.8008 (0.8100)  loss_bbox_dn_0: 0.2215 (0.2951)  loss_giou_dn_0: 0.5243 (0.5530)  loss_fgl_dn_0: 1.3146 (1.3043)  loss_ddf_dn_0: 1.0475 (1.1193)  loss_mal_dn_1: 0.7114 (0.7249)  loss_bbox_dn_1: 0.1371 (0.2003)  loss_giou_dn_1: 0.3430 (0.3824)  loss_fgl_dn_1: 1.2339 (1.2364)  loss_ddf_dn_1: 0.2880 (0.3061)  loss_mal_dn_2: 0.6099 (0.6319)  loss_bbox_dn_2: 0.1224 (0.1776)  loss_giou_dn_2: 0.3012 (0.3441)  loss_fgl_dn_2: 1.2200 (1.2171)  loss_ddf_dn_2: 0.0775 (0.0828)  loss_mal_dn_3: 0.5859 (0.5981)  loss_bbox_dn_3: 0.1191 (0.1685)  loss_giou_dn_3: 0.2878 (0.3301)  loss_fgl_dn_3: 1.2143 (1.2125)  loss_ddf_dn_3: 0.0154 (0.0164)  loss_mal_dn_4: 0.5835 (0.5878)  loss_bbox_dn_4: 0.1190 (0.1658)  loss_giou_dn_4: 0.2850 (0.3258)  loss_fgl_dn_4: 1.2087 (1.2121)  loss_ddf_dn_4: 0.0018 (0.0019)  loss_mal_dn_5: 0.5781 (0.5860)  loss_bbox_dn_5: 0.1192 (0.1650)  loss_giou_dn_5: 0.2842 (0.3243)  loss_fgl_dn_5: 1.2053 (1.2126)  loss_mal_dn_pre: 0.7998 (0.8090)  loss_bbox_dn_pre: 0.2196 (0.2978)  loss_giou_dn_pre: 0.5203 (0.5506)  time: 1.2594  data: 0.0113  max mem: 13413\nEpoch: [26] Total time: 0:05:05 (1.2180 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7848  data: 0.4730  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3500  data: 0.0620  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3048  data: 0.0200  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2933  data: 0.0195  max mem: 13413\nTest: Total time: 0:00:07 (0.3182 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.330\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.562\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.330\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.352\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.445\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.538\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.648\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.870\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.788\nbest_stat: {'epoch': 26, 'coco_eval_bbox': 0.3301681420872041}\nEpoch: [27]  [  0/251]  eta: 0:10:37  lr: 0.000003  loss: 32.0615 (32.0615)  loss_mal: 0.4775 (0.4775)  loss_bbox: 0.1049 (0.1049)  loss_giou: 0.2690 (0.2690)  loss_fgl: 1.2160 (1.2160)  loss_mal_aux_0: 1.0537 (1.0537)  loss_bbox_aux_0: 0.1754 (0.1754)  loss_giou_aux_0: 0.3355 (0.3355)  loss_fgl_aux_0: 1.2350 (1.2350)  loss_ddf_aux_0: 0.1472 (0.1472)  loss_mal_aux_1: 0.6699 (0.6699)  loss_bbox_aux_1: 0.1043 (0.1043)  loss_giou_aux_1: 0.2548 (0.2548)  loss_fgl_aux_1: 1.2237 (1.2237)  loss_ddf_aux_1: 0.0584 (0.0584)  loss_mal_aux_2: 0.5537 (0.5537)  loss_bbox_aux_2: 0.0990 (0.0990)  loss_giou_aux_2: 0.2646 (0.2646)  loss_fgl_aux_2: 1.2106 (1.2106)  loss_ddf_aux_2: 0.0130 (0.0130)  loss_mal_aux_3: 0.4451 (0.4451)  loss_bbox_aux_3: 0.0986 (0.0986)  loss_giou_aux_3: 0.2653 (0.2653)  loss_fgl_aux_3: 1.2214 (1.2214)  loss_ddf_aux_3: 0.0026 (0.0026)  loss_mal_aux_4: 0.4783 (0.4783)  loss_bbox_aux_4: 0.1050 (0.1050)  loss_giou_aux_4: 0.2704 (0.2704)  loss_fgl_aux_4: 1.2165 (1.2165)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.0557 (1.0557)  loss_bbox_pre: 0.1531 (0.1531)  loss_giou_pre: 0.3150 (0.3150)  loss_mal_enc_0: 1.3594 (1.3594)  loss_bbox_enc_0: 0.3155 (0.3155)  loss_giou_enc_0: 0.6264 (0.6264)  loss_mal_dn_0: 0.7705 (0.7705)  loss_bbox_dn_0: 0.1664 (0.1664)  loss_giou_dn_0: 0.3958 (0.3958)  loss_fgl_dn_0: 1.2778 (1.2778)  loss_ddf_dn_0: 0.7797 (0.7797)  loss_mal_dn_1: 0.6284 (0.6284)  loss_bbox_dn_1: 0.0986 (0.0986)  loss_giou_dn_1: 0.2414 (0.2414)  loss_fgl_dn_1: 1.1801 (1.1801)  loss_ddf_dn_1: 0.1994 (0.1994)  loss_mal_dn_2: 0.4890 (0.4890)  loss_bbox_dn_2: 0.0831 (0.0831)  loss_giou_dn_2: 0.2087 (0.2087)  loss_fgl_dn_2: 1.1463 (1.1463)  loss_ddf_dn_2: 0.0456 (0.0456)  loss_mal_dn_3: 0.4565 (0.4565)  loss_bbox_dn_3: 0.0774 (0.0774)  loss_giou_dn_3: 0.2004 (0.2004)  loss_fgl_dn_3: 1.1412 (1.1412)  loss_ddf_dn_3: 0.0090 (0.0090)  loss_mal_dn_4: 0.4497 (0.4497)  loss_bbox_dn_4: 0.0763 (0.0763)  loss_giou_dn_4: 0.1994 (0.1994)  loss_fgl_dn_4: 1.1390 (1.1390)  loss_ddf_dn_4: 0.0011 (0.0011)  loss_mal_dn_5: 0.4460 (0.4460)  loss_bbox_dn_5: 0.0760 (0.0760)  loss_giou_dn_5: 0.2000 (0.2000)  loss_fgl_dn_5: 1.1381 (1.1381)  loss_mal_dn_pre: 0.7686 (0.7686)  loss_bbox_dn_pre: 0.1725 (0.1725)  loss_giou_dn_pre: 0.4044 (0.4044)  time: 2.5414  data: 0.9093  max mem: 13413\nEpoch: [27]  [100/251]  eta: 0:03:02  lr: 0.000003  loss: 38.2896 (37.2441)  loss_mal: 0.6460 (0.7415)  loss_bbox: 0.1308 (0.1440)  loss_giou: 0.2845 (0.2992)  loss_fgl: 1.2326 (1.2423)  loss_mal_aux_0: 1.2246 (1.0845)  loss_bbox_aux_0: 0.1450 (0.1830)  loss_giou_aux_0: 0.3656 (0.3752)  loss_fgl_aux_0: 1.2707 (1.2939)  loss_ddf_aux_0: 0.1282 (0.1456)  loss_mal_aux_1: 1.0400 (0.9155)  loss_bbox_aux_1: 0.1368 (0.1567)  loss_giou_aux_1: 0.3041 (0.3230)  loss_fgl_aux_1: 1.2494 (1.2547)  loss_ddf_aux_1: 0.0431 (0.0499)  loss_mal_aux_2: 0.7837 (0.7926)  loss_bbox_aux_2: 0.1327 (0.1479)  loss_giou_aux_2: 0.2888 (0.3063)  loss_fgl_aux_2: 1.2411 (1.2449)  loss_ddf_aux_2: 0.0076 (0.0097)  loss_mal_aux_3: 0.7393 (0.7514)  loss_bbox_aux_3: 0.1310 (0.1451)  loss_giou_aux_3: 0.2807 (0.3015)  loss_fgl_aux_3: 1.2338 (1.2425)  loss_ddf_aux_3: 0.0018 (0.0021)  loss_mal_aux_4: 0.6782 (0.7487)  loss_bbox_aux_4: 0.1312 (0.1442)  loss_giou_aux_4: 0.2834 (0.2997)  loss_fgl_aux_4: 1.2326 (1.2424)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.1826 (1.0841)  loss_bbox_pre: 0.1443 (0.1825)  loss_giou_pre: 0.3654 (0.3741)  loss_mal_enc_0: 1.2041 (1.2791)  loss_bbox_enc_0: 0.2860 (0.2897)  loss_giou_enc_0: 0.5149 (0.5550)  loss_mal_dn_0: 0.7988 (0.8032)  loss_bbox_dn_0: 0.2860 (0.2997)  loss_giou_dn_0: 0.5528 (0.5468)  loss_fgl_dn_0: 1.3089 (1.3049)  loss_ddf_dn_0: 0.9555 (1.1592)  loss_mal_dn_1: 0.6875 (0.7128)  loss_bbox_dn_1: 0.1795 (0.2057)  loss_giou_dn_1: 0.3740 (0.3809)  loss_fgl_dn_1: 1.2284 (1.2316)  loss_ddf_dn_1: 0.2420 (0.3099)  loss_mal_dn_2: 0.6006 (0.6174)  loss_bbox_dn_2: 0.1508 (0.1820)  loss_giou_dn_2: 0.3220 (0.3428)  loss_fgl_dn_2: 1.2106 (1.2101)  loss_ddf_dn_2: 0.0584 (0.0823)  loss_mal_dn_3: 0.5684 (0.5872)  loss_bbox_dn_3: 0.1443 (0.1728)  loss_giou_dn_3: 0.3040 (0.3274)  loss_fgl_dn_3: 1.1954 (1.2043)  loss_ddf_dn_3: 0.0120 (0.0158)  loss_mal_dn_4: 0.5620 (0.5778)  loss_bbox_dn_4: 0.1417 (0.1702)  loss_giou_dn_4: 0.2990 (0.3225)  loss_fgl_dn_4: 1.1887 (1.2038)  loss_ddf_dn_4: 0.0013 (0.0018)  loss_mal_dn_5: 0.5635 (0.5759)  loss_bbox_dn_5: 0.1408 (0.1693)  loss_giou_dn_5: 0.2972 (0.3207)  loss_fgl_dn_5: 1.1859 (1.2041)  loss_mal_dn_pre: 0.7979 (0.8029)  loss_bbox_dn_pre: 0.2824 (0.3003)  loss_giou_dn_pre: 0.5484 (0.5453)  time: 1.2009  data: 0.0120  max mem: 13413\nEpoch: [27]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 35.3247 (36.7020)  loss_mal: 0.5059 (0.6906)  loss_bbox: 0.1265 (0.1428)  loss_giou: 0.2515 (0.2931)  loss_fgl: 1.1939 (1.2397)  loss_mal_aux_0: 1.1338 (1.0782)  loss_bbox_aux_0: 0.1528 (0.1794)  loss_giou_aux_0: 0.3419 (0.3623)  loss_fgl_aux_0: 1.2803 (1.2910)  loss_ddf_aux_0: 0.1266 (0.1412)  loss_mal_aux_1: 0.7827 (0.8730)  loss_bbox_aux_1: 0.1339 (0.1548)  loss_giou_aux_1: 0.2904 (0.3146)  loss_fgl_aux_1: 1.2258 (1.2523)  loss_ddf_aux_1: 0.0409 (0.0470)  loss_mal_aux_2: 0.5938 (0.7496)  loss_bbox_aux_2: 0.1238 (0.1465)  loss_giou_aux_2: 0.2540 (0.2992)  loss_fgl_aux_2: 1.2036 (1.2420)  loss_ddf_aux_2: 0.0073 (0.0089)  loss_mal_aux_3: 0.5229 (0.7062)  loss_bbox_aux_3: 0.1249 (0.1439)  loss_giou_aux_3: 0.2542 (0.2948)  loss_fgl_aux_3: 1.1996 (1.2399)  loss_ddf_aux_3: 0.0015 (0.0019)  loss_mal_aux_4: 0.5103 (0.6983)  loss_bbox_aux_4: 0.1259 (0.1430)  loss_giou_aux_4: 0.2519 (0.2934)  loss_fgl_aux_4: 1.1951 (1.2397)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.1143 (1.0769)  loss_bbox_pre: 0.1527 (0.1789)  loss_giou_pre: 0.3469 (0.3611)  loss_mal_enc_0: 1.2744 (1.2756)  loss_bbox_enc_0: 0.2417 (0.2833)  loss_giou_enc_0: 0.5423 (0.5434)  loss_mal_dn_0: 0.7998 (0.8000)  loss_bbox_dn_0: 0.2386 (0.2930)  loss_giou_dn_0: 0.5400 (0.5429)  loss_fgl_dn_0: 1.3172 (1.3068)  loss_ddf_dn_0: 0.8986 (1.1231)  loss_mal_dn_1: 0.7144 (0.7115)  loss_bbox_dn_1: 0.1750 (0.1995)  loss_giou_dn_1: 0.3372 (0.3726)  loss_fgl_dn_1: 1.2263 (1.2303)  loss_ddf_dn_1: 0.2399 (0.3014)  loss_mal_dn_2: 0.6011 (0.6150)  loss_bbox_dn_2: 0.1427 (0.1761)  loss_giou_dn_2: 0.2972 (0.3331)  loss_fgl_dn_2: 1.1900 (1.2076)  loss_ddf_dn_2: 0.0741 (0.0807)  loss_mal_dn_3: 0.5537 (0.5836)  loss_bbox_dn_3: 0.1280 (0.1670)  loss_giou_dn_3: 0.2784 (0.3182)  loss_fgl_dn_3: 1.1963 (1.2019)  loss_ddf_dn_3: 0.0137 (0.0156)  loss_mal_dn_4: 0.5444 (0.5735)  loss_bbox_dn_4: 0.1257 (0.1641)  loss_giou_dn_4: 0.2719 (0.3135)  loss_fgl_dn_4: 1.1949 (1.2014)  loss_ddf_dn_4: 0.0015 (0.0018)  loss_mal_dn_5: 0.5405 (0.5707)  loss_bbox_dn_5: 0.1249 (0.1632)  loss_giou_dn_5: 0.2697 (0.3119)  loss_fgl_dn_5: 1.1949 (1.2016)  loss_mal_dn_pre: 0.8013 (0.8000)  loss_bbox_dn_pre: 0.2543 (0.2937)  loss_giou_dn_pre: 0.5310 (0.5401)  time: 1.2807  data: 0.0113  max mem: 13413\nEpoch: [27]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 33.5516 (36.5743)  loss_mal: 0.5171 (0.6783)  loss_bbox: 0.0851 (0.1435)  loss_giou: 0.2520 (0.2960)  loss_fgl: 1.1930 (1.2418)  loss_mal_aux_0: 0.9214 (1.0665)  loss_bbox_aux_0: 0.1204 (0.1791)  loss_giou_aux_0: 0.3171 (0.3655)  loss_fgl_aux_0: 1.2642 (1.2931)  loss_ddf_aux_0: 0.1331 (0.1391)  loss_mal_aux_1: 0.7275 (0.8607)  loss_bbox_aux_1: 0.1079 (0.1551)  loss_giou_aux_1: 0.2754 (0.3175)  loss_fgl_aux_1: 1.2324 (1.2540)  loss_ddf_aux_1: 0.0434 (0.0460)  loss_mal_aux_2: 0.6191 (0.7357)  loss_bbox_aux_2: 0.0882 (0.1471)  loss_giou_aux_2: 0.2589 (0.3025)  loss_fgl_aux_2: 1.2020 (1.2437)  loss_ddf_aux_2: 0.0072 (0.0088)  loss_mal_aux_3: 0.5640 (0.6936)  loss_bbox_aux_3: 0.0874 (0.1446)  loss_giou_aux_3: 0.2548 (0.2980)  loss_fgl_aux_3: 1.1939 (1.2418)  loss_ddf_aux_3: 0.0015 (0.0019)  loss_mal_aux_4: 0.5381 (0.6860)  loss_bbox_aux_4: 0.0855 (0.1437)  loss_giou_aux_4: 0.2536 (0.2965)  loss_fgl_aux_4: 1.1932 (1.2417)  loss_ddf_aux_4: 0.0001 (0.0003)  loss_mal_pre: 0.9194 (1.0645)  loss_bbox_pre: 0.1200 (0.1786)  loss_giou_pre: 0.3126 (0.3643)  loss_mal_enc_0: 1.2070 (1.2660)  loss_bbox_enc_0: 0.2141 (0.2800)  loss_giou_enc_0: 0.5340 (0.5440)  loss_mal_dn_0: 0.7744 (0.7986)  loss_bbox_dn_0: 0.2198 (0.2909)  loss_giou_dn_0: 0.5006 (0.5445)  loss_fgl_dn_0: 1.2966 (1.3056)  loss_ddf_dn_0: 0.9799 (1.0909)  loss_mal_dn_1: 0.7046 (0.7111)  loss_bbox_dn_1: 0.1341 (0.1975)  loss_giou_dn_1: 0.3141 (0.3736)  loss_fgl_dn_1: 1.2074 (1.2296)  loss_ddf_dn_1: 0.2734 (0.2931)  loss_mal_dn_2: 0.5874 (0.6127)  loss_bbox_dn_2: 0.1088 (0.1746)  loss_giou_dn_2: 0.2694 (0.3343)  loss_fgl_dn_2: 1.1630 (1.2071)  loss_ddf_dn_2: 0.0732 (0.0790)  loss_mal_dn_3: 0.5469 (0.5809)  loss_bbox_dn_3: 0.0998 (0.1656)  loss_giou_dn_3: 0.2609 (0.3196)  loss_fgl_dn_3: 1.1553 (1.2014)  loss_ddf_dn_3: 0.0137 (0.0152)  loss_mal_dn_4: 0.5327 (0.5709)  loss_bbox_dn_4: 0.0966 (0.1629)  loss_giou_dn_4: 0.2555 (0.3150)  loss_fgl_dn_4: 1.1556 (1.2008)  loss_ddf_dn_4: 0.0015 (0.0017)  loss_mal_dn_5: 0.5288 (0.5684)  loss_bbox_dn_5: 0.0961 (0.1620)  loss_giou_dn_5: 0.2529 (0.3133)  loss_fgl_dn_5: 1.1562 (1.2011)  loss_mal_dn_pre: 0.7764 (0.7984)  loss_bbox_dn_pre: 0.2222 (0.2923)  loss_giou_dn_pre: 0.5097 (0.5421)  time: 1.2038  data: 0.0121  max mem: 13413\nEpoch: [27] Total time: 0:05:07 (1.2236 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7898  data: 0.4814  max mem: 13413\nTest:  [10/25]  eta: 0:00:06    time: 0.4066  data: 0.0661  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3361  data: 0.0221  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2944  data: 0.0205  max mem: 13413\nTest: Total time: 0:00:08 (0.3428 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.536\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.322\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.337\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.435\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.572\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.658\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.860\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.779\nbest_stat: {'epoch': 26, 'coco_eval_bbox': 0.3301681420872041}\nEpoch: [28]  [  0/251]  eta: 0:07:17  lr: 0.000003  loss: 31.8005 (31.8005)  loss_mal: 0.4543 (0.4543)  loss_bbox: 0.1098 (0.1098)  loss_giou: 0.2354 (0.2354)  loss_fgl: 1.1728 (1.1728)  loss_mal_aux_0: 0.9541 (0.9541)  loss_bbox_aux_0: 0.1301 (0.1301)  loss_giou_aux_0: 0.2585 (0.2585)  loss_fgl_aux_0: 1.2303 (1.2303)  loss_ddf_aux_0: 0.1054 (0.1054)  loss_mal_aux_1: 0.6689 (0.6689)  loss_bbox_aux_1: 0.1210 (0.1210)  loss_giou_aux_1: 0.2443 (0.2443)  loss_fgl_aux_1: 1.1908 (1.1908)  loss_ddf_aux_1: 0.0346 (0.0346)  loss_mal_aux_2: 0.4666 (0.4666)  loss_bbox_aux_2: 0.1090 (0.1090)  loss_giou_aux_2: 0.2374 (0.2374)  loss_fgl_aux_2: 1.1733 (1.1733)  loss_ddf_aux_2: 0.0057 (0.0057)  loss_mal_aux_3: 0.4543 (0.4543)  loss_bbox_aux_3: 0.1080 (0.1080)  loss_giou_aux_3: 0.2365 (0.2365)  loss_fgl_aux_3: 1.1706 (1.1706)  loss_ddf_aux_3: 0.0014 (0.0014)  loss_mal_aux_4: 0.4524 (0.4524)  loss_bbox_aux_4: 0.1091 (0.1091)  loss_giou_aux_4: 0.2355 (0.2355)  loss_fgl_aux_4: 1.1712 (1.1712)  loss_ddf_aux_4: 0.0000 (0.0000)  loss_mal_pre: 0.9531 (0.9531)  loss_bbox_pre: 0.1313 (0.1313)  loss_giou_pre: 0.2598 (0.2598)  loss_mal_enc_0: 1.2539 (1.2539)  loss_bbox_enc_0: 0.2177 (0.2177)  loss_giou_enc_0: 0.3407 (0.3407)  loss_mal_dn_0: 0.7764 (0.7764)  loss_bbox_dn_0: 0.2632 (0.2632)  loss_giou_dn_0: 0.4322 (0.4322)  loss_fgl_dn_0: 1.3121 (1.3121)  loss_ddf_dn_0: 1.0583 (1.0583)  loss_mal_dn_1: 0.6489 (0.6489)  loss_bbox_dn_1: 0.1457 (0.1457)  loss_giou_dn_1: 0.2774 (0.2774)  loss_fgl_dn_1: 1.1911 (1.1911)  loss_ddf_dn_1: 0.2600 (0.2600)  loss_mal_dn_2: 0.5127 (0.5127)  loss_bbox_dn_2: 0.1155 (0.1155)  loss_giou_dn_2: 0.2433 (0.2433)  loss_fgl_dn_2: 1.1494 (1.1494)  loss_ddf_dn_2: 0.0632 (0.0632)  loss_mal_dn_3: 0.4951 (0.4951)  loss_bbox_dn_3: 0.1040 (0.1040)  loss_giou_dn_3: 0.2260 (0.2260)  loss_fgl_dn_3: 1.1414 (1.1414)  loss_ddf_dn_3: 0.0126 (0.0126)  loss_mal_dn_4: 0.4751 (0.4751)  loss_bbox_dn_4: 0.1045 (0.1045)  loss_giou_dn_4: 0.2225 (0.2225)  loss_fgl_dn_4: 1.1398 (1.1398)  loss_ddf_dn_4: 0.0013 (0.0013)  loss_mal_dn_5: 0.4724 (0.4724)  loss_bbox_dn_5: 0.1064 (0.1064)  loss_giou_dn_5: 0.2225 (0.2225)  loss_fgl_dn_5: 1.1390 (1.1390)  loss_mal_dn_pre: 0.7788 (0.7788)  loss_bbox_dn_pre: 0.2713 (0.2713)  loss_giou_dn_pre: 0.4404 (0.4404)  time: 1.7432  data: 0.5356  max mem: 13413\nEpoch: [28]  [100/251]  eta: 0:03:05  lr: 0.000003  loss: 34.5985 (35.7791)  loss_mal: 0.5151 (0.6668)  loss_bbox: 0.1040 (0.1245)  loss_giou: 0.2443 (0.2752)  loss_fgl: 1.1796 (1.2274)  loss_mal_aux_0: 1.1426 (1.0845)  loss_bbox_aux_0: 0.1426 (0.1554)  loss_giou_aux_0: 0.2846 (0.3372)  loss_fgl_aux_0: 1.2546 (1.2834)  loss_ddf_aux_0: 0.1515 (0.1437)  loss_mal_aux_1: 0.7666 (0.8289)  loss_bbox_aux_1: 0.1098 (0.1310)  loss_giou_aux_1: 0.2429 (0.2920)  loss_fgl_aux_1: 1.1960 (1.2399)  loss_ddf_aux_1: 0.0421 (0.0453)  loss_mal_aux_2: 0.5840 (0.7142)  loss_bbox_aux_2: 0.1019 (0.1257)  loss_giou_aux_2: 0.2513 (0.2798)  loss_fgl_aux_2: 1.1920 (1.2296)  loss_ddf_aux_2: 0.0071 (0.0083)  loss_mal_aux_3: 0.5674 (0.6824)  loss_bbox_aux_3: 0.1010 (0.1249)  loss_giou_aux_3: 0.2453 (0.2766)  loss_fgl_aux_3: 1.1885 (1.2281)  loss_ddf_aux_3: 0.0014 (0.0017)  loss_mal_aux_4: 0.5254 (0.6747)  loss_bbox_aux_4: 0.1038 (0.1248)  loss_giou_aux_4: 0.2437 (0.2757)  loss_fgl_aux_4: 1.1820 (1.2276)  loss_ddf_aux_4: 0.0003 (0.0002)  loss_mal_pre: 1.1406 (1.0856)  loss_bbox_pre: 0.1425 (0.1552)  loss_giou_pre: 0.2790 (0.3366)  loss_mal_enc_0: 1.2393 (1.2538)  loss_bbox_enc_0: 0.2359 (0.2545)  loss_giou_enc_0: 0.4937 (0.5099)  loss_mal_dn_0: 0.7993 (0.7908)  loss_bbox_dn_0: 0.2549 (0.2801)  loss_giou_dn_0: 0.5208 (0.5295)  loss_fgl_dn_0: 1.3050 (1.3076)  loss_ddf_dn_0: 0.9977 (1.1346)  loss_mal_dn_1: 0.6938 (0.6974)  loss_bbox_dn_1: 0.1565 (0.1838)  loss_giou_dn_1: 0.3248 (0.3550)  loss_fgl_dn_1: 1.2143 (1.2231)  loss_ddf_dn_1: 0.2609 (0.3020)  loss_mal_dn_2: 0.5854 (0.5962)  loss_bbox_dn_2: 0.1355 (0.1609)  loss_giou_dn_2: 0.2897 (0.3151)  loss_fgl_dn_2: 1.1716 (1.2007)  loss_ddf_dn_2: 0.0676 (0.0819)  loss_mal_dn_3: 0.5254 (0.5639)  loss_bbox_dn_3: 0.1313 (0.1528)  loss_giou_dn_3: 0.2680 (0.3008)  loss_fgl_dn_3: 1.1577 (1.1951)  loss_ddf_dn_3: 0.0135 (0.0159)  loss_mal_dn_4: 0.5176 (0.5537)  loss_bbox_dn_4: 0.1277 (0.1504)  loss_giou_dn_4: 0.2567 (0.2965)  loss_fgl_dn_4: 1.1546 (1.1941)  loss_ddf_dn_4: 0.0015 (0.0018)  loss_mal_dn_5: 0.5166 (0.5500)  loss_bbox_dn_5: 0.1278 (0.1496)  loss_giou_dn_5: 0.2525 (0.2949)  loss_fgl_dn_5: 1.1532 (1.1942)  loss_mal_dn_pre: 0.8027 (0.7905)  loss_bbox_dn_pre: 0.2674 (0.2838)  loss_giou_dn_pre: 0.5155 (0.5272)  time: 1.2903  data: 0.0123  max mem: 13413\nEpoch: [28]  [200/251]  eta: 0:01:02  lr: 0.000003  loss: 35.5753 (35.7543)  loss_mal: 0.5391 (0.6676)  loss_bbox: 0.1083 (0.1250)  loss_giou: 0.2762 (0.2776)  loss_fgl: 1.2254 (1.2283)  loss_mal_aux_0: 1.1328 (1.0716)  loss_bbox_aux_0: 0.1275 (0.1543)  loss_giou_aux_0: 0.3434 (0.3356)  loss_fgl_aux_0: 1.2954 (1.2818)  loss_ddf_aux_0: 0.1269 (0.1446)  loss_mal_aux_1: 0.7720 (0.8308)  loss_bbox_aux_1: 0.1218 (0.1319)  loss_giou_aux_1: 0.3102 (0.2926)  loss_fgl_aux_1: 1.2529 (1.2384)  loss_ddf_aux_1: 0.0394 (0.0454)  loss_mal_aux_2: 0.5752 (0.7172)  loss_bbox_aux_2: 0.1139 (0.1265)  loss_giou_aux_2: 0.2800 (0.2819)  loss_fgl_aux_2: 1.2510 (1.2300)  loss_ddf_aux_2: 0.0078 (0.0085)  loss_mal_aux_3: 0.5479 (0.6801)  loss_bbox_aux_3: 0.1104 (0.1255)  loss_giou_aux_3: 0.2747 (0.2789)  loss_fgl_aux_3: 1.2373 (1.2286)  loss_ddf_aux_3: 0.0016 (0.0018)  loss_mal_aux_4: 0.5400 (0.6720)  loss_bbox_aux_4: 0.1088 (0.1251)  loss_giou_aux_4: 0.2746 (0.2779)  loss_fgl_aux_4: 1.2286 (1.2283)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 1.1309 (1.0719)  loss_bbox_pre: 0.1280 (0.1540)  loss_giou_pre: 0.3439 (0.3347)  loss_mal_enc_0: 1.2168 (1.2327)  loss_bbox_enc_0: 0.1871 (0.2506)  loss_giou_enc_0: 0.5386 (0.5116)  loss_mal_dn_0: 0.8096 (0.7924)  loss_bbox_dn_0: 0.2182 (0.2767)  loss_giou_dn_0: 0.5023 (0.5289)  loss_fgl_dn_0: 1.3134 (1.3059)  loss_ddf_dn_0: 1.1225 (1.1470)  loss_mal_dn_1: 0.7026 (0.6974)  loss_bbox_dn_1: 0.1545 (0.1829)  loss_giou_dn_1: 0.3543 (0.3566)  loss_fgl_dn_1: 1.2186 (1.2203)  loss_ddf_dn_1: 0.2878 (0.3046)  loss_mal_dn_2: 0.5854 (0.5993)  loss_bbox_dn_2: 0.1242 (0.1605)  loss_giou_dn_2: 0.3133 (0.3174)  loss_fgl_dn_2: 1.1995 (1.1976)  loss_ddf_dn_2: 0.0767 (0.0842)  loss_mal_dn_3: 0.5654 (0.5680)  loss_bbox_dn_3: 0.1148 (0.1520)  loss_giou_dn_3: 0.2911 (0.3027)  loss_fgl_dn_3: 1.1836 (1.1919)  loss_ddf_dn_3: 0.0160 (0.0164)  loss_mal_dn_4: 0.5586 (0.5583)  loss_bbox_dn_4: 0.1141 (0.1492)  loss_giou_dn_4: 0.2871 (0.2981)  loss_fgl_dn_4: 1.1763 (1.1909)  loss_ddf_dn_4: 0.0018 (0.0018)  loss_mal_dn_5: 0.5586 (0.5557)  loss_bbox_dn_5: 0.1155 (0.1484)  loss_giou_dn_5: 0.2849 (0.2966)  loss_fgl_dn_5: 1.1776 (1.1910)  loss_mal_dn_pre: 0.8066 (0.7924)  loss_bbox_dn_pre: 0.2159 (0.2793)  loss_giou_dn_pre: 0.4965 (0.5265)  time: 1.2186  data: 0.0106  max mem: 13413\nEpoch: [28]  [250/251]  eta: 0:00:01  lr: 0.000003  loss: 36.0267 (35.6819)  loss_mal: 0.6494 (0.6636)  loss_bbox: 0.1088 (0.1240)  loss_giou: 0.2415 (0.2746)  loss_fgl: 1.2341 (1.2284)  loss_mal_aux_0: 1.1064 (1.0821)  loss_bbox_aux_0: 0.1202 (0.1522)  loss_giou_aux_0: 0.2863 (0.3308)  loss_fgl_aux_0: 1.2542 (1.2807)  loss_ddf_aux_0: 0.1133 (0.1435)  loss_mal_aux_1: 0.7998 (0.8322)  loss_bbox_aux_1: 0.1137 (0.1309)  loss_giou_aux_1: 0.2534 (0.2884)  loss_fgl_aux_1: 1.2268 (1.2378)  loss_ddf_aux_1: 0.0373 (0.0450)  loss_mal_aux_2: 0.7544 (0.7149)  loss_bbox_aux_2: 0.1078 (0.1255)  loss_giou_aux_2: 0.2462 (0.2784)  loss_fgl_aux_2: 1.2287 (1.2297)  loss_ddf_aux_2: 0.0076 (0.0085)  loss_mal_aux_3: 0.6587 (0.6764)  loss_bbox_aux_3: 0.1092 (0.1244)  loss_giou_aux_3: 0.2418 (0.2758)  loss_fgl_aux_3: 1.2300 (1.2284)  loss_ddf_aux_3: 0.0017 (0.0018)  loss_mal_aux_4: 0.6313 (0.6666)  loss_bbox_aux_4: 0.1091 (0.1242)  loss_giou_aux_4: 0.2413 (0.2750)  loss_fgl_aux_4: 1.2333 (1.2283)  loss_ddf_aux_4: 0.0003 (0.0002)  loss_mal_pre: 1.1035 (1.0823)  loss_bbox_pre: 0.1211 (0.1521)  loss_giou_pre: 0.2862 (0.3301)  loss_mal_enc_0: 1.2520 (1.2471)  loss_bbox_enc_0: 0.1964 (0.2486)  loss_giou_enc_0: 0.4773 (0.5051)  loss_mal_dn_0: 0.7734 (0.7928)  loss_bbox_dn_0: 0.2342 (0.2766)  loss_giou_dn_0: 0.5024 (0.5254)  loss_fgl_dn_0: 1.3059 (1.3066)  loss_ddf_dn_0: 0.9173 (1.1322)  loss_mal_dn_1: 0.6626 (0.6949)  loss_bbox_dn_1: 0.1446 (0.1823)  loss_giou_dn_1: 0.3337 (0.3532)  loss_fgl_dn_1: 1.2120 (1.2207)  loss_ddf_dn_1: 0.2321 (0.2996)  loss_mal_dn_2: 0.5864 (0.5972)  loss_bbox_dn_2: 0.1262 (0.1600)  loss_giou_dn_2: 0.3085 (0.3147)  loss_fgl_dn_2: 1.1889 (1.1984)  loss_ddf_dn_2: 0.0653 (0.0828)  loss_mal_dn_3: 0.5654 (0.5664)  loss_bbox_dn_3: 0.1208 (0.1517)  loss_giou_dn_3: 0.2995 (0.3004)  loss_fgl_dn_3: 1.1868 (1.1929)  loss_ddf_dn_3: 0.0127 (0.0161)  loss_mal_dn_4: 0.5513 (0.5562)  loss_bbox_dn_4: 0.1187 (0.1491)  loss_giou_dn_4: 0.2967 (0.2960)  loss_fgl_dn_4: 1.1904 (1.1922)  loss_ddf_dn_4: 0.0014 (0.0018)  loss_mal_dn_5: 0.5640 (0.5538)  loss_bbox_dn_5: 0.1187 (0.1484)  loss_giou_dn_5: 0.2926 (0.2945)  loss_fgl_dn_5: 1.1903 (1.1924)  loss_mal_dn_pre: 0.7739 (0.7927)  loss_bbox_dn_pre: 0.2396 (0.2790)  loss_giou_dn_pre: 0.5045 (0.5232)  time: 1.2562  data: 0.0114  max mem: 13413\nEpoch: [28] Total time: 0:05:08 (1.2275 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7855  data: 0.4772  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3502  data: 0.0625  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3040  data: 0.0199  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2922  data: 0.0188  max mem: 13413\nTest: Total time: 0:00:07 (0.3169 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.325\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.541\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.323\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.344\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.433\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.566\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.658\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.633\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.860\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.743\nbest_stat: {'epoch': 26, 'coco_eval_bbox': 0.3301681420872041}\nEpoch: [29]  [  0/251]  eta: 0:10:26  lr: 0.000003  loss: 38.6333 (38.6333)  loss_mal: 0.7129 (0.7129)  loss_bbox: 0.2319 (0.2319)  loss_giou: 0.3512 (0.3512)  loss_fgl: 1.2961 (1.2961)  loss_mal_aux_0: 0.9126 (0.9126)  loss_bbox_aux_0: 0.2722 (0.2722)  loss_giou_aux_0: 0.3841 (0.3841)  loss_fgl_aux_0: 1.3413 (1.3413)  loss_ddf_aux_0: 0.1714 (0.1714)  loss_mal_aux_1: 0.7646 (0.7646)  loss_bbox_aux_1: 0.2590 (0.2590)  loss_giou_aux_1: 0.3544 (0.3544)  loss_fgl_aux_1: 1.3223 (1.3223)  loss_ddf_aux_1: 0.0617 (0.0617)  loss_mal_aux_2: 0.6689 (0.6689)  loss_bbox_aux_2: 0.2426 (0.2426)  loss_giou_aux_2: 0.3535 (0.3535)  loss_fgl_aux_2: 1.3191 (1.3191)  loss_ddf_aux_2: 0.0103 (0.0103)  loss_mal_aux_3: 0.7065 (0.7065)  loss_bbox_aux_3: 0.2366 (0.2366)  loss_giou_aux_3: 0.3549 (0.3549)  loss_fgl_aux_3: 1.3077 (1.3077)  loss_ddf_aux_3: 0.0023 (0.0023)  loss_mal_aux_4: 0.7266 (0.7266)  loss_bbox_aux_4: 0.2334 (0.2334)  loss_giou_aux_4: 0.3529 (0.3529)  loss_fgl_aux_4: 1.3010 (1.3010)  loss_ddf_aux_4: 0.0004 (0.0004)  loss_mal_pre: 0.9180 (0.9180)  loss_bbox_pre: 0.2708 (0.2708)  loss_giou_pre: 0.3793 (0.3793)  loss_mal_enc_0: 1.3428 (1.3428)  loss_bbox_enc_0: 0.2122 (0.2122)  loss_giou_enc_0: 0.4099 (0.4099)  loss_mal_dn_0: 0.7681 (0.7681)  loss_bbox_dn_0: 0.3493 (0.3493)  loss_giou_dn_0: 0.5078 (0.5078)  loss_fgl_dn_0: 1.3178 (1.3178)  loss_ddf_dn_0: 1.2229 (1.2229)  loss_mal_dn_1: 0.7051 (0.7051)  loss_bbox_dn_1: 0.3035 (0.3035)  loss_giou_dn_1: 0.3965 (0.3965)  loss_fgl_dn_1: 1.2780 (1.2780)  loss_ddf_dn_1: 0.3226 (0.3226)  loss_mal_dn_2: 0.6099 (0.6099)  loss_bbox_dn_2: 0.2708 (0.2708)  loss_giou_dn_2: 0.3771 (0.3771)  loss_fgl_dn_2: 1.2855 (1.2855)  loss_ddf_dn_2: 0.0843 (0.0843)  loss_mal_dn_3: 0.6069 (0.6069)  loss_bbox_dn_3: 0.2520 (0.2520)  loss_giou_dn_3: 0.3655 (0.3655)  loss_fgl_dn_3: 1.2699 (1.2699)  loss_ddf_dn_3: 0.0163 (0.0163)  loss_mal_dn_4: 0.6030 (0.6030)  loss_bbox_dn_4: 0.2418 (0.2418)  loss_giou_dn_4: 0.3582 (0.3582)  loss_fgl_dn_4: 1.2605 (1.2605)  loss_ddf_dn_4: 0.0020 (0.0020)  loss_mal_dn_5: 0.6074 (0.6074)  loss_bbox_dn_5: 0.2363 (0.2363)  loss_giou_dn_5: 0.3531 (0.3531)  loss_fgl_dn_5: 1.2522 (1.2522)  loss_mal_dn_pre: 0.7651 (0.7651)  loss_bbox_dn_pre: 0.3544 (0.3544)  loss_giou_dn_pre: 0.5040 (0.5040)  time: 2.4953  data: 1.0629  max mem: 13413\nEpoch: [29]  [100/251]  eta: 0:03:04  lr: 0.000002  loss: 33.9283 (35.8916)  loss_mal: 0.5625 (0.6703)  loss_bbox: 0.0831 (0.1287)  loss_giou: 0.2440 (0.2762)  loss_fgl: 1.2070 (1.2421)  loss_mal_aux_0: 0.9390 (1.0291)  loss_bbox_aux_0: 0.1246 (0.1548)  loss_giou_aux_0: 0.3136 (0.3386)  loss_fgl_aux_0: 1.2790 (1.2904)  loss_ddf_aux_0: 0.1300 (0.1493)  loss_mal_aux_1: 0.8052 (0.8317)  loss_bbox_aux_1: 0.0969 (0.1346)  loss_giou_aux_1: 0.2690 (0.2919)  loss_fgl_aux_1: 1.2202 (1.2478)  loss_ddf_aux_1: 0.0383 (0.0485)  loss_mal_aux_2: 0.6201 (0.7227)  loss_bbox_aux_2: 0.0892 (0.1299)  loss_giou_aux_2: 0.2597 (0.2798)  loss_fgl_aux_2: 1.2037 (1.2412)  loss_ddf_aux_2: 0.0072 (0.0095)  loss_mal_aux_3: 0.5537 (0.6799)  loss_bbox_aux_3: 0.0842 (0.1292)  loss_giou_aux_3: 0.2456 (0.2774)  loss_fgl_aux_3: 1.2039 (1.2408)  loss_ddf_aux_3: 0.0014 (0.0020)  loss_mal_aux_4: 0.5571 (0.6698)  loss_bbox_aux_4: 0.0833 (0.1288)  loss_giou_aux_4: 0.2447 (0.2765)  loss_fgl_aux_4: 1.2070 (1.2414)  loss_ddf_aux_4: 0.0002 (0.0003)  loss_mal_pre: 0.9385 (1.0286)  loss_bbox_pre: 0.1210 (0.1537)  loss_giou_pre: 0.3112 (0.3371)  loss_mal_enc_0: 1.1875 (1.2269)  loss_bbox_enc_0: 0.2242 (0.2503)  loss_giou_enc_0: 0.5049 (0.5118)  loss_mal_dn_0: 0.7808 (0.7926)  loss_bbox_dn_0: 0.2159 (0.2776)  loss_giou_dn_0: 0.4813 (0.5211)  loss_fgl_dn_0: 1.3178 (1.3191)  loss_ddf_dn_0: 0.9699 (1.1692)  loss_mal_dn_1: 0.6792 (0.6992)  loss_bbox_dn_1: 0.1429 (0.1872)  loss_giou_dn_1: 0.3086 (0.3539)  loss_fgl_dn_1: 1.2128 (1.2319)  loss_ddf_dn_1: 0.2480 (0.3071)  loss_mal_dn_2: 0.5737 (0.6015)  loss_bbox_dn_2: 0.1251 (0.1651)  loss_giou_dn_2: 0.2671 (0.3160)  loss_fgl_dn_2: 1.1838 (1.2107)  loss_ddf_dn_2: 0.0690 (0.0864)  loss_mal_dn_3: 0.5293 (0.5714)  loss_bbox_dn_3: 0.1232 (0.1574)  loss_giou_dn_3: 0.2543 (0.3023)  loss_fgl_dn_3: 1.1755 (1.2047)  loss_ddf_dn_3: 0.0125 (0.0165)  loss_mal_dn_4: 0.5137 (0.5613)  loss_bbox_dn_4: 0.1168 (0.1554)  loss_giou_dn_4: 0.2500 (0.2983)  loss_fgl_dn_4: 1.1729 (1.2048)  loss_ddf_dn_4: 0.0015 (0.0018)  loss_mal_dn_5: 0.5103 (0.5608)  loss_bbox_dn_5: 0.1146 (0.1548)  loss_giou_dn_5: 0.2490 (0.2971)  loss_fgl_dn_5: 1.1718 (1.2052)  loss_mal_dn_pre: 0.7793 (0.7920)  loss_bbox_dn_pre: 0.2189 (0.2791)  loss_giou_dn_pre: 0.4816 (0.5182)  time: 1.1418  data: 0.0110  max mem: 13413\nEpoch: [29]  [200/251]  eta: 0:01:02  lr: 0.000002  loss: 35.4834 (35.9675)  loss_mal: 0.5864 (0.6607)  loss_bbox: 0.1207 (0.1300)  loss_giou: 0.2745 (0.2798)  loss_fgl: 1.2331 (1.2407)  loss_mal_aux_0: 1.0996 (1.0511)  loss_bbox_aux_0: 0.1614 (0.1603)  loss_giou_aux_0: 0.3343 (0.3390)  loss_fgl_aux_0: 1.2861 (1.2917)  loss_ddf_aux_0: 0.1307 (0.1460)  loss_mal_aux_1: 0.7856 (0.8193)  loss_bbox_aux_1: 0.1294 (0.1384)  loss_giou_aux_1: 0.2715 (0.2950)  loss_fgl_aux_1: 1.2486 (1.2488)  loss_ddf_aux_1: 0.0383 (0.0472)  loss_mal_aux_2: 0.6265 (0.7126)  loss_bbox_aux_2: 0.1239 (0.1324)  loss_giou_aux_2: 0.2788 (0.2838)  loss_fgl_aux_2: 1.2455 (1.2417)  loss_ddf_aux_2: 0.0070 (0.0093)  loss_mal_aux_3: 0.5806 (0.6746)  loss_bbox_aux_3: 0.1237 (0.1307)  loss_giou_aux_3: 0.2749 (0.2811)  loss_fgl_aux_3: 1.2306 (1.2401)  loss_ddf_aux_3: 0.0014 (0.0019)  loss_mal_aux_4: 0.5889 (0.6635)  loss_bbox_aux_4: 0.1202 (0.1302)  loss_giou_aux_4: 0.2755 (0.2802)  loss_fgl_aux_4: 1.2307 (1.2404)  loss_ddf_aux_4: 0.0002 (0.0003)  loss_mal_pre: 1.0977 (1.0497)  loss_bbox_pre: 0.1627 (0.1594)  loss_giou_pre: 0.3378 (0.3378)  loss_mal_enc_0: 1.2158 (1.2386)  loss_bbox_enc_0: 0.2383 (0.2580)  loss_giou_enc_0: 0.5070 (0.5113)  loss_mal_dn_0: 0.8096 (0.7935)  loss_bbox_dn_0: 0.2976 (0.2838)  loss_giou_dn_0: 0.5471 (0.5293)  loss_fgl_dn_0: 1.2991 (1.3129)  loss_ddf_dn_0: 1.1244 (1.1776)  loss_mal_dn_1: 0.7158 (0.6974)  loss_bbox_dn_1: 0.1774 (0.1898)  loss_giou_dn_1: 0.3669 (0.3587)  loss_fgl_dn_1: 1.2107 (1.2253)  loss_ddf_dn_1: 0.3022 (0.3099)  loss_mal_dn_2: 0.6128 (0.5994)  loss_bbox_dn_2: 0.1556 (0.1670)  loss_giou_dn_2: 0.3104 (0.3199)  loss_fgl_dn_2: 1.1717 (1.2035)  loss_ddf_dn_2: 0.0844 (0.0878)  loss_mal_dn_3: 0.5708 (0.5696)  loss_bbox_dn_3: 0.1513 (0.1588)  loss_giou_dn_3: 0.2934 (0.3062)  loss_fgl_dn_3: 1.1628 (1.1979)  loss_ddf_dn_3: 0.0156 (0.0169)  loss_mal_dn_4: 0.5713 (0.5607)  loss_bbox_dn_4: 0.1491 (0.1564)  loss_giou_dn_4: 0.2864 (0.3021)  loss_fgl_dn_4: 1.1624 (1.1978)  loss_ddf_dn_4: 0.0017 (0.0019)  loss_mal_dn_5: 0.5605 (0.5590)  loss_bbox_dn_5: 0.1489 (0.1557)  loss_giou_dn_5: 0.2847 (0.3008)  loss_fgl_dn_5: 1.1623 (1.1982)  loss_mal_dn_pre: 0.8101 (0.7936)  loss_bbox_dn_pre: 0.2993 (0.2846)  loss_giou_dn_pre: 0.5379 (0.5261)  time: 1.1652  data: 0.0119  max mem: 13413\nEpoch: [29]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 35.3878 (35.9872)  loss_mal: 0.6182 (0.6698)  loss_bbox: 0.0959 (0.1292)  loss_giou: 0.2660 (0.2813)  loss_fgl: 1.2158 (1.2395)  loss_mal_aux_0: 1.0596 (1.0544)  loss_bbox_aux_0: 0.1266 (0.1591)  loss_giou_aux_0: 0.3178 (0.3402)  loss_fgl_aux_0: 1.2786 (1.2916)  loss_ddf_aux_0: 0.1430 (0.1460)  loss_mal_aux_1: 0.7329 (0.8296)  loss_bbox_aux_1: 0.1058 (0.1378)  loss_giou_aux_1: 0.2918 (0.2969)  loss_fgl_aux_1: 1.2363 (1.2488)  loss_ddf_aux_1: 0.0439 (0.0476)  loss_mal_aux_2: 0.6484 (0.7200)  loss_bbox_aux_2: 0.0994 (0.1314)  loss_giou_aux_2: 0.2768 (0.2853)  loss_fgl_aux_2: 1.2175 (1.2406)  loss_ddf_aux_2: 0.0082 (0.0095)  loss_mal_aux_3: 0.6201 (0.6838)  loss_bbox_aux_3: 0.0976 (0.1299)  loss_giou_aux_3: 0.2701 (0.2826)  loss_fgl_aux_3: 1.2117 (1.2389)  loss_ddf_aux_3: 0.0019 (0.0020)  loss_mal_aux_4: 0.6172 (0.6734)  loss_bbox_aux_4: 0.0962 (0.1294)  loss_giou_aux_4: 0.2662 (0.2817)  loss_fgl_aux_4: 1.2119 (1.2391)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 1.0596 (1.0533)  loss_bbox_pre: 0.1248 (0.1581)  loss_giou_pre: 0.3183 (0.3389)  loss_mal_enc_0: 1.2178 (1.2380)  loss_bbox_enc_0: 0.1984 (0.2533)  loss_giou_enc_0: 0.4877 (0.5090)  loss_mal_dn_0: 0.7871 (0.7930)  loss_bbox_dn_0: 0.2283 (0.2800)  loss_giou_dn_0: 0.5037 (0.5289)  loss_fgl_dn_0: 1.3010 (1.3129)  loss_ddf_dn_0: 1.2779 (1.1715)  loss_mal_dn_1: 0.6743 (0.6970)  loss_bbox_dn_1: 0.1413 (0.1873)  loss_giou_dn_1: 0.3146 (0.3589)  loss_fgl_dn_1: 1.1974 (1.2255)  loss_ddf_dn_1: 0.3378 (0.3079)  loss_mal_dn_2: 0.5884 (0.5998)  loss_bbox_dn_2: 0.1194 (0.1647)  loss_giou_dn_2: 0.2814 (0.3200)  loss_fgl_dn_2: 1.1787 (1.2039)  loss_ddf_dn_2: 0.1006 (0.0877)  loss_mal_dn_3: 0.5547 (0.5698)  loss_bbox_dn_3: 0.1113 (0.1567)  loss_giou_dn_3: 0.2770 (0.3065)  loss_fgl_dn_3: 1.1611 (1.1984)  loss_ddf_dn_3: 0.0184 (0.0168)  loss_mal_dn_4: 0.5537 (0.5609)  loss_bbox_dn_4: 0.1087 (0.1543)  loss_giou_dn_4: 0.2754 (0.3024)  loss_fgl_dn_4: 1.1592 (1.1982)  loss_ddf_dn_4: 0.0020 (0.0019)  loss_mal_dn_5: 0.5571 (0.5592)  loss_bbox_dn_5: 0.1080 (0.1536)  loss_giou_dn_5: 0.2741 (0.3011)  loss_fgl_dn_5: 1.1595 (1.1987)  loss_mal_dn_pre: 0.7900 (0.7932)  loss_bbox_dn_pre: 0.2374 (0.2810)  loss_giou_dn_pre: 0.5088 (0.5252)  time: 1.3033  data: 0.0110  max mem: 13413\nEpoch: [29] Total time: 0:05:10 (1.2367 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7748  data: 0.4602  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3518  data: 0.0632  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3067  data: 0.0219  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2931  data: 0.0194  max mem: 13413\nTest: Total time: 0:00:07 (0.3190 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.05s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.535\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.327\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.446\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.578\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.644\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.658\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.630\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.860\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.743\nbest_stat: {'epoch': 26, 'coco_eval_bbox': 0.3301681420872041}\nEpoch: [30]  [  0/251]  eta: 0:08:45  lr: 0.000002  loss: 35.2382 (35.2382)  loss_mal: 0.5186 (0.5186)  loss_bbox: 0.1146 (0.1146)  loss_giou: 0.2390 (0.2390)  loss_fgl: 1.2625 (1.2625)  loss_mal_aux_0: 1.0049 (1.0049)  loss_bbox_aux_0: 0.1300 (0.1300)  loss_giou_aux_0: 0.2956 (0.2956)  loss_fgl_aux_0: 1.2591 (1.2591)  loss_ddf_aux_0: 0.1244 (0.1244)  loss_mal_aux_1: 0.6719 (0.6719)  loss_bbox_aux_1: 0.1175 (0.1175)  loss_giou_aux_1: 0.2526 (0.2526)  loss_fgl_aux_1: 1.2692 (1.2692)  loss_ddf_aux_1: 0.0436 (0.0436)  loss_mal_aux_2: 0.5190 (0.5190)  loss_bbox_aux_2: 0.1151 (0.1151)  loss_giou_aux_2: 0.2352 (0.2352)  loss_fgl_aux_2: 1.2715 (1.2715)  loss_ddf_aux_2: 0.0079 (0.0079)  loss_mal_aux_3: 0.5068 (0.5068)  loss_bbox_aux_3: 0.1154 (0.1154)  loss_giou_aux_3: 0.2380 (0.2380)  loss_fgl_aux_3: 1.2662 (1.2662)  loss_ddf_aux_3: 0.0014 (0.0014)  loss_mal_aux_4: 0.5088 (0.5088)  loss_bbox_aux_4: 0.1154 (0.1154)  loss_giou_aux_4: 0.2404 (0.2404)  loss_fgl_aux_4: 1.2649 (1.2649)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.0049 (1.0049)  loss_bbox_pre: 0.1297 (0.1297)  loss_giou_pre: 0.2947 (0.2947)  loss_mal_enc_0: 1.3721 (1.3721)  loss_bbox_enc_0: 0.2850 (0.2850)  loss_giou_enc_0: 0.4735 (0.4735)  loss_mal_dn_0: 0.8154 (0.8154)  loss_bbox_dn_0: 0.3715 (0.3715)  loss_giou_dn_0: 0.5533 (0.5533)  loss_fgl_dn_0: 1.3228 (1.3228)  loss_ddf_dn_0: 1.2954 (1.2954)  loss_mal_dn_1: 0.7339 (0.7339)  loss_bbox_dn_1: 0.2294 (0.2294)  loss_giou_dn_1: 0.3550 (0.3550)  loss_fgl_dn_1: 1.2321 (1.2321)  loss_ddf_dn_1: 0.3116 (0.3116)  loss_mal_dn_2: 0.6421 (0.6421)  loss_bbox_dn_2: 0.2033 (0.2033)  loss_giou_dn_2: 0.3077 (0.3077)  loss_fgl_dn_2: 1.1930 (1.1930)  loss_ddf_dn_2: 0.0770 (0.0770)  loss_mal_dn_3: 0.5630 (0.5630)  loss_bbox_dn_3: 0.1824 (0.1824)  loss_giou_dn_3: 0.2743 (0.2743)  loss_fgl_dn_3: 1.1798 (1.1798)  loss_ddf_dn_3: 0.0130 (0.0130)  loss_mal_dn_4: 0.5630 (0.5630)  loss_bbox_dn_4: 0.1796 (0.1796)  loss_giou_dn_4: 0.2672 (0.2672)  loss_fgl_dn_4: 1.1764 (1.1764)  loss_ddf_dn_4: 0.0013 (0.0013)  loss_mal_dn_5: 0.5669 (0.5669)  loss_bbox_dn_5: 0.1762 (0.1762)  loss_giou_dn_5: 0.2627 (0.2627)  loss_fgl_dn_5: 1.1743 (1.1743)  loss_mal_dn_pre: 0.8154 (0.8154)  loss_bbox_dn_pre: 0.3775 (0.3775)  loss_giou_dn_pre: 0.5526 (0.5526)  time: 2.0932  data: 0.6731  max mem: 13413\nEpoch: [30]  [100/251]  eta: 0:03:07  lr: 0.000002  loss: 32.8428 (35.2970)  loss_mal: 0.5688 (0.6337)  loss_bbox: 0.0913 (0.1232)  loss_giou: 0.2237 (0.2754)  loss_fgl: 1.1990 (1.2367)  loss_mal_aux_0: 0.9790 (1.0701)  loss_bbox_aux_0: 0.1360 (0.1496)  loss_giou_aux_0: 0.3067 (0.3386)  loss_fgl_aux_0: 1.2762 (1.2873)  loss_ddf_aux_0: 0.1440 (0.1443)  loss_mal_aux_1: 0.7446 (0.8125)  loss_bbox_aux_1: 0.1029 (0.1295)  loss_giou_aux_1: 0.2479 (0.2900)  loss_fgl_aux_1: 1.2169 (1.2423)  loss_ddf_aux_1: 0.0435 (0.0448)  loss_mal_aux_2: 0.6133 (0.6881)  loss_bbox_aux_2: 0.0952 (0.1244)  loss_giou_aux_2: 0.2262 (0.2794)  loss_fgl_aux_2: 1.2020 (1.2364)  loss_ddf_aux_2: 0.0083 (0.0088)  loss_mal_aux_3: 0.6064 (0.6510)  loss_bbox_aux_3: 0.0930 (0.1236)  loss_giou_aux_3: 0.2231 (0.2764)  loss_fgl_aux_3: 1.1958 (1.2353)  loss_ddf_aux_3: 0.0015 (0.0018)  loss_mal_aux_4: 0.5869 (0.6319)  loss_bbox_aux_4: 0.0908 (0.1233)  loss_giou_aux_4: 0.2231 (0.2757)  loss_fgl_aux_4: 1.1963 (1.2359)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.9858 (1.0696)  loss_bbox_pre: 0.1343 (0.1490)  loss_giou_pre: 0.3047 (0.3376)  loss_mal_enc_0: 1.0967 (1.2120)  loss_bbox_enc_0: 0.2120 (0.2416)  loss_giou_enc_0: 0.4948 (0.5108)  loss_mal_dn_0: 0.7944 (0.7928)  loss_bbox_dn_0: 0.2388 (0.2628)  loss_giou_dn_0: 0.4742 (0.5164)  loss_fgl_dn_0: 1.3095 (1.3141)  loss_ddf_dn_0: 1.0288 (1.0489)  loss_mal_dn_1: 0.6689 (0.6909)  loss_bbox_dn_1: 0.1387 (0.1730)  loss_giou_dn_1: 0.3078 (0.3442)  loss_fgl_dn_1: 1.2170 (1.2234)  loss_ddf_dn_1: 0.2686 (0.2719)  loss_mal_dn_2: 0.5918 (0.5939)  loss_bbox_dn_2: 0.1110 (0.1523)  loss_giou_dn_2: 0.2622 (0.3070)  loss_fgl_dn_2: 1.1693 (1.2020)  loss_ddf_dn_2: 0.0766 (0.0777)  loss_mal_dn_3: 0.5381 (0.5578)  loss_bbox_dn_3: 0.1025 (0.1455)  loss_giou_dn_3: 0.2437 (0.2947)  loss_fgl_dn_3: 1.1582 (1.1971)  loss_ddf_dn_3: 0.0138 (0.0144)  loss_mal_dn_4: 0.5273 (0.5471)  loss_bbox_dn_4: 0.1002 (0.1433)  loss_giou_dn_4: 0.2398 (0.2910)  loss_fgl_dn_4: 1.1642 (1.1974)  loss_ddf_dn_4: 0.0014 (0.0015)  loss_mal_dn_5: 0.5181 (0.5438)  loss_bbox_dn_5: 0.1000 (0.1428)  loss_giou_dn_5: 0.2392 (0.2900)  loss_fgl_dn_5: 1.1661 (1.1981)  loss_mal_dn_pre: 0.7944 (0.7925)  loss_bbox_dn_pre: 0.2474 (0.2652)  loss_giou_dn_pre: 0.4693 (0.5130)  time: 1.1849  data: 0.0117  max mem: 13413\nEpoch: [30]  [200/251]  eta: 0:01:02  lr: 0.000002  loss: 33.3727 (35.0549)  loss_mal: 0.5718 (0.6286)  loss_bbox: 0.0979 (0.1227)  loss_giou: 0.2366 (0.2706)  loss_fgl: 1.2238 (1.2304)  loss_mal_aux_0: 0.9512 (1.0396)  loss_bbox_aux_0: 0.1274 (0.1535)  loss_giou_aux_0: 0.3013 (0.3361)  loss_fgl_aux_0: 1.2922 (1.2892)  loss_ddf_aux_0: 0.1444 (0.1491)  loss_mal_aux_1: 0.6753 (0.7913)  loss_bbox_aux_1: 0.1176 (0.1307)  loss_giou_aux_1: 0.2543 (0.2867)  loss_fgl_aux_1: 1.2332 (1.2401)  loss_ddf_aux_1: 0.0418 (0.0456)  loss_mal_aux_2: 0.5645 (0.6807)  loss_bbox_aux_2: 0.1067 (0.1247)  loss_giou_aux_2: 0.2451 (0.2752)  loss_fgl_aux_2: 1.2230 (1.2321)  loss_ddf_aux_2: 0.0078 (0.0089)  loss_mal_aux_3: 0.5635 (0.6449)  loss_bbox_aux_3: 0.1006 (0.1234)  loss_giou_aux_3: 0.2384 (0.2718)  loss_fgl_aux_3: 1.2250 (1.2302)  loss_ddf_aux_3: 0.0016 (0.0018)  loss_mal_aux_4: 0.5532 (0.6289)  loss_bbox_aux_4: 0.0990 (0.1229)  loss_giou_aux_4: 0.2360 (0.2709)  loss_fgl_aux_4: 1.2235 (1.2301)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.9497 (1.0384)  loss_bbox_pre: 0.1269 (0.1535)  loss_giou_pre: 0.2967 (0.3354)  loss_mal_enc_0: 1.0537 (1.1869)  loss_bbox_enc_0: 0.2184 (0.2516)  loss_giou_enc_0: 0.4979 (0.5129)  loss_mal_dn_0: 0.7773 (0.7859)  loss_bbox_dn_0: 0.2096 (0.2681)  loss_giou_dn_0: 0.5030 (0.5151)  loss_fgl_dn_0: 1.3193 (1.3165)  loss_ddf_dn_0: 1.0384 (1.0576)  loss_mal_dn_1: 0.6660 (0.6867)  loss_bbox_dn_1: 0.1357 (0.1731)  loss_giou_dn_1: 0.3174 (0.3400)  loss_fgl_dn_1: 1.2048 (1.2215)  loss_ddf_dn_1: 0.2695 (0.2743)  loss_mal_dn_2: 0.5503 (0.5889)  loss_bbox_dn_2: 0.1184 (0.1503)  loss_giou_dn_2: 0.2769 (0.3004)  loss_fgl_dn_2: 1.1720 (1.1965)  loss_ddf_dn_2: 0.0747 (0.0787)  loss_mal_dn_3: 0.5161 (0.5536)  loss_bbox_dn_3: 0.1101 (0.1424)  loss_giou_dn_3: 0.2548 (0.2875)  loss_fgl_dn_3: 1.1589 (1.1901)  loss_ddf_dn_3: 0.0137 (0.0145)  loss_mal_dn_4: 0.5044 (0.5426)  loss_bbox_dn_4: 0.1060 (0.1400)  loss_giou_dn_4: 0.2518 (0.2835)  loss_fgl_dn_4: 1.1570 (1.1895)  loss_ddf_dn_4: 0.0015 (0.0015)  loss_mal_dn_5: 0.5063 (0.5398)  loss_bbox_dn_5: 0.1046 (0.1392)  loss_giou_dn_5: 0.2497 (0.2822)  loss_fgl_dn_5: 1.1568 (1.1897)  loss_mal_dn_pre: 0.7754 (0.7862)  loss_bbox_dn_pre: 0.2108 (0.2689)  loss_giou_dn_pre: 0.5100 (0.5109)  time: 1.2148  data: 0.0124  max mem: 13413\nEpoch: [30]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 35.5899 (35.1985)  loss_mal: 0.5879 (0.6361)  loss_bbox: 0.1137 (0.1266)  loss_giou: 0.2830 (0.2733)  loss_fgl: 1.2329 (1.2287)  loss_mal_aux_0: 0.9819 (1.0387)  loss_bbox_aux_0: 0.1508 (0.1570)  loss_giou_aux_0: 0.3473 (0.3385)  loss_fgl_aux_0: 1.3047 (1.2881)  loss_ddf_aux_0: 0.1606 (0.1509)  loss_mal_aux_1: 0.7734 (0.7949)  loss_bbox_aux_1: 0.1279 (0.1354)  loss_giou_aux_1: 0.2893 (0.2902)  loss_fgl_aux_1: 1.2435 (1.2386)  loss_ddf_aux_1: 0.0512 (0.0464)  loss_mal_aux_2: 0.7163 (0.6928)  loss_bbox_aux_2: 0.1174 (0.1291)  loss_giou_aux_2: 0.2862 (0.2783)  loss_fgl_aux_2: 1.2191 (1.2306)  loss_ddf_aux_2: 0.0090 (0.0090)  loss_mal_aux_3: 0.6221 (0.6570)  loss_bbox_aux_3: 0.1147 (0.1275)  loss_giou_aux_3: 0.2826 (0.2747)  loss_fgl_aux_3: 1.2123 (1.2286)  loss_ddf_aux_3: 0.0018 (0.0018)  loss_mal_aux_4: 0.5913 (0.6395)  loss_bbox_aux_4: 0.1139 (0.1268)  loss_giou_aux_4: 0.2825 (0.2737)  loss_fgl_aux_4: 1.2261 (1.2284)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.9858 (1.0375)  loss_bbox_pre: 0.1497 (0.1566)  loss_giou_pre: 0.3458 (0.3377)  loss_mal_enc_0: 1.1533 (1.1979)  loss_bbox_enc_0: 0.2611 (0.2526)  loss_giou_enc_0: 0.5260 (0.5135)  loss_mal_dn_0: 0.7754 (0.7855)  loss_bbox_dn_0: 0.2453 (0.2719)  loss_giou_dn_0: 0.4981 (0.5154)  loss_fgl_dn_0: 1.3286 (1.3163)  loss_ddf_dn_0: 0.9373 (1.0677)  loss_mal_dn_1: 0.6846 (0.6869)  loss_bbox_dn_1: 0.1465 (0.1768)  loss_giou_dn_1: 0.3203 (0.3413)  loss_fgl_dn_1: 1.2132 (1.2211)  loss_ddf_dn_1: 0.2416 (0.2771)  loss_mal_dn_2: 0.5913 (0.5898)  loss_bbox_dn_2: 0.1276 (0.1536)  loss_giou_dn_2: 0.2812 (0.3017)  loss_fgl_dn_2: 1.1880 (1.1962)  loss_ddf_dn_2: 0.0642 (0.0794)  loss_mal_dn_3: 0.5669 (0.5535)  loss_bbox_dn_3: 0.1153 (0.1455)  loss_giou_dn_3: 0.2734 (0.2887)  loss_fgl_dn_3: 1.1874 (1.1900)  loss_ddf_dn_3: 0.0114 (0.0146)  loss_mal_dn_4: 0.5586 (0.5435)  loss_bbox_dn_4: 0.1127 (0.1430)  loss_giou_dn_4: 0.2727 (0.2848)  loss_fgl_dn_4: 1.1856 (1.1894)  loss_ddf_dn_4: 0.0012 (0.0015)  loss_mal_dn_5: 0.5635 (0.5409)  loss_bbox_dn_5: 0.1125 (0.1423)  loss_giou_dn_5: 0.2722 (0.2836)  loss_fgl_dn_5: 1.1883 (1.1896)  loss_mal_dn_pre: 0.7754 (0.7859)  loss_bbox_dn_pre: 0.2495 (0.2724)  loss_giou_dn_pre: 0.4962 (0.5112)  time: 1.1618  data: 0.0115  max mem: 13413\nEpoch: [30] Total time: 0:05:06 (1.2216 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7937  data: 0.4751  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3503  data: 0.0621  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3338  data: 0.0195  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.3221  data: 0.0185  max mem: 13413\nTest: Total time: 0:00:08 (0.3411 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.327\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.537\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.331\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.453\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.646\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.629\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.864\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.743\nbest_stat: {'epoch': 26, 'coco_eval_bbox': 0.3301681420872041}\nEpoch: [31]  [  0/251]  eta: 0:08:35  lr: 0.000002  loss: 33.6087 (33.6087)  loss_mal: 0.5884 (0.5884)  loss_bbox: 0.0892 (0.0892)  loss_giou: 0.3264 (0.3264)  loss_fgl: 1.3380 (1.3380)  loss_mal_aux_0: 0.6553 (0.6553)  loss_bbox_aux_0: 0.0750 (0.0750)  loss_giou_aux_0: 0.2931 (0.2931)  loss_fgl_aux_0: 1.3086 (1.3086)  loss_ddf_aux_0: 0.1017 (0.1017)  loss_mal_aux_1: 0.6104 (0.6104)  loss_bbox_aux_1: 0.0888 (0.0888)  loss_giou_aux_1: 0.3271 (0.3271)  loss_fgl_aux_1: 1.3160 (1.3160)  loss_ddf_aux_1: 0.0299 (0.0299)  loss_mal_aux_2: 0.5972 (0.5972)  loss_bbox_aux_2: 0.0906 (0.0906)  loss_giou_aux_2: 0.3297 (0.3297)  loss_fgl_aux_2: 1.3365 (1.3365)  loss_ddf_aux_2: 0.0063 (0.0063)  loss_mal_aux_3: 0.6030 (0.6030)  loss_bbox_aux_3: 0.0895 (0.0895)  loss_giou_aux_3: 0.3256 (0.3256)  loss_fgl_aux_3: 1.3360 (1.3360)  loss_ddf_aux_3: 0.0009 (0.0009)  loss_mal_aux_4: 0.6006 (0.6006)  loss_bbox_aux_4: 0.0891 (0.0891)  loss_giou_aux_4: 0.3259 (0.3259)  loss_fgl_aux_4: 1.3371 (1.3371)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 0.6523 (0.6523)  loss_bbox_pre: 0.0724 (0.0724)  loss_giou_pre: 0.2857 (0.2857)  loss_mal_enc_0: 0.9526 (0.9526)  loss_bbox_enc_0: 0.1319 (0.1319)  loss_giou_enc_0: 0.4623 (0.4623)  loss_mal_dn_0: 0.7480 (0.7480)  loss_bbox_dn_0: 0.1149 (0.1149)  loss_giou_dn_0: 0.4378 (0.4378)  loss_fgl_dn_0: 1.3153 (1.3153)  loss_ddf_dn_0: 1.2937 (1.2937)  loss_mal_dn_1: 0.6836 (0.6836)  loss_bbox_dn_1: 0.0921 (0.0921)  loss_giou_dn_1: 0.3429 (0.3429)  loss_fgl_dn_1: 1.2403 (1.2403)  loss_ddf_dn_1: 0.2756 (0.2756)  loss_mal_dn_2: 0.5986 (0.5986)  loss_bbox_dn_2: 0.0877 (0.0877)  loss_giou_dn_2: 0.3257 (0.3257)  loss_fgl_dn_2: 1.2372 (1.2372)  loss_ddf_dn_2: 0.0700 (0.0700)  loss_mal_dn_3: 0.5771 (0.5771)  loss_bbox_dn_3: 0.0854 (0.0854)  loss_giou_dn_3: 0.3172 (0.3172)  loss_fgl_dn_3: 1.2364 (1.2364)  loss_ddf_dn_3: 0.0123 (0.0123)  loss_mal_dn_4: 0.5708 (0.5708)  loss_bbox_dn_4: 0.0857 (0.0857)  loss_giou_dn_4: 0.3204 (0.3204)  loss_fgl_dn_4: 1.2417 (1.2417)  loss_ddf_dn_4: 0.0012 (0.0012)  loss_mal_dn_5: 0.5640 (0.5640)  loss_bbox_dn_5: 0.0862 (0.0862)  loss_giou_dn_5: 0.3223 (0.3223)  loss_fgl_dn_5: 1.2446 (1.2446)  loss_mal_dn_pre: 0.7480 (0.7480)  loss_bbox_dn_pre: 0.1156 (0.1156)  loss_giou_dn_pre: 0.4430 (0.4430)  time: 2.0538  data: 1.0904  max mem: 13413\nEpoch: [31]  [100/251]  eta: 0:03:04  lr: 0.000002  loss: 32.9849 (35.0190)  loss_mal: 0.5547 (0.6262)  loss_bbox: 0.0904 (0.1261)  loss_giou: 0.2625 (0.2704)  loss_fgl: 1.1904 (1.2176)  loss_mal_aux_0: 1.0117 (0.9942)  loss_bbox_aux_0: 0.1417 (0.1611)  loss_giou_aux_0: 0.3512 (0.3436)  loss_fgl_aux_0: 1.2885 (1.2843)  loss_ddf_aux_0: 0.1575 (0.1582)  loss_mal_aux_1: 0.7896 (0.7919)  loss_bbox_aux_1: 0.1156 (0.1365)  loss_giou_aux_1: 0.2874 (0.2900)  loss_fgl_aux_1: 1.2126 (1.2329)  loss_ddf_aux_1: 0.0448 (0.0490)  loss_mal_aux_2: 0.6465 (0.6869)  loss_bbox_aux_2: 0.1013 (0.1289)  loss_giou_aux_2: 0.2706 (0.2752)  loss_fgl_aux_2: 1.1901 (1.2201)  loss_ddf_aux_2: 0.0069 (0.0093)  loss_mal_aux_3: 0.6191 (0.6452)  loss_bbox_aux_3: 0.0931 (0.1269)  loss_giou_aux_3: 0.2655 (0.2718)  loss_fgl_aux_3: 1.1896 (1.2177)  loss_ddf_aux_3: 0.0015 (0.0019)  loss_mal_aux_4: 0.5898 (0.6292)  loss_bbox_aux_4: 0.0907 (0.1263)  loss_giou_aux_4: 0.2635 (0.2708)  loss_fgl_aux_4: 1.1876 (1.2175)  loss_ddf_aux_4: 0.0002 (0.0003)  loss_mal_pre: 1.0107 (0.9923)  loss_bbox_pre: 0.1385 (0.1607)  loss_giou_pre: 0.3426 (0.3423)  loss_mal_enc_0: 1.1875 (1.1676)  loss_bbox_enc_0: 0.2594 (0.2557)  loss_giou_enc_0: 0.4759 (0.5047)  loss_mal_dn_0: 0.7944 (0.7827)  loss_bbox_dn_0: 0.2279 (0.2734)  loss_giou_dn_0: 0.5386 (0.5218)  loss_fgl_dn_0: 1.3105 (1.3130)  loss_ddf_dn_0: 1.0251 (1.1232)  loss_mal_dn_1: 0.6860 (0.6743)  loss_bbox_dn_1: 0.1322 (0.1783)  loss_giou_dn_1: 0.3271 (0.3448)  loss_fgl_dn_1: 1.2136 (1.2148)  loss_ddf_dn_1: 0.2547 (0.2915)  loss_mal_dn_2: 0.5928 (0.5843)  loss_bbox_dn_2: 0.1143 (0.1530)  loss_giou_dn_2: 0.2819 (0.3040)  loss_fgl_dn_2: 1.1802 (1.1865)  loss_ddf_dn_2: 0.0627 (0.0823)  loss_mal_dn_3: 0.5601 (0.5518)  loss_bbox_dn_3: 0.1124 (0.1445)  loss_giou_dn_3: 0.2780 (0.2903)  loss_fgl_dn_3: 1.1645 (1.1799)  loss_ddf_dn_3: 0.0110 (0.0149)  loss_mal_dn_4: 0.5498 (0.5446)  loss_bbox_dn_4: 0.1128 (0.1419)  loss_giou_dn_4: 0.2738 (0.2862)  loss_fgl_dn_4: 1.1635 (1.1793)  loss_ddf_dn_4: 0.0013 (0.0016)  loss_mal_dn_5: 0.5527 (0.5432)  loss_bbox_dn_5: 0.1122 (0.1413)  loss_giou_dn_5: 0.2723 (0.2851)  loss_fgl_dn_5: 1.1634 (1.1796)  loss_mal_dn_pre: 0.7930 (0.7834)  loss_bbox_dn_pre: 0.2325 (0.2732)  loss_giou_dn_pre: 0.5440 (0.5173)  time: 1.2130  data: 0.0117  max mem: 13413\nEpoch: [31]  [200/251]  eta: 0:01:01  lr: 0.000002  loss: 33.9405 (35.0131)  loss_mal: 0.5181 (0.6182)  loss_bbox: 0.1140 (0.1310)  loss_giou: 0.2279 (0.2727)  loss_fgl: 1.2163 (1.2335)  loss_mal_aux_0: 0.9321 (0.9858)  loss_bbox_aux_0: 0.1583 (0.1651)  loss_giou_aux_0: 0.3330 (0.3410)  loss_fgl_aux_0: 1.2870 (1.2912)  loss_ddf_aux_0: 0.1364 (0.1537)  loss_mal_aux_1: 0.7827 (0.7803)  loss_bbox_aux_1: 0.1292 (0.1416)  loss_giou_aux_1: 0.2717 (0.2907)  loss_fgl_aux_1: 1.2450 (1.2448)  loss_ddf_aux_1: 0.0427 (0.0480)  loss_mal_aux_2: 0.5957 (0.6758)  loss_bbox_aux_2: 0.1229 (0.1339)  loss_giou_aux_2: 0.2388 (0.2772)  loss_fgl_aux_2: 1.2190 (1.2351)  loss_ddf_aux_2: 0.0083 (0.0094)  loss_mal_aux_3: 0.5181 (0.6338)  loss_bbox_aux_3: 0.1177 (0.1317)  loss_giou_aux_3: 0.2294 (0.2739)  loss_fgl_aux_3: 1.2169 (1.2331)  loss_ddf_aux_3: 0.0017 (0.0019)  loss_mal_aux_4: 0.5332 (0.6194)  loss_bbox_aux_4: 0.1135 (0.1311)  loss_giou_aux_4: 0.2275 (0.2730)  loss_fgl_aux_4: 1.2163 (1.2332)  loss_ddf_aux_4: 0.0002 (0.0003)  loss_mal_pre: 0.9336 (0.9855)  loss_bbox_pre: 0.1602 (0.1646)  loss_giou_pre: 0.3321 (0.3399)  loss_mal_enc_0: 1.1309 (1.1740)  loss_bbox_enc_0: 0.2635 (0.2558)  loss_giou_enc_0: 0.4454 (0.4970)  loss_mal_dn_0: 0.7705 (0.7815)  loss_bbox_dn_0: 0.2685 (0.2698)  loss_giou_dn_0: 0.5005 (0.5118)  loss_fgl_dn_0: 1.3153 (1.3189)  loss_ddf_dn_0: 1.0437 (1.0940)  loss_mal_dn_1: 0.6948 (0.6766)  loss_bbox_dn_1: 0.1701 (0.1755)  loss_giou_dn_1: 0.3140 (0.3391)  loss_fgl_dn_1: 1.2037 (1.2223)  loss_ddf_dn_1: 0.2611 (0.2851)  loss_mal_dn_2: 0.5767 (0.5817)  loss_bbox_dn_2: 0.1361 (0.1514)  loss_giou_dn_2: 0.2668 (0.2993)  loss_fgl_dn_2: 1.1733 (1.1965)  loss_ddf_dn_2: 0.0763 (0.0817)  loss_mal_dn_3: 0.5386 (0.5481)  loss_bbox_dn_3: 0.1331 (0.1434)  loss_giou_dn_3: 0.2428 (0.2864)  loss_fgl_dn_3: 1.1634 (1.1905)  loss_ddf_dn_3: 0.0143 (0.0148)  loss_mal_dn_4: 0.5371 (0.5402)  loss_bbox_dn_4: 0.1297 (0.1409)  loss_giou_dn_4: 0.2412 (0.2827)  loss_fgl_dn_4: 1.1596 (1.1903)  loss_ddf_dn_4: 0.0015 (0.0016)  loss_mal_dn_5: 0.5322 (0.5387)  loss_bbox_dn_5: 0.1288 (0.1404)  loss_giou_dn_5: 0.2393 (0.2817)  loss_fgl_dn_5: 1.1581 (1.1907)  loss_mal_dn_pre: 0.7681 (0.7819)  loss_bbox_dn_pre: 0.2670 (0.2702)  loss_giou_dn_pre: 0.4951 (0.5081)  time: 1.1675  data: 0.0106  max mem: 13413\nEpoch: [31]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 32.0719 (34.8218)  loss_mal: 0.5181 (0.6167)  loss_bbox: 0.0971 (0.1301)  loss_giou: 0.2375 (0.2733)  loss_fgl: 1.1861 (1.2267)  loss_mal_aux_0: 0.8569 (0.9794)  loss_bbox_aux_0: 0.1301 (0.1629)  loss_giou_aux_0: 0.2903 (0.3384)  loss_fgl_aux_0: 1.2454 (1.2841)  loss_ddf_aux_0: 0.1476 (0.1522)  loss_mal_aux_1: 0.6201 (0.7686)  loss_bbox_aux_1: 0.0997 (0.1402)  loss_giou_aux_1: 0.2581 (0.2899)  loss_fgl_aux_1: 1.2069 (1.2372)  loss_ddf_aux_1: 0.0438 (0.0474)  loss_mal_aux_2: 0.5234 (0.6723)  loss_bbox_aux_2: 0.0981 (0.1328)  loss_giou_aux_2: 0.2404 (0.2774)  loss_fgl_aux_2: 1.1990 (1.2278)  loss_ddf_aux_2: 0.0082 (0.0093)  loss_mal_aux_3: 0.5356 (0.6285)  loss_bbox_aux_3: 0.0969 (0.1307)  loss_giou_aux_3: 0.2389 (0.2745)  loss_fgl_aux_3: 1.1936 (1.2262)  loss_ddf_aux_3: 0.0016 (0.0019)  loss_mal_aux_4: 0.5137 (0.6167)  loss_bbox_aux_4: 0.0974 (0.1302)  loss_giou_aux_4: 0.2389 (0.2736)  loss_fgl_aux_4: 1.1883 (1.2264)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8579 (0.9801)  loss_bbox_pre: 0.1315 (0.1624)  loss_giou_pre: 0.2912 (0.3375)  loss_mal_enc_0: 1.0957 (1.1677)  loss_bbox_enc_0: 0.1959 (0.2530)  loss_giou_enc_0: 0.4357 (0.4956)  loss_mal_dn_0: 0.7881 (0.7807)  loss_bbox_dn_0: 0.2527 (0.2673)  loss_giou_dn_0: 0.4802 (0.5086)  loss_fgl_dn_0: 1.3121 (1.3177)  loss_ddf_dn_0: 1.0920 (1.0765)  loss_mal_dn_1: 0.6562 (0.6728)  loss_bbox_dn_1: 0.1501 (0.1735)  loss_giou_dn_1: 0.2969 (0.3365)  loss_fgl_dn_1: 1.1952 (1.2189)  loss_ddf_dn_1: 0.2767 (0.2795)  loss_mal_dn_2: 0.5552 (0.5788)  loss_bbox_dn_2: 0.1269 (0.1500)  loss_giou_dn_2: 0.2673 (0.2971)  loss_fgl_dn_2: 1.1602 (1.1933)  loss_ddf_dn_2: 0.0717 (0.0803)  loss_mal_dn_3: 0.5137 (0.5457)  loss_bbox_dn_3: 0.1165 (0.1421)  loss_giou_dn_3: 0.2503 (0.2841)  loss_fgl_dn_3: 1.1482 (1.1874)  loss_ddf_dn_3: 0.0147 (0.0147)  loss_mal_dn_4: 0.4937 (0.5384)  loss_bbox_dn_4: 0.1130 (0.1397)  loss_giou_dn_4: 0.2474 (0.2803)  loss_fgl_dn_4: 1.1466 (1.1871)  loss_ddf_dn_4: 0.0016 (0.0016)  loss_mal_dn_5: 0.4963 (0.5376)  loss_bbox_dn_5: 0.1114 (0.1392)  loss_giou_dn_5: 0.2446 (0.2794)  loss_fgl_dn_5: 1.1463 (1.1874)  loss_mal_dn_pre: 0.7876 (0.7810)  loss_bbox_dn_pre: 0.2541 (0.2680)  loss_giou_dn_pre: 0.4705 (0.5053)  time: 1.2328  data: 0.0126  max mem: 13413\nEpoch: [31] Total time: 0:05:05 (1.2158 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8010  data: 0.4974  max mem: 13413\nTest:  [10/25]  eta: 0:00:06    time: 0.4074  data: 0.0656  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3362  data: 0.0211  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.3235  data: 0.0200  max mem: 13413\nTest: Total time: 0:00:08 (0.3445 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.323\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.534\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.326\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.345\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.449\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.646\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.646\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.631\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.864\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.743\nbest_stat: {'epoch': 26, 'coco_eval_bbox': 0.3301681420872041}\nEpoch: [32]  [  0/251]  eta: 0:09:03  lr: 0.000002  loss: 29.0752 (29.0752)  loss_mal: 0.3115 (0.3115)  loss_bbox: 0.0682 (0.0682)  loss_giou: 0.1318 (0.1318)  loss_fgl: 1.1335 (1.1335)  loss_mal_aux_0: 0.9175 (0.9175)  loss_bbox_aux_0: 0.1006 (0.1006)  loss_giou_aux_0: 0.2313 (0.2313)  loss_fgl_aux_0: 1.1988 (1.1988)  loss_ddf_aux_0: 0.1477 (0.1477)  loss_mal_aux_1: 0.5278 (0.5278)  loss_bbox_aux_1: 0.0703 (0.0703)  loss_giou_aux_1: 0.1372 (0.1372)  loss_fgl_aux_1: 1.1337 (1.1337)  loss_ddf_aux_1: 0.0380 (0.0380)  loss_mal_aux_2: 0.3115 (0.3115)  loss_bbox_aux_2: 0.0707 (0.0707)  loss_giou_aux_2: 0.1298 (0.1298)  loss_fgl_aux_2: 1.1300 (1.1300)  loss_ddf_aux_2: 0.0065 (0.0065)  loss_mal_aux_3: 0.3022 (0.3022)  loss_bbox_aux_3: 0.0699 (0.0699)  loss_giou_aux_3: 0.1317 (0.1317)  loss_fgl_aux_3: 1.1338 (1.1338)  loss_ddf_aux_3: 0.0019 (0.0019)  loss_mal_aux_4: 0.3101 (0.3101)  loss_bbox_aux_4: 0.0687 (0.0687)  loss_giou_aux_4: 0.1317 (0.1317)  loss_fgl_aux_4: 1.1347 (1.1347)  loss_ddf_aux_4: 0.0000 (0.0000)  loss_mal_pre: 0.9160 (0.9160)  loss_bbox_pre: 0.1000 (0.1000)  loss_giou_pre: 0.2244 (0.2244)  loss_mal_enc_0: 0.9932 (0.9932)  loss_bbox_enc_0: 0.1825 (0.1825)  loss_giou_enc_0: 0.4086 (0.4086)  loss_mal_dn_0: 0.7358 (0.7358)  loss_bbox_dn_0: 0.2905 (0.2905)  loss_giou_dn_0: 0.4925 (0.4925)  loss_fgl_dn_0: 1.3400 (1.3400)  loss_ddf_dn_0: 1.1294 (1.1294)  loss_mal_dn_1: 0.5903 (0.5903)  loss_bbox_dn_1: 0.1486 (0.1486)  loss_giou_dn_1: 0.2536 (0.2536)  loss_fgl_dn_1: 1.1712 (1.1712)  loss_ddf_dn_1: 0.3005 (0.3005)  loss_mal_dn_2: 0.4429 (0.4429)  loss_bbox_dn_2: 0.1077 (0.1077)  loss_giou_dn_2: 0.1858 (0.1858)  loss_fgl_dn_2: 1.1110 (1.1110)  loss_ddf_dn_2: 0.0789 (0.0789)  loss_mal_dn_3: 0.4189 (0.4189)  loss_bbox_dn_3: 0.0886 (0.0886)  loss_giou_dn_3: 0.1620 (0.1620)  loss_fgl_dn_3: 1.1005 (1.1005)  loss_ddf_dn_3: 0.0154 (0.0154)  loss_mal_dn_4: 0.4189 (0.4189)  loss_bbox_dn_4: 0.0814 (0.0814)  loss_giou_dn_4: 0.1567 (0.1567)  loss_fgl_dn_4: 1.0971 (1.0971)  loss_ddf_dn_4: 0.0019 (0.0019)  loss_mal_dn_5: 0.4194 (0.4194)  loss_bbox_dn_5: 0.0798 (0.0798)  loss_giou_dn_5: 0.1554 (0.1554)  loss_fgl_dn_5: 1.0957 (1.0957)  loss_mal_dn_pre: 0.7324 (0.7324)  loss_bbox_dn_pre: 0.2855 (0.2855)  loss_giou_dn_pre: 0.4808 (0.4808)  time: 2.1635  data: 0.9401  max mem: 13413\nEpoch: [32]  [100/251]  eta: 0:03:05  lr: 0.000002  loss: 32.4015 (33.4305)  loss_mal: 0.4429 (0.5847)  loss_bbox: 0.0900 (0.1081)  loss_giou: 0.1910 (0.2369)  loss_fgl: 1.1429 (1.1882)  loss_mal_aux_0: 0.8169 (0.9294)  loss_bbox_aux_0: 0.1254 (0.1476)  loss_giou_aux_0: 0.2946 (0.3102)  loss_fgl_aux_0: 1.2592 (1.2751)  loss_ddf_aux_0: 0.1461 (0.1543)  loss_mal_aux_1: 0.6636 (0.7421)  loss_bbox_aux_1: 0.1016 (0.1190)  loss_giou_aux_1: 0.2031 (0.2554)  loss_fgl_aux_1: 1.1901 (1.2090)  loss_ddf_aux_1: 0.0496 (0.0487)  loss_mal_aux_2: 0.5376 (0.6304)  loss_bbox_aux_2: 0.0924 (0.1109)  loss_giou_aux_2: 0.2006 (0.2415)  loss_fgl_aux_2: 1.1531 (1.1910)  loss_ddf_aux_2: 0.0091 (0.0094)  loss_mal_aux_3: 0.4788 (0.5941)  loss_bbox_aux_3: 0.0900 (0.1087)  loss_giou_aux_3: 0.1953 (0.2379)  loss_fgl_aux_3: 1.1441 (1.1880)  loss_ddf_aux_3: 0.0017 (0.0018)  loss_mal_aux_4: 0.4473 (0.5843)  loss_bbox_aux_4: 0.0901 (0.1081)  loss_giou_aux_4: 0.1917 (0.2371)  loss_fgl_aux_4: 1.1429 (1.1879)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8149 (0.9285)  loss_bbox_pre: 0.1267 (0.1474)  loss_giou_pre: 0.2943 (0.3099)  loss_mal_enc_0: 1.1719 (1.1729)  loss_bbox_enc_0: 0.2220 (0.2495)  loss_giou_enc_0: 0.4491 (0.4788)  loss_mal_dn_0: 0.7769 (0.7756)  loss_bbox_dn_0: 0.2420 (0.2565)  loss_giou_dn_0: 0.4587 (0.4871)  loss_fgl_dn_0: 1.3192 (1.3171)  loss_ddf_dn_0: 0.9726 (1.0636)  loss_mal_dn_1: 0.6353 (0.6454)  loss_bbox_dn_1: 0.1362 (0.1599)  loss_giou_dn_1: 0.2877 (0.3094)  loss_fgl_dn_1: 1.1948 (1.2021)  loss_ddf_dn_1: 0.2556 (0.2787)  loss_mal_dn_2: 0.5249 (0.5497)  loss_bbox_dn_2: 0.1126 (0.1366)  loss_giou_dn_2: 0.2468 (0.2701)  loss_fgl_dn_2: 1.1543 (1.1726)  loss_ddf_dn_2: 0.0693 (0.0816)  loss_mal_dn_3: 0.4922 (0.5146)  loss_bbox_dn_3: 0.1100 (0.1288)  loss_giou_dn_3: 0.2335 (0.2574)  loss_fgl_dn_3: 1.1490 (1.1659)  loss_ddf_dn_3: 0.0124 (0.0147)  loss_mal_dn_4: 0.4744 (0.5055)  loss_bbox_dn_4: 0.1069 (0.1260)  loss_giou_dn_4: 0.2290 (0.2536)  loss_fgl_dn_4: 1.1439 (1.1654)  loss_ddf_dn_4: 0.0013 (0.0016)  loss_mal_dn_5: 0.4719 (0.5041)  loss_bbox_dn_5: 0.1052 (0.1253)  loss_giou_dn_5: 0.2273 (0.2527)  loss_fgl_dn_5: 1.1430 (1.1655)  loss_mal_dn_pre: 0.7739 (0.7763)  loss_bbox_dn_pre: 0.2489 (0.2564)  loss_giou_dn_pre: 0.4541 (0.4837)  time: 1.2704  data: 0.0120  max mem: 13413\nEpoch: [32]  [200/251]  eta: 0:01:02  lr: 0.000002  loss: 32.9423 (33.9952)  loss_mal: 0.6084 (0.6056)  loss_bbox: 0.0881 (0.1159)  loss_giou: 0.2460 (0.2518)  loss_fgl: 1.1655 (1.2074)  loss_mal_aux_0: 0.9580 (0.9614)  loss_bbox_aux_0: 0.1241 (0.1510)  loss_giou_aux_0: 0.3118 (0.3193)  loss_fgl_aux_0: 1.2587 (1.2818)  loss_ddf_aux_0: 0.1521 (0.1552)  loss_mal_aux_1: 0.6997 (0.7530)  loss_bbox_aux_1: 0.0899 (0.1255)  loss_giou_aux_1: 0.2504 (0.2692)  loss_fgl_aux_1: 1.1940 (1.2239)  loss_ddf_aux_1: 0.0447 (0.0480)  loss_mal_aux_2: 0.6592 (0.6473)  loss_bbox_aux_2: 0.0858 (0.1184)  loss_giou_aux_2: 0.2456 (0.2561)  loss_fgl_aux_2: 1.1663 (1.2105)  loss_ddf_aux_2: 0.0088 (0.0092)  loss_mal_aux_3: 0.5820 (0.6161)  loss_bbox_aux_3: 0.0860 (0.1165)  loss_giou_aux_3: 0.2413 (0.2528)  loss_fgl_aux_3: 1.1665 (1.2073)  loss_ddf_aux_3: 0.0016 (0.0018)  loss_mal_aux_4: 0.6221 (0.6049)  loss_bbox_aux_4: 0.0877 (0.1159)  loss_giou_aux_4: 0.2450 (0.2519)  loss_fgl_aux_4: 1.1655 (1.2072)  loss_ddf_aux_4: 0.0003 (0.0002)  loss_mal_pre: 0.9565 (0.9608)  loss_bbox_pre: 0.1257 (0.1508)  loss_giou_pre: 0.3107 (0.3189)  loss_mal_enc_0: 1.1377 (1.1756)  loss_bbox_enc_0: 0.2037 (0.2444)  loss_giou_enc_0: 0.4865 (0.4801)  loss_mal_dn_0: 0.7544 (0.7756)  loss_bbox_dn_0: 0.2117 (0.2548)  loss_giou_dn_0: 0.4432 (0.4901)  loss_fgl_dn_0: 1.3021 (1.3184)  loss_ddf_dn_0: 0.9593 (1.0487)  loss_mal_dn_1: 0.6270 (0.6569)  loss_bbox_dn_1: 0.1284 (0.1625)  loss_giou_dn_1: 0.2923 (0.3200)  loss_fgl_dn_1: 1.1668 (1.2107)  loss_ddf_dn_1: 0.2529 (0.2736)  loss_mal_dn_2: 0.5425 (0.5619)  loss_bbox_dn_2: 0.1034 (0.1399)  loss_giou_dn_2: 0.2629 (0.2819)  loss_fgl_dn_2: 1.1367 (1.1839)  loss_ddf_dn_2: 0.0762 (0.0799)  loss_mal_dn_3: 0.5132 (0.5277)  loss_bbox_dn_3: 0.0978 (0.1328)  loss_giou_dn_3: 0.2477 (0.2695)  loss_fgl_dn_3: 1.1369 (1.1771)  loss_ddf_dn_3: 0.0130 (0.0144)  loss_mal_dn_4: 0.5029 (0.5185)  loss_bbox_dn_4: 0.0959 (0.1304)  loss_giou_dn_4: 0.2462 (0.2659)  loss_fgl_dn_4: 1.1387 (1.1764)  loss_ddf_dn_4: 0.0014 (0.0016)  loss_mal_dn_5: 0.4971 (0.5167)  loss_bbox_dn_5: 0.0970 (0.1298)  loss_giou_dn_5: 0.2457 (0.2650)  loss_fgl_dn_5: 1.1389 (1.1766)  loss_mal_dn_pre: 0.7563 (0.7765)  loss_bbox_dn_pre: 0.2163 (0.2550)  loss_giou_dn_pre: 0.4559 (0.4868)  time: 1.1649  data: 0.0114  max mem: 13413\nEpoch: [32]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 32.8050 (34.1782)  loss_mal: 0.5552 (0.6105)  loss_bbox: 0.1028 (0.1216)  loss_giou: 0.2576 (0.2556)  loss_fgl: 1.1768 (1.2038)  loss_mal_aux_0: 0.8799 (0.9591)  loss_bbox_aux_0: 0.1308 (0.1578)  loss_giou_aux_0: 0.3168 (0.3227)  loss_fgl_aux_0: 1.2654 (1.2782)  loss_ddf_aux_0: 0.1477 (0.1569)  loss_mal_aux_1: 0.7520 (0.7560)  loss_bbox_aux_1: 0.1064 (0.1316)  loss_giou_aux_1: 0.2786 (0.2732)  loss_fgl_aux_1: 1.2006 (1.2199)  loss_ddf_aux_1: 0.0447 (0.0486)  loss_mal_aux_2: 0.5771 (0.6504)  loss_bbox_aux_2: 0.1054 (0.1246)  loss_giou_aux_2: 0.2618 (0.2606)  loss_fgl_aux_2: 1.1836 (1.2067)  loss_ddf_aux_2: 0.0086 (0.0096)  loss_mal_aux_3: 0.5913 (0.6210)  loss_bbox_aux_3: 0.1052 (0.1223)  loss_giou_aux_3: 0.2632 (0.2570)  loss_fgl_aux_3: 1.1811 (1.2036)  loss_ddf_aux_3: 0.0017 (0.0019)  loss_mal_aux_4: 0.5698 (0.6096)  loss_bbox_aux_4: 0.1026 (0.1216)  loss_giou_aux_4: 0.2588 (0.2559)  loss_fgl_aux_4: 1.1756 (1.2035)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8794 (0.9583)  loss_bbox_pre: 0.1281 (0.1577)  loss_giou_pre: 0.3155 (0.3224)  loss_mal_enc_0: 1.0674 (1.1768)  loss_bbox_enc_0: 0.2219 (0.2580)  loss_giou_enc_0: 0.5370 (0.4894)  loss_mal_dn_0: 0.7773 (0.7764)  loss_bbox_dn_0: 0.2283 (0.2611)  loss_giou_dn_0: 0.4875 (0.4937)  loss_fgl_dn_0: 1.3214 (1.3173)  loss_ddf_dn_0: 0.9683 (1.0507)  loss_mal_dn_1: 0.6436 (0.6585)  loss_bbox_dn_1: 0.1424 (0.1681)  loss_giou_dn_1: 0.3162 (0.3244)  loss_fgl_dn_1: 1.1949 (1.2098)  loss_ddf_dn_1: 0.2505 (0.2740)  loss_mal_dn_2: 0.5713 (0.5664)  loss_bbox_dn_2: 0.1150 (0.1455)  loss_giou_dn_2: 0.2649 (0.2862)  loss_fgl_dn_2: 1.1605 (1.1836)  loss_ddf_dn_2: 0.0661 (0.0799)  loss_mal_dn_3: 0.5244 (0.5331)  loss_bbox_dn_3: 0.1017 (0.1381)  loss_giou_dn_3: 0.2417 (0.2736)  loss_fgl_dn_3: 1.1492 (1.1771)  loss_ddf_dn_3: 0.0122 (0.0145)  loss_mal_dn_4: 0.5151 (0.5242)  loss_bbox_dn_4: 0.0977 (0.1356)  loss_giou_dn_4: 0.2419 (0.2697)  loss_fgl_dn_4: 1.1473 (1.1765)  loss_ddf_dn_4: 0.0012 (0.0015)  loss_mal_dn_5: 0.5176 (0.5224)  loss_bbox_dn_5: 0.0976 (0.1350)  loss_giou_dn_5: 0.2441 (0.2687)  loss_fgl_dn_5: 1.1477 (1.1767)  loss_mal_dn_pre: 0.7744 (0.7776)  loss_bbox_dn_pre: 0.2304 (0.2614)  loss_giou_dn_pre: 0.4860 (0.4907)  time: 1.1940  data: 0.0116  max mem: 13413\nEpoch: [32] Total time: 0:05:07 (1.2256 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7763  data: 0.4692  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3503  data: 0.0627  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3035  data: 0.0193  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2913  data: 0.0181  max mem: 13413\nTest: Total time: 0:00:07 (0.3160 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.533\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.328\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.326\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.448\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.567\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.647\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.646\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.634\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.864\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.743\nbest_stat: {'epoch': 26, 'coco_eval_bbox': 0.3301681420872041}\nEpoch: [33]  [  0/251]  eta: 0:08:41  lr: 0.000002  loss: 31.1829 (31.1829)  loss_mal: 0.5444 (0.5444)  loss_bbox: 0.0837 (0.0837)  loss_giou: 0.3007 (0.3007)  loss_fgl: 1.2415 (1.2415)  loss_mal_aux_0: 0.6519 (0.6519)  loss_bbox_aux_0: 0.0884 (0.0884)  loss_giou_aux_0: 0.3272 (0.3272)  loss_fgl_aux_0: 1.2504 (1.2504)  loss_ddf_aux_0: 0.0967 (0.0967)  loss_mal_aux_1: 0.5732 (0.5732)  loss_bbox_aux_1: 0.0850 (0.0850)  loss_giou_aux_1: 0.3167 (0.3167)  loss_fgl_aux_1: 1.2459 (1.2459)  loss_ddf_aux_1: 0.0323 (0.0323)  loss_mal_aux_2: 0.5503 (0.5503)  loss_bbox_aux_2: 0.0841 (0.0841)  loss_giou_aux_2: 0.3028 (0.3028)  loss_fgl_aux_2: 1.2480 (1.2480)  loss_ddf_aux_2: 0.0058 (0.0058)  loss_mal_aux_3: 0.5298 (0.5298)  loss_bbox_aux_3: 0.0840 (0.0840)  loss_giou_aux_3: 0.3012 (0.3012)  loss_fgl_aux_3: 1.2433 (1.2433)  loss_ddf_aux_3: 0.0011 (0.0011)  loss_mal_aux_4: 0.5337 (0.5337)  loss_bbox_aux_4: 0.0840 (0.0840)  loss_giou_aux_4: 0.3013 (0.3013)  loss_fgl_aux_4: 1.2428 (1.2428)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 0.6499 (0.6499)  loss_bbox_pre: 0.0872 (0.0872)  loss_giou_pre: 0.3221 (0.3221)  loss_mal_enc_0: 0.9751 (0.9751)  loss_bbox_enc_0: 0.1537 (0.1537)  loss_giou_enc_0: 0.4917 (0.4917)  loss_mal_dn_0: 0.6948 (0.6948)  loss_bbox_dn_0: 0.1127 (0.1127)  loss_giou_dn_0: 0.3913 (0.3913)  loss_fgl_dn_0: 1.2945 (1.2945)  loss_ddf_dn_0: 0.7513 (0.7513)  loss_mal_dn_1: 0.6133 (0.6133)  loss_bbox_dn_1: 0.0804 (0.0804)  loss_giou_dn_1: 0.2868 (0.2868)  loss_fgl_dn_1: 1.1811 (1.1811)  loss_ddf_dn_1: 0.2036 (0.2036)  loss_mal_dn_2: 0.5527 (0.5527)  loss_bbox_dn_2: 0.0788 (0.0788)  loss_giou_dn_2: 0.2792 (0.2792)  loss_fgl_dn_2: 1.1740 (1.1740)  loss_ddf_dn_2: 0.0625 (0.0625)  loss_mal_dn_3: 0.5278 (0.5278)  loss_bbox_dn_3: 0.0788 (0.0788)  loss_giou_dn_3: 0.2781 (0.2781)  loss_fgl_dn_3: 1.1751 (1.1751)  loss_ddf_dn_3: 0.0110 (0.0110)  loss_mal_dn_4: 0.5288 (0.5288)  loss_bbox_dn_4: 0.0777 (0.0777)  loss_giou_dn_4: 0.2786 (0.2786)  loss_fgl_dn_4: 1.1734 (1.1734)  loss_ddf_dn_4: 0.0011 (0.0011)  loss_mal_dn_5: 0.5308 (0.5308)  loss_bbox_dn_5: 0.0770 (0.0770)  loss_giou_dn_5: 0.2781 (0.2781)  loss_fgl_dn_5: 1.1734 (1.1734)  loss_mal_dn_pre: 0.6958 (0.6958)  loss_bbox_dn_pre: 0.1145 (0.1145)  loss_giou_dn_pre: 0.3958 (0.3958)  time: 2.0770  data: 0.6928  max mem: 13413\nEpoch: [33]  [100/251]  eta: 0:03:04  lr: 0.000002  loss: 32.4317 (33.0578)  loss_mal: 0.4954 (0.5665)  loss_bbox: 0.0916 (0.1068)  loss_giou: 0.2306 (0.2375)  loss_fgl: 1.1711 (1.1965)  loss_mal_aux_0: 0.8843 (0.9679)  loss_bbox_aux_0: 0.1091 (0.1368)  loss_giou_aux_0: 0.2851 (0.2997)  loss_fgl_aux_0: 1.2505 (1.2685)  loss_ddf_aux_0: 0.1548 (0.1564)  loss_mal_aux_1: 0.7275 (0.7301)  loss_bbox_aux_1: 0.0902 (0.1132)  loss_giou_aux_1: 0.2372 (0.2505)  loss_fgl_aux_1: 1.1822 (1.2089)  loss_ddf_aux_1: 0.0419 (0.0464)  loss_mal_aux_2: 0.5498 (0.6362)  loss_bbox_aux_2: 0.0904 (0.1082)  loss_giou_aux_2: 0.2312 (0.2403)  loss_fgl_aux_2: 1.1671 (1.1978)  loss_ddf_aux_2: 0.0070 (0.0087)  loss_mal_aux_3: 0.5132 (0.5866)  loss_bbox_aux_3: 0.0910 (0.1073)  loss_giou_aux_3: 0.2323 (0.2388)  loss_fgl_aux_3: 1.1720 (1.1963)  loss_ddf_aux_3: 0.0012 (0.0017)  loss_mal_aux_4: 0.5068 (0.5719)  loss_bbox_aux_4: 0.0912 (0.1069)  loss_giou_aux_4: 0.2308 (0.2378)  loss_fgl_aux_4: 1.1712 (1.1962)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8823 (0.9656)  loss_bbox_pre: 0.1081 (0.1361)  loss_giou_pre: 0.2782 (0.2985)  loss_mal_enc_0: 1.1611 (1.1496)  loss_bbox_enc_0: 0.1816 (0.2305)  loss_giou_enc_0: 0.4553 (0.4737)  loss_mal_dn_0: 0.7754 (0.7683)  loss_bbox_dn_0: 0.2291 (0.2377)  loss_giou_dn_0: 0.4354 (0.4670)  loss_fgl_dn_0: 1.3206 (1.3213)  loss_ddf_dn_0: 0.8898 (0.9783)  loss_mal_dn_1: 0.6611 (0.6443)  loss_bbox_dn_1: 0.1325 (0.1504)  loss_giou_dn_1: 0.2846 (0.2973)  loss_fgl_dn_1: 1.1889 (1.1993)  loss_ddf_dn_1: 0.2325 (0.2525)  loss_mal_dn_2: 0.5654 (0.5462)  loss_bbox_dn_2: 0.1077 (0.1297)  loss_giou_dn_2: 0.2577 (0.2602)  loss_fgl_dn_2: 1.1526 (1.1672)  loss_ddf_dn_2: 0.0630 (0.0717)  loss_mal_dn_3: 0.5054 (0.5114)  loss_bbox_dn_3: 0.0956 (0.1240)  loss_giou_dn_3: 0.2468 (0.2499)  loss_fgl_dn_3: 1.1457 (1.1602)  loss_ddf_dn_3: 0.0121 (0.0128)  loss_mal_dn_4: 0.5059 (0.5028)  loss_bbox_dn_4: 0.0941 (0.1223)  loss_giou_dn_4: 0.2426 (0.2471)  loss_fgl_dn_4: 1.1426 (1.1592)  loss_ddf_dn_4: 0.0012 (0.0013)  loss_mal_dn_5: 0.4971 (0.5012)  loss_bbox_dn_5: 0.0922 (0.1219)  loss_giou_dn_5: 0.2418 (0.2463)  loss_fgl_dn_5: 1.1432 (1.1591)  loss_mal_dn_pre: 0.7842 (0.7689)  loss_bbox_dn_pre: 0.2295 (0.2386)  loss_giou_dn_pre: 0.4381 (0.4648)  time: 1.2142  data: 0.0115  max mem: 13413\nEpoch: [33]  [200/251]  eta: 0:01:02  lr: 0.000002  loss: 32.6567 (33.5930)  loss_mal: 0.5298 (0.5750)  loss_bbox: 0.0867 (0.1138)  loss_giou: 0.2354 (0.2481)  loss_fgl: 1.1706 (1.2024)  loss_mal_aux_0: 0.8843 (0.9596)  loss_bbox_aux_0: 0.1410 (0.1473)  loss_giou_aux_0: 0.2759 (0.3132)  loss_fgl_aux_0: 1.2432 (1.2730)  loss_ddf_aux_0: 0.1536 (0.1547)  loss_mal_aux_1: 0.6465 (0.7414)  loss_bbox_aux_1: 0.1053 (0.1228)  loss_giou_aux_1: 0.2412 (0.2637)  loss_fgl_aux_1: 1.1849 (1.2157)  loss_ddf_aux_1: 0.0358 (0.0460)  loss_mal_aux_2: 0.5596 (0.6395)  loss_bbox_aux_2: 0.0905 (0.1157)  loss_giou_aux_2: 0.2344 (0.2517)  loss_fgl_aux_2: 1.1640 (1.2043)  loss_ddf_aux_2: 0.0077 (0.0088)  loss_mal_aux_3: 0.5327 (0.5942)  loss_bbox_aux_3: 0.0874 (0.1144)  loss_giou_aux_3: 0.2360 (0.2496)  loss_fgl_aux_3: 1.1694 (1.2022)  loss_ddf_aux_3: 0.0014 (0.0017)  loss_mal_aux_4: 0.5269 (0.5783)  loss_bbox_aux_4: 0.0869 (0.1140)  loss_giou_aux_4: 0.2351 (0.2484)  loss_fgl_aux_4: 1.1700 (1.2021)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.8853 (0.9614)  loss_bbox_pre: 0.1411 (0.1467)  loss_giou_pre: 0.2738 (0.3119)  loss_mal_enc_0: 1.0557 (1.1454)  loss_bbox_enc_0: 0.2192 (0.2414)  loss_giou_enc_0: 0.4300 (0.4788)  loss_mal_dn_0: 0.7568 (0.7715)  loss_bbox_dn_0: 0.2033 (0.2538)  loss_giou_dn_0: 0.4637 (0.4809)  loss_fgl_dn_0: 1.3025 (1.3208)  loss_ddf_dn_0: 1.1333 (1.0095)  loss_mal_dn_1: 0.6294 (0.6514)  loss_bbox_dn_1: 0.1266 (0.1625)  loss_giou_dn_1: 0.2800 (0.3117)  loss_fgl_dn_1: 1.1874 (1.2052)  loss_ddf_dn_1: 0.2774 (0.2636)  loss_mal_dn_2: 0.5527 (0.5586)  loss_bbox_dn_2: 0.1053 (0.1395)  loss_giou_dn_2: 0.2438 (0.2735)  loss_fgl_dn_2: 1.1459 (1.1759)  loss_ddf_dn_2: 0.0766 (0.0764)  loss_mal_dn_3: 0.5244 (0.5238)  loss_bbox_dn_3: 0.0993 (0.1323)  loss_giou_dn_3: 0.2371 (0.2619)  loss_fgl_dn_3: 1.1348 (1.1687)  loss_ddf_dn_3: 0.0148 (0.0138)  loss_mal_dn_4: 0.5142 (0.5164)  loss_bbox_dn_4: 0.0983 (0.1301)  loss_giou_dn_4: 0.2301 (0.2586)  loss_fgl_dn_4: 1.1348 (1.1679)  loss_ddf_dn_4: 0.0015 (0.0014)  loss_mal_dn_5: 0.5239 (0.5150)  loss_bbox_dn_5: 0.0983 (0.1294)  loss_giou_dn_5: 0.2290 (0.2577)  loss_fgl_dn_5: 1.1360 (1.1680)  loss_mal_dn_pre: 0.7583 (0.7721)  loss_bbox_dn_pre: 0.2102 (0.2546)  loss_giou_dn_pre: 0.4668 (0.4788)  time: 1.1270  data: 0.0117  max mem: 13413\nEpoch: [33]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 32.8280 (33.6539)  loss_mal: 0.5781 (0.5878)  loss_bbox: 0.0914 (0.1114)  loss_giou: 0.2311 (0.2462)  loss_fgl: 1.1807 (1.2013)  loss_mal_aux_0: 0.9180 (0.9627)  loss_bbox_aux_0: 0.1341 (0.1448)  loss_giou_aux_0: 0.2909 (0.3123)  loss_fgl_aux_0: 1.2458 (1.2741)  loss_ddf_aux_0: 0.1335 (0.1558)  loss_mal_aux_1: 0.6997 (0.7489)  loss_bbox_aux_1: 0.0990 (0.1199)  loss_giou_aux_1: 0.2322 (0.2617)  loss_fgl_aux_1: 1.1867 (1.2150)  loss_ddf_aux_1: 0.0395 (0.0460)  loss_mal_aux_2: 0.6270 (0.6495)  loss_bbox_aux_2: 0.0929 (0.1132)  loss_giou_aux_2: 0.2334 (0.2496)  loss_fgl_aux_2: 1.1921 (1.2035)  loss_ddf_aux_2: 0.0081 (0.0088)  loss_mal_aux_3: 0.5684 (0.6035)  loss_bbox_aux_3: 0.0910 (0.1119)  loss_giou_aux_3: 0.2303 (0.2475)  loss_fgl_aux_3: 1.1862 (1.2012)  loss_ddf_aux_3: 0.0016 (0.0017)  loss_mal_aux_4: 0.5620 (0.5896)  loss_bbox_aux_4: 0.0918 (0.1115)  loss_giou_aux_4: 0.2312 (0.2465)  loss_fgl_aux_4: 1.1818 (1.2010)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.9189 (0.9641)  loss_bbox_pre: 0.1346 (0.1442)  loss_giou_pre: 0.2907 (0.3112)  loss_mal_enc_0: 1.1309 (1.1569)  loss_bbox_enc_0: 0.2148 (0.2383)  loss_giou_enc_0: 0.4452 (0.4750)  loss_mal_dn_0: 0.7754 (0.7732)  loss_bbox_dn_0: 0.2353 (0.2524)  loss_giou_dn_0: 0.4832 (0.4835)  loss_fgl_dn_0: 1.3114 (1.3219)  loss_ddf_dn_0: 0.9775 (1.0260)  loss_mal_dn_1: 0.6450 (0.6534)  loss_bbox_dn_1: 0.1501 (0.1607)  loss_giou_dn_1: 0.3067 (0.3136)  loss_fgl_dn_1: 1.1971 (1.2055)  loss_ddf_dn_1: 0.2804 (0.2703)  loss_mal_dn_2: 0.5654 (0.5597)  loss_bbox_dn_2: 0.1260 (0.1377)  loss_giou_dn_2: 0.2657 (0.2748)  loss_fgl_dn_2: 1.1490 (1.1752)  loss_ddf_dn_2: 0.0833 (0.0793)  loss_mal_dn_3: 0.5288 (0.5245)  loss_bbox_dn_3: 0.1193 (0.1306)  loss_giou_dn_3: 0.2531 (0.2632)  loss_fgl_dn_3: 1.1387 (1.1677)  loss_ddf_dn_3: 0.0142 (0.0145)  loss_mal_dn_4: 0.5229 (0.5168)  loss_bbox_dn_4: 0.1211 (0.1284)  loss_giou_dn_4: 0.2501 (0.2598)  loss_fgl_dn_4: 1.1375 (1.1668)  loss_ddf_dn_4: 0.0015 (0.0015)  loss_mal_dn_5: 0.5215 (0.5152)  loss_bbox_dn_5: 0.1205 (0.1277)  loss_giou_dn_5: 0.2502 (0.2588)  loss_fgl_dn_5: 1.1362 (1.1669)  loss_mal_dn_pre: 0.7764 (0.7738)  loss_bbox_dn_pre: 0.2377 (0.2530)  loss_giou_dn_pre: 0.4834 (0.4809)  time: 1.2651  data: 0.0112  max mem: 13413\nEpoch: [33] Total time: 0:05:06 (1.2217 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7762  data: 0.4717  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3496  data: 0.0633  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3041  data: 0.0202  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.3208  data: 0.0193  max mem: 13413\nTest: Total time: 0:00:08 (0.3401 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.529\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.327\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.326\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.348\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.448\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.561\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.652\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.640\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.864\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.743\nbest_stat: {'epoch': 26, 'coco_eval_bbox': 0.3301681420872041}\nEpoch: [34]  [  0/251]  eta: 0:08:59  lr: 0.000002  loss: 26.1095 (26.1095)  loss_mal: 0.3040 (0.3040)  loss_bbox: 0.0464 (0.0464)  loss_giou: 0.1254 (0.1254)  loss_fgl: 1.0296 (1.0296)  loss_mal_aux_0: 0.6147 (0.6147)  loss_bbox_aux_0: 0.0865 (0.0865)  loss_giou_aux_0: 0.2121 (0.2121)  loss_fgl_aux_0: 1.1735 (1.1735)  loss_ddf_aux_0: 0.1549 (0.1549)  loss_mal_aux_1: 0.3899 (0.3899)  loss_bbox_aux_1: 0.0461 (0.0461)  loss_giou_aux_1: 0.1365 (0.1365)  loss_fgl_aux_1: 1.0624 (1.0624)  loss_ddf_aux_1: 0.0368 (0.0368)  loss_mal_aux_2: 0.3501 (0.3501)  loss_bbox_aux_2: 0.0449 (0.0449)  loss_giou_aux_2: 0.1214 (0.1214)  loss_fgl_aux_2: 1.0289 (1.0289)  loss_ddf_aux_2: 0.0071 (0.0071)  loss_mal_aux_3: 0.3074 (0.3074)  loss_bbox_aux_3: 0.0465 (0.0465)  loss_giou_aux_3: 0.1235 (0.1235)  loss_fgl_aux_3: 1.0320 (1.0320)  loss_ddf_aux_3: 0.0014 (0.0014)  loss_mal_aux_4: 0.3010 (0.3010)  loss_bbox_aux_4: 0.0461 (0.0461)  loss_giou_aux_4: 0.1242 (0.1242)  loss_fgl_aux_4: 1.0311 (1.0311)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 0.6157 (0.6157)  loss_bbox_pre: 0.0883 (0.0883)  loss_giou_pre: 0.2130 (0.2130)  loss_mal_enc_0: 0.9395 (0.9395)  loss_bbox_enc_0: 0.2253 (0.2253)  loss_giou_enc_0: 0.4322 (0.4322)  loss_mal_dn_0: 0.7363 (0.7363)  loss_bbox_dn_0: 0.1840 (0.1840)  loss_giou_dn_0: 0.3477 (0.3477)  loss_fgl_dn_0: 1.2964 (1.2964)  loss_ddf_dn_0: 0.8418 (0.8418)  loss_mal_dn_1: 0.5449 (0.5449)  loss_bbox_dn_1: 0.0878 (0.0878)  loss_giou_dn_1: 0.1699 (0.1699)  loss_fgl_dn_1: 1.1225 (1.1225)  loss_ddf_dn_1: 0.2268 (0.2268)  loss_mal_dn_2: 0.4404 (0.4404)  loss_bbox_dn_2: 0.0697 (0.0697)  loss_giou_dn_2: 0.1375 (0.1375)  loss_fgl_dn_2: 1.0713 (1.0713)  loss_ddf_dn_2: 0.0720 (0.0720)  loss_mal_dn_3: 0.3921 (0.3921)  loss_bbox_dn_3: 0.0649 (0.0649)  loss_giou_dn_3: 0.1317 (0.1317)  loss_fgl_dn_3: 1.0685 (1.0685)  loss_ddf_dn_3: 0.0134 (0.0134)  loss_mal_dn_4: 0.3914 (0.3914)  loss_bbox_dn_4: 0.0657 (0.0657)  loss_giou_dn_4: 0.1318 (0.1318)  loss_fgl_dn_4: 1.0677 (1.0677)  loss_ddf_dn_4: 0.0013 (0.0013)  loss_mal_dn_5: 0.3914 (0.3914)  loss_bbox_dn_5: 0.0663 (0.0663)  loss_giou_dn_5: 0.1324 (0.1324)  loss_fgl_dn_5: 1.0678 (1.0678)  loss_mal_dn_pre: 0.7349 (0.7349)  loss_bbox_dn_pre: 0.1884 (0.1884)  loss_giou_dn_pre: 0.3523 (0.3523)  time: 2.1491  data: 0.8071  max mem: 13413\nEpoch: [34]  [100/251]  eta: 0:03:05  lr: 0.000002  loss: 29.4410 (31.8400)  loss_mal: 0.4358 (0.5232)  loss_bbox: 0.0779 (0.0947)  loss_giou: 0.2022 (0.2165)  loss_fgl: 1.1316 (1.1646)  loss_mal_aux_0: 0.8545 (0.9082)  loss_bbox_aux_0: 0.1070 (0.1292)  loss_giou_aux_0: 0.2349 (0.2779)  loss_fgl_aux_0: 1.1996 (1.2512)  loss_ddf_aux_0: 0.1404 (0.1632)  loss_mal_aux_1: 0.5532 (0.6639)  loss_bbox_aux_1: 0.0910 (0.1031)  loss_giou_aux_1: 0.2058 (0.2302)  loss_fgl_aux_1: 1.1407 (1.1825)  loss_ddf_aux_1: 0.0405 (0.0471)  loss_mal_aux_2: 0.4810 (0.5666)  loss_bbox_aux_2: 0.0839 (0.0970)  loss_giou_aux_2: 0.2031 (0.2204)  loss_fgl_aux_2: 1.1264 (1.1687)  loss_ddf_aux_2: 0.0076 (0.0087)  loss_mal_aux_3: 0.4441 (0.5347)  loss_bbox_aux_3: 0.0824 (0.0954)  loss_giou_aux_3: 0.2009 (0.2180)  loss_fgl_aux_3: 1.1299 (1.1658)  loss_ddf_aux_3: 0.0016 (0.0017)  loss_mal_aux_4: 0.4441 (0.5236)  loss_bbox_aux_4: 0.0784 (0.0948)  loss_giou_aux_4: 0.2034 (0.2170)  loss_fgl_aux_4: 1.1307 (1.1648)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8550 (0.9082)  loss_bbox_pre: 0.1061 (0.1292)  loss_giou_pre: 0.2321 (0.2771)  loss_mal_enc_0: 1.0977 (1.0902)  loss_bbox_enc_0: 0.1984 (0.2212)  loss_giou_enc_0: 0.4014 (0.4352)  loss_mal_dn_0: 0.7261 (0.7570)  loss_bbox_dn_0: 0.2008 (0.2310)  loss_giou_dn_0: 0.4248 (0.4532)  loss_fgl_dn_0: 1.3018 (1.3231)  loss_ddf_dn_0: 0.9007 (1.0007)  loss_mal_dn_1: 0.5801 (0.6204)  loss_bbox_dn_1: 0.1056 (0.1377)  loss_giou_dn_1: 0.2296 (0.2829)  loss_fgl_dn_1: 1.1431 (1.1906)  loss_ddf_dn_1: 0.2530 (0.2657)  loss_mal_dn_2: 0.4736 (0.5271)  loss_bbox_dn_2: 0.0874 (0.1158)  loss_giou_dn_2: 0.2000 (0.2452)  loss_fgl_dn_2: 1.1065 (1.1564)  loss_ddf_dn_2: 0.0734 (0.0789)  loss_mal_dn_3: 0.4419 (0.4908)  loss_bbox_dn_3: 0.0835 (0.1088)  loss_giou_dn_3: 0.1958 (0.2339)  loss_fgl_dn_3: 1.0989 (1.1478)  loss_ddf_dn_3: 0.0134 (0.0146)  loss_mal_dn_4: 0.4385 (0.4813)  loss_bbox_dn_4: 0.0831 (0.1066)  loss_giou_dn_4: 0.1951 (0.2298)  loss_fgl_dn_4: 1.0965 (1.1461)  loss_ddf_dn_4: 0.0013 (0.0015)  loss_mal_dn_5: 0.4390 (0.4792)  loss_bbox_dn_5: 0.0838 (0.1059)  loss_giou_dn_5: 0.1951 (0.2285)  loss_fgl_dn_5: 1.0971 (1.1458)  loss_mal_dn_pre: 0.7271 (0.7573)  loss_bbox_dn_pre: 0.2030 (0.2312)  loss_giou_dn_pre: 0.4166 (0.4509)  time: 1.2639  data: 0.0117  max mem: 13413\nEpoch: [34]  [200/251]  eta: 0:01:02  lr: 0.000002  loss: 33.5910 (32.6796)  loss_mal: 0.4890 (0.5594)  loss_bbox: 0.0872 (0.1024)  loss_giou: 0.2246 (0.2300)  loss_fgl: 1.1534 (1.1791)  loss_mal_aux_0: 0.8525 (0.9142)  loss_bbox_aux_0: 0.1349 (0.1372)  loss_giou_aux_0: 0.2718 (0.2922)  loss_fgl_aux_0: 1.2628 (1.2597)  loss_ddf_aux_0: 0.1605 (0.1685)  loss_mal_aux_1: 0.6724 (0.6984)  loss_bbox_aux_1: 0.1134 (0.1119)  loss_giou_aux_1: 0.2453 (0.2447)  loss_fgl_aux_1: 1.1935 (1.1955)  loss_ddf_aux_1: 0.0491 (0.0503)  loss_mal_aux_2: 0.6016 (0.6052)  loss_bbox_aux_2: 0.1024 (0.1051)  loss_giou_aux_2: 0.2317 (0.2342)  loss_fgl_aux_2: 1.1668 (1.1831)  loss_ddf_aux_2: 0.0099 (0.0098)  loss_mal_aux_3: 0.4917 (0.5712)  loss_bbox_aux_3: 0.0920 (0.1030)  loss_giou_aux_3: 0.2265 (0.2310)  loss_fgl_aux_3: 1.1586 (1.1800)  loss_ddf_aux_3: 0.0019 (0.0019)  loss_mal_aux_4: 0.4946 (0.5597)  loss_bbox_aux_4: 0.0874 (0.1025)  loss_giou_aux_4: 0.2251 (0.2302)  loss_fgl_aux_4: 1.1543 (1.1792)  loss_ddf_aux_4: 0.0003 (0.0002)  loss_mal_pre: 0.8511 (0.9143)  loss_bbox_pre: 0.1350 (0.1373)  loss_giou_pre: 0.2702 (0.2917)  loss_mal_enc_0: 1.0293 (1.1025)  loss_bbox_enc_0: 0.2239 (0.2311)  loss_giou_enc_0: 0.4414 (0.4553)  loss_mal_dn_0: 0.7573 (0.7616)  loss_bbox_dn_0: 0.2551 (0.2421)  loss_giou_dn_0: 0.4738 (0.4665)  loss_fgl_dn_0: 1.3197 (1.3257)  loss_ddf_dn_0: 1.1290 (1.0314)  loss_mal_dn_1: 0.6299 (0.6319)  loss_bbox_dn_1: 0.1619 (0.1498)  loss_giou_dn_1: 0.3116 (0.2986)  loss_fgl_dn_1: 1.2136 (1.1997)  loss_ddf_dn_1: 0.3105 (0.2770)  loss_mal_dn_2: 0.5728 (0.5396)  loss_bbox_dn_2: 0.1422 (0.1268)  loss_giou_dn_2: 0.2692 (0.2606)  loss_fgl_dn_2: 1.1661 (1.1672)  loss_ddf_dn_2: 0.0915 (0.0829)  loss_mal_dn_3: 0.5298 (0.5062)  loss_bbox_dn_3: 0.1272 (0.1196)  loss_giou_dn_3: 0.2619 (0.2490)  loss_fgl_dn_3: 1.1370 (1.1583)  loss_ddf_dn_3: 0.0162 (0.0152)  loss_mal_dn_4: 0.5283 (0.4977)  loss_bbox_dn_4: 0.1128 (0.1173)  loss_giou_dn_4: 0.2593 (0.2452)  loss_fgl_dn_4: 1.1340 (1.1564)  loss_ddf_dn_4: 0.0017 (0.0016)  loss_mal_dn_5: 0.5142 (0.4957)  loss_bbox_dn_5: 0.1123 (0.1167)  loss_giou_dn_5: 0.2563 (0.2441)  loss_fgl_dn_5: 1.1356 (1.1561)  loss_mal_dn_pre: 0.7583 (0.7624)  loss_bbox_dn_pre: 0.2583 (0.2418)  loss_giou_dn_pre: 0.4751 (0.4629)  time: 1.2109  data: 0.0106  max mem: 13413\nEpoch: [34]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 31.4642 (33.0532)  loss_mal: 0.5586 (0.5640)  loss_bbox: 0.0904 (0.1090)  loss_giou: 0.2259 (0.2383)  loss_fgl: 1.1813 (1.1865)  loss_mal_aux_0: 0.8579 (0.9241)  loss_bbox_aux_0: 0.1235 (0.1422)  loss_giou_aux_0: 0.2763 (0.2993)  loss_fgl_aux_0: 1.2577 (1.2640)  loss_ddf_aux_0: 0.1588 (0.1709)  loss_mal_aux_1: 0.7192 (0.7121)  loss_bbox_aux_1: 0.0996 (0.1189)  loss_giou_aux_1: 0.2419 (0.2533)  loss_fgl_aux_1: 1.2197 (1.2023)  loss_ddf_aux_1: 0.0508 (0.0516)  loss_mal_aux_2: 0.6328 (0.6145)  loss_bbox_aux_2: 0.0967 (0.1120)  loss_giou_aux_2: 0.2378 (0.2426)  loss_fgl_aux_2: 1.1991 (1.1901)  loss_ddf_aux_2: 0.0100 (0.0102)  loss_mal_aux_3: 0.5503 (0.5766)  loss_bbox_aux_3: 0.0903 (0.1095)  loss_giou_aux_3: 0.2267 (0.2393)  loss_fgl_aux_3: 1.1773 (1.1873)  loss_ddf_aux_3: 0.0020 (0.0019)  loss_mal_aux_4: 0.5630 (0.5659)  loss_bbox_aux_4: 0.0902 (0.1091)  loss_giou_aux_4: 0.2258 (0.2384)  loss_fgl_aux_4: 1.1806 (1.1866)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8569 (0.9241)  loss_bbox_pre: 0.1241 (0.1425)  loss_giou_pre: 0.2754 (0.2989)  loss_mal_enc_0: 1.0625 (1.1110)  loss_bbox_enc_0: 0.1944 (0.2366)  loss_giou_enc_0: 0.4284 (0.4601)  loss_mal_dn_0: 0.7573 (0.7630)  loss_bbox_dn_0: 0.1860 (0.2472)  loss_giou_dn_0: 0.4608 (0.4730)  loss_fgl_dn_0: 1.3064 (1.3245)  loss_ddf_dn_0: 0.9772 (1.0484)  loss_mal_dn_1: 0.6401 (0.6373)  loss_bbox_dn_1: 0.1185 (0.1550)  loss_giou_dn_1: 0.2750 (0.3056)  loss_fgl_dn_1: 1.1890 (1.2014)  loss_ddf_dn_1: 0.2856 (0.2834)  loss_mal_dn_2: 0.5293 (0.5448)  loss_bbox_dn_2: 0.1055 (0.1319)  loss_giou_dn_2: 0.2434 (0.2674)  loss_fgl_dn_2: 1.1566 (1.1702)  loss_ddf_dn_2: 0.0859 (0.0850)  loss_mal_dn_3: 0.4946 (0.5116)  loss_bbox_dn_3: 0.0992 (0.1246)  loss_giou_dn_3: 0.2383 (0.2558)  loss_fgl_dn_3: 1.1478 (1.1617)  loss_ddf_dn_3: 0.0163 (0.0156)  loss_mal_dn_4: 0.4873 (0.5030)  loss_bbox_dn_4: 0.0936 (0.1223)  loss_giou_dn_4: 0.2350 (0.2520)  loss_fgl_dn_4: 1.1486 (1.1600)  loss_ddf_dn_4: 0.0017 (0.0016)  loss_mal_dn_5: 0.4829 (0.5007)  loss_bbox_dn_5: 0.0928 (0.1216)  loss_giou_dn_5: 0.2331 (0.2508)  loss_fgl_dn_5: 1.1489 (1.1599)  loss_mal_dn_pre: 0.7583 (0.7641)  loss_bbox_dn_pre: 0.1802 (0.2467)  loss_giou_dn_pre: 0.4607 (0.4694)  time: 1.1638  data: 0.0112  max mem: 13413\nEpoch: [34] Total time: 0:05:04 (1.2145 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7964  data: 0.4879  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3532  data: 0.0669  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3044  data: 0.0206  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2926  data: 0.0193  max mem: 13413\nTest: Total time: 0:00:07 (0.3181 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.324\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.531\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.332\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.325\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.451\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.551\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.652\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.864\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.747\nbest_stat: {'epoch': 26, 'coco_eval_bbox': 0.3301681420872041}\nEpoch: [35]  [  0/251]  eta: 0:07:33  lr: 0.000002  loss: 33.2821 (33.2821)  loss_mal: 0.5083 (0.5083)  loss_bbox: 0.1172 (0.1172)  loss_giou: 0.2848 (0.2848)  loss_fgl: 1.2032 (1.2032)  loss_mal_aux_0: 1.0635 (1.0635)  loss_bbox_aux_0: 0.0943 (0.0943)  loss_giou_aux_0: 0.3286 (0.3286)  loss_fgl_aux_0: 1.2102 (1.2102)  loss_ddf_aux_0: 0.1518 (0.1518)  loss_mal_aux_1: 0.7095 (0.7095)  loss_bbox_aux_1: 0.1018 (0.1018)  loss_giou_aux_1: 0.2891 (0.2891)  loss_fgl_aux_1: 1.1872 (1.1872)  loss_ddf_aux_1: 0.0391 (0.0391)  loss_mal_aux_2: 0.5024 (0.5024)  loss_bbox_aux_2: 0.1085 (0.1085)  loss_giou_aux_2: 0.2852 (0.2852)  loss_fgl_aux_2: 1.2067 (1.2067)  loss_ddf_aux_2: 0.0109 (0.0109)  loss_mal_aux_3: 0.4980 (0.4980)  loss_bbox_aux_3: 0.1156 (0.1156)  loss_giou_aux_3: 0.2846 (0.2846)  loss_fgl_aux_3: 1.2016 (1.2016)  loss_ddf_aux_3: 0.0021 (0.0021)  loss_mal_aux_4: 0.5029 (0.5029)  loss_bbox_aux_4: 0.1174 (0.1174)  loss_giou_aux_4: 0.2854 (0.2854)  loss_fgl_aux_4: 1.2037 (1.2037)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 1.0664 (1.0664)  loss_bbox_pre: 0.0990 (0.0990)  loss_giou_pre: 0.3366 (0.3366)  loss_mal_enc_0: 1.0078 (1.0078)  loss_bbox_enc_0: 0.2243 (0.2243)  loss_giou_enc_0: 0.5307 (0.5307)  loss_mal_dn_0: 0.7505 (0.7505)  loss_bbox_dn_0: 0.2267 (0.2267)  loss_giou_dn_0: 0.4712 (0.4712)  loss_fgl_dn_0: 1.2765 (1.2765)  loss_ddf_dn_0: 1.2152 (1.2152)  loss_mal_dn_1: 0.6421 (0.6421)  loss_bbox_dn_1: 0.1321 (0.1321)  loss_giou_dn_1: 0.3144 (0.3144)  loss_fgl_dn_1: 1.1681 (1.1681)  loss_ddf_dn_1: 0.3252 (0.3252)  loss_mal_dn_2: 0.5620 (0.5620)  loss_bbox_dn_2: 0.1145 (0.1145)  loss_giou_dn_2: 0.2801 (0.2801)  loss_fgl_dn_2: 1.1441 (1.1441)  loss_ddf_dn_2: 0.0955 (0.0955)  loss_mal_dn_3: 0.5386 (0.5386)  loss_bbox_dn_3: 0.1161 (0.1161)  loss_giou_dn_3: 0.2748 (0.2748)  loss_fgl_dn_3: 1.1364 (1.1364)  loss_ddf_dn_3: 0.0200 (0.0200)  loss_mal_dn_4: 0.5342 (0.5342)  loss_bbox_dn_4: 0.1177 (0.1177)  loss_giou_dn_4: 0.2733 (0.2733)  loss_fgl_dn_4: 1.1341 (1.1341)  loss_ddf_dn_4: 0.0021 (0.0021)  loss_mal_dn_5: 0.5366 (0.5366)  loss_bbox_dn_5: 0.1176 (0.1176)  loss_giou_dn_5: 0.2716 (0.2716)  loss_fgl_dn_5: 1.1318 (1.1318)  loss_mal_dn_pre: 0.7515 (0.7515)  loss_bbox_dn_pre: 0.2392 (0.2392)  loss_giou_dn_pre: 0.4897 (0.4897)  time: 1.8086  data: 0.6191  max mem: 13413\nEpoch: [35]  [100/251]  eta: 0:03:08  lr: 0.000002  loss: 30.7702 (32.2258)  loss_mal: 0.4683 (0.5437)  loss_bbox: 0.0825 (0.0956)  loss_giou: 0.2080 (0.2154)  loss_fgl: 1.1563 (1.1627)  loss_mal_aux_0: 0.8276 (0.8925)  loss_bbox_aux_0: 0.1056 (0.1332)  loss_giou_aux_0: 0.2699 (0.2871)  loss_fgl_aux_0: 1.2410 (1.2622)  loss_ddf_aux_0: 0.1741 (0.1840)  loss_mal_aux_1: 0.5913 (0.6954)  loss_bbox_aux_1: 0.0886 (0.1056)  loss_giou_aux_1: 0.2150 (0.2333)  loss_fgl_aux_1: 1.1613 (1.1870)  loss_ddf_aux_1: 0.0480 (0.0555)  loss_mal_aux_2: 0.4949 (0.5846)  loss_bbox_aux_2: 0.0844 (0.0989)  loss_giou_aux_2: 0.2123 (0.2204)  loss_fgl_aux_2: 1.1513 (1.1692)  loss_ddf_aux_2: 0.0097 (0.0111)  loss_mal_aux_3: 0.4912 (0.5549)  loss_bbox_aux_3: 0.0837 (0.0967)  loss_giou_aux_3: 0.2095 (0.2164)  loss_fgl_aux_3: 1.1546 (1.1644)  loss_ddf_aux_3: 0.0019 (0.0022)  loss_mal_aux_4: 0.4678 (0.5465)  loss_bbox_aux_4: 0.0835 (0.0958)  loss_giou_aux_4: 0.2084 (0.2156)  loss_fgl_aux_4: 1.1570 (1.1633)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8301 (0.8960)  loss_bbox_pre: 0.1059 (0.1328)  loss_giou_pre: 0.2663 (0.2863)  loss_mal_enc_0: 1.0947 (1.1228)  loss_bbox_enc_0: 0.1895 (0.2314)  loss_giou_enc_0: 0.4428 (0.4527)  loss_mal_dn_0: 0.7485 (0.7546)  loss_bbox_dn_0: 0.2136 (0.2393)  loss_giou_dn_0: 0.4390 (0.4582)  loss_fgl_dn_0: 1.3220 (1.3275)  loss_ddf_dn_0: 1.0106 (1.0657)  loss_mal_dn_1: 0.6260 (0.6270)  loss_bbox_dn_1: 0.1138 (0.1440)  loss_giou_dn_1: 0.2749 (0.2865)  loss_fgl_dn_1: 1.1802 (1.1866)  loss_ddf_dn_1: 0.2729 (0.2984)  loss_mal_dn_2: 0.5327 (0.5388)  loss_bbox_dn_2: 0.0937 (0.1187)  loss_giou_dn_2: 0.2382 (0.2448)  loss_fgl_dn_2: 1.1351 (1.1476)  loss_ddf_dn_2: 0.0857 (0.0940)  loss_mal_dn_3: 0.4807 (0.4999)  loss_bbox_dn_3: 0.0869 (0.1113)  loss_giou_dn_3: 0.2258 (0.2328)  loss_fgl_dn_3: 1.1193 (1.1383)  loss_ddf_dn_3: 0.0162 (0.0178)  loss_mal_dn_4: 0.4824 (0.4895)  loss_bbox_dn_4: 0.0843 (0.1090)  loss_giou_dn_4: 0.2225 (0.2294)  loss_fgl_dn_4: 1.1175 (1.1368)  loss_ddf_dn_4: 0.0016 (0.0018)  loss_mal_dn_5: 0.4790 (0.4883)  loss_bbox_dn_5: 0.0841 (0.1084)  loss_giou_dn_5: 0.2235 (0.2285)  loss_fgl_dn_5: 1.1157 (1.1365)  loss_mal_dn_pre: 0.7485 (0.7555)  loss_bbox_dn_pre: 0.2087 (0.2397)  loss_giou_dn_pre: 0.4359 (0.4552)  time: 1.3102  data: 0.0110  max mem: 13413\nEpoch: [35]  [200/251]  eta: 0:01:02  lr: 0.000002  loss: 32.5682 (32.9408)  loss_mal: 0.4792 (0.5741)  loss_bbox: 0.0999 (0.1073)  loss_giou: 0.2045 (0.2315)  loss_fgl: 1.1617 (1.1844)  loss_mal_aux_0: 0.8975 (0.9137)  loss_bbox_aux_0: 0.1323 (0.1417)  loss_giou_aux_0: 0.2729 (0.2968)  loss_fgl_aux_0: 1.2647 (1.2687)  loss_ddf_aux_0: 0.1602 (0.1842)  loss_mal_aux_1: 0.7085 (0.7144)  loss_bbox_aux_1: 0.1069 (0.1165)  loss_giou_aux_1: 0.2160 (0.2472)  loss_fgl_aux_1: 1.1891 (1.2012)  loss_ddf_aux_1: 0.0468 (0.0556)  loss_mal_aux_2: 0.5347 (0.6153)  loss_bbox_aux_2: 0.1022 (0.1103)  loss_giou_aux_2: 0.2065 (0.2357)  loss_fgl_aux_2: 1.1688 (1.1887)  loss_ddf_aux_2: 0.0086 (0.0112)  loss_mal_aux_3: 0.5063 (0.5873)  loss_bbox_aux_3: 0.0991 (0.1083)  loss_giou_aux_3: 0.2136 (0.2325)  loss_fgl_aux_3: 1.1619 (1.1852)  loss_ddf_aux_3: 0.0018 (0.0022)  loss_mal_aux_4: 0.4790 (0.5780)  loss_bbox_aux_4: 0.0994 (0.1075)  loss_giou_aux_4: 0.2063 (0.2318)  loss_fgl_aux_4: 1.1633 (1.1846)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8994 (0.9174)  loss_bbox_pre: 0.1308 (0.1413)  loss_giou_pre: 0.2678 (0.2960)  loss_mal_enc_0: 1.1338 (1.1182)  loss_bbox_enc_0: 0.2109 (0.2397)  loss_giou_enc_0: 0.4336 (0.4626)  loss_mal_dn_0: 0.7476 (0.7586)  loss_bbox_dn_0: 0.2289 (0.2447)  loss_giou_dn_0: 0.4553 (0.4642)  loss_fgl_dn_0: 1.3042 (1.3259)  loss_ddf_dn_0: 0.9706 (1.0677)  loss_mal_dn_1: 0.6113 (0.6313)  loss_bbox_dn_1: 0.1569 (0.1524)  loss_giou_dn_1: 0.2949 (0.2973)  loss_fgl_dn_1: 1.1812 (1.1950)  loss_ddf_dn_1: 0.2524 (0.2931)  loss_mal_dn_2: 0.5269 (0.5422)  loss_bbox_dn_2: 0.1379 (0.1292)  loss_giou_dn_2: 0.2560 (0.2588)  loss_fgl_dn_2: 1.1525 (1.1620)  loss_ddf_dn_2: 0.0744 (0.0906)  loss_mal_dn_3: 0.4966 (0.5057)  loss_bbox_dn_3: 0.1264 (0.1217)  loss_giou_dn_3: 0.2385 (0.2473)  loss_fgl_dn_3: 1.1427 (1.1540)  loss_ddf_dn_3: 0.0138 (0.0169)  loss_mal_dn_4: 0.4851 (0.4967)  loss_bbox_dn_4: 0.1246 (0.1195)  loss_giou_dn_4: 0.2348 (0.2439)  loss_fgl_dn_4: 1.1412 (1.1531)  loss_ddf_dn_4: 0.0013 (0.0017)  loss_mal_dn_5: 0.4922 (0.4955)  loss_bbox_dn_5: 0.1241 (0.1189)  loss_giou_dn_5: 0.2324 (0.2430)  loss_fgl_dn_5: 1.1422 (1.1531)  loss_mal_dn_pre: 0.7476 (0.7600)  loss_bbox_dn_pre: 0.2249 (0.2444)  loss_giou_dn_pre: 0.4611 (0.4611)  time: 1.1319  data: 0.0121  max mem: 13413\nEpoch: [35]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 30.1683 (32.8101)  loss_mal: 0.4680 (0.5737)  loss_bbox: 0.0721 (0.1055)  loss_giou: 0.1820 (0.2297)  loss_fgl: 1.1301 (1.1828)  loss_mal_aux_0: 0.9468 (0.9136)  loss_bbox_aux_0: 0.0978 (0.1394)  loss_giou_aux_0: 0.2545 (0.2952)  loss_fgl_aux_0: 1.2317 (1.2690)  loss_ddf_aux_0: 0.1633 (0.1801)  loss_mal_aux_1: 0.6035 (0.7112)  loss_bbox_aux_1: 0.0780 (0.1145)  loss_giou_aux_1: 0.1994 (0.2455)  loss_fgl_aux_1: 1.1406 (1.2000)  loss_ddf_aux_1: 0.0398 (0.0537)  loss_mal_aux_2: 0.5654 (0.6175)  loss_bbox_aux_2: 0.0747 (0.1084)  loss_giou_aux_2: 0.1896 (0.2339)  loss_fgl_aux_2: 1.1242 (1.1869)  loss_ddf_aux_2: 0.0077 (0.0108)  loss_mal_aux_3: 0.5073 (0.5867)  loss_bbox_aux_3: 0.0735 (0.1065)  loss_giou_aux_3: 0.1851 (0.2306)  loss_fgl_aux_3: 1.1317 (1.1835)  loss_ddf_aux_3: 0.0014 (0.0021)  loss_mal_aux_4: 0.4932 (0.5771)  loss_bbox_aux_4: 0.0724 (0.1057)  loss_giou_aux_4: 0.1831 (0.2299)  loss_fgl_aux_4: 1.1330 (1.1829)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.9180 (0.9165)  loss_bbox_pre: 0.0967 (0.1390)  loss_giou_pre: 0.2564 (0.2944)  loss_mal_enc_0: 1.0391 (1.1060)  loss_bbox_enc_0: 0.2027 (0.2369)  loss_giou_enc_0: 0.4539 (0.4637)  loss_mal_dn_0: 0.7236 (0.7578)  loss_bbox_dn_0: 0.1949 (0.2419)  loss_giou_dn_0: 0.4065 (0.4645)  loss_fgl_dn_0: 1.3197 (1.3268)  loss_ddf_dn_0: 0.8878 (1.0497)  loss_mal_dn_1: 0.5835 (0.6282)  loss_bbox_dn_1: 0.1014 (0.1499)  loss_giou_dn_1: 0.2453 (0.2957)  loss_fgl_dn_1: 1.1541 (1.1944)  loss_ddf_dn_1: 0.2380 (0.2866)  loss_mal_dn_2: 0.4929 (0.5398)  loss_bbox_dn_2: 0.0846 (0.1268)  loss_giou_dn_2: 0.2056 (0.2569)  loss_fgl_dn_2: 1.0887 (1.1602)  loss_ddf_dn_2: 0.0691 (0.0874)  loss_mal_dn_3: 0.4595 (0.5046)  loss_bbox_dn_3: 0.0822 (0.1197)  loss_giou_dn_3: 0.1936 (0.2453)  loss_fgl_dn_3: 1.0818 (1.1520)  loss_ddf_dn_3: 0.0118 (0.0163)  loss_mal_dn_4: 0.4497 (0.4954)  loss_bbox_dn_4: 0.0806 (0.1175)  loss_giou_dn_4: 0.1886 (0.2418)  loss_fgl_dn_4: 1.0804 (1.1510)  loss_ddf_dn_4: 0.0012 (0.0016)  loss_mal_dn_5: 0.4568 (0.4942)  loss_bbox_dn_5: 0.0797 (0.1169)  loss_giou_dn_5: 0.1850 (0.2410)  loss_fgl_dn_5: 1.0790 (1.1508)  loss_mal_dn_pre: 0.7261 (0.7590)  loss_bbox_dn_pre: 0.1976 (0.2419)  loss_giou_dn_pre: 0.4073 (0.4615)  time: 1.1502  data: 0.0116  max mem: 13413\nEpoch: [35] Total time: 0:05:03 (1.2092 s / it)\nTest:  [ 0/25]  eta: 0:00:23    time: 0.9476  data: 0.5928  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3757  data: 0.0788  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3107  data: 0.0230  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2947  data: 0.0204  max mem: 13413\nTest: Total time: 0:00:08 (0.3299 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.533\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.335\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.353\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.452\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.568\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.671\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.659\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.904\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.747\nbest_stat: {'epoch': 26, 'coco_eval_bbox': 0.3301681420872041}\nEpoch: [36]  [  0/251]  eta: 0:10:06  lr: 0.000002  loss: 28.3696 (28.3696)  loss_mal: 0.5825 (0.5825)  loss_bbox: 0.0391 (0.0391)  loss_giou: 0.1626 (0.1626)  loss_fgl: 1.1018 (1.1018)  loss_mal_aux_0: 0.8257 (0.8257)  loss_bbox_aux_0: 0.0467 (0.0467)  loss_giou_aux_0: 0.1778 (0.1778)  loss_fgl_aux_0: 1.1507 (1.1507)  loss_ddf_aux_0: 0.1475 (0.1475)  loss_mal_aux_1: 0.6450 (0.6450)  loss_bbox_aux_1: 0.0379 (0.0379)  loss_giou_aux_1: 0.1638 (0.1638)  loss_fgl_aux_1: 1.1047 (1.1047)  loss_ddf_aux_1: 0.0335 (0.0335)  loss_mal_aux_2: 0.6709 (0.6709)  loss_bbox_aux_2: 0.0389 (0.0389)  loss_giou_aux_2: 0.1615 (0.1615)  loss_fgl_aux_2: 1.0984 (1.0984)  loss_ddf_aux_2: 0.0064 (0.0064)  loss_mal_aux_3: 0.5942 (0.5942)  loss_bbox_aux_3: 0.0388 (0.0388)  loss_giou_aux_3: 0.1608 (0.1608)  loss_fgl_aux_3: 1.1015 (1.1015)  loss_ddf_aux_3: 0.0013 (0.0013)  loss_mal_aux_4: 0.5947 (0.5947)  loss_bbox_aux_4: 0.0390 (0.0390)  loss_giou_aux_4: 0.1617 (0.1617)  loss_fgl_aux_4: 1.1015 (1.1015)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 0.8257 (0.8257)  loss_bbox_pre: 0.0455 (0.0455)  loss_giou_pre: 0.1753 (0.1753)  loss_mal_enc_0: 1.0293 (1.0293)  loss_bbox_enc_0: 0.1233 (0.1233)  loss_giou_enc_0: 0.4332 (0.4332)  loss_mal_dn_0: 0.6704 (0.6704)  loss_bbox_dn_0: 0.1053 (0.1053)  loss_giou_dn_0: 0.3626 (0.3626)  loss_fgl_dn_0: 1.2997 (1.2997)  loss_ddf_dn_0: 0.6792 (0.6792)  loss_mal_dn_1: 0.5483 (0.5483)  loss_bbox_dn_1: 0.0608 (0.0608)  loss_giou_dn_1: 0.2095 (0.2095)  loss_fgl_dn_1: 1.1394 (1.1394)  loss_ddf_dn_1: 0.1859 (0.1859)  loss_mal_dn_2: 0.5024 (0.5024)  loss_bbox_dn_2: 0.0542 (0.0542)  loss_giou_dn_2: 0.1815 (0.1815)  loss_fgl_dn_2: 1.1035 (1.1035)  loss_ddf_dn_2: 0.0501 (0.0501)  loss_mal_dn_3: 0.4807 (0.4807)  loss_bbox_dn_3: 0.0531 (0.0531)  loss_giou_dn_3: 0.1774 (0.1774)  loss_fgl_dn_3: 1.1025 (1.1025)  loss_ddf_dn_3: 0.0083 (0.0083)  loss_mal_dn_4: 0.4902 (0.4902)  loss_bbox_dn_4: 0.0530 (0.0530)  loss_giou_dn_4: 0.1741 (0.1741)  loss_fgl_dn_4: 1.1031 (1.1031)  loss_ddf_dn_4: 0.0009 (0.0009)  loss_mal_dn_5: 0.4888 (0.4888)  loss_bbox_dn_5: 0.0531 (0.0531)  loss_giou_dn_5: 0.1747 (0.1747)  loss_fgl_dn_5: 1.1038 (1.1038)  loss_mal_dn_pre: 0.6689 (0.6689)  loss_bbox_dn_pre: 0.1043 (0.1043)  loss_giou_dn_pre: 0.3581 (0.3581)  time: 2.4156  data: 0.8391  max mem: 13413\nEpoch: [36]  [100/251]  eta: 0:03:03  lr: 0.000002  loss: 31.4368 (31.5175)  loss_mal: 0.4905 (0.5169)  loss_bbox: 0.0818 (0.0956)  loss_giou: 0.2253 (0.2177)  loss_fgl: 1.1567 (1.1647)  loss_mal_aux_0: 0.8784 (0.8640)  loss_bbox_aux_0: 0.1077 (0.1274)  loss_giou_aux_0: 0.2726 (0.2707)  loss_fgl_aux_0: 1.2703 (1.2481)  loss_ddf_aux_0: 0.1532 (0.1682)  loss_mal_aux_1: 0.6313 (0.6551)  loss_bbox_aux_1: 0.0826 (0.1042)  loss_giou_aux_1: 0.2330 (0.2293)  loss_fgl_aux_1: 1.1836 (1.1807)  loss_ddf_aux_1: 0.0425 (0.0488)  loss_mal_aux_2: 0.5391 (0.5753)  loss_bbox_aux_2: 0.0827 (0.0983)  loss_giou_aux_2: 0.2289 (0.2209)  loss_fgl_aux_2: 1.1570 (1.1686)  loss_ddf_aux_2: 0.0079 (0.0097)  loss_mal_aux_3: 0.5171 (0.5308)  loss_bbox_aux_3: 0.0832 (0.0964)  loss_giou_aux_3: 0.2267 (0.2190)  loss_fgl_aux_3: 1.1589 (1.1651)  loss_ddf_aux_3: 0.0015 (0.0018)  loss_mal_aux_4: 0.5078 (0.5220)  loss_bbox_aux_4: 0.0824 (0.0957)  loss_giou_aux_4: 0.2255 (0.2180)  loss_fgl_aux_4: 1.1567 (1.1646)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8784 (0.8639)  loss_bbox_pre: 0.1063 (0.1273)  loss_giou_pre: 0.2740 (0.2696)  loss_mal_enc_0: 1.0801 (1.0728)  loss_bbox_enc_0: 0.2041 (0.2221)  loss_giou_enc_0: 0.4439 (0.4349)  loss_mal_dn_0: 0.7510 (0.7465)  loss_bbox_dn_0: 0.1995 (0.2200)  loss_giou_dn_0: 0.4417 (0.4382)  loss_fgl_dn_0: 1.3282 (1.3198)  loss_ddf_dn_0: 0.9442 (0.9991)  loss_mal_dn_1: 0.6021 (0.6046)  loss_bbox_dn_1: 0.1118 (0.1330)  loss_giou_dn_1: 0.2638 (0.2760)  loss_fgl_dn_1: 1.1795 (1.1768)  loss_ddf_dn_1: 0.2371 (0.2630)  loss_mal_dn_2: 0.5347 (0.5205)  loss_bbox_dn_2: 0.0913 (0.1127)  loss_giou_dn_2: 0.2412 (0.2416)  loss_fgl_dn_2: 1.1339 (1.1423)  loss_ddf_dn_2: 0.0689 (0.0758)  loss_mal_dn_3: 0.5020 (0.4887)  loss_bbox_dn_3: 0.0863 (0.1075)  loss_giou_dn_3: 0.2269 (0.2326)  loss_fgl_dn_3: 1.1139 (1.1346)  loss_ddf_dn_3: 0.0128 (0.0137)  loss_mal_dn_4: 0.5034 (0.4816)  loss_bbox_dn_4: 0.0816 (0.1056)  loss_giou_dn_4: 0.2210 (0.2292)  loss_fgl_dn_4: 1.1070 (1.1334)  loss_ddf_dn_4: 0.0012 (0.0014)  loss_mal_dn_5: 0.4971 (0.4790)  loss_bbox_dn_5: 0.0798 (0.1053)  loss_giou_dn_5: 0.2200 (0.2284)  loss_fgl_dn_5: 1.1061 (1.1335)  loss_mal_dn_pre: 0.7471 (0.7469)  loss_bbox_dn_pre: 0.1970 (0.2212)  loss_giou_dn_pre: 0.4386 (0.4365)  time: 1.1524  data: 0.0125  max mem: 13413\nEpoch: [36]  [200/251]  eta: 0:01:01  lr: 0.000002  loss: 32.0592 (31.9832)  loss_mal: 0.5381 (0.5434)  loss_bbox: 0.0894 (0.0971)  loss_giou: 0.2362 (0.2241)  loss_fgl: 1.1544 (1.1742)  loss_mal_aux_0: 0.9136 (0.8957)  loss_bbox_aux_0: 0.1253 (0.1296)  loss_giou_aux_0: 0.3162 (0.2865)  loss_fgl_aux_0: 1.2360 (1.2612)  loss_ddf_aux_0: 0.1830 (0.1756)  loss_mal_aux_1: 0.6738 (0.6797)  loss_bbox_aux_1: 0.0970 (0.1052)  loss_giou_aux_1: 0.2336 (0.2378)  loss_fgl_aux_1: 1.1691 (1.1903)  loss_ddf_aux_1: 0.0523 (0.0508)  loss_mal_aux_2: 0.5786 (0.5982)  loss_bbox_aux_2: 0.0906 (0.0996)  loss_giou_aux_2: 0.2306 (0.2280)  loss_fgl_aux_2: 1.1582 (1.1776)  loss_ddf_aux_2: 0.0102 (0.0101)  loss_mal_aux_3: 0.5522 (0.5601)  loss_bbox_aux_3: 0.0928 (0.0979)  loss_giou_aux_3: 0.2353 (0.2253)  loss_fgl_aux_3: 1.1526 (1.1743)  loss_ddf_aux_3: 0.0020 (0.0019)  loss_mal_aux_4: 0.5352 (0.5471)  loss_bbox_aux_4: 0.0910 (0.0972)  loss_giou_aux_4: 0.2360 (0.2243)  loss_fgl_aux_4: 1.1560 (1.1742)  loss_ddf_aux_4: 0.0003 (0.0002)  loss_mal_pre: 0.9136 (0.8958)  loss_bbox_pre: 0.1258 (0.1292)  loss_giou_pre: 0.3190 (0.2856)  loss_mal_enc_0: 1.0898 (1.0852)  loss_bbox_enc_0: 0.2138 (0.2251)  loss_giou_enc_0: 0.4603 (0.4565)  loss_mal_dn_0: 0.7402 (0.7520)  loss_bbox_dn_0: 0.2118 (0.2250)  loss_giou_dn_0: 0.4410 (0.4500)  loss_fgl_dn_0: 1.3318 (1.3214)  loss_ddf_dn_0: 0.8590 (0.9760)  loss_mal_dn_1: 0.6191 (0.6130)  loss_bbox_dn_1: 0.1176 (0.1362)  loss_giou_dn_1: 0.2734 (0.2833)  loss_fgl_dn_1: 1.1898 (1.1813)  loss_ddf_dn_1: 0.2410 (0.2613)  loss_mal_dn_2: 0.5425 (0.5247)  loss_bbox_dn_2: 0.0935 (0.1154)  loss_giou_dn_2: 0.2403 (0.2463)  loss_fgl_dn_2: 1.1384 (1.1454)  loss_ddf_dn_2: 0.0676 (0.0766)  loss_mal_dn_3: 0.4824 (0.4917)  loss_bbox_dn_3: 0.0911 (0.1098)  loss_giou_dn_3: 0.2281 (0.2364)  loss_fgl_dn_3: 1.1369 (1.1373)  loss_ddf_dn_3: 0.0131 (0.0138)  loss_mal_dn_4: 0.4709 (0.4829)  loss_bbox_dn_4: 0.0866 (0.1078)  loss_giou_dn_4: 0.2267 (0.2330)  loss_fgl_dn_4: 1.1446 (1.1360)  loss_ddf_dn_4: 0.0013 (0.0014)  loss_mal_dn_5: 0.4658 (0.4810)  loss_bbox_dn_5: 0.0863 (0.1074)  loss_giou_dn_5: 0.2269 (0.2322)  loss_fgl_dn_5: 1.1458 (1.1359)  loss_mal_dn_pre: 0.7437 (0.7527)  loss_bbox_dn_pre: 0.2056 (0.2249)  loss_giou_dn_pre: 0.4436 (0.4466)  time: 1.3090  data: 0.0114  max mem: 13413\nEpoch: [36]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 32.6433 (32.1753)  loss_mal: 0.4832 (0.5505)  loss_bbox: 0.0880 (0.1007)  loss_giou: 0.2182 (0.2251)  loss_fgl: 1.1820 (1.1764)  loss_mal_aux_0: 0.8896 (0.8997)  loss_bbox_aux_0: 0.1214 (0.1347)  loss_giou_aux_0: 0.2901 (0.2886)  loss_fgl_aux_0: 1.2525 (1.2635)  loss_ddf_aux_0: 0.1690 (0.1774)  loss_mal_aux_1: 0.6479 (0.6892)  loss_bbox_aux_1: 0.0974 (0.1093)  loss_giou_aux_1: 0.2362 (0.2392)  loss_fgl_aux_1: 1.2097 (1.1928)  loss_ddf_aux_1: 0.0451 (0.0520)  loss_mal_aux_2: 0.5186 (0.6051)  loss_bbox_aux_2: 0.0895 (0.1033)  loss_giou_aux_2: 0.2211 (0.2293)  loss_fgl_aux_2: 1.1924 (1.1797)  loss_ddf_aux_2: 0.0093 (0.0105)  loss_mal_aux_3: 0.4834 (0.5654)  loss_bbox_aux_3: 0.0873 (0.1015)  loss_giou_aux_3: 0.2194 (0.2265)  loss_fgl_aux_3: 1.1895 (1.1763)  loss_ddf_aux_3: 0.0020 (0.0020)  loss_mal_aux_4: 0.4863 (0.5537)  loss_bbox_aux_4: 0.0875 (0.1008)  loss_giou_aux_4: 0.2179 (0.2253)  loss_fgl_aux_4: 1.1841 (1.1763)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8911 (0.8997)  loss_bbox_pre: 0.1190 (0.1344)  loss_giou_pre: 0.2922 (0.2877)  loss_mal_enc_0: 1.0869 (1.0890)  loss_bbox_enc_0: 0.2049 (0.2302)  loss_giou_enc_0: 0.4329 (0.4546)  loss_mal_dn_0: 0.7754 (0.7529)  loss_bbox_dn_0: 0.2478 (0.2322)  loss_giou_dn_0: 0.4453 (0.4507)  loss_fgl_dn_0: 1.3429 (1.3226)  loss_ddf_dn_0: 0.8280 (0.9747)  loss_mal_dn_1: 0.6362 (0.6154)  loss_bbox_dn_1: 0.1377 (0.1421)  loss_giou_dn_1: 0.2792 (0.2851)  loss_fgl_dn_1: 1.2125 (1.1846)  loss_ddf_dn_1: 0.2130 (0.2619)  loss_mal_dn_2: 0.5308 (0.5267)  loss_bbox_dn_2: 0.1080 (0.1205)  loss_giou_dn_2: 0.2450 (0.2484)  loss_fgl_dn_2: 1.1751 (1.1497)  loss_ddf_dn_2: 0.0654 (0.0777)  loss_mal_dn_3: 0.5107 (0.4939)  loss_bbox_dn_3: 0.1002 (0.1144)  loss_giou_dn_3: 0.2381 (0.2382)  loss_fgl_dn_3: 1.1517 (1.1416)  loss_ddf_dn_3: 0.0123 (0.0142)  loss_mal_dn_4: 0.5068 (0.4854)  loss_bbox_dn_4: 0.0971 (0.1122)  loss_giou_dn_4: 0.2276 (0.2346)  loss_fgl_dn_4: 1.1424 (1.1401)  loss_ddf_dn_4: 0.0012 (0.0014)  loss_mal_dn_5: 0.5044 (0.4839)  loss_bbox_dn_5: 0.0981 (0.1118)  loss_giou_dn_5: 0.2279 (0.2338)  loss_fgl_dn_5: 1.1423 (1.1400)  loss_mal_dn_pre: 0.7764 (0.7534)  loss_bbox_dn_pre: 0.2561 (0.2327)  loss_giou_dn_pre: 0.4430 (0.4479)  time: 1.2270  data: 0.0109  max mem: 13413\nEpoch: [36] Total time: 0:05:04 (1.2135 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7743  data: 0.4617  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3501  data: 0.0628  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3059  data: 0.0215  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2941  data: 0.0206  max mem: 13413\nTest: Total time: 0:00:07 (0.3181 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.536\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.343\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.451\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.570\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.668\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.656\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.904\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.747\nbest_stat: {'epoch': 26, 'coco_eval_bbox': 0.3301681420872041}\nEpoch: [37]  [  0/251]  eta: 0:09:57  lr: 0.000002  loss: 31.3277 (31.3277)  loss_mal: 0.6001 (0.6001)  loss_bbox: 0.1227 (0.1227)  loss_giou: 0.2048 (0.2048)  loss_fgl: 1.1124 (1.1124)  loss_mal_aux_0: 0.7827 (0.7827)  loss_bbox_aux_0: 0.1874 (0.1874)  loss_giou_aux_0: 0.3030 (0.3030)  loss_fgl_aux_0: 1.2471 (1.2471)  loss_ddf_aux_0: 0.1777 (0.1777)  loss_mal_aux_1: 0.6934 (0.6934)  loss_bbox_aux_1: 0.1467 (0.1467)  loss_giou_aux_1: 0.2444 (0.2444)  loss_fgl_aux_1: 1.1609 (1.1609)  loss_ddf_aux_1: 0.0474 (0.0474)  loss_mal_aux_2: 0.5884 (0.5884)  loss_bbox_aux_2: 0.1306 (0.1306)  loss_giou_aux_2: 0.2212 (0.2212)  loss_fgl_aux_2: 1.1303 (1.1303)  loss_ddf_aux_2: 0.0089 (0.0089)  loss_mal_aux_3: 0.5571 (0.5571)  loss_bbox_aux_3: 0.1258 (0.1258)  loss_giou_aux_3: 0.2110 (0.2110)  loss_fgl_aux_3: 1.1211 (1.1211)  loss_ddf_aux_3: 0.0015 (0.0015)  loss_mal_aux_4: 0.6025 (0.6025)  loss_bbox_aux_4: 0.1241 (0.1241)  loss_giou_aux_4: 0.2066 (0.2066)  loss_fgl_aux_4: 1.1158 (1.1158)  loss_ddf_aux_4: -0.0001 (-0.0001)  loss_mal_pre: 0.7837 (0.7837)  loss_bbox_pre: 0.1865 (0.1865)  loss_giou_pre: 0.3020 (0.3020)  loss_mal_enc_0: 0.8730 (0.8730)  loss_bbox_enc_0: 0.1749 (0.1749)  loss_giou_enc_0: 0.3979 (0.3979)  loss_mal_dn_0: 0.7627 (0.7627)  loss_bbox_dn_0: 0.2632 (0.2632)  loss_giou_dn_0: 0.4633 (0.4633)  loss_fgl_dn_0: 1.3001 (1.3001)  loss_ddf_dn_0: 0.9612 (0.9612)  loss_mal_dn_1: 0.6206 (0.6206)  loss_bbox_dn_1: 0.1700 (0.1700)  loss_giou_dn_1: 0.2912 (0.2912)  loss_fgl_dn_1: 1.1617 (1.1617)  loss_ddf_dn_1: 0.2517 (0.2517)  loss_mal_dn_2: 0.5269 (0.5269)  loss_bbox_dn_2: 0.1360 (0.1360)  loss_giou_dn_2: 0.2406 (0.2406)  loss_fgl_dn_2: 1.1016 (1.1016)  loss_ddf_dn_2: 0.0736 (0.0736)  loss_mal_dn_3: 0.4624 (0.4624)  loss_bbox_dn_3: 0.1228 (0.1228)  loss_giou_dn_3: 0.2182 (0.2182)  loss_fgl_dn_3: 1.0840 (1.0840)  loss_ddf_dn_3: 0.0123 (0.0123)  loss_mal_dn_4: 0.4475 (0.4475)  loss_bbox_dn_4: 0.1188 (0.1188)  loss_giou_dn_4: 0.2105 (0.2105)  loss_fgl_dn_4: 1.0789 (1.0789)  loss_ddf_dn_4: 0.0011 (0.0011)  loss_mal_dn_5: 0.4441 (0.4441)  loss_bbox_dn_5: 0.1174 (0.1174)  loss_giou_dn_5: 0.2090 (0.2090)  loss_fgl_dn_5: 1.0768 (1.0768)  loss_mal_dn_pre: 0.7656 (0.7656)  loss_bbox_dn_pre: 0.2701 (0.2701)  loss_giou_dn_pre: 0.4703 (0.4703)  time: 2.3812  data: 1.3228  max mem: 13413\nEpoch: [37]  [100/251]  eta: 0:03:07  lr: 0.000002  loss: 32.0986 (31.8471)  loss_mal: 0.4668 (0.5264)  loss_bbox: 0.0945 (0.0958)  loss_giou: 0.2121 (0.2159)  loss_fgl: 1.1502 (1.1595)  loss_mal_aux_0: 0.8691 (0.9043)  loss_bbox_aux_0: 0.1335 (0.1309)  loss_giou_aux_0: 0.2857 (0.2777)  loss_fgl_aux_0: 1.2543 (1.2546)  loss_ddf_aux_0: 0.1893 (0.1870)  loss_mal_aux_1: 0.6953 (0.6953)  loss_bbox_aux_1: 0.1005 (0.1045)  loss_giou_aux_1: 0.2145 (0.2293)  loss_fgl_aux_1: 1.1596 (1.1783)  loss_ddf_aux_1: 0.0531 (0.0551)  loss_mal_aux_2: 0.5713 (0.5935)  loss_bbox_aux_2: 0.0979 (0.0976)  loss_giou_aux_2: 0.2136 (0.2188)  loss_fgl_aux_2: 1.1494 (1.1624)  loss_ddf_aux_2: 0.0104 (0.0104)  loss_mal_aux_3: 0.4858 (0.5474)  loss_bbox_aux_3: 0.0952 (0.0961)  loss_giou_aux_3: 0.2113 (0.2164)  loss_fgl_aux_3: 1.1452 (1.1603)  loss_ddf_aux_3: 0.0021 (0.0019)  loss_mal_aux_4: 0.4695 (0.5389)  loss_bbox_aux_4: 0.0946 (0.0958)  loss_giou_aux_4: 0.2125 (0.2160)  loss_fgl_aux_4: 1.1481 (1.1596)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8696 (0.9061)  loss_bbox_pre: 0.1319 (0.1304)  loss_giou_pre: 0.2869 (0.2765)  loss_mal_enc_0: 1.0898 (1.1025)  loss_bbox_enc_0: 0.2179 (0.2247)  loss_giou_enc_0: 0.4523 (0.4465)  loss_mal_dn_0: 0.7515 (0.7481)  loss_bbox_dn_0: 0.2189 (0.2293)  loss_giou_dn_0: 0.4438 (0.4443)  loss_fgl_dn_0: 1.3220 (1.3217)  loss_ddf_dn_0: 0.9991 (1.0119)  loss_mal_dn_1: 0.6304 (0.6109)  loss_bbox_dn_1: 0.1316 (0.1387)  loss_giou_dn_1: 0.2801 (0.2797)  loss_fgl_dn_1: 1.1776 (1.1800)  loss_ddf_dn_1: 0.2645 (0.2703)  loss_mal_dn_2: 0.5259 (0.5235)  loss_bbox_dn_2: 0.1030 (0.1160)  loss_giou_dn_2: 0.2393 (0.2414)  loss_fgl_dn_2: 1.1288 (1.1426)  loss_ddf_dn_2: 0.0748 (0.0785)  loss_mal_dn_3: 0.5068 (0.4882)  loss_bbox_dn_3: 0.0972 (0.1101)  loss_giou_dn_3: 0.2295 (0.2315)  loss_fgl_dn_3: 1.1155 (1.1341)  loss_ddf_dn_3: 0.0161 (0.0149)  loss_mal_dn_4: 0.4934 (0.4788)  loss_bbox_dn_4: 0.0932 (0.1083)  loss_giou_dn_4: 0.2265 (0.2285)  loss_fgl_dn_4: 1.1139 (1.1328)  loss_ddf_dn_4: 0.0016 (0.0014)  loss_mal_dn_5: 0.4822 (0.4763)  loss_bbox_dn_5: 0.0924 (0.1081)  loss_giou_dn_5: 0.2243 (0.2280)  loss_fgl_dn_5: 1.1131 (1.1325)  loss_mal_dn_pre: 0.7515 (0.7490)  loss_bbox_dn_pre: 0.2226 (0.2297)  loss_giou_dn_pre: 0.4360 (0.4416)  time: 1.2691  data: 0.0118  max mem: 13413\nEpoch: [37]  [200/251]  eta: 0:01:02  lr: 0.000002  loss: 31.0743 (31.8336)  loss_mal: 0.4556 (0.5343)  loss_bbox: 0.0788 (0.0967)  loss_giou: 0.2035 (0.2161)  loss_fgl: 1.1505 (1.1612)  loss_mal_aux_0: 0.8413 (0.9018)  loss_bbox_aux_0: 0.1061 (0.1305)  loss_giou_aux_0: 0.2491 (0.2811)  loss_fgl_aux_0: 1.2350 (1.2546)  loss_ddf_aux_0: 0.1850 (0.1902)  loss_mal_aux_1: 0.6392 (0.6909)  loss_bbox_aux_1: 0.0846 (0.1051)  loss_giou_aux_1: 0.2245 (0.2303)  loss_fgl_aux_1: 1.1547 (1.1798)  loss_ddf_aux_1: 0.0482 (0.0553)  loss_mal_aux_2: 0.6489 (0.5983)  loss_bbox_aux_2: 0.0819 (0.0990)  loss_giou_aux_2: 0.2272 (0.2195)  loss_fgl_aux_2: 1.1489 (1.1648)  loss_ddf_aux_2: 0.0094 (0.0105)  loss_mal_aux_3: 0.5132 (0.5555)  loss_bbox_aux_3: 0.0792 (0.0973)  loss_giou_aux_3: 0.2145 (0.2169)  loss_fgl_aux_3: 1.1529 (1.1620)  loss_ddf_aux_3: 0.0018 (0.0020)  loss_mal_aux_4: 0.4707 (0.5440)  loss_bbox_aux_4: 0.0777 (0.0968)  loss_giou_aux_4: 0.2068 (0.2163)  loss_fgl_aux_4: 1.1504 (1.1613)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8403 (0.9033)  loss_bbox_pre: 0.1057 (0.1303)  loss_giou_pre: 0.2450 (0.2803)  loss_mal_enc_0: 1.0059 (1.0824)  loss_bbox_enc_0: 0.1801 (0.2244)  loss_giou_enc_0: 0.4219 (0.4512)  loss_mal_dn_0: 0.7485 (0.7493)  loss_bbox_dn_0: 0.2133 (0.2271)  loss_giou_dn_0: 0.3981 (0.4401)  loss_fgl_dn_0: 1.3132 (1.3205)  loss_ddf_dn_0: 0.9459 (1.0065)  loss_mal_dn_1: 0.5864 (0.6092)  loss_bbox_dn_1: 0.1106 (0.1376)  loss_giou_dn_1: 0.2415 (0.2769)  loss_fgl_dn_1: 1.1501 (1.1783)  loss_ddf_dn_1: 0.2414 (0.2647)  loss_mal_dn_2: 0.5068 (0.5217)  loss_bbox_dn_2: 0.0864 (0.1155)  loss_giou_dn_2: 0.2143 (0.2397)  loss_fgl_dn_2: 1.1132 (1.1432)  loss_ddf_dn_2: 0.0683 (0.0769)  loss_mal_dn_3: 0.4690 (0.4868)  loss_bbox_dn_3: 0.0821 (0.1095)  loss_giou_dn_3: 0.2129 (0.2299)  loss_fgl_dn_3: 1.1136 (1.1355)  loss_ddf_dn_3: 0.0141 (0.0146)  loss_mal_dn_4: 0.4509 (0.4770)  loss_bbox_dn_4: 0.0816 (0.1078)  loss_giou_dn_4: 0.2107 (0.2270)  loss_fgl_dn_4: 1.1153 (1.1342)  loss_ddf_dn_4: 0.0013 (0.0014)  loss_mal_dn_5: 0.4568 (0.4747)  loss_bbox_dn_5: 0.0826 (0.1075)  loss_giou_dn_5: 0.2107 (0.2265)  loss_fgl_dn_5: 1.1142 (1.1340)  loss_mal_dn_pre: 0.7515 (0.7505)  loss_bbox_dn_pre: 0.2138 (0.2274)  loss_giou_dn_pre: 0.4057 (0.4379)  time: 1.1575  data: 0.0119  max mem: 13413\nEpoch: [37]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 30.4808 (31.9792)  loss_mal: 0.4678 (0.5412)  loss_bbox: 0.0744 (0.0963)  loss_giou: 0.2089 (0.2170)  loss_fgl: 1.1249 (1.1606)  loss_mal_aux_0: 0.9565 (0.9139)  loss_bbox_aux_0: 0.1015 (0.1309)  loss_giou_aux_0: 0.2598 (0.2836)  loss_fgl_aux_0: 1.2213 (1.2555)  loss_ddf_aux_0: 0.2005 (0.1960)  loss_mal_aux_1: 0.6655 (0.6978)  loss_bbox_aux_1: 0.0810 (0.1053)  loss_giou_aux_1: 0.2206 (0.2316)  loss_fgl_aux_1: 1.1664 (1.1801)  loss_ddf_aux_1: 0.0484 (0.0574)  loss_mal_aux_2: 0.4875 (0.5997)  loss_bbox_aux_2: 0.0773 (0.0989)  loss_giou_aux_2: 0.2134 (0.2204)  loss_fgl_aux_2: 1.1567 (1.1646)  loss_ddf_aux_2: 0.0098 (0.0109)  loss_mal_aux_3: 0.4734 (0.5599)  loss_bbox_aux_3: 0.0770 (0.0970)  loss_giou_aux_3: 0.2104 (0.2178)  loss_fgl_aux_3: 1.1353 (1.1613)  loss_ddf_aux_3: 0.0017 (0.0020)  loss_mal_aux_4: 0.4714 (0.5488)  loss_bbox_aux_4: 0.0753 (0.0964)  loss_giou_aux_4: 0.2089 (0.2172)  loss_fgl_aux_4: 1.1267 (1.1606)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.9551 (0.9148)  loss_bbox_pre: 0.1020 (0.1308)  loss_giou_pre: 0.2552 (0.2829)  loss_mal_enc_0: 1.0459 (1.1000)  loss_bbox_enc_0: 0.2116 (0.2257)  loss_giou_enc_0: 0.4426 (0.4554)  loss_mal_dn_0: 0.7437 (0.7507)  loss_bbox_dn_0: 0.2161 (0.2285)  loss_giou_dn_0: 0.4029 (0.4422)  loss_fgl_dn_0: 1.3081 (1.3215)  loss_ddf_dn_0: 0.9882 (1.0110)  loss_mal_dn_1: 0.5913 (0.6130)  loss_bbox_dn_1: 0.1206 (0.1388)  loss_giou_dn_1: 0.2515 (0.2792)  loss_fgl_dn_1: 1.1749 (1.1802)  loss_ddf_dn_1: 0.2602 (0.2674)  loss_mal_dn_2: 0.5103 (0.5250)  loss_bbox_dn_2: 0.0894 (0.1166)  loss_giou_dn_2: 0.2207 (0.2417)  loss_fgl_dn_2: 1.1280 (1.1448)  loss_ddf_dn_2: 0.0788 (0.0775)  loss_mal_dn_3: 0.4778 (0.4904)  loss_bbox_dn_3: 0.0788 (0.1104)  loss_giou_dn_3: 0.2075 (0.2317)  loss_fgl_dn_3: 1.1164 (1.1370)  loss_ddf_dn_3: 0.0154 (0.0147)  loss_mal_dn_4: 0.4717 (0.4800)  loss_bbox_dn_4: 0.0745 (0.1086)  loss_giou_dn_4: 0.2062 (0.2287)  loss_fgl_dn_4: 1.1122 (1.1357)  loss_ddf_dn_4: 0.0014 (0.0014)  loss_mal_dn_5: 0.4729 (0.4781)  loss_bbox_dn_5: 0.0746 (0.1083)  loss_giou_dn_5: 0.2071 (0.2282)  loss_fgl_dn_5: 1.1105 (1.1355)  loss_mal_dn_pre: 0.7432 (0.7518)  loss_bbox_dn_pre: 0.2183 (0.2286)  loss_giou_dn_pre: 0.4080 (0.4397)  time: 1.2857  data: 0.0116  max mem: 13413\nEpoch: [37] Total time: 0:05:12 (1.2448 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7787  data: 0.4623  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3542  data: 0.0646  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3080  data: 0.0220  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2954  data: 0.0201  max mem: 13413\nTest: Total time: 0:00:08 (0.3209 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.538\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.346\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.460\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.575\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.669\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.657\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.904\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.743\nbest_stat: {'epoch': 37, 'coco_eval_bbox': 0.33732990994399764}\nLoad last_epoch\nLoad model.state_dict\nLoad criterion.state_dict\nLoad postprocessor.state_dict\nLoad ema.state_dict\nLoad scaler.state_dict\nLoad optimizer.state_dict\nLoad lr_warmup_scheduler.state_dict\nRefresh EMA at epoch 38 with decay 0.9998\nEpoch: [38]  [  0/251]  eta: 0:09:17  lr: 0.000002  loss: 27.3762 (27.3762)  loss_mal: 0.3560 (0.3560)  loss_bbox: 0.0651 (0.0651)  loss_giou: 0.1528 (0.1528)  loss_fgl: 1.0310 (1.0310)  loss_mal_aux_0: 0.9614 (0.9614)  loss_bbox_aux_0: 0.0990 (0.0990)  loss_giou_aux_0: 0.2331 (0.2331)  loss_fgl_aux_0: 1.1853 (1.1853)  loss_ddf_aux_0: 0.2063 (0.2063)  loss_mal_aux_1: 0.4355 (0.4355)  loss_bbox_aux_1: 0.0700 (0.0700)  loss_giou_aux_1: 0.1591 (0.1591)  loss_fgl_aux_1: 1.0626 (1.0626)  loss_ddf_aux_1: 0.0502 (0.0502)  loss_mal_aux_2: 0.3657 (0.3657)  loss_bbox_aux_2: 0.0640 (0.0640)  loss_giou_aux_2: 0.1509 (0.1509)  loss_fgl_aux_2: 1.0322 (1.0322)  loss_ddf_aux_2: 0.0064 (0.0064)  loss_mal_aux_3: 0.3577 (0.3577)  loss_bbox_aux_3: 0.0639 (0.0639)  loss_giou_aux_3: 0.1511 (0.1511)  loss_fgl_aux_3: 1.0315 (1.0315)  loss_ddf_aux_3: 0.0012 (0.0012)  loss_mal_aux_4: 0.3569 (0.3569)  loss_bbox_aux_4: 0.0648 (0.0648)  loss_giou_aux_4: 0.1523 (0.1523)  loss_fgl_aux_4: 1.0319 (1.0319)  loss_ddf_aux_4: 0.0004 (0.0004)  loss_mal_pre: 0.9648 (0.9648)  loss_bbox_pre: 0.0986 (0.0986)  loss_giou_pre: 0.2332 (0.2332)  loss_mal_enc_0: 1.2119 (1.2119)  loss_bbox_enc_0: 0.1859 (0.1859)  loss_giou_enc_0: 0.3930 (0.3930)  loss_mal_dn_0: 0.7349 (0.7349)  loss_bbox_dn_0: 0.1681 (0.1681)  loss_giou_dn_0: 0.3574 (0.3574)  loss_fgl_dn_0: 1.2750 (1.2750)  loss_ddf_dn_0: 1.0451 (1.0451)  loss_mal_dn_1: 0.4863 (0.4863)  loss_bbox_dn_1: 0.0780 (0.0780)  loss_giou_dn_1: 0.1820 (0.1820)  loss_fgl_dn_1: 1.0578 (1.0578)  loss_ddf_dn_1: 0.2471 (0.2471)  loss_mal_dn_2: 0.3992 (0.3992)  loss_bbox_dn_2: 0.0643 (0.0643)  loss_giou_dn_2: 0.1562 (0.1562)  loss_fgl_dn_2: 1.0090 (1.0090)  loss_ddf_dn_2: 0.0631 (0.0631)  loss_mal_dn_3: 0.3738 (0.3738)  loss_bbox_dn_3: 0.0641 (0.0641)  loss_giou_dn_3: 0.1541 (0.1541)  loss_fgl_dn_3: 1.0055 (1.0055)  loss_ddf_dn_3: 0.0107 (0.0107)  loss_mal_dn_4: 0.3752 (0.3752)  loss_bbox_dn_4: 0.0639 (0.0639)  loss_giou_dn_4: 0.1555 (0.1555)  loss_fgl_dn_4: 1.0037 (1.0037)  loss_ddf_dn_4: 0.0011 (0.0011)  loss_mal_dn_5: 0.3750 (0.3750)  loss_bbox_dn_5: 0.0639 (0.0639)  loss_giou_dn_5: 0.1561 (0.1561)  loss_fgl_dn_5: 1.0025 (1.0025)  loss_mal_dn_pre: 0.7349 (0.7349)  loss_bbox_dn_pre: 0.1710 (0.1710)  loss_giou_dn_pre: 0.3560 (0.3560)  time: 2.2213  data: 0.8854  max mem: 13413\nEpoch: [38]  [100/251]  eta: 0:03:02  lr: 0.000002  loss: 29.3252 (30.3054)  loss_mal: 0.4072 (0.4583)  loss_bbox: 0.0660 (0.0859)  loss_giou: 0.1596 (0.1948)  loss_fgl: 1.0917 (1.1286)  loss_mal_aux_0: 0.8120 (0.8886)  loss_bbox_aux_0: 0.1010 (0.1179)  loss_giou_aux_0: 0.2229 (0.2578)  loss_fgl_aux_0: 1.2251 (1.2354)  loss_ddf_aux_0: 0.1921 (0.2031)  loss_mal_aux_1: 0.5605 (0.6343)  loss_bbox_aux_1: 0.0794 (0.0922)  loss_giou_aux_1: 0.1847 (0.2064)  loss_fgl_aux_1: 1.1355 (1.1505)  loss_ddf_aux_1: 0.0514 (0.0566)  loss_mal_aux_2: 0.4714 (0.5215)  loss_bbox_aux_2: 0.0693 (0.0875)  loss_giou_aux_2: 0.1641 (0.1969)  loss_fgl_aux_2: 1.1029 (1.1323)  loss_ddf_aux_2: 0.0088 (0.0096)  loss_mal_aux_3: 0.4360 (0.4750)  loss_bbox_aux_3: 0.0675 (0.0862)  loss_giou_aux_3: 0.1610 (0.1951)  loss_fgl_aux_3: 1.0918 (1.1292)  loss_ddf_aux_3: 0.0015 (0.0018)  loss_mal_aux_4: 0.4180 (0.4607)  loss_bbox_aux_4: 0.0659 (0.0860)  loss_giou_aux_4: 0.1607 (0.1949)  loss_fgl_aux_4: 1.0918 (1.1287)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8115 (0.8898)  loss_bbox_pre: 0.1007 (0.1175)  loss_giou_pre: 0.2203 (0.2571)  loss_mal_enc_0: 1.0400 (1.0614)  loss_bbox_enc_0: 0.1876 (0.2092)  loss_giou_enc_0: 0.3865 (0.4246)  loss_mal_dn_0: 0.7236 (0.7384)  loss_bbox_dn_0: 0.1829 (0.2096)  loss_giou_dn_0: 0.3957 (0.4077)  loss_fgl_dn_0: 1.3198 (1.3231)  loss_ddf_dn_0: 0.9329 (0.9897)  loss_mal_dn_1: 0.5747 (0.5826)  loss_bbox_dn_1: 0.1078 (0.1209)  loss_giou_dn_1: 0.2408 (0.2461)  loss_fgl_dn_1: 1.1496 (1.1560)  loss_ddf_dn_1: 0.2267 (0.2500)  loss_mal_dn_2: 0.4675 (0.4972)  loss_bbox_dn_2: 0.0846 (0.0995)  loss_giou_dn_2: 0.1959 (0.2110)  loss_fgl_dn_2: 1.0940 (1.1126)  loss_ddf_dn_2: 0.0603 (0.0685)  loss_mal_dn_3: 0.4446 (0.4599)  loss_bbox_dn_3: 0.0776 (0.0938)  loss_giou_dn_3: 0.1819 (0.2024)  loss_fgl_dn_3: 1.0829 (1.1035)  loss_ddf_dn_3: 0.0124 (0.0128)  loss_mal_dn_4: 0.4326 (0.4516)  loss_bbox_dn_4: 0.0752 (0.0922)  loss_giou_dn_4: 0.1813 (0.2002)  loss_fgl_dn_4: 1.0828 (1.1016)  loss_ddf_dn_4: 0.0012 (0.0012)  loss_mal_dn_5: 0.4275 (0.4495)  loss_bbox_dn_5: 0.0746 (0.0919)  loss_giou_dn_5: 0.1801 (0.1997)  loss_fgl_dn_5: 1.0827 (1.1012)  loss_mal_dn_pre: 0.7231 (0.7390)  loss_bbox_dn_pre: 0.1835 (0.2099)  loss_giou_dn_pre: 0.3994 (0.4065)  time: 1.2209  data: 0.0125  max mem: 13413\nEpoch: [38]  [200/251]  eta: 0:01:01  lr: 0.000002  loss: 28.2465 (30.3833)  loss_mal: 0.4089 (0.4681)  loss_bbox: 0.0688 (0.0905)  loss_giou: 0.1661 (0.1980)  loss_fgl: 1.0990 (1.1338)  loss_mal_aux_0: 0.7588 (0.8716)  loss_bbox_aux_0: 0.1089 (0.1229)  loss_giou_aux_0: 0.2443 (0.2624)  loss_fgl_aux_0: 1.2131 (1.2413)  loss_ddf_aux_0: 0.1802 (0.2016)  loss_mal_aux_1: 0.5098 (0.6359)  loss_bbox_aux_1: 0.0820 (0.0981)  loss_giou_aux_1: 0.1831 (0.2105)  loss_fgl_aux_1: 1.1264 (1.1574)  loss_ddf_aux_1: 0.0450 (0.0551)  loss_mal_aux_2: 0.4495 (0.5272)  loss_bbox_aux_2: 0.0711 (0.0928)  loss_giou_aux_2: 0.1673 (0.2008)  loss_fgl_aux_2: 1.0986 (1.1393)  loss_ddf_aux_2: 0.0079 (0.0093)  loss_mal_aux_3: 0.4211 (0.4835)  loss_bbox_aux_3: 0.0669 (0.0911)  loss_giou_aux_3: 0.1673 (0.1985)  loss_fgl_aux_3: 1.0996 (1.1349)  loss_ddf_aux_3: 0.0013 (0.0017)  loss_mal_aux_4: 0.4146 (0.4702)  loss_bbox_aux_4: 0.0679 (0.0907)  loss_giou_aux_4: 0.1668 (0.1981)  loss_fgl_aux_4: 1.0992 (1.1340)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.7588 (0.8720)  loss_bbox_pre: 0.1088 (0.1226)  loss_giou_pre: 0.2439 (0.2617)  loss_mal_enc_0: 1.0146 (1.0481)  loss_bbox_enc_0: 0.1798 (0.2138)  loss_giou_enc_0: 0.3756 (0.4225)  loss_mal_dn_0: 0.7285 (0.7371)  loss_bbox_dn_0: 0.1906 (0.2109)  loss_giou_dn_0: 0.3843 (0.4112)  loss_fgl_dn_0: 1.3155 (1.3223)  loss_ddf_dn_0: 0.9132 (0.9432)  loss_mal_dn_1: 0.5718 (0.5808)  loss_bbox_dn_1: 0.1005 (0.1239)  loss_giou_dn_1: 0.2246 (0.2493)  loss_fgl_dn_1: 1.1322 (1.1583)  loss_ddf_dn_1: 0.2219 (0.2378)  loss_mal_dn_2: 0.4758 (0.4948)  loss_bbox_dn_2: 0.0801 (0.1034)  loss_giou_dn_2: 0.1873 (0.2150)  loss_fgl_dn_2: 1.0855 (1.1171)  loss_ddf_dn_2: 0.0539 (0.0658)  loss_mal_dn_3: 0.4331 (0.4592)  loss_bbox_dn_3: 0.0736 (0.0977)  loss_giou_dn_3: 0.1727 (0.2061)  loss_fgl_dn_3: 1.0699 (1.1080)  loss_ddf_dn_3: 0.0096 (0.0121)  loss_mal_dn_4: 0.4275 (0.4507)  loss_bbox_dn_4: 0.0714 (0.0960)  loss_giou_dn_4: 0.1730 (0.2037)  loss_fgl_dn_4: 1.0664 (1.1062)  loss_ddf_dn_4: 0.0009 (0.0011)  loss_mal_dn_5: 0.4211 (0.4488)  loss_bbox_dn_5: 0.0709 (0.0957)  loss_giou_dn_5: 0.1720 (0.2031)  loss_fgl_dn_5: 1.0665 (1.1058)  loss_mal_dn_pre: 0.7329 (0.7376)  loss_bbox_dn_pre: 0.1975 (0.2114)  loss_giou_dn_pre: 0.3898 (0.4094)  time: 1.1910  data: 0.0104  max mem: 13413\nEpoch: [38]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 28.1535 (30.2197)  loss_mal: 0.3674 (0.4671)  loss_bbox: 0.0810 (0.0875)  loss_giou: 0.1556 (0.1940)  loss_fgl: 1.0775 (1.1282)  loss_mal_aux_0: 0.8198 (0.8705)  loss_bbox_aux_0: 0.1158 (0.1197)  loss_giou_aux_0: 0.2262 (0.2579)  loss_fgl_aux_0: 1.1932 (1.2368)  loss_ddf_aux_0: 0.1821 (0.1999)  loss_mal_aux_1: 0.5737 (0.6340)  loss_bbox_aux_1: 0.0845 (0.0950)  loss_giou_aux_1: 0.1774 (0.2061)  loss_fgl_aux_1: 1.1086 (1.1522)  loss_ddf_aux_1: 0.0519 (0.0543)  loss_mal_aux_2: 0.4124 (0.5245)  loss_bbox_aux_2: 0.0839 (0.0896)  loss_giou_aux_2: 0.1654 (0.1964)  loss_fgl_aux_2: 1.0874 (1.1334)  loss_ddf_aux_2: 0.0087 (0.0091)  loss_mal_aux_3: 0.3762 (0.4820)  loss_bbox_aux_3: 0.0807 (0.0880)  loss_giou_aux_3: 0.1585 (0.1944)  loss_fgl_aux_3: 1.0842 (1.1292)  loss_ddf_aux_3: 0.0013 (0.0016)  loss_mal_aux_4: 0.3665 (0.4687)  loss_bbox_aux_4: 0.0815 (0.0876)  loss_giou_aux_4: 0.1570 (0.1940)  loss_fgl_aux_4: 1.0797 (1.1284)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.8252 (0.8714)  loss_bbox_pre: 0.1152 (0.1193)  loss_giou_pre: 0.2246 (0.2571)  loss_mal_enc_0: 1.0557 (1.0511)  loss_bbox_enc_0: 0.1902 (0.2080)  loss_giou_enc_0: 0.3740 (0.4161)  loss_mal_dn_0: 0.7280 (0.7368)  loss_bbox_dn_0: 0.2123 (0.2094)  loss_giou_dn_0: 0.3973 (0.4095)  loss_fgl_dn_0: 1.3251 (1.3224)  loss_ddf_dn_0: 1.0065 (0.9435)  loss_mal_dn_1: 0.5557 (0.5795)  loss_bbox_dn_1: 0.1141 (0.1217)  loss_giou_dn_1: 0.2159 (0.2467)  loss_fgl_dn_1: 1.1366 (1.1565)  loss_ddf_dn_1: 0.2539 (0.2366)  loss_mal_dn_2: 0.4578 (0.4919)  loss_bbox_dn_2: 0.0982 (0.1010)  loss_giou_dn_2: 0.1815 (0.2120)  loss_fgl_dn_2: 1.0758 (1.1142)  loss_ddf_dn_2: 0.0668 (0.0651)  loss_mal_dn_3: 0.4175 (0.4574)  loss_bbox_dn_3: 0.0947 (0.0952)  loss_giou_dn_3: 0.1704 (0.2031)  loss_fgl_dn_3: 1.0633 (1.1051)  loss_ddf_dn_3: 0.0116 (0.0118)  loss_mal_dn_4: 0.4194 (0.4493)  loss_bbox_dn_4: 0.0941 (0.0936)  loss_giou_dn_4: 0.1691 (0.2006)  loss_fgl_dn_4: 1.0594 (1.1032)  loss_ddf_dn_4: 0.0011 (0.0011)  loss_mal_dn_5: 0.4226 (0.4475)  loss_bbox_dn_5: 0.0939 (0.0933)  loss_giou_dn_5: 0.1690 (0.2001)  loss_fgl_dn_5: 1.0589 (1.1028)  loss_mal_dn_pre: 0.7280 (0.7373)  loss_bbox_dn_pre: 0.2115 (0.2098)  loss_giou_dn_pre: 0.4021 (0.4079)  time: 1.1837  data: 0.0107  max mem: 13413\nEpoch: [38] Total time: 0:05:00 (1.1983 s / it)\nTest:  [ 0/25]  eta: 0:00:22    time: 0.9060  data: 0.6068  max mem: 13413\nTest:  [10/25]  eta: 0:00:06    time: 0.4104  data: 0.0743  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3310  data: 0.0194  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.3192  data: 0.0182  max mem: 13413\nTest: Total time: 0:00:08 (0.3448 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.540\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.341\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.366\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.460\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.580\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.675\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.780\nbest_stat: {'epoch': 38, 'coco_eval_bbox': 0.3374040358831138}\nEpoch: [39]  [  0/251]  eta: 0:09:26  lr: 0.000002  loss: 37.3830 (37.3830)  loss_mal: 0.5469 (0.5469)  loss_bbox: 0.1746 (0.1746)  loss_giou: 0.2810 (0.2810)  loss_fgl: 1.4215 (1.4215)  loss_mal_aux_0: 0.8877 (0.8877)  loss_bbox_aux_0: 0.2283 (0.2283)  loss_giou_aux_0: 0.3847 (0.3847)  loss_fgl_aux_0: 1.4259 (1.4259)  loss_ddf_aux_0: 0.2475 (0.2475)  loss_mal_aux_1: 0.6479 (0.6479)  loss_bbox_aux_1: 0.1957 (0.1957)  loss_giou_aux_1: 0.3127 (0.3127)  loss_fgl_aux_1: 1.3885 (1.3885)  loss_ddf_aux_1: 0.0690 (0.0690)  loss_mal_aux_2: 0.5347 (0.5347)  loss_bbox_aux_2: 0.1792 (0.1792)  loss_giou_aux_2: 0.2882 (0.2882)  loss_fgl_aux_2: 1.4022 (1.4022)  loss_ddf_aux_2: 0.0118 (0.0118)  loss_mal_aux_3: 0.5400 (0.5400)  loss_bbox_aux_3: 0.1744 (0.1744)  loss_giou_aux_3: 0.2821 (0.2821)  loss_fgl_aux_3: 1.4094 (1.4094)  loss_ddf_aux_3: 0.0017 (0.0017)  loss_mal_aux_4: 0.5190 (0.5190)  loss_bbox_aux_4: 0.1747 (0.1747)  loss_giou_aux_4: 0.2815 (0.2815)  loss_fgl_aux_4: 1.4195 (1.4195)  loss_ddf_aux_4: 0.0000 (0.0000)  loss_mal_pre: 0.8896 (0.8896)  loss_bbox_pre: 0.2293 (0.2293)  loss_giou_pre: 0.3863 (0.3863)  loss_mal_enc_0: 1.0332 (1.0332)  loss_bbox_enc_0: 0.2802 (0.2802)  loss_giou_enc_0: 0.4869 (0.4869)  loss_mal_dn_0: 0.7920 (0.7920)  loss_bbox_dn_0: 0.2758 (0.2758)  loss_giou_dn_0: 0.5213 (0.5213)  loss_fgl_dn_0: 1.3879 (1.3879)  loss_ddf_dn_0: 1.2730 (1.2730)  loss_mal_dn_1: 0.6499 (0.6499)  loss_bbox_dn_1: 0.2052 (0.2052)  loss_giou_dn_1: 0.3550 (0.3550)  loss_fgl_dn_1: 1.3367 (1.3367)  loss_ddf_dn_1: 0.3128 (0.3128)  loss_mal_dn_2: 0.5928 (0.5928)  loss_bbox_dn_2: 0.1875 (0.1875)  loss_giou_dn_2: 0.3149 (0.3149)  loss_fgl_dn_2: 1.3830 (1.3830)  loss_ddf_dn_2: 0.0739 (0.0739)  loss_mal_dn_3: 0.5781 (0.5781)  loss_bbox_dn_3: 0.1793 (0.1793)  loss_giou_dn_3: 0.3039 (0.3039)  loss_fgl_dn_3: 1.3977 (1.3977)  loss_ddf_dn_3: 0.0121 (0.0121)  loss_mal_dn_4: 0.5620 (0.5620)  loss_bbox_dn_4: 0.1775 (0.1775)  loss_giou_dn_4: 0.2999 (0.2999)  loss_fgl_dn_4: 1.4104 (1.4104)  loss_ddf_dn_4: 0.0014 (0.0014)  loss_mal_dn_5: 0.5737 (0.5737)  loss_bbox_dn_5: 0.1772 (0.1772)  loss_giou_dn_5: 0.2984 (0.2984)  loss_fgl_dn_5: 1.4156 (1.4156)  loss_mal_dn_pre: 0.7930 (0.7930)  loss_bbox_dn_pre: 0.2826 (0.2826)  loss_giou_dn_pre: 0.5228 (0.5228)  time: 2.2561  data: 1.0140  max mem: 13413\nEpoch: [39]  [100/251]  eta: 0:03:02  lr: 0.000002  loss: 28.5802 (29.9775)  loss_mal: 0.4062 (0.4677)  loss_bbox: 0.0700 (0.0869)  loss_giou: 0.1759 (0.1861)  loss_fgl: 1.1164 (1.1183)  loss_mal_aux_0: 0.7788 (0.8541)  loss_bbox_aux_0: 0.0892 (0.1233)  loss_giou_aux_0: 0.2294 (0.2517)  loss_fgl_aux_0: 1.2063 (1.2285)  loss_ddf_aux_0: 0.1987 (0.2057)  loss_mal_aux_1: 0.5566 (0.6428)  loss_bbox_aux_1: 0.0718 (0.0974)  loss_giou_aux_1: 0.1843 (0.1985)  loss_fgl_aux_1: 1.1329 (1.1392)  loss_ddf_aux_1: 0.0475 (0.0546)  loss_mal_aux_2: 0.4614 (0.5246)  loss_bbox_aux_2: 0.0707 (0.0906)  loss_giou_aux_2: 0.1807 (0.1894)  loss_fgl_aux_2: 1.1191 (1.1229)  loss_ddf_aux_2: 0.0083 (0.0100)  loss_mal_aux_3: 0.4141 (0.4840)  loss_bbox_aux_3: 0.0708 (0.0883)  loss_giou_aux_3: 0.1772 (0.1874)  loss_fgl_aux_3: 1.1174 (1.1195)  loss_ddf_aux_3: 0.0017 (0.0018)  loss_mal_aux_4: 0.4058 (0.4699)  loss_bbox_aux_4: 0.0702 (0.0872)  loss_giou_aux_4: 0.1764 (0.1863)  loss_fgl_aux_4: 1.1157 (1.1185)  loss_ddf_aux_4: 0.0004 (0.0002)  loss_mal_pre: 0.7803 (0.8579)  loss_bbox_pre: 0.0891 (0.1220)  loss_giou_pre: 0.2265 (0.2504)  loss_mal_enc_0: 0.9951 (1.0050)  loss_bbox_enc_0: 0.1447 (0.2075)  loss_giou_enc_0: 0.3716 (0.4020)  loss_mal_dn_0: 0.7148 (0.7244)  loss_bbox_dn_0: 0.1768 (0.2170)  loss_giou_dn_0: 0.3843 (0.4081)  loss_fgl_dn_0: 1.3076 (1.3186)  loss_ddf_dn_0: 0.9556 (0.9765)  loss_mal_dn_1: 0.5493 (0.5657)  loss_bbox_dn_1: 0.0970 (0.1261)  loss_giou_dn_1: 0.2233 (0.2438)  loss_fgl_dn_1: 1.1347 (1.1488)  loss_ddf_dn_1: 0.2255 (0.2492)  loss_mal_dn_2: 0.4673 (0.4787)  loss_bbox_dn_2: 0.0736 (0.1041)  loss_giou_dn_2: 0.1880 (0.2084)  loss_fgl_dn_2: 1.0933 (1.1073)  loss_ddf_dn_2: 0.0598 (0.0702)  loss_mal_dn_3: 0.4319 (0.4453)  loss_bbox_dn_3: 0.0722 (0.0982)  loss_giou_dn_3: 0.1792 (0.1990)  loss_fgl_dn_3: 1.0841 (1.0985)  loss_ddf_dn_3: 0.0115 (0.0128)  loss_mal_dn_4: 0.4268 (0.4369)  loss_bbox_dn_4: 0.0730 (0.0963)  loss_giou_dn_4: 0.1781 (0.1954)  loss_fgl_dn_4: 1.0834 (1.0968)  loss_ddf_dn_4: 0.0011 (0.0012)  loss_mal_dn_5: 0.4285 (0.4349)  loss_bbox_dn_5: 0.0743 (0.0958)  loss_giou_dn_5: 0.1781 (0.1946)  loss_fgl_dn_5: 1.0836 (1.0966)  loss_mal_dn_pre: 0.7173 (0.7247)  loss_bbox_dn_pre: 0.1761 (0.2179)  loss_giou_dn_pre: 0.3814 (0.4056)  time: 1.1947  data: 0.0108  max mem: 13413\nEpoch: [39]  [200/251]  eta: 0:01:01  lr: 0.000002  loss: 27.7136 (29.3291)  loss_mal: 0.3826 (0.4533)  loss_bbox: 0.0697 (0.0787)  loss_giou: 0.1654 (0.1798)  loss_fgl: 1.0666 (1.1088)  loss_mal_aux_0: 0.7983 (0.8316)  loss_bbox_aux_0: 0.1019 (0.1129)  loss_giou_aux_0: 0.2314 (0.2443)  loss_fgl_aux_0: 1.2178 (1.2237)  loss_ddf_aux_0: 0.2113 (0.2074)  loss_mal_aux_1: 0.5513 (0.6239)  loss_bbox_aux_1: 0.0774 (0.0882)  loss_giou_aux_1: 0.1824 (0.1925)  loss_fgl_aux_1: 1.1022 (1.1321)  loss_ddf_aux_1: 0.0472 (0.0544)  loss_mal_aux_2: 0.4026 (0.5059)  loss_bbox_aux_2: 0.0709 (0.0819)  loss_giou_aux_2: 0.1720 (0.1830)  loss_fgl_aux_2: 1.0672 (1.1140)  loss_ddf_aux_2: 0.0073 (0.0097)  loss_mal_aux_3: 0.4165 (0.4678)  loss_bbox_aux_3: 0.0703 (0.0798)  loss_giou_aux_3: 0.1682 (0.1809)  loss_fgl_aux_3: 1.0678 (1.1102)  loss_ddf_aux_3: 0.0014 (0.0017)  loss_mal_aux_4: 0.3855 (0.4547)  loss_bbox_aux_4: 0.0705 (0.0789)  loss_giou_aux_4: 0.1662 (0.1800)  loss_fgl_aux_4: 1.0639 (1.1090)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.7993 (0.8333)  loss_bbox_pre: 0.1001 (0.1121)  loss_giou_pre: 0.2306 (0.2432)  loss_mal_enc_0: 0.9258 (0.9914)  loss_bbox_enc_0: 0.1709 (0.1927)  loss_giou_enc_0: 0.3597 (0.3876)  loss_mal_dn_0: 0.7231 (0.7201)  loss_bbox_dn_0: 0.1728 (0.2029)  loss_giou_dn_0: 0.3838 (0.3953)  loss_fgl_dn_0: 1.3097 (1.3179)  loss_ddf_dn_0: 0.8331 (0.9325)  loss_mal_dn_1: 0.5493 (0.5643)  loss_bbox_dn_1: 0.0901 (0.1144)  loss_giou_dn_1: 0.2097 (0.2332)  loss_fgl_dn_1: 1.1034 (1.1387)  loss_ddf_dn_1: 0.1999 (0.2356)  loss_mal_dn_2: 0.4382 (0.4707)  loss_bbox_dn_2: 0.0771 (0.0934)  loss_giou_dn_2: 0.1778 (0.1989)  loss_fgl_dn_2: 1.0472 (1.0936)  loss_ddf_dn_2: 0.0542 (0.0659)  loss_mal_dn_3: 0.4153 (0.4391)  loss_bbox_dn_3: 0.0698 (0.0877)  loss_giou_dn_3: 0.1736 (0.1900)  loss_fgl_dn_3: 1.0383 (1.0837)  loss_ddf_dn_3: 0.0105 (0.0122)  loss_mal_dn_4: 0.4131 (0.4322)  loss_bbox_dn_4: 0.0693 (0.0858)  loss_giou_dn_4: 0.1725 (0.1868)  loss_fgl_dn_4: 1.0400 (1.0814)  loss_ddf_dn_4: 0.0009 (0.0012)  loss_mal_dn_5: 0.4148 (0.4313)  loss_bbox_dn_5: 0.0694 (0.0854)  loss_giou_dn_5: 0.1712 (0.1861)  loss_fgl_dn_5: 1.0394 (1.0810)  loss_mal_dn_pre: 0.7207 (0.7203)  loss_bbox_dn_pre: 0.1771 (0.2042)  loss_giou_dn_pre: 0.3897 (0.3936)  time: 1.1900  data: 0.0118  max mem: 13413\nEpoch: [39]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 27.7840 (29.3220)  loss_mal: 0.3818 (0.4573)  loss_bbox: 0.0560 (0.0772)  loss_giou: 0.1476 (0.1785)  loss_fgl: 1.0487 (1.1069)  loss_mal_aux_0: 0.7783 (0.8308)  loss_bbox_aux_0: 0.0896 (0.1114)  loss_giou_aux_0: 0.2272 (0.2434)  loss_fgl_aux_0: 1.1779 (1.2238)  loss_ddf_aux_0: 0.2129 (0.2076)  loss_mal_aux_1: 0.5439 (0.6235)  loss_bbox_aux_1: 0.0628 (0.0862)  loss_giou_aux_1: 0.1688 (0.1912)  loss_fgl_aux_1: 1.0868 (1.1307)  loss_ddf_aux_1: 0.0538 (0.0541)  loss_mal_aux_2: 0.4343 (0.5086)  loss_bbox_aux_2: 0.0578 (0.0801)  loss_giou_aux_2: 0.1515 (0.1816)  loss_fgl_aux_2: 1.0544 (1.1122)  loss_ddf_aux_2: 0.0093 (0.0096)  loss_mal_aux_3: 0.3962 (0.4730)  loss_bbox_aux_3: 0.0563 (0.0781)  loss_giou_aux_3: 0.1457 (0.1795)  loss_fgl_aux_3: 1.0468 (1.1083)  loss_ddf_aux_3: 0.0017 (0.0017)  loss_mal_aux_4: 0.3884 (0.4582)  loss_bbox_aux_4: 0.0560 (0.0773)  loss_giou_aux_4: 0.1466 (0.1787)  loss_fgl_aux_4: 1.0475 (1.1072)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.7832 (0.8324)  loss_bbox_pre: 0.0901 (0.1107)  loss_giou_pre: 0.2205 (0.2424)  loss_mal_enc_0: 0.9932 (0.9917)  loss_bbox_enc_0: 0.1560 (0.1902)  loss_giou_enc_0: 0.3715 (0.3869)  loss_mal_dn_0: 0.7231 (0.7222)  loss_bbox_dn_0: 0.1752 (0.2014)  loss_giou_dn_0: 0.3710 (0.3958)  loss_fgl_dn_0: 1.3254 (1.3195)  loss_ddf_dn_0: 1.0062 (0.9417)  loss_mal_dn_1: 0.5474 (0.5648)  loss_bbox_dn_1: 0.0938 (0.1135)  loss_giou_dn_1: 0.2179 (0.2336)  loss_fgl_dn_1: 1.1228 (1.1396)  loss_ddf_dn_1: 0.2428 (0.2374)  loss_mal_dn_2: 0.4385 (0.4704)  loss_bbox_dn_2: 0.0724 (0.0924)  loss_giou_dn_2: 0.1785 (0.1987)  loss_fgl_dn_2: 1.0515 (1.0941)  loss_ddf_dn_2: 0.0678 (0.0664)  loss_mal_dn_3: 0.4163 (0.4388)  loss_bbox_dn_3: 0.0649 (0.0868)  loss_giou_dn_3: 0.1669 (0.1896)  loss_fgl_dn_3: 1.0377 (1.0840)  loss_ddf_dn_3: 0.0133 (0.0123)  loss_mal_dn_4: 0.4092 (0.4316)  loss_bbox_dn_4: 0.0642 (0.0850)  loss_giou_dn_4: 0.1668 (0.1866)  loss_fgl_dn_4: 1.0382 (1.0818)  loss_ddf_dn_4: 0.0012 (0.0012)  loss_mal_dn_5: 0.4062 (0.4306)  loss_bbox_dn_5: 0.0644 (0.0846)  loss_giou_dn_5: 0.1660 (0.1858)  loss_fgl_dn_5: 1.0388 (1.0813)  loss_mal_dn_pre: 0.7246 (0.7227)  loss_bbox_dn_pre: 0.1767 (0.2025)  loss_giou_dn_pre: 0.3699 (0.3941)  time: 1.2045  data: 0.0116  max mem: 13413\nEpoch: [39] Total time: 0:05:01 (1.2020 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7736  data: 0.4861  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3489  data: 0.0636  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3050  data: 0.0204  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2944  data: 0.0201  max mem: 13413\nTest: Total time: 0:00:07 (0.3186 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.05s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.337\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.538\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.342\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.294\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.365\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.462\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.579\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.685\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.787\nbest_stat: {'epoch': 38, 'coco_eval_bbox': 0.3374040358831138}\nLoad last_epoch\nLoad model.state_dict\nLoad criterion.state_dict\nLoad postprocessor.state_dict\nLoad ema.state_dict\nLoad scaler.state_dict\nLoad optimizer.state_dict\nLoad lr_warmup_scheduler.state_dict\nRefresh EMA at epoch 39 with decay 0.9997\nEpoch: [40]  [  0/251]  eta: 0:09:21  lr: 0.000002  loss: 27.5815 (27.5815)  loss_mal: 0.3777 (0.3777)  loss_bbox: 0.0654 (0.0654)  loss_giou: 0.1634 (0.1634)  loss_fgl: 1.0523 (1.0523)  loss_mal_aux_0: 0.8325 (0.8325)  loss_bbox_aux_0: 0.1193 (0.1193)  loss_giou_aux_0: 0.2453 (0.2453)  loss_fgl_aux_0: 1.2140 (1.2140)  loss_ddf_aux_0: 0.2330 (0.2330)  loss_mal_aux_1: 0.5186 (0.5186)  loss_bbox_aux_1: 0.0786 (0.0786)  loss_giou_aux_1: 0.1748 (0.1748)  loss_fgl_aux_1: 1.0964 (1.0964)  loss_ddf_aux_1: 0.0603 (0.0603)  loss_mal_aux_2: 0.4065 (0.4065)  loss_bbox_aux_2: 0.0687 (0.0687)  loss_giou_aux_2: 0.1649 (0.1649)  loss_fgl_aux_2: 1.0629 (1.0629)  loss_ddf_aux_2: 0.0088 (0.0088)  loss_mal_aux_3: 0.3879 (0.3879)  loss_bbox_aux_3: 0.0669 (0.0669)  loss_giou_aux_3: 0.1634 (0.1634)  loss_fgl_aux_3: 1.0532 (1.0532)  loss_ddf_aux_3: 0.0016 (0.0016)  loss_mal_aux_4: 0.3845 (0.3845)  loss_bbox_aux_4: 0.0654 (0.0654)  loss_giou_aux_4: 0.1632 (0.1632)  loss_fgl_aux_4: 1.0527 (1.0527)  loss_ddf_aux_4: 0.0000 (0.0000)  loss_mal_pre: 0.8379 (0.8379)  loss_bbox_pre: 0.1212 (0.1212)  loss_giou_pre: 0.2492 (0.2492)  loss_mal_enc_0: 0.8896 (0.8896)  loss_bbox_enc_0: 0.1613 (0.1613)  loss_giou_enc_0: 0.2941 (0.2941)  loss_mal_dn_0: 0.7114 (0.7114)  loss_bbox_dn_0: 0.1655 (0.1655)  loss_giou_dn_0: 0.3500 (0.3500)  loss_fgl_dn_0: 1.2793 (1.2793)  loss_ddf_dn_0: 0.8521 (0.8521)  loss_mal_dn_1: 0.5576 (0.5576)  loss_bbox_dn_1: 0.0881 (0.0881)  loss_giou_dn_1: 0.2136 (0.2136)  loss_fgl_dn_1: 1.1050 (1.1050)  loss_ddf_dn_1: 0.2176 (0.2176)  loss_mal_dn_2: 0.4524 (0.4524)  loss_bbox_dn_2: 0.0736 (0.0736)  loss_giou_dn_2: 0.1836 (0.1836)  loss_fgl_dn_2: 1.0572 (1.0572)  loss_ddf_dn_2: 0.0626 (0.0626)  loss_mal_dn_3: 0.4170 (0.4170)  loss_bbox_dn_3: 0.0708 (0.0708)  loss_giou_dn_3: 0.1776 (0.1776)  loss_fgl_dn_3: 1.0527 (1.0527)  loss_ddf_dn_3: 0.0118 (0.0118)  loss_mal_dn_4: 0.4131 (0.4131)  loss_bbox_dn_4: 0.0709 (0.0709)  loss_giou_dn_4: 0.1780 (0.1780)  loss_fgl_dn_4: 1.0527 (1.0527)  loss_ddf_dn_4: 0.0011 (0.0011)  loss_mal_dn_5: 0.4072 (0.4072)  loss_bbox_dn_5: 0.0715 (0.0715)  loss_giou_dn_5: 0.1789 (0.1789)  loss_fgl_dn_5: 1.0528 (1.0528)  loss_mal_dn_pre: 0.7119 (0.7119)  loss_bbox_dn_pre: 0.1639 (0.1639)  loss_giou_dn_pre: 0.3445 (0.3445)  time: 2.2354  data: 0.9271  max mem: 13413\nEpoch: [40]  [100/251]  eta: 0:03:02  lr: 0.000002  loss: 29.3071 (29.4655)  loss_mal: 0.4199 (0.4645)  loss_bbox: 0.0732 (0.0764)  loss_giou: 0.1781 (0.1841)  loss_fgl: 1.0966 (1.1112)  loss_mal_aux_0: 0.8003 (0.8615)  loss_bbox_aux_0: 0.0951 (0.1041)  loss_giou_aux_0: 0.2235 (0.2428)  loss_fgl_aux_0: 1.2073 (1.2225)  loss_ddf_aux_0: 0.1854 (0.1893)  loss_mal_aux_1: 0.5903 (0.6178)  loss_bbox_aux_1: 0.0794 (0.0820)  loss_giou_aux_1: 0.1818 (0.1948)  loss_fgl_aux_1: 1.1169 (1.1352)  loss_ddf_aux_1: 0.0468 (0.0512)  loss_mal_aux_2: 0.4675 (0.5155)  loss_bbox_aux_2: 0.0778 (0.0775)  loss_giou_aux_2: 0.1794 (0.1865)  loss_fgl_aux_2: 1.0993 (1.1166)  loss_ddf_aux_2: 0.0073 (0.0090)  loss_mal_aux_3: 0.4272 (0.4774)  loss_bbox_aux_3: 0.0751 (0.0767)  loss_giou_aux_3: 0.1767 (0.1848)  loss_fgl_aux_3: 1.0995 (1.1129)  loss_ddf_aux_3: 0.0016 (0.0016)  loss_mal_aux_4: 0.4185 (0.4645)  loss_bbox_aux_4: 0.0740 (0.0764)  loss_giou_aux_4: 0.1771 (0.1842)  loss_fgl_aux_4: 1.0973 (1.1116)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.8003 (0.8625)  loss_bbox_pre: 0.0952 (0.1038)  loss_giou_pre: 0.2213 (0.2422)  loss_mal_enc_0: 0.9678 (1.0133)  loss_bbox_enc_0: 0.1701 (0.1787)  loss_giou_enc_0: 0.3547 (0.3879)  loss_mal_dn_0: 0.7231 (0.7300)  loss_bbox_dn_0: 0.1970 (0.1951)  loss_giou_dn_0: 0.3888 (0.3942)  loss_fgl_dn_0: 1.3189 (1.3164)  loss_ddf_dn_0: 0.9748 (0.9507)  loss_mal_dn_1: 0.5654 (0.5705)  loss_bbox_dn_1: 0.1050 (0.1099)  loss_giou_dn_1: 0.2230 (0.2346)  loss_fgl_dn_1: 1.1418 (1.1427)  loss_ddf_dn_1: 0.2322 (0.2362)  loss_mal_dn_2: 0.4685 (0.4760)  loss_bbox_dn_2: 0.0882 (0.0906)  loss_giou_dn_2: 0.2019 (0.2012)  loss_fgl_dn_2: 1.0831 (1.0991)  loss_ddf_dn_2: 0.0584 (0.0642)  loss_mal_dn_3: 0.4417 (0.4427)  loss_bbox_dn_3: 0.0839 (0.0854)  loss_giou_dn_3: 0.1953 (0.1922)  loss_fgl_dn_3: 1.0781 (1.0902)  loss_ddf_dn_3: 0.0116 (0.0117)  loss_mal_dn_4: 0.4329 (0.4344)  loss_bbox_dn_4: 0.0829 (0.0839)  loss_giou_dn_4: 0.1929 (0.1894)  loss_fgl_dn_4: 1.0795 (1.0880)  loss_ddf_dn_4: 0.0011 (0.0011)  loss_mal_dn_5: 0.4346 (0.4340)  loss_bbox_dn_5: 0.0830 (0.0836)  loss_giou_dn_5: 0.1925 (0.1888)  loss_fgl_dn_5: 1.0788 (1.0875)  loss_mal_dn_pre: 0.7236 (0.7303)  loss_bbox_dn_pre: 0.1949 (0.1963)  loss_giou_dn_pre: 0.3871 (0.3930)  time: 1.2184  data: 0.0114  max mem: 13413\nEpoch: [40]  [200/251]  eta: 0:01:01  lr: 0.000002  loss: 30.6409 (29.9168)  loss_mal: 0.4568 (0.4787)  loss_bbox: 0.0854 (0.0807)  loss_giou: 0.2118 (0.1934)  loss_fgl: 1.1243 (1.1286)  loss_mal_aux_0: 0.8857 (0.8454)  loss_bbox_aux_0: 0.1019 (0.1111)  loss_giou_aux_0: 0.2568 (0.2540)  loss_fgl_aux_0: 1.2206 (1.2354)  loss_ddf_aux_0: 0.1863 (0.1909)  loss_mal_aux_1: 0.6528 (0.6261)  loss_bbox_aux_1: 0.0953 (0.0875)  loss_giou_aux_1: 0.2101 (0.2046)  loss_fgl_aux_1: 1.1434 (1.1499)  loss_ddf_aux_1: 0.0498 (0.0513)  loss_mal_aux_2: 0.5415 (0.5299)  loss_bbox_aux_2: 0.0922 (0.0823)  loss_giou_aux_2: 0.1938 (0.1958)  loss_fgl_aux_2: 1.1306 (1.1338)  loss_ddf_aux_2: 0.0085 (0.0090)  loss_mal_aux_3: 0.5073 (0.4946)  loss_bbox_aux_3: 0.0880 (0.0811)  loss_giou_aux_3: 0.2053 (0.1941)  loss_fgl_aux_3: 1.1268 (1.1301)  loss_ddf_aux_3: 0.0015 (0.0016)  loss_mal_aux_4: 0.4695 (0.4799)  loss_bbox_aux_4: 0.0859 (0.0808)  loss_giou_aux_4: 0.2109 (0.1935)  loss_fgl_aux_4: 1.1266 (1.1289)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8687 (0.8466)  loss_bbox_pre: 0.1021 (0.1108)  loss_giou_pre: 0.2553 (0.2534)  loss_mal_enc_0: 1.0430 (1.0168)  loss_bbox_enc_0: 0.2077 (0.1870)  loss_giou_enc_0: 0.4292 (0.4002)  loss_mal_dn_0: 0.7456 (0.7310)  loss_bbox_dn_0: 0.2124 (0.1981)  loss_giou_dn_0: 0.3931 (0.4012)  loss_fgl_dn_0: 1.3177 (1.3200)  loss_ddf_dn_0: 0.8798 (0.9312)  loss_mal_dn_1: 0.5928 (0.5745)  loss_bbox_dn_1: 0.1106 (0.1142)  loss_giou_dn_1: 0.2487 (0.2430)  loss_fgl_dn_1: 1.1417 (1.1543)  loss_ddf_dn_1: 0.2187 (0.2314)  loss_mal_dn_2: 0.5117 (0.4859)  loss_bbox_dn_2: 0.0992 (0.0952)  loss_giou_dn_2: 0.2164 (0.2101)  loss_fgl_dn_2: 1.1156 (1.1143)  loss_ddf_dn_2: 0.0625 (0.0633)  loss_mal_dn_3: 0.4673 (0.4526)  loss_bbox_dn_3: 0.0931 (0.0899)  loss_giou_dn_3: 0.2051 (0.2014)  loss_fgl_dn_3: 1.1167 (1.1058)  loss_ddf_dn_3: 0.0104 (0.0115)  loss_mal_dn_4: 0.4602 (0.4444)  loss_bbox_dn_4: 0.0918 (0.0884)  loss_giou_dn_4: 0.2032 (0.1989)  loss_fgl_dn_4: 1.1130 (1.1038)  loss_ddf_dn_4: 0.0010 (0.0011)  loss_mal_dn_5: 0.4487 (0.4432)  loss_bbox_dn_5: 0.0916 (0.0881)  loss_giou_dn_5: 0.2035 (0.1983)  loss_fgl_dn_5: 1.1120 (1.1033)  loss_mal_dn_pre: 0.7456 (0.7314)  loss_bbox_dn_pre: 0.2150 (0.1990)  loss_giou_dn_pre: 0.3996 (0.3999)  time: 1.1991  data: 0.0119  max mem: 13413\nEpoch: [40]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 29.2498 (30.0468)  loss_mal: 0.4263 (0.4794)  loss_bbox: 0.0793 (0.0824)  loss_giou: 0.1936 (0.1936)  loss_fgl: 1.1628 (1.1358)  loss_mal_aux_0: 0.7910 (0.8465)  loss_bbox_aux_0: 0.1240 (0.1130)  loss_giou_aux_0: 0.2472 (0.2538)  loss_fgl_aux_0: 1.2282 (1.2373)  loss_ddf_aux_0: 0.1818 (0.1916)  loss_mal_aux_1: 0.5806 (0.6294)  loss_bbox_aux_1: 0.0889 (0.0891)  loss_giou_aux_1: 0.2028 (0.2045)  loss_fgl_aux_1: 1.1756 (1.1544)  loss_ddf_aux_1: 0.0439 (0.0505)  loss_mal_aux_2: 0.4822 (0.5334)  loss_bbox_aux_2: 0.0793 (0.0840)  loss_giou_aux_2: 0.2017 (0.1960)  loss_fgl_aux_2: 1.1728 (1.1399)  loss_ddf_aux_2: 0.0069 (0.0088)  loss_mal_aux_3: 0.4380 (0.4957)  loss_bbox_aux_3: 0.0789 (0.0827)  loss_giou_aux_3: 0.2014 (0.1943)  loss_fgl_aux_3: 1.1660 (1.1367)  loss_ddf_aux_3: 0.0013 (0.0016)  loss_mal_aux_4: 0.4294 (0.4809)  loss_bbox_aux_4: 0.0790 (0.0824)  loss_giou_aux_4: 0.1952 (0.1937)  loss_fgl_aux_4: 1.1630 (1.1359)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.7920 (0.8476)  loss_bbox_pre: 0.1205 (0.1127)  loss_giou_pre: 0.2467 (0.2532)  loss_mal_enc_0: 0.9727 (1.0232)  loss_bbox_enc_0: 0.1764 (0.1886)  loss_giou_enc_0: 0.3926 (0.3988)  loss_mal_dn_0: 0.7261 (0.7312)  loss_bbox_dn_0: 0.2145 (0.2043)  loss_giou_dn_0: 0.3989 (0.4026)  loss_fgl_dn_0: 1.3280 (1.3220)  loss_ddf_dn_0: 0.8570 (0.9274)  loss_mal_dn_1: 0.5820 (0.5755)  loss_bbox_dn_1: 0.1247 (0.1194)  loss_giou_dn_1: 0.2514 (0.2450)  loss_fgl_dn_1: 1.1750 (1.1581)  loss_ddf_dn_1: 0.2231 (0.2294)  loss_mal_dn_2: 0.4736 (0.4874)  loss_bbox_dn_2: 0.1006 (0.0995)  loss_giou_dn_2: 0.2111 (0.2117)  loss_fgl_dn_2: 1.1275 (1.1189)  loss_ddf_dn_2: 0.0578 (0.0624)  loss_mal_dn_3: 0.4451 (0.4535)  loss_bbox_dn_3: 0.0937 (0.0937)  loss_giou_dn_3: 0.2006 (0.2026)  loss_fgl_dn_3: 1.1216 (1.1106)  loss_ddf_dn_3: 0.0107 (0.0113)  loss_mal_dn_4: 0.4397 (0.4452)  loss_bbox_dn_4: 0.0922 (0.0921)  loss_giou_dn_4: 0.1972 (0.2000)  loss_fgl_dn_4: 1.1216 (1.1088)  loss_ddf_dn_4: 0.0010 (0.0011)  loss_mal_dn_5: 0.4402 (0.4439)  loss_bbox_dn_5: 0.0921 (0.0918)  loss_giou_dn_5: 0.1942 (0.1994)  loss_fgl_dn_5: 1.1219 (1.1084)  loss_mal_dn_pre: 0.7280 (0.7317)  loss_bbox_dn_pre: 0.2124 (0.2051)  loss_giou_dn_pre: 0.3945 (0.4013)  time: 1.1881  data: 0.0118  max mem: 13413\nEpoch: [40] Total time: 0:05:02 (1.2045 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7724  data: 0.4670  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3522  data: 0.0643  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3071  data: 0.0219  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2940  data: 0.0200  max mem: 13413\nTest: Total time: 0:00:07 (0.3199 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.05s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.540\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.344\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.359\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.462\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.780\nbest_stat: {'epoch': 38, 'coco_eval_bbox': 0.3374040358831138}\nEpoch: [41]  [  0/251]  eta: 0:07:41  lr: 0.000002  loss: 25.8745 (25.8745)  loss_mal: 0.3875 (0.3875)  loss_bbox: 0.0505 (0.0505)  loss_giou: 0.1305 (0.1305)  loss_fgl: 0.9982 (0.9982)  loss_mal_aux_0: 0.8032 (0.8032)  loss_bbox_aux_0: 0.0848 (0.0848)  loss_giou_aux_0: 0.1792 (0.1792)  loss_fgl_aux_0: 1.1380 (1.1380)  loss_ddf_aux_0: 0.1645 (0.1645)  loss_mal_aux_1: 0.4067 (0.4067)  loss_bbox_aux_1: 0.0606 (0.0606)  loss_giou_aux_1: 0.1467 (0.1467)  loss_fgl_aux_1: 1.0446 (1.0446)  loss_ddf_aux_1: 0.0457 (0.0457)  loss_mal_aux_2: 0.3809 (0.3809)  loss_bbox_aux_2: 0.0512 (0.0512)  loss_giou_aux_2: 0.1291 (0.1291)  loss_fgl_aux_2: 1.0085 (1.0085)  loss_ddf_aux_2: 0.0077 (0.0077)  loss_mal_aux_3: 0.3545 (0.3545)  loss_bbox_aux_3: 0.0509 (0.0509)  loss_giou_aux_3: 0.1302 (0.1302)  loss_fgl_aux_3: 1.0040 (1.0040)  loss_ddf_aux_3: 0.0013 (0.0013)  loss_mal_aux_4: 0.3928 (0.3928)  loss_bbox_aux_4: 0.0506 (0.0506)  loss_giou_aux_4: 0.1299 (0.1299)  loss_fgl_aux_4: 1.0007 (1.0007)  loss_ddf_aux_4: -0.0002 (-0.0002)  loss_mal_pre: 0.8052 (0.8052)  loss_bbox_pre: 0.0843 (0.0843)  loss_giou_pre: 0.1773 (0.1773)  loss_mal_enc_0: 0.8931 (0.8931)  loss_bbox_enc_0: 0.1804 (0.1804)  loss_giou_enc_0: 0.2761 (0.2761)  loss_mal_dn_0: 0.6660 (0.6660)  loss_bbox_dn_0: 0.1847 (0.1847)  loss_giou_dn_0: 0.3396 (0.3396)  loss_fgl_dn_0: 1.2733 (1.2733)  loss_ddf_dn_0: 0.8543 (0.8543)  loss_mal_dn_1: 0.5010 (0.5010)  loss_bbox_dn_1: 0.0978 (0.0978)  loss_giou_dn_1: 0.1983 (0.1983)  loss_fgl_dn_1: 1.0881 (1.0881)  loss_ddf_dn_1: 0.2181 (0.2181)  loss_mal_dn_2: 0.3892 (0.3892)  loss_bbox_dn_2: 0.0666 (0.0666)  loss_giou_dn_2: 0.1554 (0.1554)  loss_fgl_dn_2: 1.0330 (1.0330)  loss_ddf_dn_2: 0.0616 (0.0616)  loss_mal_dn_3: 0.3623 (0.3623)  loss_bbox_dn_3: 0.0630 (0.0630)  loss_giou_dn_3: 0.1514 (0.1514)  loss_fgl_dn_3: 1.0270 (1.0270)  loss_ddf_dn_3: 0.0117 (0.0117)  loss_mal_dn_4: 0.3584 (0.3584)  loss_bbox_dn_4: 0.0631 (0.0631)  loss_giou_dn_4: 0.1496 (0.1496)  loss_fgl_dn_4: 1.0250 (1.0250)  loss_ddf_dn_4: 0.0009 (0.0009)  loss_mal_dn_5: 0.3557 (0.3557)  loss_bbox_dn_5: 0.0629 (0.0629)  loss_giou_dn_5: 0.1492 (0.1492)  loss_fgl_dn_5: 1.0244 (1.0244)  loss_mal_dn_pre: 0.6660 (0.6660)  loss_bbox_dn_pre: 0.1875 (0.1875)  loss_giou_dn_pre: 0.3405 (0.3405)  time: 1.8384  data: 0.5453  max mem: 13413\nEpoch: [41]  [100/251]  eta: 0:03:01  lr: 0.000002  loss: 28.0893 (28.2979)  loss_mal: 0.3806 (0.4225)  loss_bbox: 0.0672 (0.0701)  loss_giou: 0.1643 (0.1730)  loss_fgl: 1.0743 (1.0956)  loss_mal_aux_0: 0.8052 (0.7927)  loss_bbox_aux_0: 0.0858 (0.0934)  loss_giou_aux_0: 0.2272 (0.2228)  loss_fgl_aux_0: 1.1999 (1.2035)  loss_ddf_aux_0: 0.1780 (0.1793)  loss_mal_aux_1: 0.5483 (0.5924)  loss_bbox_aux_1: 0.0643 (0.0748)  loss_giou_aux_1: 0.1858 (0.1826)  loss_fgl_aux_1: 1.0978 (1.1176)  loss_ddf_aux_1: 0.0435 (0.0440)  loss_mal_aux_2: 0.4314 (0.4719)  loss_bbox_aux_2: 0.0663 (0.0712)  loss_giou_aux_2: 0.1707 (0.1751)  loss_fgl_aux_2: 1.0712 (1.1003)  loss_ddf_aux_2: 0.0071 (0.0076)  loss_mal_aux_3: 0.3896 (0.4372)  loss_bbox_aux_3: 0.0665 (0.0703)  loss_giou_aux_3: 0.1709 (0.1735)  loss_fgl_aux_3: 1.0713 (1.0969)  loss_ddf_aux_3: 0.0012 (0.0014)  loss_mal_aux_4: 0.3843 (0.4265)  loss_bbox_aux_4: 0.0670 (0.0701)  loss_giou_aux_4: 0.1675 (0.1731)  loss_fgl_aux_4: 1.0727 (1.0958)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8091 (0.7927)  loss_bbox_pre: 0.0847 (0.0930)  loss_giou_pre: 0.2279 (0.2219)  loss_mal_enc_0: 0.9600 (0.9595)  loss_bbox_enc_0: 0.1617 (0.1608)  loss_giou_enc_0: 0.3532 (0.3590)  loss_mal_dn_0: 0.7090 (0.7131)  loss_bbox_dn_0: 0.1543 (0.1848)  loss_giou_dn_0: 0.3874 (0.3765)  loss_fgl_dn_0: 1.3134 (1.3175)  loss_ddf_dn_0: 0.8838 (0.8614)  loss_mal_dn_1: 0.5576 (0.5501)  loss_bbox_dn_1: 0.0978 (0.1031)  loss_giou_dn_1: 0.2330 (0.2219)  loss_fgl_dn_1: 1.1164 (1.1329)  loss_ddf_dn_1: 0.2163 (0.2057)  loss_mal_dn_2: 0.4524 (0.4542)  loss_bbox_dn_2: 0.0761 (0.0838)  loss_giou_dn_2: 0.1903 (0.1888)  loss_fgl_dn_2: 1.0805 (1.0883)  loss_ddf_dn_2: 0.0574 (0.0551)  loss_mal_dn_3: 0.4282 (0.4228)  loss_bbox_dn_3: 0.0715 (0.0790)  loss_giou_dn_3: 0.1750 (0.1800)  loss_fgl_dn_3: 1.0740 (1.0793)  loss_ddf_dn_3: 0.0102 (0.0099)  loss_mal_dn_4: 0.4216 (0.4157)  loss_bbox_dn_4: 0.0706 (0.0776)  loss_giou_dn_4: 0.1718 (0.1775)  loss_fgl_dn_4: 1.0763 (1.0773)  loss_ddf_dn_4: 0.0010 (0.0009)  loss_mal_dn_5: 0.4106 (0.4124)  loss_bbox_dn_5: 0.0705 (0.0773)  loss_giou_dn_5: 0.1716 (0.1769)  loss_fgl_dn_5: 1.0772 (1.0769)  loss_mal_dn_pre: 0.7104 (0.7137)  loss_bbox_dn_pre: 0.1568 (0.1859)  loss_giou_dn_pre: 0.3835 (0.3756)  time: 1.1894  data: 0.0118  max mem: 13413\nEpoch: [41]  [200/251]  eta: 0:01:01  lr: 0.000002  loss: 27.9057 (28.6279)  loss_mal: 0.3730 (0.4346)  loss_bbox: 0.0599 (0.0769)  loss_giou: 0.1528 (0.1792)  loss_fgl: 1.0515 (1.1012)  loss_mal_aux_0: 0.7710 (0.7947)  loss_bbox_aux_0: 0.0858 (0.1003)  loss_giou_aux_0: 0.2389 (0.2297)  loss_fgl_aux_0: 1.1897 (1.2048)  loss_ddf_aux_0: 0.1742 (0.1795)  loss_mal_aux_1: 0.5259 (0.5930)  loss_bbox_aux_1: 0.0672 (0.0809)  loss_giou_aux_1: 0.1673 (0.1877)  loss_fgl_aux_1: 1.0758 (1.1206)  loss_ddf_aux_1: 0.0453 (0.0447)  loss_mal_aux_2: 0.4551 (0.4901)  loss_bbox_aux_2: 0.0621 (0.0769)  loss_giou_aux_2: 0.1536 (0.1808)  loss_fgl_aux_2: 1.0466 (1.1058)  loss_ddf_aux_2: 0.0071 (0.0077)  loss_mal_aux_3: 0.3647 (0.4522)  loss_bbox_aux_3: 0.0617 (0.0769)  loss_giou_aux_3: 0.1521 (0.1798)  loss_fgl_aux_3: 1.0483 (1.1024)  loss_ddf_aux_3: 0.0016 (0.0014)  loss_mal_aux_4: 0.3650 (0.4381)  loss_bbox_aux_4: 0.0603 (0.0771)  loss_giou_aux_4: 0.1530 (0.1794)  loss_fgl_aux_4: 1.0521 (1.1014)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.7720 (0.7947)  loss_bbox_pre: 0.0851 (0.1007)  loss_giou_pre: 0.2382 (0.2293)  loss_mal_enc_0: 0.9658 (0.9820)  loss_bbox_enc_0: 0.1446 (0.1720)  loss_giou_enc_0: 0.3707 (0.3650)  loss_mal_dn_0: 0.7119 (0.7135)  loss_bbox_dn_0: 0.1924 (0.1954)  loss_giou_dn_0: 0.3844 (0.3850)  loss_fgl_dn_0: 1.3042 (1.3152)  loss_ddf_dn_0: 0.9446 (0.8732)  loss_mal_dn_1: 0.5503 (0.5508)  loss_bbox_dn_1: 0.0928 (0.1096)  loss_giou_dn_1: 0.2131 (0.2278)  loss_fgl_dn_1: 1.1046 (1.1325)  loss_ddf_dn_1: 0.2341 (0.2120)  loss_mal_dn_2: 0.4438 (0.4567)  loss_bbox_dn_2: 0.0735 (0.0887)  loss_giou_dn_2: 0.1726 (0.1937)  loss_fgl_dn_2: 1.0417 (1.0875)  loss_ddf_dn_2: 0.0652 (0.0571)  loss_mal_dn_3: 0.4238 (0.4262)  loss_bbox_dn_3: 0.0694 (0.0830)  loss_giou_dn_3: 0.1552 (0.1842)  loss_fgl_dn_3: 1.0368 (1.0782)  loss_ddf_dn_3: 0.0119 (0.0104)  loss_mal_dn_4: 0.3975 (0.4181)  loss_bbox_dn_4: 0.0692 (0.0814)  loss_giou_dn_4: 0.1545 (0.1814)  loss_fgl_dn_4: 1.0336 (1.0760)  loss_ddf_dn_4: 0.0011 (0.0010)  loss_mal_dn_5: 0.3962 (0.4160)  loss_bbox_dn_5: 0.0687 (0.0810)  loss_giou_dn_5: 0.1553 (0.1807)  loss_fgl_dn_5: 1.0314 (1.0755)  loss_mal_dn_pre: 0.7119 (0.7144)  loss_bbox_dn_pre: 0.1926 (0.1964)  loss_giou_dn_pre: 0.3826 (0.3837)  time: 1.2143  data: 0.0109  max mem: 13413\nEpoch: [41]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 27.8074 (28.5907)  loss_mal: 0.3774 (0.4353)  loss_bbox: 0.0592 (0.0758)  loss_giou: 0.1431 (0.1771)  loss_fgl: 1.0536 (1.0984)  loss_mal_aux_0: 0.8101 (0.8004)  loss_bbox_aux_0: 0.0918 (0.1007)  loss_giou_aux_0: 0.2070 (0.2297)  loss_fgl_aux_0: 1.1705 (1.2023)  loss_ddf_aux_0: 0.1933 (0.1815)  loss_mal_aux_1: 0.5444 (0.5934)  loss_bbox_aux_1: 0.0668 (0.0804)  loss_giou_aux_1: 0.1655 (0.1866)  loss_fgl_aux_1: 1.0788 (1.1170)  loss_ddf_aux_1: 0.0500 (0.0452)  loss_mal_aux_2: 0.4434 (0.4891)  loss_bbox_aux_2: 0.0568 (0.0759)  loss_giou_aux_2: 0.1513 (0.1791)  loss_fgl_aux_2: 1.0619 (1.1025)  loss_ddf_aux_2: 0.0082 (0.0078)  loss_mal_aux_3: 0.3884 (0.4518)  loss_bbox_aux_3: 0.0585 (0.0759)  loss_giou_aux_3: 0.1450 (0.1777)  loss_fgl_aux_3: 1.0584 (1.0995)  loss_ddf_aux_3: 0.0014 (0.0014)  loss_mal_aux_4: 0.3762 (0.4379)  loss_bbox_aux_4: 0.0591 (0.0760)  loss_giou_aux_4: 0.1432 (0.1773)  loss_fgl_aux_4: 1.0551 (1.0986)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8096 (0.8002)  loss_bbox_pre: 0.0910 (0.1008)  loss_giou_pre: 0.2079 (0.2291)  loss_mal_enc_0: 0.9351 (0.9889)  loss_bbox_enc_0: 0.1480 (0.1720)  loss_giou_enc_0: 0.3684 (0.3673)  loss_mal_dn_0: 0.7017 (0.7135)  loss_bbox_dn_0: 0.1585 (0.1944)  loss_giou_dn_0: 0.3593 (0.3830)  loss_fgl_dn_0: 1.3130 (1.3140)  loss_ddf_dn_0: 0.9026 (0.8698)  loss_mal_dn_1: 0.5151 (0.5486)  loss_bbox_dn_1: 0.0918 (0.1093)  loss_giou_dn_1: 0.2032 (0.2265)  loss_fgl_dn_1: 1.1134 (1.1307)  loss_ddf_dn_1: 0.2218 (0.2114)  loss_mal_dn_2: 0.4316 (0.4557)  loss_bbox_dn_2: 0.0739 (0.0888)  loss_giou_dn_2: 0.1723 (0.1928)  loss_fgl_dn_2: 1.0513 (1.0865)  loss_ddf_dn_2: 0.0548 (0.0570)  loss_mal_dn_3: 0.4062 (0.4247)  loss_bbox_dn_3: 0.0697 (0.0833)  loss_giou_dn_3: 0.1565 (0.1834)  loss_fgl_dn_3: 1.0491 (1.0775)  loss_ddf_dn_3: 0.0103 (0.0105)  loss_mal_dn_4: 0.3904 (0.4160)  loss_bbox_dn_4: 0.0650 (0.0816)  loss_giou_dn_4: 0.1516 (0.1807)  loss_fgl_dn_4: 1.0490 (1.0755)  loss_ddf_dn_4: 0.0009 (0.0010)  loss_mal_dn_5: 0.3972 (0.4141)  loss_bbox_dn_5: 0.0636 (0.0813)  loss_giou_dn_5: 0.1512 (0.1800)  loss_fgl_dn_5: 1.0490 (1.0750)  loss_mal_dn_pre: 0.7036 (0.7144)  loss_bbox_dn_pre: 0.1588 (0.1952)  loss_giou_dn_pre: 0.3590 (0.3815)  time: 1.1914  data: 0.0121  max mem: 13413\nEpoch: [41] Total time: 0:05:01 (1.2004 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7840  data: 0.4821  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3516  data: 0.0649  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3064  data: 0.0217  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.3232  data: 0.0203  max mem: 13413\nTest: Total time: 0:00:08 (0.3432 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.333\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.538\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.337\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.410\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.356\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.432\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.557\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.672\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.791\nbest_stat: {'epoch': 38, 'coco_eval_bbox': 0.3374040358831138}\nLoad last_epoch\nLoad model.state_dict\nLoad criterion.state_dict\nLoad postprocessor.state_dict\nLoad ema.state_dict\nLoad scaler.state_dict\nLoad optimizer.state_dict\nLoad lr_warmup_scheduler.state_dict\nRefresh EMA at epoch 41 with decay 0.9996\nEpoch: [42]  [  0/251]  eta: 0:10:16  lr: 0.000002  loss: 36.2824 (36.2824)  loss_mal: 0.5801 (0.5801)  loss_bbox: 0.1437 (0.1437)  loss_giou: 0.3095 (0.3095)  loss_fgl: 1.2962 (1.2962)  loss_mal_aux_0: 1.0479 (1.0479)  loss_bbox_aux_0: 0.1559 (0.1559)  loss_giou_aux_0: 0.3236 (0.3236)  loss_fgl_aux_0: 1.3536 (1.3536)  loss_ddf_aux_0: 0.1757 (0.1757)  loss_mal_aux_1: 0.6138 (0.6138)  loss_bbox_aux_1: 0.1593 (0.1593)  loss_giou_aux_1: 0.3242 (0.3242)  loss_fgl_aux_1: 1.3364 (1.3364)  loss_ddf_aux_1: 0.0541 (0.0541)  loss_mal_aux_2: 0.6313 (0.6313)  loss_bbox_aux_2: 0.1522 (0.1522)  loss_giou_aux_2: 0.3127 (0.3127)  loss_fgl_aux_2: 1.3090 (1.3090)  loss_ddf_aux_2: 0.0122 (0.0122)  loss_mal_aux_3: 0.5854 (0.5854)  loss_bbox_aux_3: 0.1483 (0.1483)  loss_giou_aux_3: 0.3113 (0.3113)  loss_fgl_aux_3: 1.2976 (1.2976)  loss_ddf_aux_3: 0.0025 (0.0025)  loss_mal_aux_4: 0.5811 (0.5811)  loss_bbox_aux_4: 0.1454 (0.1454)  loss_giou_aux_4: 0.3093 (0.3093)  loss_fgl_aux_4: 1.2973 (1.2973)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.0498 (1.0498)  loss_bbox_pre: 0.1534 (0.1534)  loss_giou_pre: 0.3203 (0.3203)  loss_mal_enc_0: 1.1328 (1.1328)  loss_bbox_enc_0: 0.2932 (0.2932)  loss_giou_enc_0: 0.5141 (0.5141)  loss_mal_dn_0: 0.7612 (0.7612)  loss_bbox_dn_0: 0.2396 (0.2396)  loss_giou_dn_0: 0.4893 (0.4893)  loss_fgl_dn_0: 1.3653 (1.3653)  loss_ddf_dn_0: 1.0827 (1.0827)  loss_mal_dn_1: 0.6206 (0.6206)  loss_bbox_dn_1: 0.1666 (0.1666)  loss_giou_dn_1: 0.3706 (0.3706)  loss_fgl_dn_1: 1.3394 (1.3394)  loss_ddf_dn_1: 0.2963 (0.2963)  loss_mal_dn_2: 0.5786 (0.5786)  loss_bbox_dn_2: 0.1503 (0.1503)  loss_giou_dn_2: 0.3541 (0.3541)  loss_fgl_dn_2: 1.3350 (1.3350)  loss_ddf_dn_2: 0.0843 (0.0843)  loss_mal_dn_3: 0.5410 (0.5410)  loss_bbox_dn_3: 0.1448 (0.1448)  loss_giou_dn_3: 0.3488 (0.3488)  loss_fgl_dn_3: 1.3330 (1.3330)  loss_ddf_dn_3: 0.0144 (0.0144)  loss_mal_dn_4: 0.5381 (0.5381)  loss_bbox_dn_4: 0.1416 (0.1416)  loss_giou_dn_4: 0.3465 (0.3465)  loss_fgl_dn_4: 1.3361 (1.3361)  loss_ddf_dn_4: 0.0013 (0.0013)  loss_mal_dn_5: 0.5449 (0.5449)  loss_bbox_dn_5: 0.1411 (0.1411)  loss_giou_dn_5: 0.3475 (0.3475)  loss_fgl_dn_5: 1.3368 (1.3368)  loss_mal_dn_pre: 0.7607 (0.7607)  loss_bbox_dn_pre: 0.2463 (0.2463)  loss_giou_dn_pre: 0.4922 (0.4922)  time: 2.4567  data: 1.2402  max mem: 13413\nEpoch: [42]  [100/251]  eta: 0:03:01  lr: 0.000002  loss: 29.2048 (29.4551)  loss_mal: 0.4338 (0.4496)  loss_bbox: 0.0722 (0.0756)  loss_giou: 0.1858 (0.1858)  loss_fgl: 1.1243 (1.1228)  loss_mal_aux_0: 0.7871 (0.8554)  loss_bbox_aux_0: 0.1100 (0.1041)  loss_giou_aux_0: 0.2401 (0.2443)  loss_fgl_aux_0: 1.2234 (1.2210)  loss_ddf_aux_0: 0.1801 (0.1831)  loss_mal_aux_1: 0.5630 (0.6218)  loss_bbox_aux_1: 0.0800 (0.0821)  loss_giou_aux_1: 0.2026 (0.1986)  loss_fgl_aux_1: 1.1559 (1.1425)  loss_ddf_aux_1: 0.0409 (0.0489)  loss_mal_aux_2: 0.4961 (0.5103)  loss_bbox_aux_2: 0.0764 (0.0773)  loss_giou_aux_2: 0.1913 (0.1894)  loss_fgl_aux_2: 1.1169 (1.1259)  loss_ddf_aux_2: 0.0066 (0.0086)  loss_mal_aux_3: 0.4490 (0.4714)  loss_bbox_aux_3: 0.0720 (0.0759)  loss_giou_aux_3: 0.1875 (0.1866)  loss_fgl_aux_3: 1.1217 (1.1239)  loss_ddf_aux_3: 0.0012 (0.0016)  loss_mal_aux_4: 0.4355 (0.4532)  loss_bbox_aux_4: 0.0725 (0.0756)  loss_giou_aux_4: 0.1860 (0.1859)  loss_fgl_aux_4: 1.1233 (1.1234)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.7871 (0.8567)  loss_bbox_pre: 0.1092 (0.1043)  loss_giou_pre: 0.2411 (0.2439)  loss_mal_enc_0: 1.0146 (1.0176)  loss_bbox_enc_0: 0.1838 (0.1839)  loss_giou_enc_0: 0.3606 (0.3959)  loss_mal_dn_0: 0.7227 (0.7261)  loss_bbox_dn_0: 0.1944 (0.1921)  loss_giou_dn_0: 0.3839 (0.3926)  loss_fgl_dn_0: 1.3222 (1.3136)  loss_ddf_dn_0: 0.8936 (0.9121)  loss_mal_dn_1: 0.5688 (0.5661)  loss_bbox_dn_1: 0.1114 (0.1072)  loss_giou_dn_1: 0.2365 (0.2342)  loss_fgl_dn_1: 1.1468 (1.1477)  loss_ddf_dn_1: 0.2142 (0.2258)  loss_mal_dn_2: 0.4814 (0.4734)  loss_bbox_dn_2: 0.0862 (0.0883)  loss_giou_dn_2: 0.2085 (0.2021)  loss_fgl_dn_2: 1.1012 (1.1072)  loss_ddf_dn_2: 0.0544 (0.0615)  loss_mal_dn_3: 0.4597 (0.4438)  loss_bbox_dn_3: 0.0803 (0.0837)  loss_giou_dn_3: 0.1988 (0.1942)  loss_fgl_dn_3: 1.0903 (1.0991)  loss_ddf_dn_3: 0.0099 (0.0112)  loss_mal_dn_4: 0.4524 (0.4364)  loss_bbox_dn_4: 0.0777 (0.0823)  loss_giou_dn_4: 0.1954 (0.1919)  loss_fgl_dn_4: 1.0892 (1.0976)  loss_ddf_dn_4: 0.0009 (0.0011)  loss_mal_dn_5: 0.4456 (0.4347)  loss_bbox_dn_5: 0.0773 (0.0821)  loss_giou_dn_5: 0.1940 (0.1913)  loss_fgl_dn_5: 1.0892 (1.0972)  loss_mal_dn_pre: 0.7231 (0.7266)  loss_bbox_dn_pre: 0.1974 (0.1932)  loss_giou_dn_pre: 0.3871 (0.3916)  time: 1.1886  data: 0.0119  max mem: 13413\nEpoch: [42]  [200/251]  eta: 0:01:01  lr: 0.000002  loss: 28.8899 (29.7322)  loss_mal: 0.4182 (0.4629)  loss_bbox: 0.0706 (0.0814)  loss_giou: 0.2004 (0.1877)  loss_fgl: 1.1120 (1.1237)  loss_mal_aux_0: 0.8545 (0.8550)  loss_bbox_aux_0: 0.0925 (0.1118)  loss_giou_aux_0: 0.2538 (0.2469)  loss_fgl_aux_0: 1.2175 (1.2246)  loss_ddf_aux_0: 0.1714 (0.1879)  loss_mal_aux_1: 0.5698 (0.6250)  loss_bbox_aux_1: 0.0747 (0.0893)  loss_giou_aux_1: 0.2079 (0.1999)  loss_fgl_aux_1: 1.1373 (1.1441)  loss_ddf_aux_1: 0.0405 (0.0509)  loss_mal_aux_2: 0.4758 (0.5117)  loss_bbox_aux_2: 0.0732 (0.0833)  loss_giou_aux_2: 0.2020 (0.1907)  loss_fgl_aux_2: 1.1332 (1.1273)  loss_ddf_aux_2: 0.0074 (0.0090)  loss_mal_aux_3: 0.4285 (0.4795)  loss_bbox_aux_3: 0.0737 (0.0820)  loss_giou_aux_3: 0.2004 (0.1885)  loss_fgl_aux_3: 1.1265 (1.1246)  loss_ddf_aux_3: 0.0015 (0.0016)  loss_mal_aux_4: 0.4180 (0.4657)  loss_bbox_aux_4: 0.0718 (0.0816)  loss_giou_aux_4: 0.2002 (0.1878)  loss_fgl_aux_4: 1.1128 (1.1240)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8530 (0.8529)  loss_bbox_pre: 0.0911 (0.1117)  loss_giou_pre: 0.2519 (0.2462)  loss_mal_enc_0: 0.9985 (1.0242)  loss_bbox_enc_0: 0.1409 (0.1935)  loss_giou_enc_0: 0.3808 (0.3931)  loss_mal_dn_0: 0.7246 (0.7262)  loss_bbox_dn_0: 0.1601 (0.2032)  loss_giou_dn_0: 0.3948 (0.3961)  loss_fgl_dn_0: 1.3037 (1.3164)  loss_ddf_dn_0: 0.8311 (0.9420)  loss_mal_dn_1: 0.5581 (0.5649)  loss_bbox_dn_1: 0.1170 (0.1175)  loss_giou_dn_1: 0.2358 (0.2394)  loss_fgl_dn_1: 1.1339 (1.1509)  loss_ddf_dn_1: 0.2013 (0.2366)  loss_mal_dn_2: 0.4856 (0.4747)  loss_bbox_dn_2: 0.0826 (0.0975)  loss_giou_dn_2: 0.2057 (0.2062)  loss_fgl_dn_2: 1.0975 (1.1101)  loss_ddf_dn_2: 0.0559 (0.0655)  loss_mal_dn_3: 0.4497 (0.4448)  loss_bbox_dn_3: 0.0776 (0.0918)  loss_giou_dn_3: 0.1976 (0.1973)  loss_fgl_dn_3: 1.0885 (1.1018)  loss_ddf_dn_3: 0.0099 (0.0122)  loss_mal_dn_4: 0.4319 (0.4365)  loss_bbox_dn_4: 0.0763 (0.0902)  loss_giou_dn_4: 0.1974 (0.1946)  loss_fgl_dn_4: 1.0864 (1.1002)  loss_ddf_dn_4: 0.0009 (0.0012)  loss_mal_dn_5: 0.4299 (0.4345)  loss_bbox_dn_5: 0.0749 (0.0899)  loss_giou_dn_5: 0.1979 (0.1941)  loss_fgl_dn_5: 1.0864 (1.0999)  loss_mal_dn_pre: 0.7246 (0.7268)  loss_bbox_dn_pre: 0.1608 (0.2042)  loss_giou_dn_pre: 0.3968 (0.3949)  time: 1.1882  data: 0.0113  max mem: 13413\nEpoch: [42]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 29.4453 (29.7631)  loss_mal: 0.4373 (0.4594)  loss_bbox: 0.0819 (0.0823)  loss_giou: 0.1984 (0.1920)  loss_fgl: 1.1443 (1.1295)  loss_mal_aux_0: 0.6987 (0.8421)  loss_bbox_aux_0: 0.0935 (0.1121)  loss_giou_aux_0: 0.2476 (0.2499)  loss_fgl_aux_0: 1.2272 (1.2295)  loss_ddf_aux_0: 0.1719 (0.1882)  loss_mal_aux_1: 0.4873 (0.6166)  loss_bbox_aux_1: 0.0856 (0.0900)  loss_giou_aux_1: 0.2057 (0.2037)  loss_fgl_aux_1: 1.1588 (1.1496)  loss_ddf_aux_1: 0.0419 (0.0505)  loss_mal_aux_2: 0.4666 (0.5093)  loss_bbox_aux_2: 0.0812 (0.0842)  loss_giou_aux_2: 0.2065 (0.1948)  loss_fgl_aux_2: 1.1434 (1.1336)  loss_ddf_aux_2: 0.0074 (0.0089)  loss_mal_aux_3: 0.4434 (0.4752)  loss_bbox_aux_3: 0.0797 (0.0829)  loss_giou_aux_3: 0.1995 (0.1928)  loss_fgl_aux_3: 1.1482 (1.1305)  loss_ddf_aux_3: 0.0013 (0.0016)  loss_mal_aux_4: 0.4424 (0.4625)  loss_bbox_aux_4: 0.0812 (0.0824)  loss_giou_aux_4: 0.1984 (0.1921)  loss_fgl_aux_4: 1.1465 (1.1298)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.7021 (0.8403)  loss_bbox_pre: 0.0938 (0.1119)  loss_giou_pre: 0.2453 (0.2492)  loss_mal_enc_0: 0.9800 (1.0210)  loss_bbox_enc_0: 0.1482 (0.1906)  loss_giou_enc_0: 0.3831 (0.3940)  loss_mal_dn_0: 0.7163 (0.7277)  loss_bbox_dn_0: 0.1610 (0.2019)  loss_giou_dn_0: 0.3902 (0.3974)  loss_fgl_dn_0: 1.3237 (1.3186)  loss_ddf_dn_0: 0.8359 (0.9271)  loss_mal_dn_1: 0.5874 (0.5674)  loss_bbox_dn_1: 0.0947 (0.1166)  loss_giou_dn_1: 0.2457 (0.2409)  loss_fgl_dn_1: 1.1666 (1.1535)  loss_ddf_dn_1: 0.1830 (0.2319)  loss_mal_dn_2: 0.4753 (0.4786)  loss_bbox_dn_2: 0.0856 (0.0969)  loss_giou_dn_2: 0.2145 (0.2085)  loss_fgl_dn_2: 1.1065 (1.1131)  loss_ddf_dn_2: 0.0496 (0.0642)  loss_mal_dn_3: 0.4482 (0.4467)  loss_bbox_dn_3: 0.0808 (0.0912)  loss_giou_dn_3: 0.2026 (0.1998)  loss_fgl_dn_3: 1.0920 (1.1046)  loss_ddf_dn_3: 0.0091 (0.0119)  loss_mal_dn_4: 0.4490 (0.4385)  loss_bbox_dn_4: 0.0831 (0.0896)  loss_giou_dn_4: 0.1976 (0.1971)  loss_fgl_dn_4: 1.0882 (1.1028)  loss_ddf_dn_4: 0.0009 (0.0011)  loss_mal_dn_5: 0.4478 (0.4365)  loss_bbox_dn_5: 0.0834 (0.0893)  loss_giou_dn_5: 0.1956 (0.1965)  loss_fgl_dn_5: 1.0876 (1.1025)  loss_mal_dn_pre: 0.7183 (0.7282)  loss_bbox_dn_pre: 0.1612 (0.2030)  loss_giou_dn_pre: 0.3930 (0.3962)  time: 1.2003  data: 0.0111  max mem: 13413\nEpoch: [42] Total time: 0:05:00 (1.1963 s / it)\nTest:  [ 0/25]  eta: 0:00:22    time: 0.8985  data: 0.6007  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3568  data: 0.0722  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3025  data: 0.0194  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2915  data: 0.0188  max mem: 13413\nTest: Total time: 0:00:08 (0.3214 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.540\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.344\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.409\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.360\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.459\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.580\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.780\nbest_stat: {'epoch': 38, 'coco_eval_bbox': 0.3374040358831138}\nEpoch: [43]  [  0/251]  eta: 0:09:30  lr: 0.000002  loss: 26.3558 (26.3558)  loss_mal: 0.3311 (0.3311)  loss_bbox: 0.0469 (0.0469)  loss_giou: 0.1210 (0.1210)  loss_fgl: 1.0091 (1.0091)  loss_mal_aux_0: 0.7837 (0.7837)  loss_bbox_aux_0: 0.0679 (0.0679)  loss_giou_aux_0: 0.1952 (0.1952)  loss_fgl_aux_0: 1.1666 (1.1666)  loss_ddf_aux_0: 0.2310 (0.2310)  loss_mal_aux_1: 0.4602 (0.4602)  loss_bbox_aux_1: 0.0525 (0.0525)  loss_giou_aux_1: 0.1406 (0.1406)  loss_fgl_aux_1: 1.0482 (1.0482)  loss_ddf_aux_1: 0.0575 (0.0575)  loss_mal_aux_2: 0.3613 (0.3613)  loss_bbox_aux_2: 0.0503 (0.0503)  loss_giou_aux_2: 0.1243 (0.1243)  loss_fgl_aux_2: 1.0140 (1.0140)  loss_ddf_aux_2: 0.0084 (0.0084)  loss_mal_aux_3: 0.3345 (0.3345)  loss_bbox_aux_3: 0.0478 (0.0478)  loss_giou_aux_3: 0.1192 (0.1192)  loss_fgl_aux_3: 1.0118 (1.0118)  loss_ddf_aux_3: 0.0014 (0.0014)  loss_mal_aux_4: 0.3398 (0.3398)  loss_bbox_aux_4: 0.0472 (0.0472)  loss_giou_aux_4: 0.1207 (0.1207)  loss_fgl_aux_4: 1.0098 (1.0098)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 0.7754 (0.7754)  loss_bbox_pre: 0.0667 (0.0667)  loss_giou_pre: 0.1917 (0.1917)  loss_mal_enc_0: 1.0127 (1.0127)  loss_bbox_enc_0: 0.1418 (0.1418)  loss_giou_enc_0: 0.3681 (0.3681)  loss_mal_dn_0: 0.7388 (0.7388)  loss_bbox_dn_0: 0.1855 (0.1855)  loss_giou_dn_0: 0.4178 (0.4178)  loss_fgl_dn_0: 1.3407 (1.3407)  loss_ddf_dn_0: 0.8001 (0.8001)  loss_mal_dn_1: 0.5996 (0.5996)  loss_bbox_dn_1: 0.0962 (0.0962)  loss_giou_dn_1: 0.2130 (0.2130)  loss_fgl_dn_1: 1.1004 (1.1004)  loss_ddf_dn_1: 0.2158 (0.2158)  loss_mal_dn_2: 0.4639 (0.4639)  loss_bbox_dn_2: 0.0666 (0.0666)  loss_giou_dn_2: 0.1525 (0.1525)  loss_fgl_dn_2: 1.0206 (1.0206)  loss_ddf_dn_2: 0.0509 (0.0509)  loss_mal_dn_3: 0.3870 (0.3870)  loss_bbox_dn_3: 0.0553 (0.0553)  loss_giou_dn_3: 0.1309 (0.1309)  loss_fgl_dn_3: 1.0060 (1.0060)  loss_ddf_dn_3: 0.0084 (0.0084)  loss_mal_dn_4: 0.3779 (0.3779)  loss_bbox_dn_4: 0.0531 (0.0531)  loss_giou_dn_4: 0.1253 (0.1253)  loss_fgl_dn_4: 1.0032 (1.0032)  loss_ddf_dn_4: 0.0007 (0.0007)  loss_mal_dn_5: 0.3689 (0.3689)  loss_bbox_dn_5: 0.0531 (0.0531)  loss_giou_dn_5: 0.1251 (0.1251)  loss_fgl_dn_5: 1.0023 (1.0023)  loss_mal_dn_pre: 0.7383 (0.7383)  loss_bbox_dn_pre: 0.1852 (0.1852)  loss_giou_dn_pre: 0.4143 (0.4143)  time: 2.2728  data: 1.0491  max mem: 13413\nEpoch: [43]  [100/251]  eta: 0:03:00  lr: 0.000002  loss: 26.7412 (28.3230)  loss_mal: 0.3311 (0.4370)  loss_bbox: 0.0551 (0.0721)  loss_giou: 0.1376 (0.1715)  loss_fgl: 1.0362 (1.0871)  loss_mal_aux_0: 0.7847 (0.7918)  loss_bbox_aux_0: 0.0867 (0.0991)  loss_giou_aux_0: 0.1998 (0.2298)  loss_fgl_aux_0: 1.1747 (1.2001)  loss_ddf_aux_0: 0.1835 (0.1797)  loss_mal_aux_1: 0.4888 (0.5724)  loss_bbox_aux_1: 0.0561 (0.0784)  loss_giou_aux_1: 0.1470 (0.1820)  loss_fgl_aux_1: 1.0765 (1.1133)  loss_ddf_aux_1: 0.0493 (0.0462)  loss_mal_aux_2: 0.3660 (0.4721)  loss_bbox_aux_2: 0.0545 (0.0738)  loss_giou_aux_2: 0.1391 (0.1740)  loss_fgl_aux_2: 1.0378 (1.0930)  loss_ddf_aux_2: 0.0072 (0.0079)  loss_mal_aux_3: 0.3359 (0.4472)  loss_bbox_aux_3: 0.0541 (0.0726)  loss_giou_aux_3: 0.1382 (0.1721)  loss_fgl_aux_3: 1.0402 (1.0891)  loss_ddf_aux_3: 0.0012 (0.0014)  loss_mal_aux_4: 0.3325 (0.4398)  loss_bbox_aux_4: 0.0549 (0.0723)  loss_giou_aux_4: 0.1377 (0.1716)  loss_fgl_aux_4: 1.0376 (1.0875)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.7822 (0.7923)  loss_bbox_pre: 0.0858 (0.0989)  loss_giou_pre: 0.1993 (0.2290)  loss_mal_enc_0: 0.9521 (1.0083)  loss_bbox_enc_0: 0.1612 (0.1656)  loss_giou_enc_0: 0.3562 (0.3543)  loss_mal_dn_0: 0.7012 (0.7167)  loss_bbox_dn_0: 0.1827 (0.1880)  loss_giou_dn_0: 0.3572 (0.3792)  loss_fgl_dn_0: 1.3068 (1.3097)  loss_ddf_dn_0: 0.8123 (0.8527)  loss_mal_dn_1: 0.5088 (0.5433)  loss_bbox_dn_1: 0.0846 (0.1047)  loss_giou_dn_1: 0.1930 (0.2199)  loss_fgl_dn_1: 1.1045 (1.1259)  loss_ddf_dn_1: 0.1909 (0.2086)  loss_mal_dn_2: 0.4204 (0.4524)  loss_bbox_dn_2: 0.0650 (0.0860)  loss_giou_dn_2: 0.1540 (0.1875)  loss_fgl_dn_2: 1.0547 (1.0823)  loss_ddf_dn_2: 0.0512 (0.0569)  loss_mal_dn_3: 0.3804 (0.4197)  loss_bbox_dn_3: 0.0605 (0.0810)  loss_giou_dn_3: 0.1445 (0.1788)  loss_fgl_dn_3: 1.0452 (1.0735)  loss_ddf_dn_3: 0.0093 (0.0105)  loss_mal_dn_4: 0.3672 (0.4119)  loss_bbox_dn_4: 0.0571 (0.0795)  loss_giou_dn_4: 0.1449 (0.1764)  loss_fgl_dn_4: 1.0401 (1.0715)  loss_ddf_dn_4: 0.0009 (0.0010)  loss_mal_dn_5: 0.3638 (0.4107)  loss_bbox_dn_5: 0.0571 (0.0793)  loss_giou_dn_5: 0.1459 (0.1759)  loss_fgl_dn_5: 1.0384 (1.0711)  loss_mal_dn_pre: 0.7012 (0.7170)  loss_bbox_dn_pre: 0.1923 (0.1896)  loss_giou_dn_pre: 0.3546 (0.3783)  time: 1.1912  data: 0.0116  max mem: 13413\nEpoch: [43]  [200/251]  eta: 0:01:01  lr: 0.000002  loss: 28.7125 (28.3492)  loss_mal: 0.3960 (0.4240)  loss_bbox: 0.0713 (0.0728)  loss_giou: 0.1793 (0.1711)  loss_fgl: 1.0649 (1.0886)  loss_mal_aux_0: 0.7520 (0.8006)  loss_bbox_aux_0: 0.1077 (0.1009)  loss_giou_aux_0: 0.2403 (0.2304)  loss_fgl_aux_0: 1.2271 (1.2039)  loss_ddf_aux_0: 0.1710 (0.1846)  loss_mal_aux_1: 0.5005 (0.5607)  loss_bbox_aux_1: 0.0770 (0.0797)  loss_giou_aux_1: 0.2003 (0.1825)  loss_fgl_aux_1: 1.1075 (1.1151)  loss_ddf_aux_1: 0.0506 (0.0474)  loss_mal_aux_2: 0.4226 (0.4689)  loss_bbox_aux_2: 0.0721 (0.0745)  loss_giou_aux_2: 0.1806 (0.1736)  loss_fgl_aux_2: 1.0865 (1.0944)  loss_ddf_aux_2: 0.0071 (0.0080)  loss_mal_aux_3: 0.4109 (0.4389)  loss_bbox_aux_3: 0.0721 (0.0734)  loss_giou_aux_3: 0.1793 (0.1716)  loss_fgl_aux_3: 1.0772 (1.0902)  loss_ddf_aux_3: 0.0015 (0.0014)  loss_mal_aux_4: 0.3965 (0.4276)  loss_bbox_aux_4: 0.0712 (0.0729)  loss_giou_aux_4: 0.1783 (0.1711)  loss_fgl_aux_4: 1.0677 (1.0890)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.7534 (0.8008)  loss_bbox_pre: 0.1074 (0.1003)  loss_giou_pre: 0.2476 (0.2297)  loss_mal_enc_0: 0.9175 (0.9870)  loss_bbox_enc_0: 0.1552 (0.1712)  loss_giou_enc_0: 0.3352 (0.3594)  loss_mal_dn_0: 0.7100 (0.7176)  loss_bbox_dn_0: 0.1758 (0.1899)  loss_giou_dn_0: 0.3785 (0.3800)  loss_fgl_dn_0: 1.2994 (1.3133)  loss_ddf_dn_0: 0.8340 (0.8837)  loss_mal_dn_1: 0.5635 (0.5449)  loss_bbox_dn_1: 0.1049 (0.1047)  loss_giou_dn_1: 0.2370 (0.2202)  loss_fgl_dn_1: 1.1281 (1.1256)  loss_ddf_dn_1: 0.2150 (0.2161)  loss_mal_dn_2: 0.4690 (0.4537)  loss_bbox_dn_2: 0.0844 (0.0854)  loss_giou_dn_2: 0.1946 (0.1872)  loss_fgl_dn_2: 1.0716 (1.0800)  loss_ddf_dn_2: 0.0588 (0.0589)  loss_mal_dn_3: 0.4199 (0.4208)  loss_bbox_dn_3: 0.0806 (0.0803)  loss_giou_dn_3: 0.1829 (0.1786)  loss_fgl_dn_3: 1.0597 (1.0706)  loss_ddf_dn_3: 0.0114 (0.0109)  loss_mal_dn_4: 0.4211 (0.4132)  loss_bbox_dn_4: 0.0759 (0.0788)  loss_giou_dn_4: 0.1817 (0.1762)  loss_fgl_dn_4: 1.0578 (1.0685)  loss_ddf_dn_4: 0.0010 (0.0010)  loss_mal_dn_5: 0.4185 (0.4118)  loss_bbox_dn_5: 0.0742 (0.0785)  loss_giou_dn_5: 0.1820 (0.1758)  loss_fgl_dn_5: 1.0567 (1.0680)  loss_mal_dn_pre: 0.7095 (0.7177)  loss_bbox_dn_pre: 0.1724 (0.1914)  loss_giou_dn_pre: 0.3780 (0.3792)  time: 1.1908  data: 0.0119  max mem: 13413\nEpoch: [43]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 28.1908 (28.4482)  loss_mal: 0.4324 (0.4375)  loss_bbox: 0.0547 (0.0720)  loss_giou: 0.1587 (0.1700)  loss_fgl: 1.0618 (1.0858)  loss_mal_aux_0: 0.7393 (0.7924)  loss_bbox_aux_0: 0.0809 (0.1015)  loss_giou_aux_0: 0.1931 (0.2304)  loss_fgl_aux_0: 1.1654 (1.2045)  loss_ddf_aux_0: 0.1982 (0.1904)  loss_mal_aux_1: 0.5747 (0.5751)  loss_bbox_aux_1: 0.0581 (0.0792)  loss_giou_aux_1: 0.1815 (0.1819)  loss_fgl_aux_1: 1.1131 (1.1135)  loss_ddf_aux_1: 0.0482 (0.0491)  loss_mal_aux_2: 0.4551 (0.4829)  loss_bbox_aux_2: 0.0552 (0.0738)  loss_giou_aux_2: 0.1704 (0.1726)  loss_fgl_aux_2: 1.0927 (1.0922)  loss_ddf_aux_2: 0.0082 (0.0084)  loss_mal_aux_3: 0.4224 (0.4533)  loss_bbox_aux_3: 0.0546 (0.0726)  loss_giou_aux_3: 0.1681 (0.1707)  loss_fgl_aux_3: 1.0685 (1.0877)  loss_ddf_aux_3: 0.0014 (0.0015)  loss_mal_aux_4: 0.4302 (0.4410)  loss_bbox_aux_4: 0.0550 (0.0722)  loss_giou_aux_4: 0.1627 (0.1701)  loss_fgl_aux_4: 1.0624 (1.0863)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.7388 (0.7925)  loss_bbox_pre: 0.0806 (0.1009)  loss_giou_pre: 0.1928 (0.2295)  loss_mal_enc_0: 0.9595 (0.9817)  loss_bbox_enc_0: 0.1321 (0.1718)  loss_giou_enc_0: 0.3685 (0.3593)  loss_mal_dn_0: 0.7212 (0.7171)  loss_bbox_dn_0: 0.1667 (0.1916)  loss_giou_dn_0: 0.3533 (0.3826)  loss_fgl_dn_0: 1.3011 (1.3140)  loss_ddf_dn_0: 0.9795 (0.9201)  loss_mal_dn_1: 0.5479 (0.5460)  loss_bbox_dn_1: 0.0808 (0.1057)  loss_giou_dn_1: 0.2166 (0.2215)  loss_fgl_dn_1: 1.1015 (1.1246)  loss_ddf_dn_1: 0.2242 (0.2260)  loss_mal_dn_2: 0.4485 (0.4552)  loss_bbox_dn_2: 0.0697 (0.0860)  loss_giou_dn_2: 0.1740 (0.1877)  loss_fgl_dn_2: 1.0469 (1.0783)  loss_ddf_dn_2: 0.0653 (0.0622)  loss_mal_dn_3: 0.4216 (0.4222)  loss_bbox_dn_3: 0.0675 (0.0806)  loss_giou_dn_3: 0.1603 (0.1788)  loss_fgl_dn_3: 1.0464 (1.0687)  loss_ddf_dn_3: 0.0128 (0.0116)  loss_mal_dn_4: 0.4146 (0.4151)  loss_bbox_dn_4: 0.0664 (0.0790)  loss_giou_dn_4: 0.1556 (0.1762)  loss_fgl_dn_4: 1.0459 (1.0664)  loss_ddf_dn_4: 0.0011 (0.0011)  loss_mal_dn_5: 0.4182 (0.4135)  loss_bbox_dn_5: 0.0660 (0.0787)  loss_giou_dn_5: 0.1538 (0.1757)  loss_fgl_dn_5: 1.0443 (1.0659)  loss_mal_dn_pre: 0.7202 (0.7173)  loss_bbox_dn_pre: 0.1670 (0.1929)  loss_giou_dn_pre: 0.3539 (0.3815)  time: 1.1890  data: 0.0111  max mem: 13413\nEpoch: [43] Total time: 0:05:00 (1.1959 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8049  data: 0.5026  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3501  data: 0.0639  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3332  data: 0.0210  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.3224  data: 0.0206  max mem: 13413\nTest: Total time: 0:00:08 (0.3429 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.538\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.338\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.358\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.440\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.578\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.674\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.787\nbest_stat: {'epoch': 38, 'coco_eval_bbox': 0.3374040358831138}\nLoad last_epoch\nLoad model.state_dict\nLoad criterion.state_dict\nLoad postprocessor.state_dict\nLoad ema.state_dict\nLoad scaler.state_dict\nLoad optimizer.state_dict\nLoad lr_warmup_scheduler.state_dict\nRefresh EMA at epoch 43 with decay 0.9995\nEpoch: [44]  [  0/251]  eta: 0:08:56  lr: 0.000002  loss: 27.2467 (27.2467)  loss_mal: 0.3101 (0.3101)  loss_bbox: 0.0909 (0.0909)  loss_giou: 0.1243 (0.1243)  loss_fgl: 1.0305 (1.0305)  loss_mal_aux_0: 0.9585 (0.9585)  loss_bbox_aux_0: 0.1281 (0.1281)  loss_giou_aux_0: 0.1944 (0.1944)  loss_fgl_aux_0: 1.1574 (1.1574)  loss_ddf_aux_0: 0.1863 (0.1863)  loss_mal_aux_1: 0.5479 (0.5479)  loss_bbox_aux_1: 0.0884 (0.0884)  loss_giou_aux_1: 0.1260 (0.1260)  loss_fgl_aux_1: 1.0394 (1.0394)  loss_ddf_aux_1: 0.0483 (0.0483)  loss_mal_aux_2: 0.3252 (0.3252)  loss_bbox_aux_2: 0.0924 (0.0924)  loss_giou_aux_2: 0.1260 (0.1260)  loss_fgl_aux_2: 1.0330 (1.0330)  loss_ddf_aux_2: 0.0079 (0.0079)  loss_mal_aux_3: 0.3149 (0.3149)  loss_bbox_aux_3: 0.0914 (0.0914)  loss_giou_aux_3: 0.1256 (0.1256)  loss_fgl_aux_3: 1.0332 (1.0332)  loss_ddf_aux_3: 0.0011 (0.0011)  loss_mal_aux_4: 0.3125 (0.3125)  loss_bbox_aux_4: 0.0908 (0.0908)  loss_giou_aux_4: 0.1240 (0.1240)  loss_fgl_aux_4: 1.0313 (1.0313)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 0.9595 (0.9595)  loss_bbox_pre: 0.1257 (0.1257)  loss_giou_pre: 0.1910 (0.1910)  loss_mal_enc_0: 1.1562 (1.1562)  loss_bbox_enc_0: 0.2175 (0.2175)  loss_giou_enc_0: 0.3779 (0.3779)  loss_mal_dn_0: 0.7002 (0.7002)  loss_bbox_dn_0: 0.2060 (0.2060)  loss_giou_dn_0: 0.3142 (0.3142)  loss_fgl_dn_0: 1.2864 (1.2864)  loss_ddf_dn_0: 0.8418 (0.8418)  loss_mal_dn_1: 0.4941 (0.4941)  loss_bbox_dn_1: 0.1213 (0.1213)  loss_giou_dn_1: 0.1703 (0.1703)  loss_fgl_dn_1: 1.1026 (1.1026)  loss_ddf_dn_1: 0.2079 (0.2079)  loss_mal_dn_2: 0.4170 (0.4170)  loss_bbox_dn_2: 0.1053 (0.1053)  loss_giou_dn_2: 0.1435 (0.1435)  loss_fgl_dn_2: 1.0663 (1.0663)  loss_ddf_dn_2: 0.0576 (0.0576)  loss_mal_dn_3: 0.3809 (0.3809)  loss_bbox_dn_3: 0.0998 (0.0998)  loss_giou_dn_3: 0.1339 (0.1339)  loss_fgl_dn_3: 1.0665 (1.0665)  loss_ddf_dn_3: 0.0103 (0.0103)  loss_mal_dn_4: 0.3687 (0.3687)  loss_bbox_dn_4: 0.0973 (0.0973)  loss_giou_dn_4: 0.1299 (0.1299)  loss_fgl_dn_4: 1.0644 (1.0644)  loss_ddf_dn_4: 0.0009 (0.0009)  loss_mal_dn_5: 0.3650 (0.3650)  loss_bbox_dn_5: 0.0970 (0.0970)  loss_giou_dn_5: 0.1297 (0.1297)  loss_fgl_dn_5: 1.0627 (1.0627)  loss_mal_dn_pre: 0.6992 (0.6992)  loss_bbox_dn_pre: 0.2164 (0.2164)  loss_giou_dn_pre: 0.3222 (0.3222)  time: 2.1363  data: 0.9188  max mem: 13413\nEpoch: [44]  [100/251]  eta: 0:03:00  lr: 0.000002  loss: 28.8747 (29.5733)  loss_mal: 0.4055 (0.4701)  loss_bbox: 0.0673 (0.0758)  loss_giou: 0.1879 (0.1857)  loss_fgl: 1.1033 (1.1084)  loss_mal_aux_0: 0.8115 (0.8666)  loss_bbox_aux_0: 0.0897 (0.1050)  loss_giou_aux_0: 0.2256 (0.2487)  loss_fgl_aux_0: 1.1886 (1.2251)  loss_ddf_aux_0: 0.1810 (0.1935)  loss_mal_aux_1: 0.5654 (0.6296)  loss_bbox_aux_1: 0.0720 (0.0822)  loss_giou_aux_1: 0.1918 (0.1979)  loss_fgl_aux_1: 1.1184 (1.1357)  loss_ddf_aux_1: 0.0412 (0.0527)  loss_mal_aux_2: 0.4333 (0.5230)  loss_bbox_aux_2: 0.0688 (0.0773)  loss_giou_aux_2: 0.1894 (0.1884)  loss_fgl_aux_2: 1.1030 (1.1145)  loss_ddf_aux_2: 0.0077 (0.0096)  loss_mal_aux_3: 0.4114 (0.4835)  loss_bbox_aux_3: 0.0679 (0.0762)  loss_giou_aux_3: 0.1927 (0.1867)  loss_fgl_aux_3: 1.1019 (1.1102)  loss_ddf_aux_3: 0.0014 (0.0017)  loss_mal_aux_4: 0.4084 (0.4702)  loss_bbox_aux_4: 0.0674 (0.0758)  loss_giou_aux_4: 0.1892 (0.1859)  loss_fgl_aux_4: 1.1029 (1.1089)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.8159 (0.8669)  loss_bbox_pre: 0.0902 (0.1048)  loss_giou_pre: 0.2269 (0.2483)  loss_mal_enc_0: 1.0078 (1.0246)  loss_bbox_enc_0: 0.1552 (0.1860)  loss_giou_enc_0: 0.3782 (0.4045)  loss_mal_dn_0: 0.7129 (0.7299)  loss_bbox_dn_0: 0.1651 (0.1957)  loss_giou_dn_0: 0.3666 (0.3977)  loss_fgl_dn_0: 1.3002 (1.3124)  loss_ddf_dn_0: 0.7674 (0.9353)  loss_mal_dn_1: 0.5479 (0.5716)  loss_bbox_dn_1: 0.0918 (0.1121)  loss_giou_dn_1: 0.2218 (0.2377)  loss_fgl_dn_1: 1.1373 (1.1434)  loss_ddf_dn_1: 0.1931 (0.2388)  loss_mal_dn_2: 0.4646 (0.4764)  loss_bbox_dn_2: 0.0758 (0.0925)  loss_giou_dn_2: 0.1886 (0.2038)  loss_fgl_dn_2: 1.0913 (1.0984)  loss_ddf_dn_2: 0.0495 (0.0659)  loss_mal_dn_3: 0.4226 (0.4409)  loss_bbox_dn_3: 0.0734 (0.0868)  loss_giou_dn_3: 0.1828 (0.1945)  loss_fgl_dn_3: 1.0820 (1.0888)  loss_ddf_dn_3: 0.0091 (0.0121)  loss_mal_dn_4: 0.4133 (0.4326)  loss_bbox_dn_4: 0.0729 (0.0852)  loss_giou_dn_4: 0.1800 (0.1919)  loss_fgl_dn_4: 1.0766 (1.0864)  loss_ddf_dn_4: 0.0009 (0.0011)  loss_mal_dn_5: 0.4160 (0.4314)  loss_bbox_dn_5: 0.0721 (0.0849)  loss_giou_dn_5: 0.1806 (0.1912)  loss_fgl_dn_5: 1.0751 (1.0857)  loss_mal_dn_pre: 0.7158 (0.7303)  loss_bbox_dn_pre: 0.1687 (0.1970)  loss_giou_dn_pre: 0.3667 (0.3968)  time: 1.1886  data: 0.0125  max mem: 13413\nEpoch: [44]  [200/251]  eta: 0:01:00  lr: 0.000002  loss: 28.8279 (29.3944)  loss_mal: 0.3799 (0.4553)  loss_bbox: 0.0611 (0.0771)  loss_giou: 0.1791 (0.1837)  loss_fgl: 1.0807 (1.1068)  loss_mal_aux_0: 0.7959 (0.8522)  loss_bbox_aux_0: 0.0813 (0.1068)  loss_giou_aux_0: 0.2319 (0.2453)  loss_fgl_aux_0: 1.1894 (1.2214)  loss_ddf_aux_0: 0.1826 (0.1920)  loss_mal_aux_1: 0.5581 (0.6220)  loss_bbox_aux_1: 0.0607 (0.0833)  loss_giou_aux_1: 0.1846 (0.1951)  loss_fgl_aux_1: 1.1003 (1.1331)  loss_ddf_aux_1: 0.0444 (0.0513)  loss_mal_aux_2: 0.4626 (0.5074)  loss_bbox_aux_2: 0.0596 (0.0781)  loss_giou_aux_2: 0.1801 (0.1862)  loss_fgl_aux_2: 1.0797 (1.1126)  loss_ddf_aux_2: 0.0065 (0.0089)  loss_mal_aux_3: 0.3882 (0.4687)  loss_bbox_aux_3: 0.0604 (0.0773)  loss_giou_aux_3: 0.1795 (0.1844)  loss_fgl_aux_3: 1.0793 (1.1088)  loss_ddf_aux_3: 0.0013 (0.0016)  loss_mal_aux_4: 0.3845 (0.4563)  loss_bbox_aux_4: 0.0612 (0.0771)  loss_giou_aux_4: 0.1792 (0.1839)  loss_fgl_aux_4: 1.0803 (1.1074)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.7959 (0.8528)  loss_bbox_pre: 0.0828 (0.1064)  loss_giou_pre: 0.2321 (0.2448)  loss_mal_enc_0: 0.9614 (1.0311)  loss_bbox_enc_0: 0.1517 (0.1879)  loss_giou_enc_0: 0.3575 (0.3974)  loss_mal_dn_0: 0.7124 (0.7261)  loss_bbox_dn_0: 0.1664 (0.1989)  loss_giou_dn_0: 0.3889 (0.3940)  loss_fgl_dn_0: 1.3086 (1.3163)  loss_ddf_dn_0: 0.7739 (0.9232)  loss_mal_dn_1: 0.5547 (0.5634)  loss_bbox_dn_1: 0.0869 (0.1133)  loss_giou_dn_1: 0.2098 (0.2348)  loss_fgl_dn_1: 1.1071 (1.1436)  loss_ddf_dn_1: 0.1884 (0.2328)  loss_mal_dn_2: 0.4573 (0.4697)  loss_bbox_dn_2: 0.0755 (0.0931)  loss_giou_dn_2: 0.1761 (0.2013)  loss_fgl_dn_2: 1.0607 (1.0987)  loss_ddf_dn_2: 0.0447 (0.0633)  loss_mal_dn_3: 0.4233 (0.4365)  loss_bbox_dn_3: 0.0741 (0.0875)  loss_giou_dn_3: 0.1694 (0.1924)  loss_fgl_dn_3: 1.0512 (1.0895)  loss_ddf_dn_3: 0.0083 (0.0115)  loss_mal_dn_4: 0.4111 (0.4283)  loss_bbox_dn_4: 0.0762 (0.0859)  loss_giou_dn_4: 0.1678 (0.1897)  loss_fgl_dn_4: 1.0480 (1.0871)  loss_ddf_dn_4: 0.0008 (0.0011)  loss_mal_dn_5: 0.4077 (0.4270)  loss_bbox_dn_5: 0.0758 (0.0856)  loss_giou_dn_5: 0.1670 (0.1891)  loss_fgl_dn_5: 1.0486 (1.0864)  loss_mal_dn_pre: 0.7124 (0.7265)  loss_bbox_dn_pre: 0.1664 (0.2002)  loss_giou_dn_pre: 0.3836 (0.3929)  time: 1.1869  data: 0.0114  max mem: 13413\nEpoch: [44]  [250/251]  eta: 0:00:01  lr: 0.000002  loss: 28.0829 (29.4633)  loss_mal: 0.3848 (0.4562)  loss_bbox: 0.0622 (0.0781)  loss_giou: 0.1653 (0.1848)  loss_fgl: 1.0652 (1.1098)  loss_mal_aux_0: 0.8022 (0.8531)  loss_bbox_aux_0: 0.1018 (0.1080)  loss_giou_aux_0: 0.2183 (0.2463)  loss_fgl_aux_0: 1.1688 (1.2231)  loss_ddf_aux_0: 0.1803 (0.1921)  loss_mal_aux_1: 0.5415 (0.6226)  loss_bbox_aux_1: 0.0684 (0.0846)  loss_giou_aux_1: 0.1955 (0.1964)  loss_fgl_aux_1: 1.0925 (1.1355)  loss_ddf_aux_1: 0.0435 (0.0509)  loss_mal_aux_2: 0.4451 (0.5092)  loss_bbox_aux_2: 0.0610 (0.0794)  loss_giou_aux_2: 0.1892 (0.1878)  loss_fgl_aux_2: 1.0813 (1.1159)  loss_ddf_aux_2: 0.0074 (0.0088)  loss_mal_aux_3: 0.4031 (0.4709)  loss_bbox_aux_3: 0.0603 (0.0784)  loss_giou_aux_3: 0.1754 (0.1858)  loss_fgl_aux_3: 1.0677 (1.1117)  loss_ddf_aux_3: 0.0014 (0.0016)  loss_mal_aux_4: 0.3962 (0.4584)  loss_bbox_aux_4: 0.0619 (0.0781)  loss_giou_aux_4: 0.1685 (0.1851)  loss_fgl_aux_4: 1.0656 (1.1104)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8047 (0.8542)  loss_bbox_pre: 0.1016 (0.1078)  loss_giou_pre: 0.2184 (0.2459)  loss_mal_enc_0: 1.0410 (1.0363)  loss_bbox_enc_0: 0.1660 (0.1905)  loss_giou_enc_0: 0.3688 (0.3982)  loss_mal_dn_0: 0.7217 (0.7259)  loss_bbox_dn_0: 0.1727 (0.2014)  loss_giou_dn_0: 0.3685 (0.3946)  loss_fgl_dn_0: 1.2966 (1.3158)  loss_ddf_dn_0: 0.8787 (0.9153)  loss_mal_dn_1: 0.5400 (0.5647)  loss_bbox_dn_1: 0.0931 (0.1146)  loss_giou_dn_1: 0.2078 (0.2358)  loss_fgl_dn_1: 1.0943 (1.1440)  loss_ddf_dn_1: 0.2091 (0.2292)  loss_mal_dn_2: 0.4424 (0.4708)  loss_bbox_dn_2: 0.0751 (0.0945)  loss_giou_dn_2: 0.1763 (0.2024)  loss_fgl_dn_2: 1.0510 (1.1001)  loss_ddf_dn_2: 0.0519 (0.0622)  loss_mal_dn_3: 0.4138 (0.4381)  loss_bbox_dn_3: 0.0710 (0.0888)  loss_giou_dn_3: 0.1729 (0.1934)  loss_fgl_dn_3: 1.0455 (1.0909)  loss_ddf_dn_3: 0.0086 (0.0113)  loss_mal_dn_4: 0.4041 (0.4300)  loss_bbox_dn_4: 0.0721 (0.0872)  loss_giou_dn_4: 0.1685 (0.1907)  loss_fgl_dn_4: 1.0431 (1.0884)  loss_ddf_dn_4: 0.0008 (0.0011)  loss_mal_dn_5: 0.4050 (0.4286)  loss_bbox_dn_5: 0.0727 (0.0869)  loss_giou_dn_5: 0.1660 (0.1901)  loss_fgl_dn_5: 1.0422 (1.0877)  loss_mal_dn_pre: 0.7217 (0.7264)  loss_bbox_dn_pre: 0.1762 (0.2026)  loss_giou_dn_pre: 0.3672 (0.3936)  time: 1.1860  data: 0.0112  max mem: 13413\nEpoch: [44] Total time: 0:04:59 (1.1923 s / it)\nTest:  [ 0/25]  eta: 0:00:20    time: 0.8002  data: 0.5003  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3528  data: 0.0661  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3067  data: 0.0217  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2938  data: 0.0199  max mem: 13413\nTest: Total time: 0:00:08 (0.3203 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.538\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.343\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.358\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.461\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.579\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.621\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.780\nbest_stat: {'epoch': 38, 'coco_eval_bbox': 0.3374040358831138}\nEpoch: [45]  [  0/251]  eta: 0:07:55  lr: 0.000002  loss: 26.5352 (26.5352)  loss_mal: 0.3755 (0.3755)  loss_bbox: 0.0608 (0.0608)  loss_giou: 0.1571 (0.1571)  loss_fgl: 1.0535 (1.0535)  loss_mal_aux_0: 0.6182 (0.6182)  loss_bbox_aux_0: 0.0819 (0.0819)  loss_giou_aux_0: 0.1774 (0.1774)  loss_fgl_aux_0: 1.1494 (1.1494)  loss_ddf_aux_0: 0.1565 (0.1565)  loss_mal_aux_1: 0.6226 (0.6226)  loss_bbox_aux_1: 0.0606 (0.0606)  loss_giou_aux_1: 0.1529 (0.1529)  loss_fgl_aux_1: 1.0808 (1.0808)  loss_ddf_aux_1: 0.0408 (0.0408)  loss_mal_aux_2: 0.4316 (0.4316)  loss_bbox_aux_2: 0.0598 (0.0598)  loss_giou_aux_2: 0.1574 (0.1574)  loss_fgl_aux_2: 1.0545 (1.0545)  loss_ddf_aux_2: 0.0073 (0.0073)  loss_mal_aux_3: 0.3918 (0.3918)  loss_bbox_aux_3: 0.0614 (0.0614)  loss_giou_aux_3: 0.1590 (0.1590)  loss_fgl_aux_3: 1.0547 (1.0547)  loss_ddf_aux_3: 0.0013 (0.0013)  loss_mal_aux_4: 0.3735 (0.3735)  loss_bbox_aux_4: 0.0609 (0.0609)  loss_giou_aux_4: 0.1573 (0.1573)  loss_fgl_aux_4: 1.0527 (1.0527)  loss_ddf_aux_4: 0.0000 (0.0000)  loss_mal_pre: 0.6172 (0.6172)  loss_bbox_pre: 0.0816 (0.0816)  loss_giou_pre: 0.1770 (0.1770)  loss_mal_enc_0: 1.1426 (1.1426)  loss_bbox_enc_0: 0.0967 (0.0967)  loss_giou_enc_0: 0.2347 (0.2347)  loss_mal_dn_0: 0.7285 (0.7285)  loss_bbox_dn_0: 0.1531 (0.1531)  loss_giou_dn_0: 0.3456 (0.3456)  loss_fgl_dn_0: 1.2929 (1.2929)  loss_ddf_dn_0: 0.7152 (0.7152)  loss_mal_dn_1: 0.5537 (0.5537)  loss_bbox_dn_1: 0.0811 (0.0811)  loss_giou_dn_1: 0.1980 (0.1980)  loss_fgl_dn_1: 1.0906 (1.0906)  loss_ddf_dn_1: 0.1619 (0.1619)  loss_mal_dn_2: 0.4500 (0.4500)  loss_bbox_dn_2: 0.0652 (0.0652)  loss_giou_dn_2: 0.1675 (0.1675)  loss_fgl_dn_2: 1.0472 (1.0472)  loss_ddf_dn_2: 0.0435 (0.0435)  loss_mal_dn_3: 0.4060 (0.4060)  loss_bbox_dn_3: 0.0661 (0.0661)  loss_giou_dn_3: 0.1670 (0.1670)  loss_fgl_dn_3: 1.0437 (1.0437)  loss_ddf_dn_3: 0.0083 (0.0083)  loss_mal_dn_4: 0.3936 (0.3936)  loss_bbox_dn_4: 0.0670 (0.0670)  loss_giou_dn_4: 0.1689 (0.1689)  loss_fgl_dn_4: 1.0448 (1.0448)  loss_ddf_dn_4: 0.0009 (0.0009)  loss_mal_dn_5: 0.3970 (0.3970)  loss_bbox_dn_5: 0.0672 (0.0672)  loss_giou_dn_5: 0.1696 (0.1696)  loss_fgl_dn_5: 1.0460 (1.0460)  loss_mal_dn_pre: 0.7280 (0.7280)  loss_bbox_dn_pre: 0.1560 (0.1560)  loss_giou_dn_pre: 0.3500 (0.3500)  time: 1.8959  data: 0.5967  max mem: 13413\nEpoch: [45]  [100/251]  eta: 0:03:01  lr: 0.000001  loss: 27.2441 (28.4751)  loss_mal: 0.3689 (0.4071)  loss_bbox: 0.0549 (0.0785)  loss_giou: 0.1649 (0.1737)  loss_fgl: 1.0597 (1.0897)  loss_mal_aux_0: 0.7998 (0.8319)  loss_bbox_aux_0: 0.0812 (0.1081)  loss_giou_aux_0: 0.2119 (0.2314)  loss_fgl_aux_0: 1.1743 (1.1986)  loss_ddf_aux_0: 0.1664 (0.1810)  loss_mal_aux_1: 0.4797 (0.5767)  loss_bbox_aux_1: 0.0601 (0.0883)  loss_giou_aux_1: 0.1671 (0.1847)  loss_fgl_aux_1: 1.0790 (1.1121)  loss_ddf_aux_1: 0.0418 (0.0460)  loss_mal_aux_2: 0.4075 (0.4631)  loss_bbox_aux_2: 0.0538 (0.0818)  loss_giou_aux_2: 0.1618 (0.1757)  loss_fgl_aux_2: 1.0648 (1.0948)  loss_ddf_aux_2: 0.0069 (0.0076)  loss_mal_aux_3: 0.3840 (0.4286)  loss_bbox_aux_3: 0.0538 (0.0797)  loss_giou_aux_3: 0.1640 (0.1742)  loss_fgl_aux_3: 1.0640 (1.0911)  loss_ddf_aux_3: 0.0013 (0.0014)  loss_mal_aux_4: 0.3779 (0.4128)  loss_bbox_aux_4: 0.0545 (0.0788)  loss_giou_aux_4: 0.1639 (0.1737)  loss_fgl_aux_4: 1.0619 (1.0901)  loss_ddf_aux_4: 0.0003 (0.0002)  loss_mal_pre: 0.8008 (0.8353)  loss_bbox_pre: 0.0820 (0.1085)  loss_giou_pre: 0.2112 (0.2312)  loss_mal_enc_0: 0.9990 (1.0095)  loss_bbox_enc_0: 0.1524 (0.1938)  loss_giou_enc_0: 0.3672 (0.3773)  loss_mal_dn_0: 0.7158 (0.7169)  loss_bbox_dn_0: 0.1732 (0.1962)  loss_giou_dn_0: 0.3753 (0.3868)  loss_fgl_dn_0: 1.2962 (1.3146)  loss_ddf_dn_0: 0.7917 (0.8480)  loss_mal_dn_1: 0.5283 (0.5447)  loss_bbox_dn_1: 0.0834 (0.1107)  loss_giou_dn_1: 0.2044 (0.2259)  loss_fgl_dn_1: 1.0953 (1.1244)  loss_ddf_dn_1: 0.1944 (0.2046)  loss_mal_dn_2: 0.4326 (0.4497)  loss_bbox_dn_2: 0.0682 (0.0904)  loss_giou_dn_2: 0.1796 (0.1914)  loss_fgl_dn_2: 1.0555 (1.0767)  loss_ddf_dn_2: 0.0516 (0.0540)  loss_mal_dn_3: 0.3950 (0.4173)  loss_bbox_dn_3: 0.0615 (0.0842)  loss_giou_dn_3: 0.1680 (0.1816)  loss_fgl_dn_3: 1.0486 (1.0664)  loss_ddf_dn_3: 0.0091 (0.0098)  loss_mal_dn_4: 0.3875 (0.4086)  loss_bbox_dn_4: 0.0584 (0.0824)  loss_giou_dn_4: 0.1638 (0.1787)  loss_fgl_dn_4: 1.0443 (1.0638)  loss_ddf_dn_4: 0.0009 (0.0009)  loss_mal_dn_5: 0.3848 (0.4068)  loss_bbox_dn_5: 0.0580 (0.0820)  loss_giou_dn_5: 0.1627 (0.1781)  loss_fgl_dn_5: 1.0437 (1.0629)  loss_mal_dn_pre: 0.7178 (0.7174)  loss_bbox_dn_pre: 0.1752 (0.1968)  loss_giou_dn_pre: 0.3748 (0.3857)  time: 1.1859  data: 0.0111  max mem: 13413\nEpoch: [45]  [200/251]  eta: 0:01:00  lr: 0.000001  loss: 27.2820 (28.5662)  loss_mal: 0.3726 (0.4178)  loss_bbox: 0.0617 (0.0770)  loss_giou: 0.1506 (0.1716)  loss_fgl: 1.0626 (1.0915)  loss_mal_aux_0: 0.7847 (0.8201)  loss_bbox_aux_0: 0.1009 (0.1072)  loss_giou_aux_0: 0.2099 (0.2309)  loss_fgl_aux_0: 1.1763 (1.2017)  loss_ddf_aux_0: 0.1860 (0.1903)  loss_mal_aux_1: 0.5107 (0.5814)  loss_bbox_aux_1: 0.0722 (0.0857)  loss_giou_aux_1: 0.1642 (0.1829)  loss_fgl_aux_1: 1.0864 (1.1136)  loss_ddf_aux_1: 0.0478 (0.0488)  loss_mal_aux_2: 0.4441 (0.4760)  loss_bbox_aux_2: 0.0640 (0.0797)  loss_giou_aux_2: 0.1527 (0.1740)  loss_fgl_aux_2: 1.0669 (1.0962)  loss_ddf_aux_2: 0.0082 (0.0082)  loss_mal_aux_3: 0.4084 (0.4370)  loss_bbox_aux_3: 0.0609 (0.0778)  loss_giou_aux_3: 0.1512 (0.1721)  loss_fgl_aux_3: 1.0618 (1.0928)  loss_ddf_aux_3: 0.0014 (0.0015)  loss_mal_aux_4: 0.3984 (0.4221)  loss_bbox_aux_4: 0.0615 (0.0772)  loss_giou_aux_4: 0.1506 (0.1716)  loss_fgl_aux_4: 1.0613 (1.0918)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.7847 (0.8228)  loss_bbox_pre: 0.1000 (0.1073)  loss_giou_pre: 0.2098 (0.2306)  loss_mal_enc_0: 0.9556 (1.0057)  loss_bbox_enc_0: 0.1696 (0.1914)  loss_giou_enc_0: 0.3340 (0.3756)  loss_mal_dn_0: 0.7358 (0.7189)  loss_bbox_dn_0: 0.1708 (0.1987)  loss_giou_dn_0: 0.3769 (0.3851)  loss_fgl_dn_0: 1.3216 (1.3158)  loss_ddf_dn_0: 0.8984 (0.8839)  loss_mal_dn_1: 0.5425 (0.5490)  loss_bbox_dn_1: 0.0925 (0.1113)  loss_giou_dn_1: 0.2026 (0.2234)  loss_fgl_dn_1: 1.1135 (1.1260)  loss_ddf_dn_1: 0.2292 (0.2141)  loss_mal_dn_2: 0.4500 (0.4530)  loss_bbox_dn_2: 0.0804 (0.0906)  loss_giou_dn_2: 0.1720 (0.1892)  loss_fgl_dn_2: 1.0487 (1.0792)  loss_ddf_dn_2: 0.0626 (0.0574)  loss_mal_dn_3: 0.4148 (0.4190)  loss_bbox_dn_3: 0.0680 (0.0844)  loss_giou_dn_3: 0.1607 (0.1799)  loss_fgl_dn_3: 1.0318 (1.0695)  loss_ddf_dn_3: 0.0125 (0.0108)  loss_mal_dn_4: 0.4031 (0.4105)  loss_bbox_dn_4: 0.0632 (0.0827)  loss_giou_dn_4: 0.1592 (0.1772)  loss_fgl_dn_4: 1.0271 (1.0671)  loss_ddf_dn_4: 0.0010 (0.0010)  loss_mal_dn_5: 0.3977 (0.4083)  loss_bbox_dn_5: 0.0637 (0.0823)  loss_giou_dn_5: 0.1586 (0.1766)  loss_fgl_dn_5: 1.0258 (1.0664)  loss_mal_dn_pre: 0.7329 (0.7193)  loss_bbox_dn_pre: 0.1723 (0.1996)  loss_giou_dn_pre: 0.3787 (0.3840)  time: 1.1911  data: 0.0119  max mem: 13413\nEpoch: [45]  [250/251]  eta: 0:00:01  lr: 0.000001  loss: 27.0718 (28.4036)  loss_mal: 0.3513 (0.4143)  loss_bbox: 0.0588 (0.0753)  loss_giou: 0.1484 (0.1711)  loss_fgl: 1.0390 (1.0881)  loss_mal_aux_0: 0.7480 (0.8081)  loss_bbox_aux_0: 0.0848 (0.1049)  loss_giou_aux_0: 0.2072 (0.2301)  loss_fgl_aux_0: 1.1835 (1.2005)  loss_ddf_aux_0: 0.2064 (0.1926)  loss_mal_aux_1: 0.5718 (0.5775)  loss_bbox_aux_1: 0.0595 (0.0832)  loss_giou_aux_1: 0.1621 (0.1823)  loss_fgl_aux_1: 1.0683 (1.1106)  loss_ddf_aux_1: 0.0495 (0.0491)  loss_mal_aux_2: 0.4260 (0.4699)  loss_bbox_aux_2: 0.0604 (0.0777)  loss_giou_aux_2: 0.1514 (0.1735)  loss_fgl_aux_2: 1.0425 (1.0929)  loss_ddf_aux_2: 0.0068 (0.0082)  loss_mal_aux_3: 0.3611 (0.4325)  loss_bbox_aux_3: 0.0601 (0.0760)  loss_giou_aux_3: 0.1482 (0.1717)  loss_fgl_aux_3: 1.0376 (1.0894)  loss_ddf_aux_3: 0.0012 (0.0015)  loss_mal_aux_4: 0.3530 (0.4182)  loss_bbox_aux_4: 0.0592 (0.0754)  loss_giou_aux_4: 0.1490 (0.1712)  loss_fgl_aux_4: 1.0372 (1.0884)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.7480 (0.8106)  loss_bbox_pre: 0.0830 (0.1048)  loss_giou_pre: 0.2092 (0.2298)  loss_mal_enc_0: 0.9062 (0.9885)  loss_bbox_enc_0: 0.1422 (0.1849)  loss_giou_enc_0: 0.3423 (0.3701)  loss_mal_dn_0: 0.6919 (0.7163)  loss_bbox_dn_0: 0.1463 (0.1950)  loss_giou_dn_0: 0.3596 (0.3833)  loss_fgl_dn_0: 1.3075 (1.3150)  loss_ddf_dn_0: 0.8629 (0.8831)  loss_mal_dn_1: 0.5366 (0.5464)  loss_bbox_dn_1: 0.0766 (0.1086)  loss_giou_dn_1: 0.2003 (0.2222)  loss_fgl_dn_1: 1.1065 (1.1239)  loss_ddf_dn_1: 0.1910 (0.2129)  loss_mal_dn_2: 0.4373 (0.4517)  loss_bbox_dn_2: 0.0643 (0.0883)  loss_giou_dn_2: 0.1668 (0.1884)  loss_fgl_dn_2: 1.0483 (1.0769)  loss_ddf_dn_2: 0.0540 (0.0570)  loss_mal_dn_3: 0.4041 (0.4180)  loss_bbox_dn_3: 0.0624 (0.0823)  loss_giou_dn_3: 0.1562 (0.1791)  loss_fgl_dn_3: 1.0378 (1.0672)  loss_ddf_dn_3: 0.0097 (0.0107)  loss_mal_dn_4: 0.3899 (0.4094)  loss_bbox_dn_4: 0.0614 (0.0806)  loss_giou_dn_4: 0.1534 (0.1764)  loss_fgl_dn_4: 1.0368 (1.0647)  loss_ddf_dn_4: 0.0009 (0.0010)  loss_mal_dn_5: 0.3877 (0.4074)  loss_bbox_dn_5: 0.0605 (0.0803)  loss_giou_dn_5: 0.1524 (0.1758)  loss_fgl_dn_5: 1.0373 (1.0640)  loss_mal_dn_pre: 0.6934 (0.7167)  loss_bbox_dn_pre: 0.1472 (0.1958)  loss_giou_dn_pre: 0.3595 (0.3820)  time: 1.1910  data: 0.0106  max mem: 13413\nEpoch: [45] Total time: 0:04:59 (1.1924 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7987  data: 0.5060  max mem: 13413\nTest:  [10/25]  eta: 0:00:06    time: 0.4009  data: 0.0643  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3335  data: 0.0207  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2943  data: 0.0206  max mem: 13413\nTest: Total time: 0:00:08 (0.3422 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.539\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.339\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.411\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.358\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.432\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.574\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.680\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.787\nbest_stat: {'epoch': 38, 'coco_eval_bbox': 0.3374040358831138}\nLoad last_epoch\nLoad model.state_dict\nLoad criterion.state_dict\nLoad postprocessor.state_dict\nLoad ema.state_dict\nLoad scaler.state_dict\nLoad optimizer.state_dict\nLoad lr_warmup_scheduler.state_dict\nRefresh EMA at epoch 45 with decay 0.9994000000000001\nEpoch: [46]  [  0/251]  eta: 0:08:22  lr: 0.000001  loss: 29.3113 (29.3113)  loss_mal: 0.4058 (0.4058)  loss_bbox: 0.0670 (0.0670)  loss_giou: 0.2206 (0.2206)  loss_fgl: 1.1071 (1.1071)  loss_mal_aux_0: 0.8745 (0.8745)  loss_bbox_aux_0: 0.0876 (0.0876)  loss_giou_aux_0: 0.2372 (0.2372)  loss_fgl_aux_0: 1.1776 (1.1776)  loss_ddf_aux_0: 0.1045 (0.1045)  loss_mal_aux_1: 0.6982 (0.6982)  loss_bbox_aux_1: 0.0727 (0.0727)  loss_giou_aux_1: 0.2254 (0.2254)  loss_fgl_aux_1: 1.1294 (1.1294)  loss_ddf_aux_1: 0.0318 (0.0318)  loss_mal_aux_2: 0.4417 (0.4417)  loss_bbox_aux_2: 0.0696 (0.0696)  loss_giou_aux_2: 0.2209 (0.2209)  loss_fgl_aux_2: 1.1110 (1.1110)  loss_ddf_aux_2: 0.0069 (0.0069)  loss_mal_aux_3: 0.4041 (0.4041)  loss_bbox_aux_3: 0.0670 (0.0670)  loss_giou_aux_3: 0.2182 (0.2182)  loss_fgl_aux_3: 1.1068 (1.1068)  loss_ddf_aux_3: 0.0012 (0.0012)  loss_mal_aux_4: 0.4050 (0.4050)  loss_bbox_aux_4: 0.0667 (0.0667)  loss_giou_aux_4: 0.2201 (0.2201)  loss_fgl_aux_4: 1.1067 (1.1067)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8745 (0.8745)  loss_bbox_pre: 0.0871 (0.0871)  loss_giou_pre: 0.2365 (0.2365)  loss_mal_enc_0: 1.0518 (1.0518)  loss_bbox_enc_0: 0.1504 (0.1504)  loss_giou_enc_0: 0.4376 (0.4376)  loss_mal_dn_0: 0.6982 (0.6982)  loss_bbox_dn_0: 0.2221 (0.2221)  loss_giou_dn_0: 0.3528 (0.3528)  loss_fgl_dn_0: 1.2968 (1.2968)  loss_ddf_dn_0: 1.0006 (1.0006)  loss_mal_dn_1: 0.5503 (0.5503)  loss_bbox_dn_1: 0.1049 (0.1049)  loss_giou_dn_1: 0.2257 (0.2257)  loss_fgl_dn_1: 1.1358 (1.1358)  loss_ddf_dn_1: 0.2420 (0.2420)  loss_mal_dn_2: 0.5049 (0.5049)  loss_bbox_dn_2: 0.0855 (0.0855)  loss_giou_dn_2: 0.2154 (0.2154)  loss_fgl_dn_2: 1.0973 (1.0973)  loss_ddf_dn_2: 0.0672 (0.0672)  loss_mal_dn_3: 0.4651 (0.4651)  loss_bbox_dn_3: 0.0753 (0.0753)  loss_giou_dn_3: 0.2085 (0.2085)  loss_fgl_dn_3: 1.0863 (1.0863)  loss_ddf_dn_3: 0.0111 (0.0111)  loss_mal_dn_4: 0.4609 (0.4609)  loss_bbox_dn_4: 0.0731 (0.0731)  loss_giou_dn_4: 0.2080 (0.2080)  loss_fgl_dn_4: 1.0836 (1.0836)  loss_ddf_dn_4: 0.0009 (0.0009)  loss_mal_dn_5: 0.4597 (0.4597)  loss_bbox_dn_5: 0.0728 (0.0728)  loss_giou_dn_5: 0.2078 (0.2078)  loss_fgl_dn_5: 1.0832 (1.0832)  loss_mal_dn_pre: 0.6987 (0.6987)  loss_bbox_dn_pre: 0.2299 (0.2299)  loss_giou_dn_pre: 0.3637 (0.3637)  time: 2.0009  data: 0.6863  max mem: 13413\nEpoch: [46]  [100/251]  eta: 0:03:01  lr: 0.000001  loss: 29.4181 (29.6437)  loss_mal: 0.4241 (0.4607)  loss_bbox: 0.0757 (0.0812)  loss_giou: 0.1976 (0.1881)  loss_fgl: 1.1100 (1.1166)  loss_mal_aux_0: 0.8203 (0.8806)  loss_bbox_aux_0: 0.1177 (0.1110)  loss_giou_aux_0: 0.2574 (0.2509)  loss_fgl_aux_0: 1.2354 (1.2237)  loss_ddf_aux_0: 0.1924 (0.1912)  loss_mal_aux_1: 0.6045 (0.6143)  loss_bbox_aux_1: 0.0949 (0.0894)  loss_giou_aux_1: 0.2071 (0.2014)  loss_fgl_aux_1: 1.1478 (1.1416)  loss_ddf_aux_1: 0.0503 (0.0510)  loss_mal_aux_2: 0.4897 (0.5090)  loss_bbox_aux_2: 0.0836 (0.0840)  loss_giou_aux_2: 0.1995 (0.1918)  loss_fgl_aux_2: 1.1194 (1.1231)  loss_ddf_aux_2: 0.0081 (0.0092)  loss_mal_aux_3: 0.4277 (0.4744)  loss_bbox_aux_3: 0.0774 (0.0822)  loss_giou_aux_3: 0.1958 (0.1892)  loss_fgl_aux_3: 1.1088 (1.1186)  loss_ddf_aux_3: 0.0017 (0.0017)  loss_mal_aux_4: 0.4294 (0.4635)  loss_bbox_aux_4: 0.0755 (0.0815)  loss_giou_aux_4: 0.1963 (0.1885)  loss_fgl_aux_4: 1.1092 (1.1170)  loss_ddf_aux_4: 0.0002 (0.0001)  loss_mal_pre: 0.8213 (0.8853)  loss_bbox_pre: 0.1174 (0.1106)  loss_giou_pre: 0.2557 (0.2505)  loss_mal_enc_0: 0.9712 (1.0230)  loss_bbox_enc_0: 0.1895 (0.1939)  loss_giou_enc_0: 0.4028 (0.4121)  loss_mal_dn_0: 0.7520 (0.7305)  loss_bbox_dn_0: 0.1937 (0.1966)  loss_giou_dn_0: 0.4096 (0.3877)  loss_fgl_dn_0: 1.3315 (1.3127)  loss_ddf_dn_0: 0.9472 (0.9633)  loss_mal_dn_1: 0.5708 (0.5638)  loss_bbox_dn_1: 0.1164 (0.1101)  loss_giou_dn_1: 0.2393 (0.2314)  loss_fgl_dn_1: 1.1486 (1.1434)  loss_ddf_dn_1: 0.2408 (0.2375)  loss_mal_dn_2: 0.4841 (0.4735)  loss_bbox_dn_2: 0.1025 (0.0908)  loss_giou_dn_2: 0.2079 (0.1996)  loss_fgl_dn_2: 1.0919 (1.1024)  loss_ddf_dn_2: 0.0641 (0.0655)  loss_mal_dn_3: 0.4490 (0.4397)  loss_bbox_dn_3: 0.0875 (0.0858)  loss_giou_dn_3: 0.1969 (0.1912)  loss_fgl_dn_3: 1.0812 (1.0938)  loss_ddf_dn_3: 0.0130 (0.0123)  loss_mal_dn_4: 0.4336 (0.4300)  loss_bbox_dn_4: 0.0800 (0.0841)  loss_giou_dn_4: 0.1926 (0.1885)  loss_fgl_dn_4: 1.0832 (1.0916)  loss_ddf_dn_4: 0.0012 (0.0012)  loss_mal_dn_5: 0.4290 (0.4276)  loss_bbox_dn_5: 0.0780 (0.0837)  loss_giou_dn_5: 0.1910 (0.1879)  loss_fgl_dn_5: 1.0833 (1.0909)  loss_mal_dn_pre: 0.7539 (0.7306)  loss_bbox_dn_pre: 0.1965 (0.1978)  loss_giou_dn_pre: 0.4137 (0.3871)  time: 1.1889  data: 0.0113  max mem: 13413\nEpoch: [46]  [200/251]  eta: 0:01:00  lr: 0.000001  loss: 29.8885 (29.9014)  loss_mal: 0.4368 (0.4615)  loss_bbox: 0.0803 (0.0828)  loss_giou: 0.1806 (0.1906)  loss_fgl: 1.1176 (1.1202)  loss_mal_aux_0: 0.8931 (0.8812)  loss_bbox_aux_0: 0.1032 (0.1151)  loss_giou_aux_0: 0.2566 (0.2569)  loss_fgl_aux_0: 1.2322 (1.2316)  loss_ddf_aux_0: 0.1917 (0.1974)  loss_mal_aux_1: 0.6221 (0.6261)  loss_bbox_aux_1: 0.0836 (0.0908)  loss_giou_aux_1: 0.2038 (0.2038)  loss_fgl_aux_1: 1.1451 (1.1451)  loss_ddf_aux_1: 0.0481 (0.0523)  loss_mal_aux_2: 0.5063 (0.5174)  loss_bbox_aux_2: 0.0823 (0.0850)  loss_giou_aux_2: 0.1782 (0.1936)  loss_fgl_aux_2: 1.1211 (1.1260)  loss_ddf_aux_2: 0.0079 (0.0093)  loss_mal_aux_3: 0.4636 (0.4791)  loss_bbox_aux_3: 0.0819 (0.0835)  loss_giou_aux_3: 0.1808 (0.1914)  loss_fgl_aux_3: 1.1157 (1.1217)  loss_ddf_aux_3: 0.0016 (0.0017)  loss_mal_aux_4: 0.4417 (0.4658)  loss_bbox_aux_4: 0.0808 (0.0829)  loss_giou_aux_4: 0.1807 (0.1908)  loss_fgl_aux_4: 1.1168 (1.1204)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.8931 (0.8839)  loss_bbox_pre: 0.1020 (0.1150)  loss_giou_pre: 0.2580 (0.2565)  loss_mal_enc_0: 1.0430 (1.0272)  loss_bbox_enc_0: 0.1971 (0.2041)  loss_giou_enc_0: 0.3947 (0.4189)  loss_mal_dn_0: 0.7402 (0.7342)  loss_bbox_dn_0: 0.1669 (0.2048)  loss_giou_dn_0: 0.4046 (0.3986)  loss_fgl_dn_0: 1.3057 (1.3151)  loss_ddf_dn_0: 0.9600 (0.9467)  loss_mal_dn_1: 0.6206 (0.5727)  loss_bbox_dn_1: 0.0984 (0.1163)  loss_giou_dn_1: 0.2350 (0.2392)  loss_fgl_dn_1: 1.1437 (1.1467)  loss_ddf_dn_1: 0.2325 (0.2347)  loss_mal_dn_2: 0.5112 (0.4816)  loss_bbox_dn_2: 0.0848 (0.0960)  loss_giou_dn_2: 0.2077 (0.2060)  loss_fgl_dn_2: 1.1054 (1.1051)  loss_ddf_dn_2: 0.0624 (0.0646)  loss_mal_dn_3: 0.4741 (0.4481)  loss_bbox_dn_3: 0.0814 (0.0906)  loss_giou_dn_3: 0.1993 (0.1971)  loss_fgl_dn_3: 1.0933 (1.0961)  loss_ddf_dn_3: 0.0110 (0.0121)  loss_mal_dn_4: 0.4565 (0.4380)  loss_bbox_dn_4: 0.0802 (0.0890)  loss_giou_dn_4: 0.1976 (0.1943)  loss_fgl_dn_4: 1.0845 (1.0940)  loss_ddf_dn_4: 0.0011 (0.0011)  loss_mal_dn_5: 0.4517 (0.4350)  loss_bbox_dn_5: 0.0799 (0.0887)  loss_giou_dn_5: 0.1963 (0.1937)  loss_fgl_dn_5: 1.0819 (1.0936)  loss_mal_dn_pre: 0.7427 (0.7344)  loss_bbox_dn_pre: 0.1699 (0.2057)  loss_giou_dn_pre: 0.4011 (0.3975)  time: 1.1851  data: 0.0118  max mem: 13413\nEpoch: [46]  [250/251]  eta: 0:00:01  lr: 0.000001  loss: 28.6588 (29.8265)  loss_mal: 0.3857 (0.4598)  loss_bbox: 0.0697 (0.0820)  loss_giou: 0.1819 (0.1906)  loss_fgl: 1.1068 (1.1218)  loss_mal_aux_0: 0.8345 (0.8778)  loss_bbox_aux_0: 0.0815 (0.1130)  loss_giou_aux_0: 0.2447 (0.2546)  loss_fgl_aux_0: 1.2147 (1.2289)  loss_ddf_aux_0: 0.1734 (0.1948)  loss_mal_aux_1: 0.5146 (0.6195)  loss_bbox_aux_1: 0.0714 (0.0891)  loss_giou_aux_1: 0.1898 (0.2023)  loss_fgl_aux_1: 1.1234 (1.1441)  loss_ddf_aux_1: 0.0455 (0.0513)  loss_mal_aux_2: 0.4019 (0.5130)  loss_bbox_aux_2: 0.0692 (0.0837)  loss_giou_aux_2: 0.1767 (0.1929)  loss_fgl_aux_2: 1.1063 (1.1263)  loss_ddf_aux_2: 0.0068 (0.0090)  loss_mal_aux_3: 0.3909 (0.4763)  loss_bbox_aux_3: 0.0690 (0.0825)  loss_giou_aux_3: 0.1819 (0.1912)  loss_fgl_aux_3: 1.1042 (1.1228)  loss_ddf_aux_3: 0.0014 (0.0017)  loss_mal_aux_4: 0.3843 (0.4629)  loss_bbox_aux_4: 0.0697 (0.0822)  loss_giou_aux_4: 0.1816 (0.1908)  loss_fgl_aux_4: 1.1048 (1.1219)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.8350 (0.8801)  loss_bbox_pre: 0.0816 (0.1128)  loss_giou_pre: 0.2449 (0.2542)  loss_mal_enc_0: 1.0020 (1.0275)  loss_bbox_enc_0: 0.1666 (0.1986)  loss_giou_enc_0: 0.3776 (0.4155)  loss_mal_dn_0: 0.7031 (0.7313)  loss_bbox_dn_0: 0.1532 (0.2024)  loss_giou_dn_0: 0.3655 (0.3985)  loss_fgl_dn_0: 1.3078 (1.3162)  loss_ddf_dn_0: 1.0070 (0.9375)  loss_mal_dn_1: 0.5518 (0.5707)  loss_bbox_dn_1: 0.0847 (0.1155)  loss_giou_dn_1: 0.2175 (0.2392)  loss_fgl_dn_1: 1.1298 (1.1480)  loss_ddf_dn_1: 0.2313 (0.2317)  loss_mal_dn_2: 0.4585 (0.4808)  loss_bbox_dn_2: 0.0725 (0.0957)  loss_giou_dn_2: 0.1912 (0.2061)  loss_fgl_dn_2: 1.0873 (1.1064)  loss_ddf_dn_2: 0.0620 (0.0633)  loss_mal_dn_3: 0.4360 (0.4481)  loss_bbox_dn_3: 0.0698 (0.0904)  loss_giou_dn_3: 0.1909 (0.1972)  loss_fgl_dn_3: 1.0793 (1.0973)  loss_ddf_dn_3: 0.0105 (0.0118)  loss_mal_dn_4: 0.4248 (0.4381)  loss_bbox_dn_4: 0.0689 (0.0887)  loss_giou_dn_4: 0.1902 (0.1945)  loss_fgl_dn_4: 1.0742 (1.0953)  loss_ddf_dn_4: 0.0010 (0.0011)  loss_mal_dn_5: 0.4229 (0.4357)  loss_bbox_dn_5: 0.0691 (0.0885)  loss_giou_dn_5: 0.1905 (0.1940)  loss_fgl_dn_5: 1.0728 (1.0948)  loss_mal_dn_pre: 0.7100 (0.7316)  loss_bbox_dn_pre: 0.1507 (0.2033)  loss_giou_dn_pre: 0.3650 (0.3972)  time: 1.1856  data: 0.0113  max mem: 13413\nEpoch: [46] Total time: 0:04:59 (1.1934 s / it)\nTest:  [ 0/25]  eta: 0:00:22    time: 0.8858  data: 0.5832  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3581  data: 0.0723  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3029  data: 0.0197  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2919  data: 0.0189  max mem: 13413\nTest: Total time: 0:00:08 (0.3214 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.539\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.341\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.415\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.358\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.461\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.576\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.673\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.780\nbest_stat: {'epoch': 38, 'coco_eval_bbox': 0.3374040358831138}\nEpoch: [47]  [  0/251]  eta: 0:07:47  lr: 0.000001  loss: 27.5046 (27.5046)  loss_mal: 0.7612 (0.7612)  loss_bbox: 0.0316 (0.0316)  loss_giou: 0.1117 (0.1117)  loss_fgl: 0.9962 (0.9962)  loss_mal_aux_0: 0.9146 (0.9146)  loss_bbox_aux_0: 0.0602 (0.0602)  loss_giou_aux_0: 0.2144 (0.2144)  loss_fgl_aux_0: 1.1952 (1.1952)  loss_ddf_aux_0: 0.2163 (0.2163)  loss_mal_aux_1: 0.9785 (0.9785)  loss_bbox_aux_1: 0.0364 (0.0364)  loss_giou_aux_1: 0.1381 (0.1381)  loss_fgl_aux_1: 1.0448 (1.0448)  loss_ddf_aux_1: 0.0540 (0.0540)  loss_mal_aux_2: 0.6431 (0.6431)  loss_bbox_aux_2: 0.0310 (0.0310)  loss_giou_aux_2: 0.1114 (0.1114)  loss_fgl_aux_2: 1.0012 (1.0012)  loss_ddf_aux_2: 0.0088 (0.0088)  loss_mal_aux_3: 0.7461 (0.7461)  loss_bbox_aux_3: 0.0310 (0.0310)  loss_giou_aux_3: 0.1106 (0.1106)  loss_fgl_aux_3: 0.9985 (0.9985)  loss_ddf_aux_3: 0.0015 (0.0015)  loss_mal_aux_4: 0.7314 (0.7314)  loss_bbox_aux_4: 0.0318 (0.0318)  loss_giou_aux_4: 0.1120 (0.1120)  loss_fgl_aux_4: 0.9971 (0.9971)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.9160 (0.9160)  loss_bbox_pre: 0.0594 (0.0594)  loss_giou_pre: 0.2125 (0.2125)  loss_mal_enc_0: 0.9727 (0.9727)  loss_bbox_enc_0: 0.1187 (0.1187)  loss_giou_enc_0: 0.3583 (0.3583)  loss_mal_dn_0: 0.6724 (0.6724)  loss_bbox_dn_0: 0.1152 (0.1152)  loss_giou_dn_0: 0.3237 (0.3237)  loss_fgl_dn_0: 1.2735 (1.2735)  loss_ddf_dn_0: 1.0635 (1.0635)  loss_mal_dn_1: 0.4443 (0.4443)  loss_bbox_dn_1: 0.0459 (0.0459)  loss_giou_dn_1: 0.1449 (0.1449)  loss_fgl_dn_1: 1.0597 (1.0597)  loss_ddf_dn_1: 0.2394 (0.2394)  loss_mal_dn_2: 0.3560 (0.3560)  loss_bbox_dn_2: 0.0367 (0.0367)  loss_giou_dn_2: 0.1165 (0.1165)  loss_fgl_dn_2: 1.0103 (1.0103)  loss_ddf_dn_2: 0.0660 (0.0660)  loss_mal_dn_3: 0.3374 (0.3374)  loss_bbox_dn_3: 0.0357 (0.0357)  loss_giou_dn_3: 0.1149 (0.1149)  loss_fgl_dn_3: 1.0026 (1.0026)  loss_ddf_dn_3: 0.0122 (0.0122)  loss_mal_dn_4: 0.3352 (0.3352)  loss_bbox_dn_4: 0.0356 (0.0356)  loss_giou_dn_4: 0.1158 (0.1158)  loss_fgl_dn_4: 1.0010 (1.0010)  loss_ddf_dn_4: 0.0012 (0.0012)  loss_mal_dn_5: 0.3318 (0.3318)  loss_bbox_dn_5: 0.0353 (0.0353)  loss_giou_dn_5: 0.1150 (0.1150)  loss_fgl_dn_5: 0.9997 (0.9997)  loss_mal_dn_pre: 0.6743 (0.6743)  loss_bbox_dn_pre: 0.1147 (0.1147)  loss_giou_dn_pre: 0.3277 (0.3277)  time: 1.8618  data: 0.5537  max mem: 13413\nEpoch: [47]  [100/251]  eta: 0:03:01  lr: 0.000001  loss: 26.2738 (28.3518)  loss_mal: 0.3098 (0.4129)  loss_bbox: 0.0550 (0.0719)  loss_giou: 0.1355 (0.1704)  loss_fgl: 1.0027 (1.0776)  loss_mal_aux_0: 0.8110 (0.8287)  loss_bbox_aux_0: 0.0865 (0.1030)  loss_giou_aux_0: 0.2008 (0.2351)  loss_fgl_aux_0: 1.1583 (1.2013)  loss_ddf_aux_0: 0.1914 (0.1983)  loss_mal_aux_1: 0.4907 (0.5752)  loss_bbox_aux_1: 0.0648 (0.0783)  loss_giou_aux_1: 0.1442 (0.1837)  loss_fgl_aux_1: 1.0446 (1.1034)  loss_ddf_aux_1: 0.0435 (0.0513)  loss_mal_aux_2: 0.3564 (0.4724)  loss_bbox_aux_2: 0.0585 (0.0734)  loss_giou_aux_2: 0.1365 (0.1727)  loss_fgl_aux_2: 1.0092 (1.0818)  loss_ddf_aux_2: 0.0063 (0.0084)  loss_mal_aux_3: 0.3269 (0.4288)  loss_bbox_aux_3: 0.0554 (0.0722)  loss_giou_aux_3: 0.1340 (0.1707)  loss_fgl_aux_3: 1.0044 (1.0792)  loss_ddf_aux_3: 0.0012 (0.0015)  loss_mal_aux_4: 0.3164 (0.4153)  loss_bbox_aux_4: 0.0550 (0.0719)  loss_giou_aux_4: 0.1360 (0.1704)  loss_fgl_aux_4: 1.0030 (1.0780)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8125 (0.8305)  loss_bbox_pre: 0.0866 (0.1026)  loss_giou_pre: 0.1996 (0.2343)  loss_mal_enc_0: 0.9644 (0.9919)  loss_bbox_enc_0: 0.1679 (0.1829)  loss_giou_enc_0: 0.3570 (0.3863)  loss_mal_dn_0: 0.7012 (0.7119)  loss_bbox_dn_0: 0.1723 (0.1889)  loss_giou_dn_0: 0.3434 (0.3790)  loss_fgl_dn_0: 1.2935 (1.3099)  loss_ddf_dn_0: 0.8617 (0.9191)  loss_mal_dn_1: 0.5015 (0.5395)  loss_bbox_dn_1: 0.0916 (0.1042)  loss_giou_dn_1: 0.1837 (0.2191)  loss_fgl_dn_1: 1.0897 (1.1202)  loss_ddf_dn_1: 0.1854 (0.2179)  loss_mal_dn_2: 0.4041 (0.4466)  loss_bbox_dn_2: 0.0731 (0.0850)  loss_giou_dn_2: 0.1510 (0.1868)  loss_fgl_dn_2: 1.0200 (1.0753)  loss_ddf_dn_2: 0.0499 (0.0568)  loss_mal_dn_3: 0.3757 (0.4142)  loss_bbox_dn_3: 0.0709 (0.0797)  loss_giou_dn_3: 0.1397 (0.1781)  loss_fgl_dn_3: 1.0112 (1.0674)  loss_ddf_dn_3: 0.0095 (0.0106)  loss_mal_dn_4: 0.3665 (0.4062)  loss_bbox_dn_4: 0.0680 (0.0782)  loss_giou_dn_4: 0.1375 (0.1755)  loss_fgl_dn_4: 1.0066 (1.0654)  loss_ddf_dn_4: 0.0008 (0.0010)  loss_mal_dn_5: 0.3643 (0.4034)  loss_bbox_dn_5: 0.0667 (0.0778)  loss_giou_dn_5: 0.1381 (0.1748)  loss_fgl_dn_5: 1.0066 (1.0649)  loss_mal_dn_pre: 0.7002 (0.7122)  loss_bbox_dn_pre: 0.1766 (0.1889)  loss_giou_dn_pre: 0.3451 (0.3771)  time: 1.2066  data: 0.0116  max mem: 13413\nEpoch: [47]  [200/251]  eta: 0:01:01  lr: 0.000001  loss: 26.4327 (27.9703)  loss_mal: 0.3394 (0.3959)  loss_bbox: 0.0595 (0.0677)  loss_giou: 0.1385 (0.1642)  loss_fgl: 1.0157 (1.0668)  loss_mal_aux_0: 0.7856 (0.8206)  loss_bbox_aux_0: 0.0823 (0.0980)  loss_giou_aux_0: 0.2109 (0.2286)  loss_fgl_aux_0: 1.1480 (1.1960)  loss_ddf_aux_0: 0.1923 (0.1988)  loss_mal_aux_1: 0.4880 (0.5626)  loss_bbox_aux_1: 0.0637 (0.0741)  loss_giou_aux_1: 0.1518 (0.1770)  loss_fgl_aux_1: 1.0509 (1.0956)  loss_ddf_aux_1: 0.0447 (0.0493)  loss_mal_aux_2: 0.3552 (0.4543)  loss_bbox_aux_2: 0.0594 (0.0694)  loss_giou_aux_2: 0.1387 (0.1671)  loss_fgl_aux_2: 1.0209 (1.0727)  loss_ddf_aux_2: 0.0067 (0.0080)  loss_mal_aux_3: 0.3381 (0.4124)  loss_bbox_aux_3: 0.0591 (0.0681)  loss_giou_aux_3: 0.1391 (0.1649)  loss_fgl_aux_3: 1.0182 (1.0687)  loss_ddf_aux_3: 0.0013 (0.0014)  loss_mal_aux_4: 0.3369 (0.3984)  loss_bbox_aux_4: 0.0595 (0.0678)  loss_giou_aux_4: 0.1383 (0.1644)  loss_fgl_aux_4: 1.0156 (1.0674)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.7837 (0.8220)  loss_bbox_pre: 0.0830 (0.0977)  loss_giou_pre: 0.2102 (0.2280)  loss_mal_enc_0: 0.9312 (0.9797)  loss_bbox_enc_0: 0.1507 (0.1770)  loss_giou_enc_0: 0.3388 (0.3827)  loss_mal_dn_0: 0.7056 (0.7099)  loss_bbox_dn_0: 0.1786 (0.1905)  loss_giou_dn_0: 0.3490 (0.3779)  loss_fgl_dn_0: 1.2907 (1.3095)  loss_ddf_dn_0: 0.8069 (0.8865)  loss_mal_dn_1: 0.4963 (0.5372)  loss_bbox_dn_1: 0.0838 (0.1036)  loss_giou_dn_1: 0.1926 (0.2166)  loss_fgl_dn_1: 1.0812 (1.1160)  loss_ddf_dn_1: 0.1809 (0.2098)  loss_mal_dn_2: 0.4285 (0.4432)  loss_bbox_dn_2: 0.0705 (0.0834)  loss_giou_dn_2: 0.1594 (0.1829)  loss_fgl_dn_2: 1.0187 (1.0684)  loss_ddf_dn_2: 0.0496 (0.0553)  loss_mal_dn_3: 0.3752 (0.4094)  loss_bbox_dn_3: 0.0604 (0.0775)  loss_giou_dn_3: 0.1456 (0.1733)  loss_fgl_dn_3: 1.0125 (1.0589)  loss_ddf_dn_3: 0.0086 (0.0103)  loss_mal_dn_4: 0.3657 (0.4011)  loss_bbox_dn_4: 0.0603 (0.0759)  loss_giou_dn_4: 0.1404 (0.1705)  loss_fgl_dn_4: 1.0125 (1.0564)  loss_ddf_dn_4: 0.0008 (0.0009)  loss_mal_dn_5: 0.3643 (0.3988)  loss_bbox_dn_5: 0.0608 (0.0755)  loss_giou_dn_5: 0.1422 (0.1698)  loss_fgl_dn_5: 1.0128 (1.0557)  loss_mal_dn_pre: 0.7070 (0.7104)  loss_bbox_dn_pre: 0.1776 (0.1912)  loss_giou_dn_pre: 0.3542 (0.3763)  time: 1.1847  data: 0.0126  max mem: 13413\nEpoch: [47]  [250/251]  eta: 0:00:01  lr: 0.000001  loss: 26.8421 (28.0424)  loss_mal: 0.4045 (0.4033)  loss_bbox: 0.0542 (0.0693)  loss_giou: 0.1494 (0.1646)  loss_fgl: 1.0466 (1.0728)  loss_mal_aux_0: 0.7715 (0.8185)  loss_bbox_aux_0: 0.0883 (0.0993)  loss_giou_aux_0: 0.1934 (0.2274)  loss_fgl_aux_0: 1.1695 (1.1978)  loss_ddf_aux_0: 0.1755 (0.1979)  loss_mal_aux_1: 0.5679 (0.5627)  loss_bbox_aux_1: 0.0583 (0.0760)  loss_giou_aux_1: 0.1736 (0.1772)  loss_fgl_aux_1: 1.0977 (1.0999)  loss_ddf_aux_1: 0.0455 (0.0491)  loss_mal_aux_2: 0.4329 (0.4558)  loss_bbox_aux_2: 0.0545 (0.0710)  loss_giou_aux_2: 0.1584 (0.1677)  loss_fgl_aux_2: 1.0572 (1.0786)  loss_ddf_aux_2: 0.0075 (0.0080)  loss_mal_aux_3: 0.4109 (0.4178)  loss_bbox_aux_3: 0.0539 (0.0698)  loss_giou_aux_3: 0.1599 (0.1654)  loss_fgl_aux_3: 1.0469 (1.0747)  loss_ddf_aux_3: 0.0013 (0.0014)  loss_mal_aux_4: 0.4126 (0.4050)  loss_bbox_aux_4: 0.0539 (0.0694)  loss_giou_aux_4: 0.1531 (0.1648)  loss_fgl_aux_4: 1.0459 (1.0734)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.7734 (0.8198)  loss_bbox_pre: 0.0872 (0.0991)  loss_giou_pre: 0.1917 (0.2268)  loss_mal_enc_0: 0.9375 (0.9808)  loss_bbox_enc_0: 0.1525 (0.1788)  loss_giou_enc_0: 0.3769 (0.3796)  loss_mal_dn_0: 0.6973 (0.7107)  loss_bbox_dn_0: 0.1632 (0.1919)  loss_giou_dn_0: 0.3621 (0.3783)  loss_fgl_dn_0: 1.2964 (1.3097)  loss_ddf_dn_0: 0.8162 (0.8775)  loss_mal_dn_1: 0.5264 (0.5374)  loss_bbox_dn_1: 0.0885 (0.1053)  loss_giou_dn_1: 0.1979 (0.2168)  loss_fgl_dn_1: 1.0968 (1.1171)  loss_ddf_dn_1: 0.1909 (0.2081)  loss_mal_dn_2: 0.4297 (0.4434)  loss_bbox_dn_2: 0.0761 (0.0850)  loss_giou_dn_2: 0.1637 (0.1830)  loss_fgl_dn_2: 1.0506 (1.0698)  loss_ddf_dn_2: 0.0517 (0.0553)  loss_mal_dn_3: 0.3926 (0.4101)  loss_bbox_dn_3: 0.0648 (0.0791)  loss_giou_dn_3: 0.1567 (0.1734)  loss_fgl_dn_3: 1.0429 (1.0605)  loss_ddf_dn_3: 0.0103 (0.0103)  loss_mal_dn_4: 0.3889 (0.4025)  loss_bbox_dn_4: 0.0627 (0.0775)  loss_giou_dn_4: 0.1534 (0.1707)  loss_fgl_dn_4: 1.0452 (1.0582)  loss_ddf_dn_4: 0.0009 (0.0009)  loss_mal_dn_5: 0.3884 (0.4010)  loss_bbox_dn_5: 0.0635 (0.0771)  loss_giou_dn_5: 0.1543 (0.1701)  loss_fgl_dn_5: 1.0454 (1.0576)  loss_mal_dn_pre: 0.6992 (0.7112)  loss_bbox_dn_pre: 0.1655 (0.1926)  loss_giou_dn_pre: 0.3642 (0.3765)  time: 1.1807  data: 0.0116  max mem: 13413\nEpoch: [47] Total time: 0:05:00 (1.1964 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7881  data: 0.4875  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3496  data: 0.0635  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3027  data: 0.0191  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2914  data: 0.0184  max mem: 13413\nTest: Total time: 0:00:07 (0.3163 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.335\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.539\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.339\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.329\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.359\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.460\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.576\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.686\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.679\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.787\nbest_stat: {'epoch': 38, 'coco_eval_bbox': 0.3374040358831138}\nEpoch: [48]  [  0/251]  eta: 0:07:57  lr: 0.000001  loss: 26.1208 (26.1208)  loss_mal: 0.3315 (0.3315)  loss_bbox: 0.0588 (0.0588)  loss_giou: 0.1278 (0.1278)  loss_fgl: 0.9724 (0.9724)  loss_mal_aux_0: 0.7661 (0.7661)  loss_bbox_aux_0: 0.0850 (0.0850)  loss_giou_aux_0: 0.1839 (0.1839)  loss_fgl_aux_0: 1.1625 (1.1625)  loss_ddf_aux_0: 0.1582 (0.1582)  loss_mal_aux_1: 0.5190 (0.5190)  loss_bbox_aux_1: 0.0632 (0.0632)  loss_giou_aux_1: 0.1370 (0.1370)  loss_fgl_aux_1: 1.0434 (1.0434)  loss_ddf_aux_1: 0.0326 (0.0326)  loss_mal_aux_2: 0.3923 (0.3923)  loss_bbox_aux_2: 0.0607 (0.0607)  loss_giou_aux_2: 0.1344 (0.1344)  loss_fgl_aux_2: 1.0092 (1.0092)  loss_ddf_aux_2: 0.0059 (0.0059)  loss_mal_aux_3: 0.3362 (0.3362)  loss_bbox_aux_3: 0.0591 (0.0591)  loss_giou_aux_3: 0.1296 (0.1296)  loss_fgl_aux_3: 0.9851 (0.9851)  loss_ddf_aux_3: 0.0007 (0.0007)  loss_mal_aux_4: 0.3315 (0.3315)  loss_bbox_aux_4: 0.0590 (0.0590)  loss_giou_aux_4: 0.1284 (0.1284)  loss_fgl_aux_4: 0.9759 (0.9759)  loss_ddf_aux_4: -0.0002 (-0.0002)  loss_mal_pre: 0.7656 (0.7656)  loss_bbox_pre: 0.0849 (0.0849)  loss_giou_pre: 0.1820 (0.1820)  loss_mal_enc_0: 0.7568 (0.7568)  loss_bbox_enc_0: 0.1594 (0.1594)  loss_giou_enc_0: 0.3798 (0.3798)  loss_mal_dn_0: 0.7637 (0.7637)  loss_bbox_dn_0: 0.2117 (0.2117)  loss_giou_dn_0: 0.3920 (0.3920)  loss_fgl_dn_0: 1.3420 (1.3420)  loss_ddf_dn_0: 1.0396 (1.0396)  loss_mal_dn_1: 0.5303 (0.5303)  loss_bbox_dn_1: 0.1010 (0.1010)  loss_giou_dn_1: 0.2003 (0.2003)  loss_fgl_dn_1: 1.0932 (1.0932)  loss_ddf_dn_1: 0.2702 (0.2702)  loss_mal_dn_2: 0.4014 (0.4014)  loss_bbox_dn_2: 0.0713 (0.0713)  loss_giou_dn_2: 0.1469 (0.1469)  loss_fgl_dn_2: 1.0067 (1.0067)  loss_ddf_dn_2: 0.0698 (0.0698)  loss_mal_dn_3: 0.3513 (0.3513)  loss_bbox_dn_3: 0.0596 (0.0596)  loss_giou_dn_3: 0.1274 (0.1274)  loss_fgl_dn_3: 0.9792 (0.9792)  loss_ddf_dn_3: 0.0096 (0.0096)  loss_mal_dn_4: 0.3416 (0.3416)  loss_bbox_dn_4: 0.0593 (0.0593)  loss_giou_dn_4: 0.1259 (0.1259)  loss_fgl_dn_4: 0.9743 (0.9743)  loss_ddf_dn_4: 0.0008 (0.0008)  loss_mal_dn_5: 0.3430 (0.3430)  loss_bbox_dn_5: 0.0597 (0.0597)  loss_giou_dn_5: 0.1258 (0.1258)  loss_fgl_dn_5: 0.9736 (0.9736)  loss_mal_dn_pre: 0.7651 (0.7651)  loss_bbox_dn_pre: 0.2147 (0.2147)  loss_giou_dn_pre: 0.3919 (0.3919)  time: 1.9042  data: 0.6277  max mem: 13413\nEpoch: [48]  [100/251]  eta: 0:02:59  lr: 0.000001  loss: 25.5501 (26.9041)  loss_mal: 0.3159 (0.3925)  loss_bbox: 0.0521 (0.0622)  loss_giou: 0.1281 (0.1480)  loss_fgl: 0.9937 (1.0395)  loss_mal_aux_0: 0.7520 (0.7713)  loss_bbox_aux_0: 0.0746 (0.0881)  loss_giou_aux_0: 0.1815 (0.2036)  loss_fgl_aux_0: 1.1322 (1.1684)  loss_ddf_aux_0: 0.1786 (0.1985)  loss_mal_aux_1: 0.4355 (0.5208)  loss_bbox_aux_1: 0.0600 (0.0672)  loss_giou_aux_1: 0.1371 (0.1590)  loss_fgl_aux_1: 1.0297 (1.0680)  loss_ddf_aux_1: 0.0412 (0.0478)  loss_mal_aux_2: 0.3381 (0.4286)  loss_bbox_aux_2: 0.0544 (0.0635)  loss_giou_aux_2: 0.1297 (0.1506)  loss_fgl_aux_2: 1.0063 (1.0455)  loss_ddf_aux_2: 0.0064 (0.0077)  loss_mal_aux_3: 0.3264 (0.4021)  loss_bbox_aux_3: 0.0539 (0.0625)  loss_giou_aux_3: 0.1296 (0.1486)  loss_fgl_aux_3: 0.9980 (1.0413)  loss_ddf_aux_3: 0.0012 (0.0013)  loss_mal_aux_4: 0.3176 (0.3938)  loss_bbox_aux_4: 0.0523 (0.0623)  loss_giou_aux_4: 0.1285 (0.1482)  loss_fgl_aux_4: 0.9955 (1.0401)  loss_ddf_aux_4: 0.0003 (0.0002)  loss_mal_pre: 0.7534 (0.7721)  loss_bbox_pre: 0.0745 (0.0880)  loss_giou_pre: 0.1801 (0.2033)  loss_mal_enc_0: 0.8721 (0.9431)  loss_bbox_enc_0: 0.1407 (0.1542)  loss_giou_enc_0: 0.3067 (0.3351)  loss_mal_dn_0: 0.6899 (0.7030)  loss_bbox_dn_0: 0.1643 (0.1829)  loss_giou_dn_0: 0.3343 (0.3582)  loss_fgl_dn_0: 1.2882 (1.3039)  loss_ddf_dn_0: 0.7642 (0.8815)  loss_mal_dn_1: 0.5156 (0.5189)  loss_bbox_dn_1: 0.0820 (0.0953)  loss_giou_dn_1: 0.1743 (0.1981)  loss_fgl_dn_1: 1.0747 (1.0952)  loss_ddf_dn_1: 0.1762 (0.2085)  loss_mal_dn_2: 0.4155 (0.4239)  loss_bbox_dn_2: 0.0641 (0.0744)  loss_giou_dn_2: 0.1444 (0.1643)  loss_fgl_dn_2: 1.0117 (1.0436)  loss_ddf_dn_2: 0.0480 (0.0561)  loss_mal_dn_3: 0.3669 (0.3913)  loss_bbox_dn_3: 0.0564 (0.0684)  loss_giou_dn_3: 0.1355 (0.1548)  loss_fgl_dn_3: 0.9993 (1.0329)  loss_ddf_dn_3: 0.0089 (0.0106)  loss_mal_dn_4: 0.3596 (0.3848)  loss_bbox_dn_4: 0.0552 (0.0669)  loss_giou_dn_4: 0.1340 (0.1522)  loss_fgl_dn_4: 0.9993 (1.0304)  loss_ddf_dn_4: 0.0009 (0.0010)  loss_mal_dn_5: 0.3601 (0.3830)  loss_bbox_dn_5: 0.0555 (0.0666)  loss_giou_dn_5: 0.1342 (0.1516)  loss_fgl_dn_5: 0.9968 (1.0298)  loss_mal_dn_pre: 0.6890 (0.7033)  loss_bbox_dn_pre: 0.1676 (0.1845)  loss_giou_dn_pre: 0.3342 (0.3574)  time: 1.1668  data: 0.0102  max mem: 13413\nEpoch: [48]  [200/251]  eta: 0:01:00  lr: 0.000001  loss: 25.7496 (26.8857)  loss_mal: 0.3074 (0.3872)  loss_bbox: 0.0561 (0.0627)  loss_giou: 0.1160 (0.1494)  loss_fgl: 0.9759 (1.0408)  loss_mal_aux_0: 0.7393 (0.7750)  loss_bbox_aux_0: 0.0834 (0.0896)  loss_giou_aux_0: 0.1933 (0.2064)  loss_fgl_aux_0: 1.1514 (1.1702)  loss_ddf_aux_0: 0.1974 (0.2015)  loss_mal_aux_1: 0.4607 (0.5189)  loss_bbox_aux_1: 0.0618 (0.0689)  loss_giou_aux_1: 0.1415 (0.1604)  loss_fgl_aux_1: 1.0256 (1.0673)  loss_ddf_aux_1: 0.0469 (0.0482)  loss_mal_aux_2: 0.3596 (0.4229)  loss_bbox_aux_2: 0.0553 (0.0645)  loss_giou_aux_2: 0.1219 (0.1516)  loss_fgl_aux_2: 0.9810 (1.0460)  loss_ddf_aux_2: 0.0070 (0.0076)  loss_mal_aux_3: 0.3176 (0.3988)  loss_bbox_aux_3: 0.0559 (0.0633)  loss_giou_aux_3: 0.1163 (0.1499)  loss_fgl_aux_3: 0.9787 (1.0425)  loss_ddf_aux_3: 0.0013 (0.0013)  loss_mal_aux_4: 0.3076 (0.3888)  loss_bbox_aux_4: 0.0561 (0.0628)  loss_giou_aux_4: 0.1161 (0.1495)  loss_fgl_aux_4: 0.9759 (1.0412)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 0.7393 (0.7754)  loss_bbox_pre: 0.0831 (0.0898)  loss_giou_pre: 0.1932 (0.2061)  loss_mal_enc_0: 0.9351 (0.9440)  loss_bbox_enc_0: 0.1511 (0.1580)  loss_giou_enc_0: 0.3363 (0.3430)  loss_mal_dn_0: 0.6777 (0.6987)  loss_bbox_dn_0: 0.1562 (0.1772)  loss_giou_dn_0: 0.3429 (0.3556)  loss_fgl_dn_0: 1.2945 (1.3059)  loss_ddf_dn_0: 0.8753 (0.8845)  loss_mal_dn_1: 0.4829 (0.5128)  loss_bbox_dn_1: 0.0828 (0.0941)  loss_giou_dn_1: 0.1784 (0.1979)  loss_fgl_dn_1: 1.0606 (1.0937)  loss_ddf_dn_1: 0.2009 (0.2061)  loss_mal_dn_2: 0.4038 (0.4195)  loss_bbox_dn_2: 0.0643 (0.0747)  loss_giou_dn_2: 0.1520 (0.1652)  loss_fgl_dn_2: 1.0055 (1.0421)  loss_ddf_dn_2: 0.0506 (0.0551)  loss_mal_dn_3: 0.3672 (0.3892)  loss_bbox_dn_3: 0.0584 (0.0689)  loss_giou_dn_3: 0.1368 (0.1559)  loss_fgl_dn_3: 0.9977 (1.0315)  loss_ddf_dn_3: 0.0092 (0.0104)  loss_mal_dn_4: 0.3606 (0.3822)  loss_bbox_dn_4: 0.0572 (0.0674)  loss_giou_dn_4: 0.1345 (0.1533)  loss_fgl_dn_4: 0.9966 (1.0287)  loss_ddf_dn_4: 0.0009 (0.0009)  loss_mal_dn_5: 0.3665 (0.3806)  loss_bbox_dn_5: 0.0569 (0.0670)  loss_giou_dn_5: 0.1344 (0.1527)  loss_fgl_dn_5: 0.9970 (1.0279)  loss_mal_dn_pre: 0.6782 (0.6992)  loss_bbox_dn_pre: 0.1602 (0.1784)  loss_giou_dn_pre: 0.3443 (0.3549)  time: 1.1813  data: 0.0113  max mem: 13413\nEpoch: [48]  [250/251]  eta: 0:00:01  lr: 0.000001  loss: 27.4219 (27.0132)  loss_mal: 0.3640 (0.3878)  loss_bbox: 0.0644 (0.0633)  loss_giou: 0.1554 (0.1498)  loss_fgl: 1.0464 (1.0397)  loss_mal_aux_0: 0.8154 (0.7729)  loss_bbox_aux_0: 0.1046 (0.0924)  loss_giou_aux_0: 0.2302 (0.2092)  loss_fgl_aux_0: 1.2026 (1.1720)  loss_ddf_aux_0: 0.2255 (0.2054)  loss_mal_aux_1: 0.5259 (0.5195)  loss_bbox_aux_1: 0.0702 (0.0700)  loss_giou_aux_1: 0.1717 (0.1615)  loss_fgl_aux_1: 1.1008 (1.0680)  loss_ddf_aux_1: 0.0454 (0.0491)  loss_mal_aux_2: 0.3918 (0.4276)  loss_bbox_aux_2: 0.0675 (0.0652)  loss_giou_aux_2: 0.1618 (0.1523)  loss_fgl_aux_2: 1.0728 (1.0457)  loss_ddf_aux_2: 0.0070 (0.0077)  loss_mal_aux_3: 0.3682 (0.4023)  loss_bbox_aux_3: 0.0655 (0.0639)  loss_giou_aux_3: 0.1604 (0.1504)  loss_fgl_aux_3: 1.0480 (1.0416)  loss_ddf_aux_3: 0.0016 (0.0014)  loss_mal_aux_4: 0.3630 (0.3901)  loss_bbox_aux_4: 0.0650 (0.0634)  loss_giou_aux_4: 0.1568 (0.1500)  loss_fgl_aux_4: 1.0477 (1.0402)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8159 (0.7734)  loss_bbox_pre: 0.1033 (0.0926)  loss_giou_pre: 0.2283 (0.2090)  loss_mal_enc_0: 0.8975 (0.9486)  loss_bbox_enc_0: 0.1720 (0.1653)  loss_giou_enc_0: 0.3435 (0.3486)  loss_mal_dn_0: 0.7090 (0.7018)  loss_bbox_dn_0: 0.1883 (0.1829)  loss_giou_dn_0: 0.3718 (0.3590)  loss_fgl_dn_0: 1.3030 (1.3069)  loss_ddf_dn_0: 0.9587 (0.8954)  loss_mal_dn_1: 0.5552 (0.5168)  loss_bbox_dn_1: 0.0974 (0.0971)  loss_giou_dn_1: 0.2213 (0.2004)  loss_fgl_dn_1: 1.1086 (1.0947)  loss_ddf_dn_1: 0.2253 (0.2097)  loss_mal_dn_2: 0.4658 (0.4245)  loss_bbox_dn_2: 0.0745 (0.0771)  loss_giou_dn_2: 0.1865 (0.1672)  loss_fgl_dn_2: 1.0454 (1.0426)  loss_ddf_dn_2: 0.0595 (0.0561)  loss_mal_dn_3: 0.4333 (0.3929)  loss_bbox_dn_3: 0.0693 (0.0710)  loss_giou_dn_3: 0.1678 (0.1578)  loss_fgl_dn_3: 1.0353 (1.0316)  loss_ddf_dn_3: 0.0118 (0.0105)  loss_mal_dn_4: 0.4094 (0.3849)  loss_bbox_dn_4: 0.0653 (0.0692)  loss_giou_dn_4: 0.1649 (0.1550)  loss_fgl_dn_4: 1.0313 (1.0286)  loss_ddf_dn_4: 0.0011 (0.0010)  loss_mal_dn_5: 0.4055 (0.3830)  loss_bbox_dn_5: 0.0637 (0.0688)  loss_giou_dn_5: 0.1649 (0.1543)  loss_fgl_dn_5: 1.0284 (1.0277)  loss_mal_dn_pre: 0.7114 (0.7024)  loss_bbox_dn_pre: 0.1953 (0.1840)  loss_giou_dn_pre: 0.3706 (0.3583)  time: 1.1727  data: 0.0121  max mem: 13413\nEpoch: [48] Total time: 0:04:57 (1.1840 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7732  data: 0.4830  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3485  data: 0.0641  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3029  data: 0.0199  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2919  data: 0.0194  max mem: 13413\nTest: Total time: 0:00:07 (0.3158 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.541\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.339\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.369\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.367\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.461\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.580\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.687\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.677\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.954\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.739\nbest_stat: {'epoch': 48, 'coco_eval_bbox': 0.3404660263717498}\nEpoch: [49]  [  0/251]  eta: 0:07:59  lr: 0.000001  loss: 22.8944 (22.8944)  loss_mal: 0.2216 (0.2216)  loss_bbox: 0.0508 (0.0508)  loss_giou: 0.0754 (0.0754)  loss_fgl: 0.8181 (0.8181)  loss_mal_aux_0: 0.7388 (0.7388)  loss_bbox_aux_0: 0.1111 (0.1111)  loss_giou_aux_0: 0.1691 (0.1691)  loss_fgl_aux_0: 1.0693 (1.0693)  loss_ddf_aux_0: 0.1970 (0.1970)  loss_mal_aux_1: 0.3203 (0.3203)  loss_bbox_aux_1: 0.0551 (0.0551)  loss_giou_aux_1: 0.0867 (0.0867)  loss_fgl_aux_1: 0.8657 (0.8657)  loss_ddf_aux_1: 0.0422 (0.0422)  loss_mal_aux_2: 0.2397 (0.2397)  loss_bbox_aux_2: 0.0485 (0.0485)  loss_giou_aux_2: 0.0728 (0.0728)  loss_fgl_aux_2: 0.8203 (0.8203)  loss_ddf_aux_2: 0.0077 (0.0077)  loss_mal_aux_3: 0.2189 (0.2189)  loss_bbox_aux_3: 0.0493 (0.0493)  loss_giou_aux_3: 0.0719 (0.0719)  loss_fgl_aux_3: 0.8182 (0.8182)  loss_ddf_aux_3: 0.0010 (0.0010)  loss_mal_aux_4: 0.2206 (0.2206)  loss_bbox_aux_4: 0.0501 (0.0501)  loss_giou_aux_4: 0.0744 (0.0744)  loss_fgl_aux_4: 0.8180 (0.8180)  loss_ddf_aux_4: 0.0000 (0.0000)  loss_mal_pre: 0.7397 (0.7397)  loss_bbox_pre: 0.1092 (0.1092)  loss_giou_pre: 0.1684 (0.1684)  loss_mal_enc_0: 0.9268 (0.9268)  loss_bbox_enc_0: 0.1658 (0.1658)  loss_giou_enc_0: 0.2446 (0.2446)  loss_mal_dn_0: 0.6963 (0.6963)  loss_bbox_dn_0: 0.2501 (0.2501)  loss_giou_dn_0: 0.3268 (0.3268)  loss_fgl_dn_0: 1.2625 (1.2625)  loss_ddf_dn_0: 0.8362 (0.8362)  loss_mal_dn_1: 0.4541 (0.4541)  loss_bbox_dn_1: 0.0991 (0.0991)  loss_giou_dn_1: 0.1334 (0.1334)  loss_fgl_dn_1: 1.0157 (1.0157)  loss_ddf_dn_1: 0.1918 (0.1918)  loss_mal_dn_2: 0.3374 (0.3374)  loss_bbox_dn_2: 0.0680 (0.0680)  loss_giou_dn_2: 0.0977 (0.0977)  loss_fgl_dn_2: 0.9555 (0.9555)  loss_ddf_dn_2: 0.0539 (0.0539)  loss_mal_dn_3: 0.2932 (0.2932)  loss_bbox_dn_3: 0.0609 (0.0609)  loss_giou_dn_3: 0.0891 (0.0891)  loss_fgl_dn_3: 0.9485 (0.9485)  loss_ddf_dn_3: 0.0123 (0.0123)  loss_mal_dn_4: 0.2874 (0.2874)  loss_bbox_dn_4: 0.0592 (0.0592)  loss_giou_dn_4: 0.0896 (0.0896)  loss_fgl_dn_4: 0.9444 (0.9444)  loss_ddf_dn_4: 0.0009 (0.0009)  loss_mal_dn_5: 0.2839 (0.2839)  loss_bbox_dn_5: 0.0586 (0.0586)  loss_giou_dn_5: 0.0894 (0.0894)  loss_fgl_dn_5: 0.9426 (0.9426)  loss_mal_dn_pre: 0.6948 (0.6948)  loss_bbox_dn_pre: 0.2477 (0.2477)  loss_giou_dn_pre: 0.3262 (0.3262)  time: 1.9095  data: 0.6717  max mem: 13413\nEpoch: [49]  [100/251]  eta: 0:02:58  lr: 0.000001  loss: 24.9350 (26.3347)  loss_mal: 0.3076 (0.3718)  loss_bbox: 0.0530 (0.0583)  loss_giou: 0.1231 (0.1375)  loss_fgl: 0.9869 (1.0125)  loss_mal_aux_0: 0.7178 (0.7529)  loss_bbox_aux_0: 0.0765 (0.0880)  loss_giou_aux_0: 0.1701 (0.1974)  loss_fgl_aux_0: 1.1214 (1.1564)  loss_ddf_aux_0: 0.1891 (0.2159)  loss_mal_aux_1: 0.4534 (0.4957)  loss_bbox_aux_1: 0.0553 (0.0648)  loss_giou_aux_1: 0.1364 (0.1482)  loss_fgl_aux_1: 1.0151 (1.0406)  loss_ddf_aux_1: 0.0430 (0.0495)  loss_mal_aux_2: 0.3418 (0.4070)  loss_bbox_aux_2: 0.0514 (0.0602)  loss_giou_aux_2: 0.1255 (0.1402)  loss_fgl_aux_2: 0.9962 (1.0176)  loss_ddf_aux_2: 0.0065 (0.0076)  loss_mal_aux_3: 0.3264 (0.3790)  loss_bbox_aux_3: 0.0510 (0.0588)  loss_giou_aux_3: 0.1246 (0.1382)  loss_fgl_aux_3: 0.9896 (1.0142)  loss_ddf_aux_3: 0.0014 (0.0014)  loss_mal_aux_4: 0.3057 (0.3748)  loss_bbox_aux_4: 0.0525 (0.0583)  loss_giou_aux_4: 0.1234 (0.1376)  loss_fgl_aux_4: 0.9881 (1.0129)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.7183 (0.7534)  loss_bbox_pre: 0.0764 (0.0879)  loss_giou_pre: 0.1689 (0.1970)  loss_mal_enc_0: 0.9282 (0.9452)  loss_bbox_enc_0: 0.1441 (0.1752)  loss_giou_enc_0: 0.3333 (0.3471)  loss_mal_dn_0: 0.6831 (0.6908)  loss_bbox_dn_0: 0.1560 (0.1855)  loss_giou_dn_0: 0.3304 (0.3487)  loss_fgl_dn_0: 1.2870 (1.2978)  loss_ddf_dn_0: 0.8557 (0.9013)  loss_mal_dn_1: 0.4968 (0.5061)  loss_bbox_dn_1: 0.0760 (0.0982)  loss_giou_dn_1: 0.1668 (0.1904)  loss_fgl_dn_1: 1.0534 (1.0724)  loss_ddf_dn_1: 0.1840 (0.2100)  loss_mal_dn_2: 0.3928 (0.4035)  loss_bbox_dn_2: 0.0549 (0.0775)  loss_giou_dn_2: 0.1348 (0.1572)  loss_fgl_dn_2: 0.9901 (1.0211)  loss_ddf_dn_2: 0.0500 (0.0555)  loss_mal_dn_3: 0.3567 (0.3723)  loss_bbox_dn_3: 0.0541 (0.0710)  loss_giou_dn_3: 0.1262 (0.1477)  loss_fgl_dn_3: 0.9760 (1.0109)  loss_ddf_dn_3: 0.0091 (0.0107)  loss_mal_dn_4: 0.3486 (0.3658)  loss_bbox_dn_4: 0.0530 (0.0691)  loss_giou_dn_4: 0.1255 (0.1453)  loss_fgl_dn_4: 0.9725 (1.0082)  loss_ddf_dn_4: 0.0008 (0.0009)  loss_mal_dn_5: 0.3430 (0.3647)  loss_bbox_dn_5: 0.0530 (0.0688)  loss_giou_dn_5: 0.1241 (0.1449)  loss_fgl_dn_5: 0.9718 (1.0075)  loss_mal_dn_pre: 0.6816 (0.6915)  loss_bbox_dn_pre: 0.1583 (0.1872)  loss_giou_dn_pre: 0.3305 (0.3488)  time: 1.1784  data: 0.0117  max mem: 13413\nEpoch: [49]  [200/251]  eta: 0:01:00  lr: 0.000001  loss: 26.3258 (26.5595)  loss_mal: 0.3274 (0.3704)  loss_bbox: 0.0570 (0.0601)  loss_giou: 0.1398 (0.1424)  loss_fgl: 0.9989 (1.0275)  loss_mal_aux_0: 0.7168 (0.7518)  loss_bbox_aux_0: 0.0866 (0.0872)  loss_giou_aux_0: 0.1967 (0.1992)  loss_fgl_aux_0: 1.1511 (1.1601)  loss_ddf_aux_0: 0.2099 (0.2160)  loss_mal_aux_1: 0.4651 (0.4985)  loss_bbox_aux_1: 0.0570 (0.0650)  loss_giou_aux_1: 0.1478 (0.1520)  loss_fgl_aux_1: 1.0348 (1.0508)  loss_ddf_aux_1: 0.0470 (0.0496)  loss_mal_aux_2: 0.4148 (0.4116)  loss_bbox_aux_2: 0.0564 (0.0611)  loss_giou_aux_2: 0.1423 (0.1444)  loss_fgl_aux_2: 1.0026 (1.0316)  loss_ddf_aux_2: 0.0071 (0.0077)  loss_mal_aux_3: 0.3364 (0.3783)  loss_bbox_aux_3: 0.0567 (0.0603)  loss_giou_aux_3: 0.1398 (0.1429)  loss_fgl_aux_3: 1.0035 (1.0284)  loss_ddf_aux_3: 0.0012 (0.0014)  loss_mal_aux_4: 0.3257 (0.3729)  loss_bbox_aux_4: 0.0571 (0.0601)  loss_giou_aux_4: 0.1398 (0.1425)  loss_fgl_aux_4: 0.9996 (1.0278)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 0.7197 (0.7525)  loss_bbox_pre: 0.0882 (0.0871)  loss_giou_pre: 0.1963 (0.1987)  loss_mal_enc_0: 0.9409 (0.9337)  loss_bbox_enc_0: 0.1581 (0.1630)  loss_giou_enc_0: 0.3441 (0.3430)  loss_mal_dn_0: 0.7046 (0.6929)  loss_bbox_dn_0: 0.1665 (0.1801)  loss_giou_dn_0: 0.3668 (0.3534)  loss_fgl_dn_0: 1.3138 (1.3040)  loss_ddf_dn_0: 0.9135 (0.9289)  loss_mal_dn_1: 0.5186 (0.5100)  loss_bbox_dn_1: 0.0963 (0.0964)  loss_giou_dn_1: 0.1942 (0.1954)  loss_fgl_dn_1: 1.0859 (1.0813)  loss_ddf_dn_1: 0.2227 (0.2159)  loss_mal_dn_2: 0.4141 (0.4098)  loss_bbox_dn_2: 0.0763 (0.0768)  loss_giou_dn_2: 0.1613 (0.1626)  loss_fgl_dn_2: 1.0342 (1.0308)  loss_ddf_dn_2: 0.0569 (0.0570)  loss_mal_dn_3: 0.3679 (0.3791)  loss_bbox_dn_3: 0.0651 (0.0709)  loss_giou_dn_3: 0.1548 (0.1533)  loss_fgl_dn_3: 1.0136 (1.0207)  loss_ddf_dn_3: 0.0099 (0.0108)  loss_mal_dn_4: 0.3579 (0.3731)  loss_bbox_dn_4: 0.0648 (0.0694)  loss_giou_dn_4: 0.1519 (0.1509)  loss_fgl_dn_4: 1.0009 (1.0181)  loss_ddf_dn_4: 0.0009 (0.0010)  loss_mal_dn_5: 0.3557 (0.3721)  loss_bbox_dn_5: 0.0652 (0.0691)  loss_giou_dn_5: 0.1523 (0.1505)  loss_fgl_dn_5: 0.9973 (1.0173)  loss_mal_dn_pre: 0.7017 (0.6934)  loss_bbox_dn_pre: 0.1701 (0.1819)  loss_giou_dn_pre: 0.3709 (0.3532)  time: 1.1733  data: 0.0108  max mem: 13413\nEpoch: [49]  [250/251]  eta: 0:00:01  lr: 0.000001  loss: 26.2555 (26.4632)  loss_mal: 0.3347 (0.3662)  loss_bbox: 0.0556 (0.0595)  loss_giou: 0.1308 (0.1412)  loss_fgl: 1.0048 (1.0257)  loss_mal_aux_0: 0.7563 (0.7502)  loss_bbox_aux_0: 0.0865 (0.0862)  loss_giou_aux_0: 0.2042 (0.1976)  loss_fgl_aux_0: 1.1824 (1.1575)  loss_ddf_aux_0: 0.2118 (0.2149)  loss_mal_aux_1: 0.4900 (0.4942)  loss_bbox_aux_1: 0.0601 (0.0642)  loss_giou_aux_1: 0.1445 (0.1504)  loss_fgl_aux_1: 1.0462 (1.0483)  loss_ddf_aux_1: 0.0426 (0.0488)  loss_mal_aux_2: 0.3857 (0.4068)  loss_bbox_aux_2: 0.0534 (0.0605)  loss_giou_aux_2: 0.1370 (0.1430)  loss_fgl_aux_2: 1.0176 (1.0295)  loss_ddf_aux_2: 0.0062 (0.0075)  loss_mal_aux_3: 0.3496 (0.3746)  loss_bbox_aux_3: 0.0551 (0.0598)  loss_giou_aux_3: 0.1328 (0.1417)  loss_fgl_aux_3: 1.0147 (1.0267)  loss_ddf_aux_3: 0.0012 (0.0014)  loss_mal_aux_4: 0.3381 (0.3686)  loss_bbox_aux_4: 0.0558 (0.0596)  loss_giou_aux_4: 0.1312 (0.1413)  loss_fgl_aux_4: 1.0064 (1.0260)  loss_ddf_aux_4: 0.0002 (0.0001)  loss_mal_pre: 0.7568 (0.7508)  loss_bbox_pre: 0.0866 (0.0861)  loss_giou_pre: 0.2018 (0.1972)  loss_mal_enc_0: 0.8911 (0.9368)  loss_bbox_enc_0: 0.1569 (0.1614)  loss_giou_enc_0: 0.3279 (0.3396)  loss_mal_dn_0: 0.6904 (0.6931)  loss_bbox_dn_0: 0.1505 (0.1791)  loss_giou_dn_0: 0.3373 (0.3519)  loss_fgl_dn_0: 1.3029 (1.3049)  loss_ddf_dn_0: 0.8808 (0.9304)  loss_mal_dn_1: 0.5083 (0.5096)  loss_bbox_dn_1: 0.0780 (0.0948)  loss_giou_dn_1: 0.1798 (0.1937)  loss_fgl_dn_1: 1.0614 (1.0801)  loss_ddf_dn_1: 0.2032 (0.2149)  loss_mal_dn_2: 0.3862 (0.4081)  loss_bbox_dn_2: 0.0650 (0.0751)  loss_giou_dn_2: 0.1435 (0.1607)  loss_fgl_dn_2: 0.9976 (1.0283)  loss_ddf_dn_2: 0.0504 (0.0563)  loss_mal_dn_3: 0.3618 (0.3770)  loss_bbox_dn_3: 0.0600 (0.0696)  loss_giou_dn_3: 0.1396 (0.1515)  loss_fgl_dn_3: 0.9916 (1.0180)  loss_ddf_dn_3: 0.0094 (0.0106)  loss_mal_dn_4: 0.3538 (0.3708)  loss_bbox_dn_4: 0.0595 (0.0681)  loss_giou_dn_4: 0.1375 (0.1492)  loss_fgl_dn_4: 0.9908 (1.0154)  loss_ddf_dn_4: 0.0008 (0.0009)  loss_mal_dn_5: 0.3560 (0.3699)  loss_bbox_dn_5: 0.0596 (0.0678)  loss_giou_dn_5: 0.1353 (0.1488)  loss_fgl_dn_5: 0.9899 (1.0147)  loss_mal_dn_pre: 0.6914 (0.6935)  loss_bbox_dn_pre: 0.1518 (0.1808)  loss_giou_dn_pre: 0.3375 (0.3517)  time: 1.1672  data: 0.0109  max mem: 13413\nEpoch: [49] Total time: 0:04:56 (1.1821 s / it)\nTest:  [ 0/25]  eta: 0:00:19    time: 0.7785  data: 0.4894  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3463  data: 0.0626  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3011  data: 0.0187  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.2900  data: 0.0184  max mem: 13413\nTest: Total time: 0:00:07 (0.3145 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.338\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.544\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.334\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.276\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.368\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.464\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.585\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.673\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.637\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.664\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.739\nbest_stat: {'epoch': 48, 'coco_eval_bbox': 0.3404660263717498}\nLoad last_epoch\nLoad model.state_dict\nLoad criterion.state_dict\nLoad postprocessor.state_dict\nLoad ema.state_dict\nLoad scaler.state_dict\nLoad optimizer.state_dict\nLoad lr_warmup_scheduler.state_dict\nRefresh EMA at epoch 49 with decay 0.9993000000000001\nEpoch: [50]  [  0/251]  eta: 0:08:34  lr: 0.000001  loss: 30.1433 (30.1433)  loss_mal: 0.3884 (0.3884)  loss_bbox: 0.1402 (0.1402)  loss_giou: 0.1651 (0.1651)  loss_fgl: 1.0539 (1.0539)  loss_mal_aux_0: 1.1533 (1.1533)  loss_bbox_aux_0: 0.2126 (0.2126)  loss_giou_aux_0: 0.2625 (0.2625)  loss_fgl_aux_0: 1.1971 (1.1971)  loss_ddf_aux_0: 0.2282 (0.2282)  loss_mal_aux_1: 0.7246 (0.7246)  loss_bbox_aux_1: 0.1595 (0.1595)  loss_giou_aux_1: 0.1915 (0.1915)  loss_fgl_aux_1: 1.0943 (1.0943)  loss_ddf_aux_1: 0.0637 (0.0637)  loss_mal_aux_2: 0.4607 (0.4607)  loss_bbox_aux_2: 0.1429 (0.1429)  loss_giou_aux_2: 0.1744 (0.1744)  loss_fgl_aux_2: 1.0606 (1.0606)  loss_ddf_aux_2: 0.0104 (0.0104)  loss_mal_aux_3: 0.4023 (0.4023)  loss_bbox_aux_3: 0.1394 (0.1394)  loss_giou_aux_3: 0.1683 (0.1683)  loss_fgl_aux_3: 1.0562 (1.0562)  loss_ddf_aux_3: 0.0018 (0.0018)  loss_mal_aux_4: 0.3896 (0.3896)  loss_bbox_aux_4: 0.1398 (0.1398)  loss_giou_aux_4: 0.1662 (0.1662)  loss_fgl_aux_4: 1.0539 (1.0539)  loss_ddf_aux_4: 0.0001 (0.0001)  loss_mal_pre: 1.1592 (1.1592)  loss_bbox_pre: 0.2088 (0.2088)  loss_giou_pre: 0.2602 (0.2602)  loss_mal_enc_0: 1.0615 (1.0615)  loss_bbox_enc_0: 0.3234 (0.3234)  loss_giou_enc_0: 0.5189 (0.5189)  loss_mal_dn_0: 0.6987 (0.6987)  loss_bbox_dn_0: 0.2502 (0.2502)  loss_giou_dn_0: 0.3680 (0.3680)  loss_fgl_dn_0: 1.2777 (1.2777)  loss_ddf_dn_0: 0.9622 (0.9622)  loss_mal_dn_1: 0.5024 (0.5024)  loss_bbox_dn_1: 0.1367 (0.1367)  loss_giou_dn_1: 0.1990 (0.1990)  loss_fgl_dn_1: 1.1043 (1.1043)  loss_ddf_dn_1: 0.2433 (0.2433)  loss_mal_dn_2: 0.4365 (0.4365)  loss_bbox_dn_2: 0.1210 (0.1210)  loss_giou_dn_2: 0.1682 (0.1682)  loss_fgl_dn_2: 1.0632 (1.0632)  loss_ddf_dn_2: 0.0714 (0.0714)  loss_mal_dn_3: 0.4082 (0.4082)  loss_bbox_dn_3: 0.1195 (0.1195)  loss_giou_dn_3: 0.1628 (0.1628)  loss_fgl_dn_3: 1.0598 (1.0598)  loss_ddf_dn_3: 0.0121 (0.0121)  loss_mal_dn_4: 0.4050 (0.4050)  loss_bbox_dn_4: 0.1199 (0.1199)  loss_giou_dn_4: 0.1632 (0.1632)  loss_fgl_dn_4: 1.0621 (1.0621)  loss_ddf_dn_4: 0.0010 (0.0010)  loss_mal_dn_5: 0.4075 (0.4075)  loss_bbox_dn_5: 0.1198 (0.1198)  loss_giou_dn_5: 0.1636 (0.1636)  loss_fgl_dn_5: 1.0629 (1.0629)  loss_mal_dn_pre: 0.7026 (0.7026)  loss_bbox_dn_pre: 0.2629 (0.2629)  loss_giou_dn_pre: 0.3740 (0.3740)  time: 2.0507  data: 0.8410  max mem: 13413\nEpoch: [50]  [100/251]  eta: 0:02:59  lr: 0.000001  loss: 27.6273 (29.3990)  loss_mal: 0.4045 (0.4504)  loss_bbox: 0.0607 (0.0820)  loss_giou: 0.1653 (0.1788)  loss_fgl: 1.0892 (1.0955)  loss_mal_aux_0: 0.8076 (0.8598)  loss_bbox_aux_0: 0.0899 (0.1154)  loss_giou_aux_0: 0.2434 (0.2482)  loss_fgl_aux_0: 1.2073 (1.2237)  loss_ddf_aux_0: 0.1990 (0.1946)  loss_mal_aux_1: 0.5371 (0.6078)  loss_bbox_aux_1: 0.0725 (0.0902)  loss_giou_aux_1: 0.1705 (0.1922)  loss_fgl_aux_1: 1.1188 (1.1288)  loss_ddf_aux_1: 0.0488 (0.0534)  loss_mal_aux_2: 0.4224 (0.5047)  loss_bbox_aux_2: 0.0658 (0.0854)  loss_giou_aux_2: 0.1694 (0.1826)  loss_fgl_aux_2: 1.1033 (1.1037)  loss_ddf_aux_2: 0.0079 (0.0096)  loss_mal_aux_3: 0.4097 (0.4675)  loss_bbox_aux_3: 0.0625 (0.0833)  loss_giou_aux_3: 0.1673 (0.1801)  loss_fgl_aux_3: 1.0924 (1.0976)  loss_ddf_aux_3: 0.0016 (0.0018)  loss_mal_aux_4: 0.4016 (0.4522)  loss_bbox_aux_4: 0.0611 (0.0823)  loss_giou_aux_4: 0.1663 (0.1792)  loss_fgl_aux_4: 1.0907 (1.0960)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.8052 (0.8616)  loss_bbox_pre: 0.0924 (0.1143)  loss_giou_pre: 0.2409 (0.2468)  loss_mal_enc_0: 0.9614 (1.0097)  loss_bbox_enc_0: 0.1700 (0.2052)  loss_giou_enc_0: 0.3751 (0.4092)  loss_mal_dn_0: 0.7114 (0.7267)  loss_bbox_dn_0: 0.1823 (0.2068)  loss_giou_dn_0: 0.3774 (0.3940)  loss_fgl_dn_0: 1.3122 (1.3156)  loss_ddf_dn_0: 0.9008 (0.9852)  loss_mal_dn_1: 0.5508 (0.5598)  loss_bbox_dn_1: 0.0885 (0.1153)  loss_giou_dn_1: 0.2145 (0.2317)  loss_fgl_dn_1: 1.1225 (1.1379)  loss_ddf_dn_1: 0.2299 (0.2477)  loss_mal_dn_2: 0.4460 (0.4648)  loss_bbox_dn_2: 0.0704 (0.0942)  loss_giou_dn_2: 0.1762 (0.1969)  loss_fgl_dn_2: 1.0676 (1.0909)  loss_ddf_dn_2: 0.0608 (0.0687)  loss_mal_dn_3: 0.4172 (0.4324)  loss_bbox_dn_3: 0.0681 (0.0878)  loss_giou_dn_3: 0.1692 (0.1870)  loss_fgl_dn_3: 1.0587 (1.0805)  loss_ddf_dn_3: 0.0121 (0.0128)  loss_mal_dn_4: 0.4163 (0.4237)  loss_bbox_dn_4: 0.0680 (0.0860)  loss_giou_dn_4: 0.1692 (0.1841)  loss_fgl_dn_4: 1.0580 (1.0780)  loss_ddf_dn_4: 0.0012 (0.0012)  loss_mal_dn_5: 0.4211 (0.4221)  loss_bbox_dn_5: 0.0679 (0.0857)  loss_giou_dn_5: 0.1682 (0.1834)  loss_fgl_dn_5: 1.0573 (1.0773)  loss_mal_dn_pre: 0.7114 (0.7270)  loss_bbox_dn_pre: 0.1832 (0.2072)  loss_giou_dn_pre: 0.3803 (0.3931)  time: 1.1990  data: 0.0115  max mem: 13413\nEpoch: [50]  [200/251]  eta: 0:01:00  lr: 0.000001  loss: 29.7785 (29.5044)  loss_mal: 0.4497 (0.4507)  loss_bbox: 0.0735 (0.0804)  loss_giou: 0.1825 (0.1806)  loss_fgl: 1.1059 (1.1010)  loss_mal_aux_0: 0.8330 (0.8658)  loss_bbox_aux_0: 0.0997 (0.1134)  loss_giou_aux_0: 0.2490 (0.2463)  loss_fgl_aux_0: 1.2283 (1.2234)  loss_ddf_aux_0: 0.1846 (0.1911)  loss_mal_aux_1: 0.6050 (0.6211)  loss_bbox_aux_1: 0.0805 (0.0892)  loss_giou_aux_1: 0.2003 (0.1943)  loss_fgl_aux_1: 1.1471 (1.1327)  loss_ddf_aux_1: 0.0491 (0.0517)  loss_mal_aux_2: 0.5024 (0.5117)  loss_bbox_aux_2: 0.0764 (0.0837)  loss_giou_aux_2: 0.1815 (0.1845)  loss_fgl_aux_2: 1.1154 (1.1093)  loss_ddf_aux_2: 0.0077 (0.0091)  loss_mal_aux_3: 0.5010 (0.4734)  loss_bbox_aux_3: 0.0747 (0.0816)  loss_giou_aux_3: 0.1812 (0.1819)  loss_fgl_aux_3: 1.1087 (1.1036)  loss_ddf_aux_3: 0.0014 (0.0017)  loss_mal_aux_4: 0.4512 (0.4571)  loss_bbox_aux_4: 0.0739 (0.0807)  loss_giou_aux_4: 0.1819 (0.1810)  loss_fgl_aux_4: 1.1085 (1.1016)  loss_ddf_aux_4: 0.0002 (0.0002)  loss_mal_pre: 0.8330 (0.8672)  loss_bbox_pre: 0.0992 (0.1128)  loss_giou_pre: 0.2492 (0.2454)  loss_mal_enc_0: 0.9668 (1.0246)  loss_bbox_enc_0: 0.1776 (0.1977)  loss_giou_enc_0: 0.3908 (0.4010)  loss_mal_dn_0: 0.7124 (0.7271)  loss_bbox_dn_0: 0.1827 (0.2044)  loss_giou_dn_0: 0.4073 (0.3961)  loss_fgl_dn_0: 1.3173 (1.3166)  loss_ddf_dn_0: 0.8928 (0.9634)  loss_mal_dn_1: 0.5620 (0.5635)  loss_bbox_dn_1: 0.1021 (0.1166)  loss_giou_dn_1: 0.2366 (0.2360)  loss_fgl_dn_1: 1.1447 (1.1431)  loss_ddf_dn_1: 0.2305 (0.2406)  loss_mal_dn_2: 0.4780 (0.4697)  loss_bbox_dn_2: 0.0913 (0.0958)  loss_giou_dn_2: 0.1931 (0.2009)  loss_fgl_dn_2: 1.0918 (1.0966)  loss_ddf_dn_2: 0.0643 (0.0659)  loss_mal_dn_3: 0.4346 (0.4378)  loss_bbox_dn_3: 0.0890 (0.0897)  loss_giou_dn_3: 0.1816 (0.1911)  loss_fgl_dn_3: 1.0769 (1.0858)  loss_ddf_dn_3: 0.0113 (0.0121)  loss_mal_dn_4: 0.4211 (0.4284)  loss_bbox_dn_4: 0.0853 (0.0879)  loss_giou_dn_4: 0.1805 (0.1881)  loss_fgl_dn_4: 1.0713 (1.0830)  loss_ddf_dn_4: 0.0010 (0.0011)  loss_mal_dn_5: 0.4233 (0.4263)  loss_bbox_dn_5: 0.0842 (0.0875)  loss_giou_dn_5: 0.1796 (0.1874)  loss_fgl_dn_5: 1.0687 (1.0822)  loss_mal_dn_pre: 0.7139 (0.7276)  loss_bbox_dn_pre: 0.1802 (0.2053)  loss_giou_dn_pre: 0.4049 (0.3951)  time: 1.1733  data: 0.0115  max mem: 13413\nEpoch: [50]  [250/251]  eta: 0:00:01  lr: 0.000001  loss: 28.3074 (29.5281)  loss_mal: 0.3835 (0.4521)  loss_bbox: 0.0716 (0.0800)  loss_giou: 0.1608 (0.1810)  loss_fgl: 1.0685 (1.1058)  loss_mal_aux_0: 0.8330 (0.8599)  loss_bbox_aux_0: 0.0989 (0.1121)  loss_giou_aux_0: 0.2231 (0.2454)  loss_fgl_aux_0: 1.2019 (1.2233)  loss_ddf_aux_0: 0.1833 (0.1910)  loss_mal_aux_1: 0.5752 (0.6249)  loss_bbox_aux_1: 0.0756 (0.0883)  loss_giou_aux_1: 0.1725 (0.1942)  loss_fgl_aux_1: 1.0838 (1.1346)  loss_ddf_aux_1: 0.0434 (0.0514)  loss_mal_aux_2: 0.4795 (0.5165)  loss_bbox_aux_2: 0.0723 (0.0830)  loss_giou_aux_2: 0.1646 (0.1847)  loss_fgl_aux_2: 1.0714 (1.1133)  loss_ddf_aux_2: 0.0071 (0.0090)  loss_mal_aux_3: 0.4067 (0.4754)  loss_bbox_aux_3: 0.0716 (0.0810)  loss_giou_aux_3: 0.1648 (0.1821)  loss_fgl_aux_3: 1.0644 (1.1080)  loss_ddf_aux_3: 0.0014 (0.0016)  loss_mal_aux_4: 0.3828 (0.4583)  loss_bbox_aux_4: 0.0718 (0.0802)  loss_giou_aux_4: 0.1621 (0.1813)  loss_fgl_aux_4: 1.0681 (1.1063)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.8369 (0.8612)  loss_bbox_pre: 0.0986 (0.1116)  loss_giou_pre: 0.2231 (0.2444)  loss_mal_enc_0: 0.9512 (1.0242)  loss_bbox_enc_0: 0.1871 (0.1945)  loss_giou_enc_0: 0.3738 (0.3979)  loss_mal_dn_0: 0.7158 (0.7268)  loss_bbox_dn_0: 0.1944 (0.2036)  loss_giou_dn_0: 0.3858 (0.3971)  loss_fgl_dn_0: 1.3249 (1.3186)  loss_ddf_dn_0: 0.9390 (0.9575)  loss_mal_dn_1: 0.5352 (0.5638)  loss_bbox_dn_1: 0.1065 (0.1164)  loss_giou_dn_1: 0.2216 (0.2369)  loss_fgl_dn_1: 1.0973 (1.1453)  loss_ddf_dn_1: 0.2122 (0.2395)  loss_mal_dn_2: 0.4580 (0.4707)  loss_bbox_dn_2: 0.0846 (0.0958)  loss_giou_dn_2: 0.1873 (0.2019)  loss_fgl_dn_2: 1.0510 (1.0996)  loss_ddf_dn_2: 0.0563 (0.0654)  loss_mal_dn_3: 0.4226 (0.4381)  loss_bbox_dn_3: 0.0825 (0.0899)  loss_giou_dn_3: 0.1812 (0.1922)  loss_fgl_dn_3: 1.0461 (1.0891)  loss_ddf_dn_3: 0.0104 (0.0120)  loss_mal_dn_4: 0.4062 (0.4288)  loss_bbox_dn_4: 0.0792 (0.0881)  loss_giou_dn_4: 0.1778 (0.1891)  loss_fgl_dn_4: 1.0451 (1.0864)  loss_ddf_dn_4: 0.0010 (0.0011)  loss_mal_dn_5: 0.4014 (0.4265)  loss_bbox_dn_5: 0.0783 (0.0877)  loss_giou_dn_5: 0.1746 (0.1883)  loss_fgl_dn_5: 1.0448 (1.0857)  loss_mal_dn_pre: 0.7173 (0.7273)  loss_bbox_dn_pre: 0.1976 (0.2043)  loss_giou_dn_pre: 0.3688 (0.3957)  time: 1.1637  data: 0.0099  max mem: 13413\nEpoch: [50] Total time: 0:04:55 (1.1790 s / it)\nTest:  [ 0/25]  eta: 0:00:18    time: 0.7597  data: 0.4670  max mem: 13413\nTest:  [10/25]  eta: 0:00:05    time: 0.3966  data: 0.0608  max mem: 13413\nTest:  [20/25]  eta: 0:00:01    time: 0.3314  data: 0.0199  max mem: 13413\nTest:  [24/25]  eta: 0:00:00    time: 0.3197  data: 0.0192  max mem: 13413\nTest: Total time: 0:00:08 (0.3380 s / it)\nAveraged stats: \nAccumulating evaluation results...\nCOCOeval_opt.accumulate() finished...\nDONE (t=0.04s).\nIoU metric: bbox\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.334\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.539\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.343\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.409\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.359\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.462\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.577\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.683\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.633\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.676\n Average Recall     (AR) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.914\n Average Recall     (AR) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.780\nbest_stat: {'epoch': 48, 'coco_eval_bbox': 0.3404660263717498}\nEpoch: [51]  [  0/251]  eta: 0:07:55  lr: 0.000001  loss: 36.7844 (36.7844)  loss_mal: 0.5435 (0.5435)  loss_bbox: 0.1549 (0.1549)  loss_giou: 0.2284 (0.2284)  loss_fgl: 1.4256 (1.4256)  loss_mal_aux_0: 0.8501 (0.8501)  loss_bbox_aux_0: 0.1882 (0.1882)  loss_giou_aux_0: 0.2694 (0.2694)  loss_fgl_aux_0: 1.4677 (1.4677)  loss_ddf_aux_0: 0.2206 (0.2206)  loss_mal_aux_1: 0.7969 (0.7969)  loss_bbox_aux_1: 0.1511 (0.1511)  loss_giou_aux_1: 0.2232 (0.2232)  loss_fgl_aux_1: 1.4237 (1.4237)  loss_ddf_aux_1: 0.0570 (0.0570)  loss_mal_aux_2: 0.8721 (0.8721)  loss_bbox_aux_2: 0.1542 (0.1542)  loss_giou_aux_2: 0.2227 (0.2227)  loss_fgl_aux_2: 1.4287 (1.4287)  loss_ddf_aux_2: 0.0098 (0.0098)  loss_mal_aux_3: 0.6851 (0.6851)  loss_bbox_aux_3: 0.1541 (0.1541)  loss_giou_aux_3: 0.2266 (0.2266)  loss_fgl_aux_3: 1.4273 (1.4273)  loss_ddf_aux_3: 0.0018 (0.0018)  loss_mal_aux_4: 0.5649 (0.5649)  loss_bbox_aux_4: 0.1545 (0.1545)  loss_giou_aux_4: 0.2277 (0.2277)  loss_fgl_aux_4: 1.4247 (1.4247)  loss_ddf_aux_4: 0.0003 (0.0003)  loss_mal_pre: 0.8516 (0.8516)  loss_bbox_pre: 0.1879 (0.1879)  loss_giou_pre: 0.2681 (0.2681)  loss_mal_enc_0: 1.0908 (1.0908)  loss_bbox_enc_0: 0.2547 (0.2547)  loss_giou_enc_0: 0.3890 (0.3890)  loss_mal_dn_0: 0.7788 (0.7788)  loss_bbox_dn_0: 0.4292 (0.4292)  loss_giou_dn_0: 0.5074 (0.5074)  loss_fgl_dn_0: 1.4375 (1.4375)  loss_ddf_dn_0: 1.0110 (1.0110)  loss_mal_dn_1: 0.6328 (0.6328)  loss_bbox_dn_1: 0.2502 (0.2502)  loss_giou_dn_1: 0.3159 (0.3159)  loss_fgl_dn_1: 1.3667 (1.3667)  loss_ddf_dn_1: 0.2472 (0.2472)  loss_mal_dn_2: 0.5576 (0.5576)  loss_bbox_dn_2: 0.1910 (0.1910)  loss_giou_dn_2: 0.2689 (0.2689)  loss_fgl_dn_2: 1.3760 (1.3760)  loss_ddf_dn_2: 0.0647 (0.0647)  loss_mal_dn_3: 0.5391 (0.5391)  loss_bbox_dn_3: 0.1670 (0.1670)  loss_giou_dn_3: 0.2557 (0.2557)  loss_fgl_dn_3: 1.3794 (1.3794)  loss_ddf_dn_3: 0.0124 (0.0124)  loss_mal_dn_4: 0.5264 (0.5264)  loss_bbox_dn_4: 0.1626 (0.1626)  loss_giou_dn_4: 0.2526 (0.2526)  loss_fgl_dn_4: 1.3811 (1.3811)  loss_ddf_dn_4: 0.0013 (0.0013)  loss_mal_dn_5: 0.5371 (0.5371)  loss_bbox_dn_5: 0.1612 (0.1612)  loss_giou_dn_5: 0.2509 (0.2509)  loss_fgl_dn_5: 1.3850 (1.3850)  loss_mal_dn_pre: 0.7769 (0.7769)  loss_bbox_dn_pre: 0.4491 (0.4491)  loss_giou_dn_pre: 0.5152 (0.5152)  time: 1.8952  data: 0.6113  max mem: 13413\nEpoch: [51]  [100/251]  eta: 0:02:57  lr: 0.000001  loss: 26.2347 (27.8512)  loss_mal: 0.3306 (0.4090)  loss_bbox: 0.0641 (0.0703)  loss_giou: 0.1427 (0.1588)  loss_fgl: 1.0233 (1.0719)  loss_mal_aux_0: 0.7324 (0.7807)  loss_bbox_aux_0: 0.1051 (0.1004)  loss_giou_aux_0: 0.1990 (0.2195)  loss_fgl_aux_0: 1.1835 (1.1972)  loss_ddf_aux_0: 0.1911 (0.1936)  loss_mal_aux_1: 0.5166 (0.5762)  loss_bbox_aux_1: 0.0683 (0.0769)  loss_giou_aux_1: 0.1560 (0.1712)  loss_fgl_aux_1: 1.0696 (1.1009)  loss_ddf_aux_1: 0.0480 (0.0495)  loss_mal_aux_2: 0.3635 (0.4595)  loss_bbox_aux_2: 0.0663 (0.0716)  loss_giou_aux_2: 0.1487 (0.1614)  loss_fgl_aux_2: 1.0303 (1.0770)  loss_ddf_aux_2: 0.0068 (0.0081)  loss_mal_aux_3: 0.3333 (0.4225)  loss_bbox_aux_3: 0.0638 (0.0705)  loss_giou_aux_3: 0.1447 (0.1595)  loss_fgl_aux_3: 1.0233 (1.0733)  loss_ddf_aux_3: 0.0013 (0.0014)  loss_mal_aux_4: 0.3315 (0.4113)  loss_bbox_aux_4: 0.0642 (0.0703)  loss_giou_aux_4: 0.1443 (0.1590)  loss_fgl_aux_4: 1.0239 (1.0722)  loss_ddf_aux_4: 0.0001 (0.0002)  loss_mal_pre: 0.7319 (0.7814)  loss_bbox_pre: 0.1039 (0.1001)  loss_giou_pre: 0.1990 (0.2193)  loss_mal_enc_0: 0.9941 (1.0014)  loss_bbox_enc_0: 0.1494 (0.1681)  loss_giou_enc_0: 0.3275 (0.3524)  loss_mal_dn_0: 0.6992 (0.7101)  loss_bbox_dn_0: 0.1857 (0.1895)  loss_giou_dn_0: 0.3600 (0.3732)  loss_fgl_dn_0: 1.3086 (1.3122)  loss_ddf_dn_0: 0.8068 (0.8707)  loss_mal_dn_1: 0.5190 (0.5334)  loss_bbox_dn_1: 0.0894 (0.1030)  loss_giou_dn_1: 0.1928 (0.2121)  loss_fgl_dn_1: 1.0948 (1.1160)  loss_ddf_dn_1: 0.1962 (0.2112)  loss_mal_dn_2: 0.4038 (0.4368)  loss_bbox_dn_2: 0.0729 (0.0833)  loss_giou_dn_2: 0.1531 (0.1781)  loss_fgl_dn_2: 1.0400 (1.0673)  loss_ddf_dn_2: 0.0514 (0.0550)  loss_mal_dn_3: 0.3643 (0.4049)  loss_bbox_dn_3: 0.0696 (0.0778)  loss_giou_dn_3: 0.1423 (0.1689)  loss_fgl_dn_3: 1.0272 (1.0584)  loss_ddf_dn_3: 0.0094 (0.0099)  loss_mal_dn_4: 0.3591 (0.3970)  loss_bbox_dn_4: 0.0661 (0.0762)  loss_giou_dn_4: 0.1445 (0.1662)  loss_fgl_dn_4: 1.0221 (1.0563)  loss_ddf_dn_4: 0.0008 (0.0009)  loss_mal_dn_5: 0.3586 (0.3951)  loss_bbox_dn_5: 0.0655 (0.0758)  loss_giou_dn_5: 0.1446 (0.1655)  loss_fgl_dn_5: 1.0213 (1.0558)  loss_mal_dn_pre: 0.7007 (0.7106)  loss_bbox_dn_pre: 0.1900 (0.1915)  loss_giou_dn_pre: 0.3524 (0.3724)  time: 1.1718  data: 0.0100  max mem: 13413\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}